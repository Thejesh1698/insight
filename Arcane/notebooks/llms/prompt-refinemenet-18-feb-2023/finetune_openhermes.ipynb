{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d96b537-8f2e-46b1-a05c-8258729fdcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_folder = '/Users/username/Desktop/ML/Recommendations/arcane/'\n",
    "from hydra import compose, initialize\n",
    "import os\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('../../../conf/application.run.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "envs_element = root.find('./configuration/envs')\n",
    "for variable in envs_element.findall('env'):\n",
    "    name = variable.get('name')\n",
    "    value = variable.get('value')\n",
    "    os.environ[name] = value\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/username/Desktop/ML/Recommendations/arcane/')\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['PATH'] = '/Users/username/anaconda3/envs/bertopicenv/bin:/Users/username/anaconda3/condabin:/usr/bin:/bin:/usr/sbin:/sbin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175b96dc-2e0b-43cc-9c52-7e668956e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from src.llm_finetuning.FinetuneLLM import FinetuneLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce2c04ec-a153-4270-a1cf-9717aec7304e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/username/Desktop/ML/Recommendations/arcane/notebooks/llms/prompt-refinemenet-18-feb-2023\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7720fd69-98ee-4b24-83f7-52e919456095",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name username to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-teknium-OpenHermes-2--2024-02-19-00-25-15-965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-19 00:25:17 Starting - Starting the training job...\n",
      "2024-02-19 00:25:31 Starting - Preparing the instances for training......\n",
      "2024-02-19 00:26:42 Downloading - Downloading input data...\n",
      "2024-02-19 00:27:11 Downloading - Downloading the training image.....................\n",
      "2024-02-19 00:30:37 Training - Training image download completed. Training in progress....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:15,072 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:15,090 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:15,099 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:15,101 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:16,404 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.35.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.5/123.5 kB 9.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.5.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting optimum==1.14.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl.metadata (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.23.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.3 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (0.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (1.24.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2023.12.25)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting coloredlogs (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 9.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (2.16.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes->-r requirements.txt (line 5)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (2023.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.14.0->-r requirements.txt (line 3)) (0.1.99)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.14.0->-r requirements.txt (line 3)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 18.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (14.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (3.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (23.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 92.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 17.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl (398 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 398.9/398.9 kB 57.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.1/258.1 kB 40.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 MB 28.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 89.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 116.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: safetensors, humanfriendly, coloredlogs, bitsandbytes, tokenizers, accelerate, transformers, peft, optimum\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.23.0 bitsandbytes-0.42.0 coloredlogs-15.0.1 humanfriendly-10.0 optimum-1.14.0 peft-0.5.0 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.35.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:28,944 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:28,944 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:28,982 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:29,010 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:29,037 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:29,047 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"gradient_accumulation_steps\": 1,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"learning_rate\": \"2e-4\",\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"cosine_with_restarts\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"merge_adapters\": false,\n",
      "        \"model_id\": \"teknium/OpenHermes-2.5-Mistral-7B\",\n",
      "        \"num_train_epochs\": 2,\n",
      "        \"output_dir\": \"/tmp/run\",\n",
      "        \"per_device_train_batch_size\": 3,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"use_flash_attn\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-teknium-OpenHermes-2--2024-02-19-00-25-15-965\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-02-19-00-25-15-965/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_qlora\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_qlora.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":1,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":\"2e-4\",\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":false,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":3,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_qlora.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_qlora\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-02-19-00-25-15-965/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":1,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":\"2e-4\",\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":false,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":3,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-teknium-OpenHermes-2--2024-02-19-00-25-15-965\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-02-19-00-25-15-965/source/sourcedir.tar.gz\",\"module_name\":\"run_qlora\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_qlora.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training\",\"--gradient_accumulation_steps\",\"1\",\"--gradient_checkpointing\",\"True\",\"--hf_token\",\"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\",\"--learning_rate\",\"2e-4\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"cosine_with_restarts\",\"--max_grad_norm\",\"0.3\",\"--merge_adapters\",\"False\",\"--model_id\",\"teknium/OpenHermes-2.5-Mistral-7B\",\"--num_train_epochs\",\"2\",\"--output_dir\",\"/tmp/run\",\"--per_device_train_batch_size\",\"3\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--use_flash_attn\",\"True\",\"--warmup_ratio\",\"0.03\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=1\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=2e-4\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=cosine_with_restarts\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=false\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=teknium/OpenHermes-2.5-Mistral-7B\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=2\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/run\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=3\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FLASH_ATTN=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 1 --gradient_checkpointing True --hf_token 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 --learning_rate 2e-4 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters False --model_id teknium/OpenHermes-2.5-Mistral-7B --num_train_epochs 2 --output_dir /tmp/run --per_device_train_batch_size 3 --save_strategy epoch --tf32 True --use_flash_attn True --warmup_ratio 0.03\u001b[0m\n",
      "\u001b[34m2024-02-19 00:31:29,076 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mCollecting flash-attn==2.4.2\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.4.2.tar.gz (2.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 3.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn==2.4.2) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn==2.4.2) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.4.2-cp310-cp310-linux_x86_64.whl size=113930372 sha256=2c7ddc942e0715ef4a7ab62e3404b519a7ac040b3b6eae8fedcdc08a36ced786\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/9d/cf/7f/d14555553b5b30698dae0a4159fdd058157e7021cec565ecaa\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mSuccessfully installed flash-attn-2.4.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mLogging into the Hugging Face Hub with token hf_NjVkEqg...\u001b[0m\n",
      "\u001b[34mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\u001b[0m\n",
      "\u001b[34mToken is valid (permission: write).\u001b[0m\n",
      "\u001b[34mYour token has been saved to /root/.cache/huggingface/token\u001b[0m\n",
      "\u001b[34mLogin successful\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/624 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 624/624 [00:00<00:00, 5.59MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 130MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 41.9M/9.94G [00:00<00:23, 416MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 94.4M/9.94G [00:00<00:24, 399MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|▏         | 136M/9.94G [00:00<00:27, 358MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 189M/9.94G [00:00<00:24, 393MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 241M/9.94G [00:00<00:23, 415MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 294M/9.94G [00:00<00:22, 427MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 346M/9.94G [00:00<00:22, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▍         | 398M/9.94G [00:00<00:22, 433MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▍         | 451M/9.94G [00:01<00:22, 431MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▌         | 503M/9.94G [00:01<00:21, 432MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 556M/9.94G [00:01<00:21, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 608M/9.94G [00:01<00:20, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 661M/9.94G [00:01<00:20, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 713M/9.94G [00:01<00:20, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 765M/9.94G [00:01<00:20, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 818M/9.94G [00:01<00:20, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 870M/9.94G [00:02<00:20, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 923M/9.94G [00:02<00:21, 418MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|▉         | 975M/9.94G [00:02<00:24, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|█         | 1.02G/9.94G [00:02<00:23, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█         | 1.07G/9.94G [00:02<00:22, 403MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█▏        | 1.12G/9.94G [00:02<00:21, 418MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.17G/9.94G [00:02<00:20, 430MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.23G/9.94G [00:02<00:19, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.28G/9.94G [00:03<00:19, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.33G/9.94G [00:03<00:19, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 1.38G/9.94G [00:03<00:19, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 1.44G/9.94G [00:03<00:18, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▍        | 1.49G/9.94G [00:03<00:18, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.54G/9.94G [00:03<00:18, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.59G/9.94G [00:03<00:18, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.65G/9.94G [00:03<00:18, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.70G/9.94G [00:03<00:17, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.75G/9.94G [00:04<00:17, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.80G/9.94G [00:04<00:17, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▊        | 1.86G/9.94G [00:04<00:17, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.91G/9.94G [00:04<00:17, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|█▉        | 1.96G/9.94G [00:04<00:17, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|██        | 2.01G/9.94G [00:04<00:19, 411MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.07G/9.94G [00:04<00:18, 419MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██▏       | 2.12G/9.94G [00:04<00:18, 419MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.17G/9.94G [00:05<00:18, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.22G/9.94G [00:05<00:18, 426MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.28G/9.94G [00:05<00:18, 407MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.33G/9.94G [00:05<00:18, 416MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▍       | 2.38G/9.94G [00:05<00:17, 427MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▍       | 2.43G/9.94G [00:05<00:17, 434MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▍       | 2.49G/9.94G [00:05<00:16, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.54G/9.94G [00:05<00:17, 415MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.59G/9.94G [00:06<00:17, 422MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.64G/9.94G [00:06<00:17, 426MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.69G/9.94G [00:06<00:16, 430MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.75G/9.94G [00:06<00:16, 429MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.80G/9.94G [00:06<00:17, 410MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▊       | 2.84G/9.94G [00:06<00:17, 397MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.89G/9.94G [00:06<00:17, 414MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|██▉       | 2.95G/9.94G [00:06<00:16, 428MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|███       | 3.00G/9.94G [00:06<00:15, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 3.05G/9.94G [00:07<00:15, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 3.10G/9.94G [00:07<00:15, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.16G/9.94G [00:07<00:16, 410MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.20G/9.94G [00:07<00:17, 381MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.25G/9.94G [00:07<00:16, 401MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.30G/9.94G [00:07<00:15, 417MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▎      | 3.36G/9.94G [00:07<00:15, 427MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▍      | 3.41G/9.94G [00:07<00:15, 433MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▍      | 3.46G/9.94G [00:08<00:14, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▌      | 3.51G/9.94G [00:08<00:14, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.57G/9.94G [00:08<00:15, 413MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▋      | 3.62G/9.94G [00:08<00:15, 421MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.67G/9.94G [00:08<00:15, 400MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.72G/9.94G [00:08<00:14, 415MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.77G/9.94G [00:08<00:14, 426MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.83G/9.94G [00:08<00:13, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.88G/9.94G [00:09<00:13, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|███▉      | 3.93G/9.94G [00:09<00:13, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|████      | 3.98G/9.94G [00:09<00:13, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.04G/9.94G [00:09<00:13, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.09G/9.94G [00:09<00:13, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.14G/9.94G [00:09<00:12, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.19G/9.94G [00:09<00:12, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.25G/9.94G [00:09<00:14, 401MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.30G/9.94G [00:10<00:20, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▎     | 4.34G/9.94G [00:10<00:18, 304MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▍     | 4.38G/9.94G [00:10<00:17, 315MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▍     | 4.44G/9.94G [00:10<00:15, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▌     | 4.49G/9.94G [00:10<00:14, 378MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.54G/9.94G [00:10<00:13, 401MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.59G/9.94G [00:10<00:12, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.65G/9.94G [00:11<00:12, 431MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.70G/9.94G [00:11<00:11, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.75G/9.94G [00:11<00:11, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.80G/9.94G [00:11<00:11, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▉     | 4.85G/9.94G [00:11<00:11, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▉     | 4.91G/9.94G [00:11<00:11, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|████▉     | 4.96G/9.94G [00:11<00:11, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|█████     | 5.01G/9.94G [00:11<00:10, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.06G/9.94G [00:11<00:10, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████▏    | 5.12G/9.94G [00:12<00:10, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.17G/9.94G [00:12<00:10, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.22G/9.94G [00:12<00:10, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.27G/9.94G [00:12<00:10, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▎    | 5.33G/9.94G [00:12<00:10, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▍    | 5.38G/9.94G [00:12<00:10, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▍    | 5.43G/9.94G [00:12<00:09, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▌    | 5.48G/9.94G [00:12<00:09, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.54G/9.94G [00:12<00:09, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.59G/9.94G [00:13<00:09, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.64G/9.94G [00:13<00:09, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.69G/9.94G [00:13<00:09, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.75G/9.94G [00:13<00:09, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.80G/9.94G [00:13<00:09, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.85G/9.94G [00:13<00:11, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.89G/9.94G [00:13<00:10, 372MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|█████▉    | 5.95G/9.94G [00:14<00:10, 390MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|██████    | 6.00G/9.94G [00:14<00:09, 400MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.05G/9.94G [00:14<00:09, 415MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████▏   | 6.10G/9.94G [00:14<00:09, 422MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.16G/9.94G [00:14<00:08, 430MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.21G/9.94G [00:14<00:08, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.26G/9.94G [00:14<00:08, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.31G/9.94G [00:14<00:08, 407MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.35G/9.94G [00:15<00:11, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.40G/9.94G [00:15<00:12, 277MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.43G/9.94G [00:15<00:13, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.46G/9.94G [00:15<00:14, 244MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.49G/9.94G [00:15<00:14, 235MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.52G/9.94G [00:15<00:15, 222MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.55G/9.94G [00:16<00:15, 218MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.59G/9.94G [00:16<00:15, 214MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.62G/9.94G [00:16<00:15, 212MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.65G/9.94G [00:16<00:15, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.68G/9.94G [00:16<00:15, 210MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.71G/9.94G [00:16<00:15, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.74G/9.94G [00:16<00:15, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.76G/9.94G [00:17<00:15, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.79G/9.94G [00:17<00:15, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▊   | 6.83G/9.94G [00:17<00:15, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.86G/9.94G [00:17<00:14, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.89G/9.94G [00:17<00:14, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|██████▉   | 6.92G/9.94G [00:17<00:14, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|██████▉   | 6.95G/9.94G [00:17<00:14, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 6.98G/9.94G [00:18<00:14, 206MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.01G/9.94G [00:18<00:14, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.05G/9.94G [00:18<00:14, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.07G/9.94G [00:18<00:14, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████▏  | 7.10G/9.94G [00:18<00:13, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.13G/9.94G [00:18<00:13, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.16G/9.94G [00:19<00:13, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.19G/9.94G [00:19<00:13, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.22G/9.94G [00:19<00:13, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.26G/9.94G [00:19<00:12, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.29G/9.94G [00:19<00:12, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▎  | 7.31G/9.94G [00:19<00:12, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.34G/9.94G [00:19<00:12, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.36G/9.94G [00:19<00:12, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.38G/9.94G [00:20<00:12, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▍  | 7.41G/9.94G [00:20<00:17, 141MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▌  | 7.47G/9.94G [00:20<00:12, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.51G/9.94G [00:20<00:10, 231MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.54G/9.94G [00:20<00:10, 224MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.57G/9.94G [00:20<00:10, 226MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▋  | 7.60G/9.94G [00:21<00:10, 215MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.63G/9.94G [00:21<00:10, 214MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.67G/9.94G [00:21<00:10, 212MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.70G/9.94G [00:21<00:10, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.73G/9.94G [00:21<00:10, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.76G/9.94G [00:21<00:10, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.78G/9.94G [00:22<00:10, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.80G/9.94G [00:22<00:10, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▊  | 7.82G/9.94G [00:22<00:10, 196MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.84G/9.94G [00:22<00:11, 187MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.86G/9.94G [00:22<00:10, 193MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.89G/9.94G [00:22<00:10, 192MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.91G/9.94G [00:22<00:11, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.93G/9.94G [00:22<00:10, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.95G/9.94G [00:22<00:10, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 7.97G/9.94G [00:23<00:10, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 7.99G/9.94G [00:23<00:10, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.01G/9.94G [00:23<00:10, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.04G/9.94G [00:23<00:09, 196MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.06G/9.94G [00:23<00:10, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████▏ | 8.08G/9.94G [00:23<00:10, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.11G/9.94G [00:23<00:09, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.13G/9.94G [00:23<00:09, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.15G/9.94G [00:23<00:09, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.17G/9.94G [00:24<00:09, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.19G/9.94G [00:24<00:09, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.21G/9.94G [00:24<00:09, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.23G/9.94G [00:24<00:09, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.25G/9.94G [00:24<00:09, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.27G/9.94G [00:24<00:09, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.29G/9.94G [00:24<00:09, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▎ | 8.32G/9.94G [00:24<00:09, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.34G/9.94G [00:25<00:08, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.36G/9.94G [00:25<00:09, 173MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.38G/9.94G [00:25<00:08, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.40G/9.94G [00:25<00:08, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.42G/9.94G [00:25<00:09, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.44G/9.94G [00:25<00:08, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.46G/9.94G [00:25<00:08, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.48G/9.94G [00:25<00:08, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.50G/9.94G [00:25<00:07, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.52G/9.94G [00:26<00:08, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.55G/9.94G [00:26<00:07, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.57G/9.94G [00:26<00:07, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▋ | 8.59G/9.94G [00:26<00:07, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.61G/9.94G [00:26<00:07, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.63G/9.94G [00:26<00:07, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.65G/9.94G [00:26<00:07, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.67G/9.94G [00:26<00:06, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.69G/9.94G [00:27<00:07, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.71G/9.94G [00:27<00:07, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.73G/9.94G [00:27<00:06, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.76G/9.94G [00:27<00:06, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.78G/9.94G [00:27<00:06, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.80G/9.94G [00:27<00:06, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▊ | 8.82G/9.94G [00:27<00:06, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.84G/9.94G [00:27<00:06, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.86G/9.94G [00:28<00:06, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.88G/9.94G [00:28<00:06, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.90G/9.94G [00:28<00:06, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.92G/9.94G [00:28<00:05, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.94G/9.94G [00:28<00:05, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 8.97G/9.94G [00:28<00:06, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 9.00G/9.94G [00:28<00:05, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.02G/9.94G [00:28<00:05, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.04G/9.94G [00:29<00:05, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.06G/9.94G [00:29<00:04, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████▏| 9.08G/9.94G [00:29<00:05, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.10G/9.94G [00:29<00:04, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.12G/9.94G [00:29<00:04, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.14G/9.94G [00:29<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.16G/9.94G [00:29<00:04, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.19G/9.94G [00:29<00:04, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.21G/9.94G [00:30<00:04, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.23G/9.94G [00:30<00:04, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.25G/9.94G [00:30<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.27G/9.94G [00:30<00:06, 111MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▎| 9.31G/9.94G [00:30<00:03, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.34G/9.94G [00:30<00:03, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.37G/9.94G [00:31<00:02, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.41G/9.94G [00:31<00:02, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.44G/9.94G [00:31<00:02, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.46G/9.94G [00:31<00:02, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.48G/9.94G [00:31<00:02, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.50G/9.94G [00:31<00:02, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.52G/9.94G [00:31<00:02, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.54G/9.94G [00:32<00:02, 159MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▋| 9.57G/9.94G [00:32<00:02, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▋| 9.59G/9.94G [00:32<00:02, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.62G/9.94G [00:32<00:02, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.64G/9.94G [00:32<00:01, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.66G/9.94G [00:32<00:01, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.68G/9.94G [00:32<00:01, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.70G/9.94G [00:33<00:01, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.72G/9.94G [00:33<00:01, 158MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.74G/9.94G [00:33<00:01, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.76G/9.94G [00:33<00:01, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.78G/9.94G [00:33<00:00, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▊| 9.80G/9.94G [00:33<00:00, 153MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.84G/9.94G [00:33<00:00, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.86G/9.94G [00:33<00:00, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.88G/9.94G [00:34<00:00, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.90G/9.94G [00:34<00:00, 175MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.92G/9.94G [00:34<00:00, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.94G/9.94G [00:34<00:00, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|██████████| 9.94G/9.94G [00:34<00:00, 288MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 1/2 [00:34<00:34, 34.95s/it]\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   1%|          | 52.4M/4.54G [00:00<00:10, 422MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   2%|▏         | 105M/4.54G [00:00<00:13, 327MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   3%|▎         | 157M/4.54G [00:00<00:11, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   5%|▍         | 210M/4.54G [00:00<00:10, 395MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   6%|▌         | 252M/4.54G [00:00<00:12, 333MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   6%|▋         | 294M/4.54G [00:00<00:16, 257MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   7%|▋         | 325M/4.54G [00:01<00:18, 231MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   8%|▊         | 357M/4.54G [00:01<00:20, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▊         | 388M/4.54G [00:01<00:21, 195MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▉         | 409M/4.54G [00:01<00:21, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▉         | 430M/4.54G [00:01<00:21, 187MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|▉         | 451M/4.54G [00:01<00:23, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|█         | 472M/4.54G [00:02<00:23, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  11%|█         | 493M/4.54G [00:02<00:23, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  11%|█▏        | 514M/4.54G [00:02<00:23, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 535M/4.54G [00:02<00:22, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 556M/4.54G [00:02<00:22, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  13%|█▎        | 577M/4.54G [00:02<00:23, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  13%|█▎        | 598M/4.54G [00:02<00:22, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  14%|█▎        | 619M/4.54G [00:02<00:23, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  14%|█▍        | 640M/4.54G [00:03<00:23, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▍        | 661M/4.54G [00:03<00:22, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▌        | 682M/4.54G [00:03<00:22, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▌        | 703M/4.54G [00:03<00:22, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▌        | 724M/4.54G [00:03<00:22, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▋        | 744M/4.54G [00:03<00:22, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 765M/4.54G [00:03<00:22, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 786M/4.54G [00:03<00:22, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 807M/4.54G [00:03<00:21, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 828M/4.54G [00:04<00:21, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  19%|█▊        | 849M/4.54G [00:04<00:21, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  19%|█▉        | 870M/4.54G [00:04<00:21, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  20%|█▉        | 891M/4.54G [00:04<00:20, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  20%|██        | 912M/4.54G [00:04<00:22, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██        | 933M/4.54G [00:04<00:20, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██        | 954M/4.54G [00:04<00:21, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██▏       | 975M/4.54G [00:04<00:20, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  22%|██▏       | 996M/4.54G [00:05<00:21, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  22%|██▏       | 1.02G/4.54G [00:05<00:21, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  23%|██▎       | 1.04G/4.54G [00:05<00:20, 175MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  23%|██▎       | 1.06G/4.54G [00:05<00:19, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 1.08G/4.54G [00:05<00:20, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 1.10G/4.54G [00:05<00:30, 114MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  25%|██▌       | 1.14G/4.54G [00:06<00:19, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  26%|██▌       | 1.17G/4.54G [00:06<00:17, 198MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  27%|██▋       | 1.21G/4.54G [00:06<00:18, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  27%|██▋       | 1.24G/4.54G [00:06<00:18, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  28%|██▊       | 1.26G/4.54G [00:06<00:18, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  28%|██▊       | 1.28G/4.54G [00:06<00:18, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  29%|██▊       | 1.30G/4.54G [00:06<00:18, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  29%|██▉       | 1.32G/4.54G [00:06<00:18, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|██▉       | 1.34G/4.54G [00:07<00:18, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|███       | 1.36G/4.54G [00:07<00:19, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|███       | 1.38G/4.54G [00:07<00:18, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  31%|███       | 1.41G/4.54G [00:07<00:18, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  31%|███▏      | 1.43G/4.54G [00:07<00:17, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  32%|███▏      | 1.45G/4.54G [00:07<00:17, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  32%|███▏      | 1.47G/4.54G [00:07<00:17, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  33%|███▎      | 1.49G/4.54G [00:07<00:17, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  33%|███▎      | 1.51G/4.54G [00:08<00:17, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  34%|███▎      | 1.53G/4.54G [00:08<00:17, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  34%|███▍      | 1.55G/4.54G [00:08<00:17, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  35%|███▍      | 1.57G/4.54G [00:08<00:17, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  35%|███▌      | 1.59G/4.54G [00:08<00:17, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▌      | 1.61G/4.54G [00:08<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▌      | 1.64G/4.54G [00:08<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▋      | 1.66G/4.54G [00:08<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 1.68G/4.54G [00:09<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 1.70G/4.54G [00:09<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  38%|███▊      | 1.72G/4.54G [00:09<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  38%|███▊      | 1.74G/4.54G [00:09<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.76G/4.54G [00:09<00:16, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.78G/4.54G [00:09<00:16, 166MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  40%|███▉      | 1.80G/4.54G [00:09<00:15, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  40%|████      | 1.82G/4.54G [00:09<00:15, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  41%|████      | 1.85G/4.54G [00:10<00:15, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  41%|████      | 1.87G/4.54G [00:10<00:15, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.89G/4.54G [00:10<00:15, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.91G/4.54G [00:10<00:15, 173MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.93G/4.54G [00:10<00:15, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  43%|████▎     | 1.95G/4.54G [00:10<00:14, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  43%|████▎     | 1.97G/4.54G [00:10<00:14, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  44%|████▍     | 1.99G/4.54G [00:10<00:14, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  44%|████▍     | 2.01G/4.54G [00:10<00:14, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▍     | 2.03G/4.54G [00:11<00:14, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▌     | 2.06G/4.54G [00:11<00:14, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▌     | 2.08G/4.54G [00:11<00:14, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▌     | 2.10G/4.54G [00:11<00:14, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 2.12G/4.54G [00:11<00:14, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 2.14G/4.54G [00:11<00:14, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.16G/4.54G [00:11<00:13, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.18G/4.54G [00:11<00:13, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.20G/4.54G [00:12<00:13, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 2.22G/4.54G [00:12<00:13, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 2.24G/4.54G [00:12<00:13, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|████▉     | 2.26G/4.54G [00:12<00:13, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|█████     | 2.29G/4.54G [00:12<00:12, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████     | 2.31G/4.54G [00:12<00:12, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████▏    | 2.33G/4.54G [00:12<00:12, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 2.35G/4.54G [00:12<00:12, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 2.37G/4.54G [00:13<00:12, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  53%|█████▎    | 2.39G/4.54G [00:13<00:12, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  53%|█████▎    | 2.41G/4.54G [00:13<00:12, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  54%|█████▎    | 2.43G/4.54G [00:13<00:11, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  54%|█████▍    | 2.45G/4.54G [00:13<00:12, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▍    | 2.47G/4.54G [00:13<00:12, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▍    | 2.50G/4.54G [00:13<00:11, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▌    | 2.52G/4.54G [00:13<00:11, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  56%|█████▌    | 2.54G/4.54G [00:14<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  56%|█████▋    | 2.56G/4.54G [00:14<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 2.58G/4.54G [00:14<00:11, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 2.60G/4.54G [00:14<00:11, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.62G/4.54G [00:14<00:11, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.64G/4.54G [00:14<00:11, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  59%|█████▊    | 2.66G/4.54G [00:14<00:10, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  59%|█████▉    | 2.68G/4.54G [00:14<00:10, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  60%|█████▉    | 2.71G/4.54G [00:14<00:10, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  60%|██████    | 2.73G/4.54G [00:15<00:10, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.75G/4.54G [00:15<00:10, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.77G/4.54G [00:15<00:10, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████▏   | 2.79G/4.54G [00:15<00:10, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.81G/4.54G [00:15<00:10, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.83G/4.54G [00:15<00:09, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.85G/4.54G [00:15<00:09, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.87G/4.54G [00:16<00:14, 118MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▍   | 2.92G/4.54G [00:16<00:09, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▍   | 2.95G/4.54G [00:16<00:08, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  66%|██████▌   | 2.98G/4.54G [00:16<00:08, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  66%|██████▌   | 3.00G/4.54G [00:16<00:08, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.02G/4.54G [00:16<00:08, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.04G/4.54G [00:16<00:08, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.06G/4.54G [00:17<00:08, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 3.08G/4.54G [00:17<00:08, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 3.10G/4.54G [00:17<00:08, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  69%|██████▉   | 3.12G/4.54G [00:17<00:08, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  69%|██████▉   | 3.15G/4.54G [00:17<00:08, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  70%|██████▉   | 3.17G/4.54G [00:17<00:07, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  70%|███████   | 3.19G/4.54G [00:17<00:07, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████   | 3.21G/4.54G [00:17<00:07, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████   | 3.23G/4.54G [00:18<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 3.25G/4.54G [00:18<00:07, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 3.27G/4.54G [00:18<00:07, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.29G/4.54G [00:18<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.31G/4.54G [00:18<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.33G/4.54G [00:18<00:06, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▍  | 3.36G/4.54G [00:18<00:06, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▍  | 3.38G/4.54G [00:18<00:06, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▍  | 3.40G/4.54G [00:18<00:06, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▌  | 3.42G/4.54G [00:19<00:06, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.44G/4.54G [00:19<00:06, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.46G/4.54G [00:19<00:06, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.48G/4.54G [00:19<00:06, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.50G/4.54G [00:19<00:06, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.52G/4.54G [00:19<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.54G/4.54G [00:19<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▊  | 3.57G/4.54G [00:19<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▉  | 3.59G/4.54G [00:20<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▉  | 3.61G/4.54G [00:20<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|███████▉  | 3.63G/4.54G [00:20<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|████████  | 3.65G/4.54G [00:20<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████  | 3.67G/4.54G [00:20<00:04, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████▏ | 3.69G/4.54G [00:20<00:05, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.71G/4.54G [00:20<00:04, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.73G/4.54G [00:20<00:04, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.75G/4.54G [00:21<00:04, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.77G/4.54G [00:21<00:04, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▎ | 3.80G/4.54G [00:21<00:04, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▍ | 3.82G/4.54G [00:21<00:04, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▍ | 3.84G/4.54G [00:21<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▍ | 3.86G/4.54G [00:21<00:03, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▌ | 3.88G/4.54G [00:21<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.90G/4.54G [00:21<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▋ | 3.92G/4.54G [00:22<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.94G/4.54G [00:22<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.96G/4.54G [00:22<00:03, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 3.98G/4.54G [00:22<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 4.01G/4.54G [00:22<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▊ | 4.03G/4.54G [00:22<00:02, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 4.05G/4.54G [00:22<00:02, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|████████▉ | 4.07G/4.54G [00:22<00:02, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|█████████ | 4.09G/4.54G [00:22<00:02, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.11G/4.54G [00:23<00:02, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.13G/4.54G [00:23<00:02, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████▏| 4.15G/4.54G [00:23<00:02, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.17G/4.54G [00:23<00:02, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.19G/4.54G [00:23<00:01, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.22G/4.54G [00:23<00:01, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.24G/4.54G [00:23<00:01, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.26G/4.54G [00:23<00:01, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.28G/4.54G [00:24<00:01, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▍| 4.30G/4.54G [00:24<00:01, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▌| 4.32G/4.54G [00:24<00:01, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 4.34G/4.54G [00:24<00:01, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 4.36G/4.54G [00:24<00:01, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.38G/4.54G [00:24<00:00, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.40G/4.54G [00:24<00:00, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.42G/4.54G [00:24<00:00, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.45G/4.54G [00:25<00:00, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.47G/4.54G [00:25<00:00, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▉| 4.49G/4.54G [00:25<00:00, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▉| 4.51G/4.54G [00:25<00:00, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|█████████▉| 4.53G/4.54G [00:25<00:00, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|██████████| 4.54G/4.54G [00:25<00:00, 177MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [01:01<00:00, 29.76s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [01:01<00:00, 30.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.62s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  7.30s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.55s/it]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 120/120 [00:00<00:00, 991kB/s]\u001b[0m\n",
      "\u001b[34mFound 7 modules to quantize: ['gate_proj', 'o_proj', 'v_proj', 'up_proj', 'q_proj', 'k_proj', 'down_proj']\u001b[0m\n",
      "\u001b[34mtrainable params: 167,772,160 || all params: 7,409,520,640 || trainable%: 2.2642781922259414\u001b[0m\n",
      "\u001b[34m0%|          | 0/488 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34m0%|          | 1/488 [00:18<2:28:19, 18.27s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/488 [00:36<2:26:23, 18.07s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 3/488 [00:54<2:25:37, 18.01s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 4/488 [01:12<2:25:05, 17.99s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 5/488 [01:30<2:24:39, 17.97s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 6/488 [01:47<2:24:16, 17.96s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 7/488 [02:05<2:23:55, 17.95s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 8/488 [02:23<2:23:35, 17.95s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 9/488 [02:41<2:23:16, 17.95s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 10/488 [02:59<2:22:57, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2655, 'learning_rate': 0.00013333333333333334, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m2%|▏         | 10/488 [02:59<2:22:57, 17.94s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 11/488 [03:17<2:22:39, 17.94s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 12/488 [03:35<2:22:20, 17.94s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 13/488 [03:53<2:22:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 14/488 [04:11<2:21:44, 17.94s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 15/488 [04:29<2:21:26, 17.94s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 16/488 [04:47<2:21:08, 17.94s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 17/488 [05:05<2:20:50, 17.94s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 18/488 [05:23<2:20:32, 17.94s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 19/488 [05:41<2:20:14, 17.94s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 20/488 [05:59<2:19:56, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8052, 'learning_rate': 0.00019994486243751075, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34m4%|▍         | 20/488 [05:59<2:19:56, 17.94s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 21/488 [06:17<2:19:38, 17.94s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 22/488 [06:35<2:19:20, 17.94s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 23/488 [06:52<2:19:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 24/488 [07:10<2:18:44, 17.94s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 25/488 [07:28<2:18:26, 17.94s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 26/488 [07:46<2:18:08, 17.94s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 27/488 [08:04<2:17:50, 17.94s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 28/488 [08:22<2:17:32, 17.94s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 29/488 [08:40<2:17:14, 17.94s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 30/488 [08:58<2:16:56, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7792, 'learning_rate': 0.00019950412668864187, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34m6%|▌         | 30/488 [08:58<2:16:56, 17.94s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 31/488 [09:16<2:16:38, 17.94s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 32/488 [09:34<2:16:20, 17.94s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 33/488 [09:52<2:16:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 34/488 [10:10<2:15:45, 17.94s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 35/488 [10:28<2:15:27, 17.94s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 36/488 [10:46<2:15:09, 17.94s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 37/488 [11:04<2:14:51, 17.94s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 38/488 [11:22<2:14:33, 17.94s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 39/488 [11:40<2:14:15, 17.94s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 40/488 [11:57<2:13:57, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7924, 'learning_rate': 0.0001986245987425344, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34m8%|▊         | 40/488 [11:57<2:13:57, 17.94s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 41/488 [12:15<2:13:39, 17.94s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 42/488 [12:33<2:13:21, 17.94s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 43/488 [12:51<2:13:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 44/488 [13:09<2:12:45, 17.94s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 45/488 [13:27<2:12:27, 17.94s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 46/488 [13:45<2:12:09, 17.94s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 47/488 [14:03<2:11:51, 17.94s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 48/488 [14:21<2:11:33, 17.94s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 49/488 [14:39<2:11:15, 17.94s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 50/488 [14:57<2:10:57, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7766, 'learning_rate': 0.00019731015713179645, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34m10%|█         | 50/488 [14:57<2:10:57, 17.94s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 51/488 [15:15<2:10:40, 17.94s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 52/488 [15:33<2:10:21, 17.94s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 53/488 [15:51<2:10:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 54/488 [16:09<2:09:46, 17.94s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 55/488 [16:27<2:09:28, 17.94s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 56/488 [16:45<2:09:10, 17.94s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 57/488 [17:02<2:08:52, 17.94s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 58/488 [17:20<2:08:34, 17.94s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 59/488 [17:38<2:08:16, 17.94s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 60/488 [17:56<2:07:58, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7143, 'learning_rate': 0.00019556659826650382, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 60/488 [17:56<2:07:58, 17.94s/it]\u001b[0m\n",
      "\u001b[34m12%|█▎        | 61/488 [18:14<2:07:40, 17.94s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 62/488 [18:32<2:07:22, 17.94s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 63/488 [18:50<2:07:04, 17.94s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 64/488 [19:08<2:06:46, 17.94s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 65/488 [19:26<2:06:28, 17.94s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 66/488 [19:44<2:06:10, 17.94s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 67/488 [20:02<2:05:52, 17.94s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 68/488 [20:20<2:05:34, 17.94s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 69/488 [20:38<2:05:16, 17.94s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 70/488 [20:56<2:04:59, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8219, 'learning_rate': 0.0001934016108732548, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 70/488 [20:56<2:04:59, 17.94s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 71/488 [21:14<2:04:41, 17.94s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 72/488 [21:32<2:04:23, 17.94s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 73/488 [21:49<2:04:05, 17.94s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 74/488 [22:07<2:03:47, 17.94s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 75/488 [22:25<2:03:29, 17.94s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 76/488 [22:43<2:03:11, 17.94s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 77/488 [23:01<2:02:53, 17.94s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 78/488 [23:19<2:02:35, 17.94s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 79/488 [23:37<2:02:17, 17.94s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 80/488 [23:55<2:01:59, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8079, 'learning_rate': 0.0001908247420895089, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34m16%|█▋        | 80/488 [23:55<2:01:59, 17.94s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 81/488 [24:13<2:01:41, 17.94s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 82/488 [24:31<2:01:23, 17.94s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 83/488 [24:49<2:01:05, 17.94s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 84/488 [25:07<2:00:48, 17.94s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 85/488 [25:25<2:00:30, 17.94s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 86/488 [25:43<2:00:12, 17.94s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 87/488 [26:01<1:59:54, 17.94s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 88/488 [26:19<1:59:36, 17.94s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 89/488 [26:37<1:59:18, 17.94s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 90/488 [26:54<1:59:00, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7736, 'learning_rate': 0.00018784735536272543, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 90/488 [26:54<1:59:00, 17.94s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 91/488 [27:12<1:58:42, 17.94s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 92/488 [27:30<1:58:24, 17.94s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 93/488 [27:48<1:58:06, 17.94s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 94/488 [28:06<1:57:48, 17.94s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 95/488 [28:24<1:57:30, 17.94s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 96/488 [28:42<1:57:12, 17.94s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 97/488 [29:00<1:56:54, 17.94s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 98/488 [29:18<1:56:36, 17.94s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 99/488 [29:36<1:56:18, 17.94s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 100/488 [29:54<1:56:00, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8104, 'learning_rate': 0.00018448258033995876, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34m20%|██        | 100/488 [29:54<1:56:00, 17.94s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 101/488 [30:12<1:55:43, 17.94s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 102/488 [30:30<1:55:24, 17.94s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 103/488 [30:48<1:55:07, 17.94s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 104/488 [31:06<1:54:49, 17.94s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 105/488 [31:24<1:54:31, 17.94s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 106/488 [31:42<1:54:13, 17.94s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 107/488 [31:59<1:53:55, 17.94s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 108/488 [32:17<1:53:37, 17.94s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 109/488 [32:35<1:53:19, 17.94s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 110/488 [32:53<1:53:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8188, 'learning_rate': 0.0001807452549688859, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 110/488 [32:53<1:53:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 111/488 [33:11<1:52:44, 17.94s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 112/488 [33:29<1:52:26, 17.94s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 113/488 [33:47<1:52:07, 17.94s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 114/488 [34:05<1:51:49, 17.94s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 115/488 [34:23<1:51:31, 17.94s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 116/488 [34:41<1:51:13, 17.94s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 117/488 [34:59<1:50:55, 17.94s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 118/488 [35:17<1:50:37, 17.94s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 119/488 [35:35<1:50:20, 17.94s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 120/488 [35:53<1:50:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8619, 'learning_rate': 0.000176651860065589, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34m25%|██▍       | 120/488 [35:53<1:50:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 121/488 [36:11<1:49:45, 17.94s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 122/488 [36:29<1:49:26, 17.94s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 123/488 [36:47<1:49:08, 17.94s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 124/488 [37:04<1:48:50, 17.94s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 125/488 [37:22<1:48:32, 17.94s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 126/488 [37:40<1:48:14, 17.94s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 127/488 [37:58<1:47:56, 17.94s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 128/488 [38:16<1:47:38, 17.94s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 129/488 [38:34<1:47:20, 17.94s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 130/488 [38:52<1:47:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7899, 'learning_rate': 0.00017222044663763484, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 130/488 [38:52<1:47:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 131/488 [39:10<1:46:45, 17.94s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 132/488 [39:28<1:46:27, 17.94s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 133/488 [39:46<1:46:09, 17.94s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 134/488 [40:04<1:45:51, 17.94s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 135/488 [40:22<1:45:33, 17.94s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 136/488 [40:40<1:45:15, 17.94s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 137/488 [40:58<1:44:57, 17.94s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 138/488 [41:16<1:44:39, 17.94s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 139/488 [41:34<1:44:21, 17.94s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 140/488 [41:52<1:44:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0255, 'learning_rate': 0.00016747055628294134, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m29%|██▊       | 140/488 [41:52<1:44:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 141/488 [42:09<1:43:45, 17.94s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 142/488 [42:27<1:43:27, 17.94s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 143/488 [42:45<1:43:09, 17.94s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 144/488 [43:03<1:42:51, 17.94s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 145/488 [43:21<1:42:33, 17.94s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 146/488 [43:39<1:42:15, 17.94s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 147/488 [43:57<1:41:57, 17.94s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 148/488 [44:15<1:41:39, 17.94s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 149/488 [44:33<1:41:21, 17.94s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 150/488 [44:51<1:41:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8049, 'learning_rate': 0.0001624231350154552, 'epoch': 0.61}\u001b[0m\n",
      "\u001b[34m31%|███       | 150/488 [44:51<1:41:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 151/488 [45:09<1:40:46, 17.94s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 152/488 [45:27<1:40:28, 17.94s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 153/488 [45:45<1:40:10, 17.94s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 154/488 [46:03<1:39:52, 17.94s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 155/488 [46:21<1:39:34, 17.94s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 156/488 [46:39<1:39:16, 17.94s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 157/488 [46:57<1:38:58, 17.94s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 158/488 [47:14<1:38:40, 17.94s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 159/488 [47:32<1:38:22, 17.94s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 160/488 [47:50<1:38:04, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7626, 'learning_rate': 0.00015710044089765145, 'epoch': 0.66}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 160/488 [47:50<1:38:04, 17.94s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 161/488 [48:08<1:37:46, 17.94s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 162/488 [48:26<1:37:28, 17.94s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 163/488 [48:44<1:37:10, 17.94s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 164/488 [49:02<1:36:52, 17.94s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 165/488 [49:20<1:36:34, 17.94s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 166/488 [49:38<1:36:16, 17.94s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 167/488 [49:56<1:35:58, 17.94s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 168/488 [50:14<1:35:40, 17.94s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 169/488 [50:32<1:35:22, 17.94s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 170/488 [50:50<1:35:04, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8448, 'learning_rate': 0.00015152594588717543, 'epoch': 0.7}\u001b[0m\n",
      "\u001b[34m35%|███▍      | 170/488 [50:50<1:35:04, 17.94s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 171/488 [51:08<1:34:47, 17.94s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 172/488 [51:26<1:34:29, 17.94s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 173/488 [51:44<1:34:11, 17.94s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 174/488 [52:02<1:33:53, 17.94s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 175/488 [52:19<1:33:35, 17.94s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 176/488 [52:37<1:33:17, 17.94s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 177/488 [52:55<1:32:59, 17.94s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 178/488 [53:13<1:32:41, 17.94s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 179/488 [53:31<1:32:23, 17.94s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 180/488 [53:49<1:32:05, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7881, 'learning_rate': 0.00014572423233046386, 'epoch': 0.74}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 180/488 [53:49<1:32:05, 17.94s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 181/488 [54:07<1:31:47, 17.94s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 182/488 [54:25<1:31:29, 17.94s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 183/488 [54:43<1:31:11, 17.94s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 184/488 [55:01<1:30:53, 17.94s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 185/488 [55:19<1:30:35, 17.94s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 186/488 [55:37<1:30:17, 17.94s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 187/488 [55:55<1:29:59, 17.94s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 188/488 [56:13<1:29:42, 17.94s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 189/488 [56:31<1:29:24, 17.94s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 190/488 [56:49<1:29:06, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8274, 'learning_rate': 0.00013972088455978536, 'epoch': 0.78}\u001b[0m\n",
      "\u001b[34m39%|███▉      | 190/488 [56:49<1:29:06, 17.94s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 191/488 [57:06<1:28:48, 17.94s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 192/488 [57:24<1:28:30, 17.94s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 193/488 [57:42<1:28:12, 17.94s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 194/488 [58:00<1:27:54, 17.94s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 195/488 [58:18<1:27:36, 17.94s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 196/488 [58:36<1:27:18, 17.94s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 197/488 [58:54<1:27:00, 17.94s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 198/488 [59:12<1:26:42, 17.94s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 199/488 [59:30<1:26:24, 17.94s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 200/488 [59:48<1:26:06, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8145, 'learning_rate': 0.00013354237607173495, 'epoch': 0.82}\u001b[0m\n",
      "\u001b[34m41%|████      | 200/488 [59:48<1:26:06, 17.94s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 201/488 [1:00:06<1:25:49, 17.94s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 202/488 [1:00:24<1:25:31, 17.94s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 203/488 [1:00:42<1:25:13, 17.94s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 204/488 [1:01:00<1:24:55, 17.94s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 205/488 [1:01:18<1:24:37, 17.94s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 206/488 [1:01:36<1:24:19, 17.94s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 207/488 [1:01:54<1:24:01, 17.94s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 208/488 [1:02:11<1:23:43, 17.94s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 209/488 [1:02:29<1:23:25, 17.94s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 210/488 [1:02:47<1:23:07, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7993, 'learning_rate': 0.0001272159527847016, 'epoch': 0.86}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 210/488 [1:02:47<1:23:07, 17.94s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 211/488 [1:03:05<1:22:49, 17.94s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 212/488 [1:03:23<1:22:31, 17.94s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 213/488 [1:03:41<1:22:13, 17.94s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 214/488 [1:03:59<1:21:55, 17.94s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 215/488 [1:04:17<1:21:37, 17.94s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 216/488 [1:04:35<1:21:19, 17.94s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 217/488 [1:04:53<1:21:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 218/488 [1:05:11<1:20:44, 17.94s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 219/488 [1:05:29<1:20:26, 17.94s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 220/488 [1:05:47<1:20:08, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7471, 'learning_rate': 0.00012076951289011884, 'epoch': 0.9}\u001b[0m\n",
      "\u001b[34m45%|████▌     | 220/488 [1:05:47<1:20:08, 17.94s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 221/488 [1:06:05<1:19:50, 17.94s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 222/488 [1:06:23<1:19:32, 17.94s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 223/488 [1:06:41<1:19:14, 17.94s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 224/488 [1:06:59<1:18:56, 17.94s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 225/488 [1:07:16<1:18:38, 17.94s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 226/488 [1:07:34<1:18:20, 17.94s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 227/488 [1:07:52<1:18:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 228/488 [1:08:10<1:17:44, 17.94s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 229/488 [1:08:28<1:17:26, 17.94s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 230/488 [1:08:46<1:17:08, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7605, 'learning_rate': 0.00011423148382732853, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[34m47%|████▋     | 230/488 [1:08:46<1:17:08, 17.94s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 231/488 [1:09:04<1:16:50, 17.94s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 232/488 [1:09:22<1:16:32, 17.94s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 233/488 [1:09:40<1:16:14, 17.94s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 234/488 [1:09:58<1:15:56, 17.94s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 235/488 [1:10:16<1:15:39, 17.94s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 236/488 [1:10:34<1:15:20, 17.94s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 237/488 [1:10:52<1:15:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 238/488 [1:11:10<1:14:45, 17.94s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 239/488 [1:11:28<1:14:27, 17.94s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 240/488 [1:11:46<1:14:09, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7749, 'learning_rate': 0.00010763069692457346, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 240/488 [1:11:46<1:14:09, 17.94s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 241/488 [1:12:04<1:13:51, 17.94s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 242/488 [1:12:21<1:13:33, 17.94s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 243/488 [1:12:39<1:13:15, 17.94s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 244/488 [1:12:57<1:12:56, 17.94s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 245/488 [1:13:16<1:13:49, 18.23s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 246/488 [1:13:34<1:13:10, 18.14s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 247/488 [1:13:52<1:12:37, 18.08s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 248/488 [1:14:10<1:12:09, 18.04s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 249/488 [1:14:28<1:11:44, 18.01s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 250/488 [1:14:46<1:11:21, 17.99s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6175, 'learning_rate': 0.0001009962602589249, 'epoch': 1.02}\u001b[0m\n",
      "\u001b[34m51%|█████     | 250/488 [1:14:46<1:11:21, 17.99s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 251/488 [1:15:04<1:10:59, 17.97s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 252/488 [1:15:22<1:10:39, 17.96s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 253/488 [1:15:40<1:10:19, 17.96s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 254/488 [1:15:58<1:10:00, 17.95s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 255/488 [1:16:16<1:09:41, 17.95s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 256/488 [1:16:34<1:09:23, 17.95s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 257/488 [1:16:52<1:09:05, 17.94s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 258/488 [1:17:09<1:08:46, 17.94s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 259/488 [1:17:27<1:08:28, 17.94s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 260/488 [1:17:45<1:08:10, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5626, 'learning_rate': 9.435743029580637e-05, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 260/488 [1:17:45<1:08:10, 17.94s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 261/488 [1:18:03<1:07:52, 17.94s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 262/488 [1:18:21<1:07:34, 17.94s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 263/488 [1:18:39<1:07:16, 17.94s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 264/488 [1:18:57<1:06:58, 17.94s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 265/488 [1:19:15<1:06:40, 17.94s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 266/488 [1:19:33<1:06:22, 17.94s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 267/488 [1:19:51<1:06:04, 17.94s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 268/488 [1:20:09<1:05:46, 17.94s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 269/488 [1:20:27<1:05:28, 17.94s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 270/488 [1:20:45<1:05:10, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5331, 'learning_rate': 8.774348287415589e-05, 'epoch': 1.11}\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 270/488 [1:20:45<1:05:10, 17.94s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 271/488 [1:21:03<1:04:53, 17.94s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 272/488 [1:21:21<1:04:35, 17.94s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 273/488 [1:21:39<1:04:17, 17.94s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 274/488 [1:21:57<1:03:59, 17.94s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 275/488 [1:22:14<1:03:41, 17.94s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 276/488 [1:22:32<1:03:23, 17.94s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 277/488 [1:22:50<1:03:05, 17.94s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 278/488 [1:23:08<1:02:47, 17.94s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 279/488 [1:23:26<1:02:29, 17.94s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 280/488 [1:23:44<1:02:11, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5266, 'learning_rate': 8.118358410615545e-05, 'epoch': 1.15}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 280/488 [1:23:44<1:02:11, 17.94s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 281/488 [1:24:02<1:01:53, 17.94s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 282/488 [1:24:20<1:01:35, 17.94s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 283/488 [1:24:38<1:01:17, 17.94s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 284/488 [1:24:56<1:00:59, 17.94s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 285/488 [1:25:14<1:00:41, 17.94s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 286/488 [1:25:32<1:00:23, 17.94s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 287/488 [1:25:50<1:00:05, 17.94s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 288/488 [1:26:08<59:47, 17.94s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 289/488 [1:26:26<59:29, 17.94s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 290/488 [1:26:44<59:11, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5409, 'learning_rate': 7.470666176083192e-05, 'epoch': 1.19}\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 290/488 [1:26:44<59:11, 17.94s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 291/488 [1:27:01<58:54, 17.94s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 292/488 [1:27:19<58:36, 17.94s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 293/488 [1:27:37<58:18, 17.94s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 294/488 [1:27:55<58:00, 17.94s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 295/488 [1:28:13<57:42, 17.94s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 296/488 [1:28:31<57:24, 17.94s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 297/488 [1:28:49<57:06, 17.94s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 298/488 [1:29:07<56:48, 17.94s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 299/488 [1:29:25<56:30, 17.94s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 300/488 [1:29:43<56:12, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4887, 'learning_rate': 6.834127769870133e-05, 'epoch': 1.23}\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 300/488 [1:29:43<56:12, 17.94s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 301/488 [1:30:01<55:54, 17.94s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 302/488 [1:30:19<55:36, 17.94s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 303/488 [1:30:37<55:18, 17.94s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 304/488 [1:30:55<55:00, 17.94s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▎   | 305/488 [1:31:13<54:42, 17.94s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 306/488 [1:31:31<54:24, 17.94s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 307/488 [1:31:49<54:06, 17.94s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 308/488 [1:32:06<53:49, 17.94s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 309/488 [1:32:24<53:31, 17.94s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 310/488 [1:32:42<53:13, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5464, 'learning_rate': 6.211550191999222e-05, 'epoch': 1.27}\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 310/488 [1:32:42<53:13, 17.94s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 311/488 [1:33:00<52:55, 17.94s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 312/488 [1:33:18<52:37, 17.94s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 313/488 [1:33:36<52:19, 17.94s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 314/488 [1:33:54<52:01, 17.94s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 315/488 [1:34:12<51:43, 17.94s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 316/488 [1:34:30<51:25, 17.94s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 317/488 [1:34:48<51:07, 17.94s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 318/488 [1:35:06<50:49, 17.94s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 319/488 [1:35:24<50:31, 17.94s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 320/488 [1:35:42<50:13, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.51, 'learning_rate': 5.6056788781869106e-05, 'epoch': 1.31}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 320/488 [1:35:42<50:13, 17.94s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 321/488 [1:36:00<49:55, 17.94s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 322/488 [1:36:18<49:38, 17.94s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 323/488 [1:36:36<49:20, 17.94s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 324/488 [1:36:53<49:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 325/488 [1:37:11<48:44, 17.94s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 326/488 [1:37:29<48:26, 17.94s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 327/488 [1:37:47<48:08, 17.94s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 328/488 [1:38:05<47:50, 17.94s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 329/488 [1:38:23<47:32, 17.94s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 330/488 [1:38:41<47:14, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5181, 'learning_rate': 5.019185593051195e-05, 'epoch': 1.35}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 330/488 [1:38:41<47:14, 17.94s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 331/488 [1:38:59<46:56, 17.94s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 332/488 [1:39:17<46:38, 17.94s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 333/488 [1:39:35<46:20, 17.94s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 334/488 [1:39:53<46:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 335/488 [1:40:11<45:44, 17.94s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 336/488 [1:40:29<45:26, 17.94s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 337/488 [1:40:47<45:08, 17.94s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 338/488 [1:41:05<44:50, 17.94s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 339/488 [1:41:23<44:32, 17.94s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 340/488 [1:41:41<44:14, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5183, 'learning_rate': 4.454656648193559e-05, 'epoch': 1.39}\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 340/488 [1:41:41<44:14, 17.94s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 341/488 [1:41:58<43:57, 17.94s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 342/488 [1:42:16<43:39, 17.94s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 343/488 [1:42:34<43:21, 17.94s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 344/488 [1:42:52<43:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 345/488 [1:43:10<42:45, 17.94s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 346/488 [1:43:28<42:27, 17.94s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 347/488 [1:43:46<42:09, 17.94s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 348/488 [1:44:04<41:51, 17.94s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 349/488 [1:44:22<41:33, 17.94s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 350/488 [1:44:40<41:15, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5553, 'learning_rate': 3.914581497110684e-05, 'epoch': 1.43}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 350/488 [1:44:40<41:15, 17.94s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 351/488 [1:44:58<40:57, 17.94s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 352/488 [1:45:16<40:39, 17.94s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 353/488 [1:45:34<40:21, 17.94s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 354/488 [1:45:52<40:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 355/488 [1:46:10<39:45, 17.94s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 356/488 [1:46:28<39:28, 17.94s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 357/488 [1:46:45<39:10, 17.94s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 358/488 [1:47:03<38:52, 17.94s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 359/488 [1:47:21<38:34, 17.94s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 360/488 [1:47:39<38:16, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5513, 'learning_rate': 3.4013417572299446e-05, 'epoch': 1.48}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 360/488 [1:47:39<38:16, 17.94s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 361/488 [1:47:57<37:58, 17.94s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 362/488 [1:48:15<37:40, 17.94s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 363/488 [1:48:33<37:22, 17.94s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 364/488 [1:48:51<37:04, 17.94s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 365/488 [1:49:09<36:46, 17.94s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 366/488 [1:49:27<36:28, 17.94s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 367/488 [1:49:45<36:10, 17.94s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 368/488 [1:50:03<35:52, 17.94s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 369/488 [1:50:21<35:34, 17.94s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 370/488 [1:50:39<35:16, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.509, 'learning_rate': 2.917200707479234e-05, 'epoch': 1.52}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 370/488 [1:50:39<35:16, 17.94s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 371/488 [1:50:57<34:59, 17.94s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 372/488 [1:51:15<34:41, 17.94s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 373/488 [1:51:33<34:23, 17.94s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 374/488 [1:51:50<34:05, 17.94s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 375/488 [1:52:08<33:47, 17.94s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 376/488 [1:52:26<33:29, 17.94s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 377/488 [1:52:44<33:11, 17.94s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 378/488 [1:53:02<32:53, 17.94s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 379/488 [1:53:20<32:35, 17.94s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 380/488 [1:53:38<32:17, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5503, 'learning_rate': 2.464293307704566e-05, 'epoch': 1.56}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 380/488 [1:53:38<32:17, 17.94s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 381/488 [1:53:56<31:59, 17.94s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 382/488 [1:54:14<31:41, 17.94s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 383/488 [1:54:32<31:23, 17.94s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 384/488 [1:54:50<31:05, 17.94s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 385/488 [1:55:08<30:47, 17.94s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 386/488 [1:55:26<30:29, 17.94s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 387/488 [1:55:44<30:11, 17.94s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 388/488 [1:56:02<29:53, 17.94s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 389/488 [1:56:20<29:36, 17.94s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 390/488 [1:56:37<29:18, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5092, 'learning_rate': 2.0446167839477814e-05, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 390/488 [1:56:38<29:18, 17.94s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 391/488 [1:56:55<29:00, 17.94s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 392/488 [1:57:13<28:42, 17.94s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 393/488 [1:57:31<28:24, 17.94s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 394/488 [1:57:49<28:06, 17.94s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 395/488 [1:58:07<27:48, 17.94s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 396/488 [1:58:25<27:30, 17.94s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 397/488 [1:58:43<27:12, 17.94s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 398/488 [1:59:01<26:54, 17.94s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 399/488 [1:59:19<26:36, 17.94s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 400/488 [1:59:37<26:18, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4672, 'learning_rate': 1.660021821101222e-05, 'epoch': 1.64}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 400/488 [1:59:37<26:18, 17.94s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 401/488 [1:59:55<26:00, 17.94s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 402/488 [2:00:13<25:42, 17.94s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 403/488 [2:00:31<25:24, 17.94s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 404/488 [2:00:49<25:06, 17.94s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 405/488 [2:01:07<24:49, 17.94s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 406/488 [2:01:25<24:31, 17.94s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 407/488 [2:01:42<24:13, 17.94s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 408/488 [2:02:00<23:55, 17.94s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 409/488 [2:02:18<23:37, 17.94s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 410/488 [2:02:36<23:19, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.563, 'learning_rate': 1.3122044017779766e-05, 'epoch': 1.68}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 410/488 [2:02:36<23:19, 17.94s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 411/488 [2:02:54<23:01, 17.94s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 412/488 [2:03:12<22:43, 17.94s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 413/488 [2:03:30<22:25, 17.94s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 414/488 [2:03:48<22:07, 17.94s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 415/488 [2:04:06<21:49, 17.94s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 416/488 [2:04:24<21:31, 17.94s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 417/488 [2:04:42<21:13, 17.94s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 418/488 [2:05:00<20:55, 17.94s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 419/488 [2:05:18<20:37, 17.94s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 420/488 [2:05:36<20:19, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5817, 'learning_rate': 1.0026983273865053e-05, 'epoch': 1.72}\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 420/488 [2:05:36<20:19, 17.94s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 421/488 [2:05:54<20:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 422/488 [2:06:12<19:44, 17.94s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 423/488 [2:06:30<19:26, 17.94s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 424/488 [2:06:47<19:08, 17.94s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 425/488 [2:07:05<18:50, 17.94s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 426/488 [2:07:23<18:32, 17.94s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 427/488 [2:07:41<18:14, 17.94s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 428/488 [2:07:59<17:56, 17.94s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 429/488 [2:08:17<17:38, 17.94s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 430/488 [2:08:35<17:20, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5416, 'learning_rate': 7.328684543901598e-06, 'epoch': 1.76}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 430/488 [2:08:35<17:20, 17.94s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 431/488 [2:08:53<17:02, 17.94s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 432/488 [2:09:11<16:44, 17.94s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 433/488 [2:09:29<16:26, 17.94s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 434/488 [2:09:47<16:08, 17.94s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 435/488 [2:10:05<15:50, 17.94s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 436/488 [2:10:23<15:32, 17.94s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 437/488 [2:10:41<15:14, 17.94s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 438/488 [2:10:59<14:56, 17.94s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 439/488 [2:11:17<14:39, 17.94s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 440/488 [2:11:34<14:21, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4875, 'learning_rate': 5.039046755782417e-06, 'epoch': 1.8}\u001b[0m\n",
      "\u001b[34m90%|█████████ | 440/488 [2:11:34<14:21, 17.94s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 441/488 [2:11:52<14:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 442/488 [2:12:10<13:45, 17.94s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 443/488 [2:12:28<13:27, 17.94s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 444/488 [2:12:46<13:09, 17.94s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 445/488 [2:13:04<12:51, 17.94s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 446/488 [2:13:22<12:33, 17.94s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 447/488 [2:13:40<12:15, 17.94s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 448/488 [2:13:58<11:57, 17.94s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 449/488 [2:14:16<11:39, 17.94s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 450/488 [2:14:34<11:21, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5514, 'learning_rate': 3.1681667288994355e-06, 'epoch': 1.84}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 450/488 [2:14:34<11:21, 17.94s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 451/488 [2:14:52<11:03, 17.94s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 452/488 [2:15:10<10:45, 17.94s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 453/488 [2:15:28<10:27, 17.94s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 454/488 [2:15:46<10:09, 17.94s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 455/488 [2:16:04<09:51, 17.94s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 456/488 [2:16:22<09:34, 17.94s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 457/488 [2:16:39<09:16, 17.94s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 458/488 [2:16:57<08:58, 17.94s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 459/488 [2:17:15<08:40, 17.94s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 460/488 [2:17:33<08:22, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5184, 'learning_rate': 1.7242946493010947e-06, 'epoch': 1.89}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 460/488 [2:17:33<08:22, 17.94s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 461/488 [2:17:51<08:04, 17.94s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 462/488 [2:18:09<07:46, 17.94s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 463/488 [2:18:27<07:28, 17.94s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 464/488 [2:18:45<07:10, 17.94s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 465/488 [2:19:03<06:52, 17.94s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 466/488 [2:19:21<06:34, 17.94s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 467/488 [2:19:39<06:16, 17.94s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 468/488 [2:19:57<05:58, 17.94s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 469/488 [2:20:15<05:40, 17.94s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 470/488 [2:20:33<05:22, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5479, 'learning_rate': 7.137976881130825e-07, 'epoch': 1.93}\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 470/488 [2:20:33<05:22, 17.94s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 471/488 [2:20:51<05:04, 17.94s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 472/488 [2:21:09<04:47, 17.94s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 473/488 [2:21:27<04:29, 17.94s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 474/488 [2:21:44<04:11, 17.94s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 475/488 [2:22:02<03:53, 17.94s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 476/488 [2:22:20<03:35, 17.94s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 477/488 [2:22:38<03:17, 17.94s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 478/488 [2:22:56<02:59, 17.94s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 479/488 [2:23:14<02:41, 17.94s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 480/488 [2:23:32<02:23, 17.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4669, 'learning_rate': 1.4113192365753369e-07, 'epoch': 1.97}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 480/488 [2:23:32<02:23, 17.94s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 481/488 [2:23:50<02:05, 17.94s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 482/488 [2:24:08<01:47, 17.94s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 483/488 [2:24:26<01:29, 17.94s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 484/488 [2:24:44<01:11, 17.94s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 485/488 [2:25:02<00:53, 17.94s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 486/488 [2:25:20<00:35, 17.94s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 487/488 [2:25:38<00:17, 17.94s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 488/488 [2:25:56<00:00, 17.93s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 8757.0634, 'train_samples_per_second': 0.167, 'train_steps_per_second': 0.056, 'train_loss': 0.6757110454997078, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 488/488 [2:25:57<00:00, 17.93s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 488/488 [2:25:57<00:00, 17.94s/it]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 1.60k/1.60k [00:00<00:00, 13.2MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 106MB/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json: 100%|██████████| 51.0/51.0 [00:00<00:00, 535kB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 101/101 [00:00<00:00, 1.22MB/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m2024-02-19 03:00:09,920 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-02-19 03:00:09,920 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-02-19 03:00:09,920 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-02-19 03:01:17 Uploading - Uploading generated training model\n",
      "2024-02-19 03:01:17 Completed - Training job completed\n",
      "Training seconds: 9276\n",
      "Billable seconds: 9276\n"
     ]
    }
   ],
   "source": [
    "finetune = FinetuneLLM(model_id='teknium/OpenHermes-2.5-Mistral-7B', \n",
    "                       finetune_id = 'WatermelonUvulaMarigold', \n",
    "                       training_input_path='s3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2024-Feb-19-teknium/OpenHermes-2.5-Mistral-7B-WatermelonUvulaMarigold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b0ffda9-8b18-4b91-9c6c-7a546f3a3a28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-02-19-00-25-15-965/output/model/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune.model_s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8201ed9-f91d-4af5-a93b-4cc550b9eae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoenv",
   "language": "python",
   "name": "recoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
