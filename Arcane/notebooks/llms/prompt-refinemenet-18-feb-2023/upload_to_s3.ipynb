{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f2b3b37-ea58-41d6-bbbe-5f5267675d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_folder = '/Users/username/Desktop/ML/Recommendations/arcane/'\n",
    "from hydra import compose, initialize\n",
    "import os\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('../../../conf/application.run.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "envs_element = root.find('./configuration/envs')\n",
    "for variable in envs_element.findall('env'):\n",
    "    name = variable.get('name')\n",
    "    value = variable.get('value')\n",
    "    os.environ[name] = value\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/username/Desktop/ML/Recommendations/arcane/')\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['PATH'] = '/Users/username/anaconda3/envs/bertopicenv/bin:/Users/username/anaconda3/condabin:/usr/bin:/bin:/usr/sbin:/sbin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe778be-9690-4a6f-be26-cd28bf257fa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from src.llm_finetuning.S3DatasetService import S3DatasetService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec34a756-169e-49aa-a68f-dca4c893751b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8044d0ea-cc6a-4fa0-be3f-da194a6f4742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "s3_openhermes = S3DatasetService(hf_model_id = 'teknium/OpenHermes-2.5-Mistral-7B',cleaned_responses_path='gpt-4-responses-2024-Feb-19_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab109de2-dcba-4676-bf27-ebf64343537b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name username to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function S3DatasetService._create_dataset.<locals>.template_dataset at 0x17959e550> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking dataset into chunks of 4096 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 732\n",
      "Total number of samples: 732\n",
      "finetune_id is WatermelonUvulaMarigold\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/732 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset to: s3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2024-Feb-19-teknium/OpenHermes-2.5-Mistral-7B-WatermelonUvulaMarigold\n"
     ]
    }
   ],
   "source": [
    "s3_openhermes.create_dataset_and_upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e303edbb-b271-4107-aca0-d8689bf84053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "level = logging.WARNING\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11e43095-575f-4757-9aff-346a017d307b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ae7f2ff3f4402fb4c2bcc4653ca648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8060f1e36f91474bbf2939b66d71d48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3d256a27a8483493a1c3a1fe2bbf08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3_noushermes = S3DatasetService(hf_model_id = 'NousResearch/Nous-Hermes-2-Yi-34B',cleaned_responses_path='gpt-4-responses-2024-Feb-19_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a119c92c-915c-4691-8750-30385ba44148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name username to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (10348 > 4096). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking dataset into chunks of 4096 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 716\n",
      "Total number of samples: 716\n",
      "finetune_id is SapphireApricotIcicle\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/716 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset to: s3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2024-Feb-19-NousResearch/Nous-Hermes-2-Yi-34B-SapphireApricotIcicle\n"
     ]
    }
   ],
   "source": [
    "s3_noushermes.create_dataset_and_upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4af718b-95ec-4ee5-9356-7ccaab7ce075",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No chat template is defined for this tokenizer - using a default chat template that implements the ChatML format (without BOS/EOS tokens!). If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3_nouscapybara = S3DatasetService(hf_model_id = 'NousResearch/Nous-Capybara-34B',cleaned_responses_path='gpt-4-responses-2024-Feb-19_cleaned.csv',is_yi_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d46c593c-6e16-4a7a-8b7f-a1de129a7ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s3_nouscapybara._custom_yi_format_text_response_as_prompt({'full_content': 'something', 'cleaned_attributes': 'something else'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90891661-b3b6-449d-9ad2-daf0ad9e5a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# message_template = [{\"role\": \"user\", \"content\": ''},{'role': \"assistant\", 'content': ''}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84bf8622-72e5-4155-accf-c59629a38241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s3_nouscapybara.tokenizer.apply_chat_template(message_template,add_generation_prompt=True,tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe0e3c9e-8710-47e2-84e6-47082c9e9967",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# s3_nouscapybara.tokenizer.encode('<s>USER:\\nASSISTANT:</s>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77f6053-6f43-434c-8d36-3a9b7f13eceb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name username to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function S3DatasetService._create_dataset.<locals>.template_dataset at 0x290ce5430> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking dataset into chunks of 4096 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1128 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 714\n",
      "Total number of samples: 714\n",
      "finetune_id is TrampolineRainbowWatermelon\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/714 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset to: s3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2024-Feb-20-NousResearch/Nous-Capybara-34B-TrampolineRainbowWatermelon\n"
     ]
    }
   ],
   "source": [
    "s3_nouscapybara.create_dataset_and_upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9807ba-b478-402a-aaab-a44ff365b914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01129083-22c2-436f-b75c-d441219a8832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopicenv",
   "language": "python",
   "name": "bertopicenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
