{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dae8e0e-fd24-4870-9f7f-6f2d8757aa16",
   "metadata": {},
   "source": [
    "## Defining sagemaker roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bc8e0f-2ba5-4e0c-8ed3-c238c3de48c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AmazonSageMaker-ExecutionRole-20231030T210397'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "iam = boto3.client('iam')\n",
    "response = iam.list_roles()\n",
    "sagemaker_roles = [role for role in response['Roles'] if 'SageMaker' in role['RoleName']]\n",
    "sagemaker_roles[0]['RoleName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c85d3a-5038-4664-8233-54f715e2ebfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name username to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20231030T210397')['Role']['Arn']\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d1dce9-a30e-41c2-95d5-c11788987a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "from random import randint\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from pack_dataset import pack_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca8391-3908-49fb-8623-3a2ace44c45e",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88b5ca-85d3-477b-9979-c1a0d5dafb20",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68482869-4c3a-44d8-92fc-9cfe23275ab2",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d12915-99b3-49b0-a53d-fa4e1d31626a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/username/anaconda3/envs/recoenv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0da848-579d-46d0-9990-ea3784aad418",
   "metadata": {},
   "source": [
    "### GPT responses EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50a65873-2dc5-405a-a21a-e9b104c98886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('gpt-4-responses-1-dec-with-headers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efdecf01-cfba-4a8d-8801-448f9798737a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns = {'0', '1', 'has_text', 'json_generated'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b13416-9e16-4a63-967b-ee3678b0d429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "761890da-068f-42a4-8525-111f7bc1d2db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>full_content</th>\n",
       "      <th>model</th>\n",
       "      <th>attributes</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Amazon workers walk out over lack of trust in ...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Ar...</td>\n",
       "      <td>2304</td>\n",
       "      <td>458</td>\n",
       "      <td>6555c8194b13023f9349092e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Laid off by Qualcomm Indian techie on H1B visa...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1638</td>\n",
       "      <td>470</td>\n",
       "      <td>653169231e5cc42b1b13d2be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Best Places to Exchange Currency in Los Angele...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>2488</td>\n",
       "      <td>484</td>\n",
       "      <td>6555cc364b13023f934a655c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\nYou are the chief editor for a leading India...   \n",
       "1  \\nYou are the chief editor for a leading India...   \n",
       "2  \\nYou are the chief editor for a leading India...   \n",
       "\n",
       "                                        full_content       model  \\\n",
       "0  Amazon workers walk out over lack of trust in ...  gpt-4-0613   \n",
       "1  Laid off by Qualcomm Indian techie on H1B visa...  gpt-4-0613   \n",
       "2  Best Places to Exchange Currency in Los Angele...  gpt-4-0613   \n",
       "\n",
       "                                          attributes  prompt_tokens  \\\n",
       "0  {\"analysis_is_financial_or_business_news\": \"Ar...           2304   \n",
       "1  {\"analysis_is_financial_or_business_news\": \"Th...           1638   \n",
       "2  {\"analysis_is_financial_or_business_news\": \"Th...           2488   \n",
       "\n",
       "   completion_tokens                article_id  \n",
       "0                458  6555c8194b13023f9349092e  \n",
       "1                470  653169231e5cc42b1b13d2be  \n",
       "2                484  6555cc364b13023f934a655c  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f35aaf-6f23-49f9-8651-0b3aaa62c17a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "res = []\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        res.append(json.loads(df.iloc[i]['attributes'])['article_validity_duration'])\n",
    "    except:\n",
    "        res.append(ast.literal_eval(json.loads(df.iloc[i]['attributes']))['article_validity_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "baa47576-95c1-45ca-b94b-57608f75156b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['validity'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6b30a52-ba57-4230-8adc-26e7d60243c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validity\n",
       "-1    150\n",
       "1     195\n",
       "3     175\n",
       "7     297\n",
       "14    110\n",
       "30    303\n",
       "90      2\n",
       "-1     37\n",
       "1      39\n",
       "14     32\n",
       "3      37\n",
       "30     78\n",
       "7      60\n",
       "90      2\n",
       "Name: validity, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('validity')['validity'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "875bdf3a-bb44-48a0-9b7e-859d2db5d8b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_set_df = df.sample(frac = 0.85)\n",
    "# train_set_df.to_csv('train-set-gpt-4-responses-1-dec.csv', index = False)\n",
    "# test_set_df = df[~df.article_id.isin(train_set.article_id.unique())]\n",
    "# test_set_df.to_csv('test-set-gpt-4-responses-1-dec.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d847b4fc-8d87-4856-8fea-f431a4a8778a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set_df = pd.read_csv('train-set-gpt-4-responses-1-dec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eeccbaf-d59c-43fb-ae3c-07ee7df56b43",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>full_content</th>\n",
       "      <th>model</th>\n",
       "      <th>attributes</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>article_id</th>\n",
       "      <th>validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Tata Motors cars to get costlier from today. D...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1486</td>\n",
       "      <td>517</td>\n",
       "      <td>65316c4d1e5cc42b1b13e030</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Dont have a PAN or Aadhaar number You cannot c...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_of_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1580</td>\n",
       "      <td>500</td>\n",
       "      <td>653169051e5cc42b1b13c9ce</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Air services from Kanpur to Delhi will begin s...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_of_financial_or_business_news\": \"Ar...</td>\n",
       "      <td>1545</td>\n",
       "      <td>513</td>\n",
       "      <td>651e12bca662d76276b878ec</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Cholamandalam Finance April 2023 NCD Public Is...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>2963</td>\n",
       "      <td>618</td>\n",
       "      <td>652fd3151e5cc42b1b13a507</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Survey Shows Real Estate Is Americans Favorite...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1361</td>\n",
       "      <td>529</td>\n",
       "      <td>6555cc9e4b13023f934aaf30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Why Would a Company Perform a Reverse Stock Sp...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>2260</td>\n",
       "      <td>484</td>\n",
       "      <td>6555c81b4b13023f93490a5f</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>How To Open Fixed Deposit Account In Post Offi...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>2663</td>\n",
       "      <td>500</td>\n",
       "      <td>652fc74a1e5cc42b1b139f64</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Pizza Hut to continue aggressive expansion spr...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1950</td>\n",
       "      <td>530</td>\n",
       "      <td>651de972a662d76276b81416</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Key considerations to know in real estate inve...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>2025</td>\n",
       "      <td>475</td>\n",
       "      <td>6555c0904b13023f9348cbde</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>BJP high command summons Yediyurappa to Delhi ...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1811</td>\n",
       "      <td>508</td>\n",
       "      <td>651e04b2a662d76276b85800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1289 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  \\\n",
       "0     \\nYou are the chief editor for a leading India...   \n",
       "1     \\nYou are the chief editor for a leading India...   \n",
       "2     \\nYou are the chief editor for a leading India...   \n",
       "3     \\nYou are the chief editor for a leading India...   \n",
       "4     \\nYou are the chief editor for a leading India...   \n",
       "...                                                 ...   \n",
       "1284  \\nYou are the chief editor for a leading India...   \n",
       "1285  \\nYou are the chief editor for a leading India...   \n",
       "1286  \\nYou are the chief editor for a leading India...   \n",
       "1287  \\nYou are the chief editor for a leading India...   \n",
       "1288  \\nYou are the chief editor for a leading India...   \n",
       "\n",
       "                                           full_content       model  \\\n",
       "0     Tata Motors cars to get costlier from today. D...  gpt-4-0613   \n",
       "1     Dont have a PAN or Aadhaar number You cannot c...  gpt-4-0613   \n",
       "2     Air services from Kanpur to Delhi will begin s...  gpt-4-0613   \n",
       "3     Cholamandalam Finance April 2023 NCD Public Is...  gpt-4-0613   \n",
       "4     Survey Shows Real Estate Is Americans Favorite...  gpt-4-0613   \n",
       "...                                                 ...         ...   \n",
       "1284  Why Would a Company Perform a Reverse Stock Sp...  gpt-4-0613   \n",
       "1285  How To Open Fixed Deposit Account In Post Offi...  gpt-4-0613   \n",
       "1286  Pizza Hut to continue aggressive expansion spr...  gpt-4-0613   \n",
       "1287  Key considerations to know in real estate inve...  gpt-4-0613   \n",
       "1288  BJP high command summons Yediyurappa to Delhi ...  gpt-4-0613   \n",
       "\n",
       "                                             attributes  prompt_tokens  \\\n",
       "0     {\"analysis_is_financial_or_business_news\": \"Th...           1486   \n",
       "1     {\"analysis_of_financial_or_business_news\": \"Th...           1580   \n",
       "2     {\"analysis_of_financial_or_business_news\": \"Ar...           1545   \n",
       "3     {\"analysis_is_financial_or_business_news\": \"Th...           2963   \n",
       "4     {\"analysis_is_financial_or_business_news\": \"Th...           1361   \n",
       "...                                                 ...            ...   \n",
       "1284  {\"analysis_is_financial_or_business_news\": \"Th...           2260   \n",
       "1285  {\"analysis_is_financial_or_business_news\": \"Th...           2663   \n",
       "1286  {\"analysis_is_financial_or_business_news\": \"Th...           1950   \n",
       "1287  {\"analysis_is_financial_or_business_news\": \"Th...           2025   \n",
       "1288  {\"analysis_is_financial_or_business_news\": \"Th...           1811   \n",
       "\n",
       "      completion_tokens                article_id  validity  \n",
       "0                   517  65316c4d1e5cc42b1b13e030         3  \n",
       "1                   500  653169051e5cc42b1b13c9ce        30  \n",
       "2                   513  651e12bca662d76276b878ec        30  \n",
       "3                   618  652fd3151e5cc42b1b13a507        30  \n",
       "4                   529  6555cc9e4b13023f934aaf30        30  \n",
       "...                 ...                       ...       ...  \n",
       "1284                484  6555c81b4b13023f93490a5f        -1  \n",
       "1285                500  652fc74a1e5cc42b1b139f64        30  \n",
       "1286                530  651de972a662d76276b81416        30  \n",
       "1287                475  6555c0904b13023f9348cbde        30  \n",
       "1288                508  651e04b2a662d76276b85800         1  \n",
       "\n",
       "[1289 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f193a00-8c2d-4e5a-b57e-cd1fd7d748a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1289.000000\n",
       "mean      506.780450\n",
       "std        47.484215\n",
       "min       327.000000\n",
       "25%       475.000000\n",
       "50%       504.000000\n",
       "75%       537.000000\n",
       "max       675.000000\n",
       "Name: completion_tokens, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df['completion_tokens'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a76aa1b2-3afd-450e-b719-097907da563f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# structuring the format\n",
    "train_set = {}\n",
    "for row in train_set_df.itertuples():\n",
    "    res = row.attributes\n",
    "    train_set[row.article_id] = {'content': row.full_content, 'response': {}}\n",
    "    train_set[row.article_id]['attributes'] = json.loads(res)\n",
    "    # train_set[art_id]['response']['summaries'] = res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9222904e-2d62-4307-a983-f9f4456e50f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert train_set_df.article_id.nunique() == len(train_set.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca3bd827-0185-4db4-873f-c5ba4a62bc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correct_validity_duration(val):\n",
    "    val = int(val)\n",
    "    valid_days = [-1, 1, 3, 7, 14, 30]\n",
    "    if val in valid_days:\n",
    "        return val\n",
    "    else:\n",
    "        for i in valid_days:\n",
    "            if val > i:\n",
    "                valid_value = i\n",
    "        return valid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a65ecfd4-c9a8-4b28-8a4d-293944bcd6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8ef7f115-7fc7-4856-9e3b-dc1f892f3a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_dict_structure = expected_dict_structure = {\"analysis_of_financial_or_business_news\": \"\",\n",
    "\"financial_or_business_news\": \"\",\n",
    "\"analysis_of_relevant_for_india\": \"\",\n",
    "\"relevant_for_india\": \"\",\n",
    "\"analysis_of_article_validity_duration\": \"\",\n",
    "\"article_validity_duration\": \"\",\n",
    "\"analysis_of_popularity\": \"\",\n",
    "\"popularity\": \"\",\n",
    "\"analysis_of_article_type\": \"\",\n",
    "\"article_type\": \"\",\n",
    "\"analysis_of_article_sentiment\": \"\",\n",
    "\"article_sentiment\": \"\",\n",
    "\"headline_suggestion\": \"\",\n",
    "\"first_attempt_summary\": \"\",\n",
    "\"improved_summary\": \"\",\n",
    "\"final_summary\": \"\",\n",
    "\"top_categories\": \"\"}\n",
    "expected_keys = sorted(list(expected_dict_structure.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85f0c9-cf95-4c37-9b06-a881b2ee51e8",
   "metadata": {},
   "source": [
    "### Cleaning the responses from GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08159380-f16a-4788-93a8-88556bd2feee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "malformed = []\n",
    "cleaned_train_set = {}\n",
    "for art_id in train_set:\n",
    "    cleaned_train_set[art_id] = {}\n",
    "    try:\n",
    "        attributes = train_set[art_id]['attributes']\n",
    "        if 'analysis_is_financial_or_business_news' in attributes:\n",
    "            attributes['analysis_of_financial_or_business_news'] = attributes['analysis_is_financial_or_business_news']\n",
    "            attributes.pop('analysis_is_financial_or_business_news')\n",
    "        if 'is_financial_or_business_news' in attributes:\n",
    "            attributes['financial_or_business_news'] = attributes['is_financial_or_business_news']\n",
    "            attributes.pop('is_financial_or_business_news')\n",
    "        keys = sorted(list(attributes.keys()))\n",
    "        if not keys == expected_keys:\n",
    "            malformed.append(art_id)\n",
    "            cleaned_train_set.pop(art_id)\n",
    "            continue\n",
    "        cleaned_train_set[art_id] = {'content': train_set[art_id]['content'], 'attributes': deepcopy(attributes)}\n",
    "        cleaned_train_set[art_id]['attributes']['financial_or_business_news'] = True if bool(attributes['financial_or_business_news']) == 1 else False if bool(attributes['financial_or_business_news']) == 0 else None\n",
    "        cleaned_train_set[art_id]['attributes']['relevant_for_india'] = True if bool(attributes['relevant_for_india']) == 1 else False if bool(attributes['relevant_for_india']) == 0 else None\n",
    "        cleaned_train_set[art_id]['attributes']['article_validity_duration'] = correct_validity_duration(attributes['article_validity_duration'])\n",
    "    except:\n",
    "        malformed.append(art_id)\n",
    "        cleaned_train_set.pop(art_id)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36857e6f-5043-4025-8716-2bffdf5cd170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'651e04b2a662d76276b85800'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89fc9122-de98-4319-bac2-ca6c47c56089",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis_is_financial_or_business_news', 'is_financial_or_business_news'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(expected_keys) - set(sorted(list(train_set['651e04b2a662d76276b85800']['attributes'].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5d72b19-f73a-4686-b358-381c1c140ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False, True}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['financial_or_business_news'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6ac7e77b-ca5a-4dd2-be95-8c1811112f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False, True}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['relevant_for_india'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b5e5641-cb85-43b2-be06-5d8db95fccd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 1, 3, 7, 14, 30}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_validity_duration'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f7734d3-3f7e-41b2-807f-533460a8850f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NA', 'bear', 'bearish', 'bull'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_sentiment'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3874a132-054f-4677-91e9-ab84081cc305",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fact', 'analysis', 'educational', 'fact', 'factual', 'opinion', 'sponsored'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_type'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ec2bae8-89f2-4f99-851f-801f6f0b4c58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Breaking_news', 'breaking_news', 'moderately_popular', 'niche'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['popularity'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c9a53-90ad-4084-8ad7-d114fcd2f829",
   "metadata": {},
   "source": [
    "### casting incorrect values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15d87389-c8d7-4c94-89d8-0826d0b5ee78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for art_id in cleaned_train_set:\n",
    "    attributes = cleaned_train_set[art_id]['attributes']\n",
    "    for key in ['article_sentiment', 'article_type', 'popularity']:\n",
    "        attributes[key] = attributes[key].lower()\n",
    "        if attributes['article_sentiment'] == 'bearish':\n",
    "            attributes['article_sentiment'] = 'bear'\n",
    "        if attributes['article_type'] in ('fact', 'Fact', 'factual'):\n",
    "            attributes['article_type'] = 'fact'\n",
    "        if attributes['popularity'] in ('Breaking_news'):\n",
    "            attributes['popularity'] = 'breaking_news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8b66d841-b464-4e71-b2d2-955f339d3a15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bear', 'bull', 'na'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_sentiment'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4c0391ee-da3b-49e4-90db-755df5321e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis', 'educational', 'fact', 'opinion', 'sponsored'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_type'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9712acce-d1db-4d6f-9cbb-5aa6883ff45f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'breaking_news', 'moderately_popular', 'niche'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['popularity'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4e052ead-30c2-4c86-8e4c-2baf4020c387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1246"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28e11ff6-85af-4d22-85ba-aa075873c116",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1287"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d11d53cd-4d8b-4c79-93b4-c6e78859961c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(malformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473eabf-cb04-4824-98b5-2f1871e3e945",
   "metadata": {},
   "source": [
    "### Properly ordering the train dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "16c3d0b5-61aa-45b7-bcc7-b92239d94c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train_set_copy = deepcopy(cleaned_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01773674-7cd6-4ee4-a3a7-d259f622edd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_dict_structure = {\"analysis_of_financial_or_business_news\": \"\",\n",
    "\"financial_or_business_news\": \"\",\n",
    "\"analysis_of_relevant_for_india\": \"\",\n",
    "\"relevant_for_india\": \"\",\n",
    "\"analysis_of_article_validity_duration\": \"\",\n",
    "\"article_validity_duration\": \"\",\n",
    "\"analysis_of_popularity\": \"\",\n",
    "\"popularity\": \"\",\n",
    "\"analysis_of_article_type\": \"\",\n",
    "\"article_type\": \"\",\n",
    "\"analysis_of_article_sentiment\": \"\",\n",
    "\"article_sentiment\": \"\",\n",
    "\"headline_suggestion\": \"\",\n",
    "\"first_attempt_summary\": \"\",\n",
    "\"improved_summary\": \"\",\n",
    "\"final_summary\": \"\",\n",
    "\"top_categories\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ccefa23-e7e5-4899-ac09-376c3f3fb6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['analysis_of_financial_or_business_news', 'financial_or_business_news', 'analysis_of_relevant_for_india', 'relevant_for_india', 'analysis_of_article_validity_duration', 'article_validity_duration', 'analysis_of_popularity', 'popularity', 'analysis_of_article_type', 'article_type', 'analysis_of_article_sentiment', 'article_sentiment', 'headline_suggestion', 'first_attempt_summary', 'improved_summary', 'final_summary', 'top_categories'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_dict_structure.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ff12b2b-be2e-4f6c-9118-d27edc12a43c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train_set = {article_id: {'content': cleaned_train_set_copy[article_id]['content'], \n",
    "                                  'attributes': {k: cleaned_train_set_copy[article_id]['attributes'][k] for k in expected_dict_structure}} for article_id in cleaned_train_set_copy.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5a70f71e-7403-4c60-885e-1d502324f109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['65316c4d1e5cc42b1b13e030',\n",
       " '653169051e5cc42b1b13c9ce',\n",
       " '651e12bca662d76276b878ec',\n",
       " '652fd3151e5cc42b1b13a507',\n",
       " '6555cc9e4b13023f934aaf30',\n",
       " '6555bed64b13023f9348c585',\n",
       " '653169401e5cc42b1b13d7aa',\n",
       " '651dfa41a662d76276b83da7',\n",
       " '65316e9b1e5cc42b1b13e5b9',\n",
       " '653169151e5cc42b1b13ce9e']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cleaned_train_set.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21d7c1d9-9984-4ca0-8550-ee3c24df1392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "malformed_top_categories = [article_id for article_id in cleaned_train_set if isinstance(cleaned_train_set[article_id]['attributes']['top_categories'], list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4da254a2-3857-4446-868e-c0e377b6e01d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train_set = {k: cleaned_train_set[k] for k in cleaned_train_set.keys() if k not in malformed_top_categories}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957d6c8-05b4-4581-82c8-bb073b9b59cc",
   "metadata": {},
   "source": [
    "### Article Truncation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9bd04673-53bb-4759-af8f-5188844be617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_tokens(text, encoder):  # Placeholder for your actual token calculation function\n",
    "    # Your implementation will go here.\n",
    "    return len(encoder.encode(text))  # Example: counting characters as tokens\n",
    "\n",
    "def truncate_text_to_token_limit(text,encoder, token_limit):\n",
    "    # First, check if the whole text is under the token limit\n",
    "    if calculate_tokens(text, encoder) <= token_limit:\n",
    "        return text  # The entire text is within the limit\n",
    "\n",
    "    def is_under_limit(index):\n",
    "        # Use the provided function to calculate tokens for the substring\n",
    "        return calculate_tokens(text[:index], encoder) <= token_limit\n",
    "\n",
    "    left, right = 0, len(text)\n",
    "    valid_limit = 0  # This will hold the index of the last valid token position\n",
    "\n",
    "    # Binary search to find the token limit\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2  # Find the midpoint\n",
    "        if is_under_limit(mid):\n",
    "            # If the midpoint is under the limit, store it as a valid limit\n",
    "            valid_limit = mid\n",
    "            left = mid + 1  # Move the left boundary to the right\n",
    "        else:\n",
    "            right = mid - 1  # Move the right boundary to the left\n",
    "\n",
    "    # Find the last space before the valid_limit to ensure we're at a word boundary\n",
    "    space_index = text.rfind(' ', 0, valid_limit)\n",
    "    if space_index == -1:\n",
    "        # If there's no space, we've hit the start of the text\n",
    "        return text[:valid_limit]  # Return up to the valid limit even if mid-word\n",
    "\n",
    "    # Return the text up to the last word within the token limit\n",
    "    return text[:space_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5e64a-ded8-46c1-b748-e0b54599ce48",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7d10e768-b5fc-4a83-aad9-61f0d32270a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt =  '''\n",
    "You are the chief editor for a leading Indian financial and business news website. You evaluate critical attributes of articles to gate keep content quality. For many attributes, you will first provide a brief analysis of 15 to 30 words, followed by assessment.\n",
    "\n",
    "1. analysis_of_financial_or_business_news (short text) : <analyse if article pertains to finance/business or not. government policies directly impacting indian corporations or investors are ok, but not if aren't>\n",
    "2. financial_or_business_news (True or False) : <True or False based on previous attribute>\n",
    "3. analysis_of_relevant_for_india (short text) : <analyse if article is relevant for indians. for example international articles about 401k or small foreign companies won't be relevant for india. however changes to fed interest rates or nasdaq or important news of large multinational corporations will be relevant>\n",
    "4. relevant_for_india (True or False) : <True or False based on previous attribute>\n",
    "5. analysis_of_article_validity_duration (short text) : <analyse relevance duration. Be stingy: Stock fluctuations, 1 day; significant policy changes - few days or a week; educational content with references to any regulations is 30 unless there are none - in which case is timeless. International news in India has shorter lifespan. breaking news are usually not timeless; quarterly analysis or results are usually valid for a 3 days, yearly analysis or results for a weeks and a much longer one for a month.>\n",
    "6. article_validity_duration (one of 1, 3, 7, 14, 30, -1) : <calculate number of days based on previous attribute. -1: timeless. 1: article is relevant only for that day. 3: for a couple of days. 7: for a week. 14: for a couple of weeks. 30: for a month>\n",
    "7. analysis_of_popularity (short text) : <analyse likely popularity of article - if its for niche audience, moderate_popularity or should be part of breaking_news section, depending on number of people who will be impacted by the news and the scale of the event. foreign entities known in india but not very popular will be mostly niche or rarely moderately popular. articles targeted to very specific business or pratices will be niche. infotainment business and financial articles with some drama are likely to be more popular. articles with a list of rules without compelling story-telling will be for niche audience>\n",
    "8. popularity (one of niche, moderately_popular, breaking_news) : <based on previous attribute>\n",
    "9. analysis_of_article_type (short text) : <analyse if the article is majorly factual, is an opinion piece, analysis, educational or likely sponsored. factual articles pass on information on events. opinion pieces have inferences or predictions either from the author or from statements without data. analysis pieces have substantial data to justify their inferences or predictions. if an article is overly zealous on certain stock and seems like an ad, then it is sponsored>\n",
    "10. article_type (one of fact, opinion, analysis, educational, sponsored) : <based on previous attribute>\n",
    "11. analysis_of_article_sentiment (short_text): <analyse if the sentiment of the article is bullish, bearish or NA. balanced is NA>\n",
    "12. article_sentiment (one of bull, bear, na): <based on previous attribute>\n",
    "13. headline_suggestion (short text) : <Write a headline based on the content of the article>\n",
    "14. first_attempt_summary (text of 60 words) : <Generate concise, entity-dense summary. The summary should become highly dense but easily understood without the Article. limit it to no more than 60 words>\n",
    "15. improved_summary (text of 60 words): <Identify contents of the article which are missing from the previous summary but are important part of the article>\n",
    "16. final_summary (text of 60 words): <The finalised summary which is a mixture of first_attempt_summary and improved_summary. Don't critique the summary. This summary should be very concise but also all the important information of the article and yet concise.>\n",
    "17. top_categories (5 semi colon seperated categories): <Hierarchy of 5 categories to which this article belongs. Start with a generic category and make it progressively specific. Select only 5 and seperate them by (;). Don't use either single or double quotes at any cost to avoid json.loads() failure>\n",
    "\n",
    "your response should be a json structure with all the 17 above keys without missing any key. It is very important that the response is directly readable with json.loads(). no preamble or postamble. respond in the exact following structure:\n",
    "\n",
    "{\n",
    "\"analysis_of_financial_or_business_news\": \"\",\n",
    "\"financial_or_business_news\": \"\",\n",
    "\"analysis_of_relevant_for_india\": \"\",\n",
    "\"relevant_for_india\": \"\",\n",
    "\"analysis_of_article_validity_duration\": \"\",\n",
    "\"article_validity_duration\": \"\",\n",
    "\"analysis_of_popularity\": \"\",\n",
    "\"popularity\": \"\",\n",
    "\"analysis_of_article_type\": \"\",\n",
    "\"article_type\": \"\",\n",
    "\"analysis_of_article_sentiment\": \"\",\n",
    "\"article_sentiment\": \"\",\n",
    "\"headline_suggestion\": \"\",\n",
    "\"first_attempt_summary\": \"\",\n",
    "\"improved_summary\": \"\",\n",
    "\"final_summary\": \"\",\n",
    "\"top_categories\": \"\"\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d85f6-f780-4ebe-91f1-2b6068561d4a",
   "metadata": {},
   "source": [
    "### Article Size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7c46f5d5-fc39-4c48-a913-17f812c060b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "article_sizes = {k: len(tokenizer.encode(cleaned_train_set[k]['content'])) for k in cleaned_train_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1cb55561-2e1b-4fe4-a74f-d448a5519efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'65316c4d1e5cc42b1b13e030': 401,\n",
       " '653169051e5cc42b1b13c9ce': 485,\n",
       " '651e12bca662d76276b878ec': 475,\n",
       " '652fd3151e5cc42b1b13a507': 2323,\n",
       " '6555cc9e4b13023f934aaf30': 251,\n",
       " '6555bed64b13023f9348c585': 1994,\n",
       " '653169401e5cc42b1b13d7aa': 506,\n",
       " '651dfa41a662d76276b83da7': 476,\n",
       " '65316e9b1e5cc42b1b13e5b9': 1488,\n",
       " '653169151e5cc42b1b13ce9e': 516,\n",
       " '651e0776a662d76276b85eac': 512,\n",
       " '652ebbdb1e5cc42b1b139b67': 837,\n",
       " '6555ccd54b13023f934adbf9': 374,\n",
       " '655c20fc4b13023f934af5cc': 440,\n",
       " '651dcd68a662d76276b7c9b2': 587,\n",
       " '653680111e5cc42b1b143f48': 1194,\n",
       " '65316f731e5cc42b1b1400aa': 1593,\n",
       " '65316f411e5cc42b1b13f5ed': 518,\n",
       " '651e0a35a662d76276b864e1': 1008,\n",
       " '6555ccc64b13023f934acf58': 184,\n",
       " '6555c84a4b13023f934924d6': 497,\n",
       " '6555cc6c4b13023f934a8d15': 544,\n",
       " '651dfeeaa662d76276b84929': 323,\n",
       " '6555c8144b13023f934905df': 459,\n",
       " '6531687f1e5cc42b1b13add0': 604,\n",
       " '651de5aaa662d76276b80a31': 434,\n",
       " '651e18d3a662d76276b88714': 649,\n",
       " '65316f6c1e5cc42b1b13ff04': 1602,\n",
       " '651dd58fa662d76276b7e02c': 272,\n",
       " '6555c7fc4b13023f9348f6a6': 559,\n",
       " '651dc721a662d76276b7b870': 1478,\n",
       " '65316a011e5cc42b1b13db03': 211,\n",
       " '65316d031e5cc42b1b13e199': 1106,\n",
       " '651dedb6a662d76276b81f4b': 1017,\n",
       " '6531692e1e5cc42b1b13d523': 486,\n",
       " '65316eb81e5cc42b1b13e66b': 423,\n",
       " '6555cab14b13023f93495aa5': 448,\n",
       " '6555cbbf4b13023f934a104a': 1873,\n",
       " '651def1ea662d76276b82308': 421,\n",
       " '651e1b88a662d76276b88d2f': 234,\n",
       " '651dc9f6a662d76276b7c05e': 957,\n",
       " '6555cafd4b13023f93498e94': 1132,\n",
       " '652ebbc51e5cc42b1b139a58': 817,\n",
       " '651dc79fa662d76276b7b9e4': 231,\n",
       " '653168cc1e5cc42b1b13baae': 499,\n",
       " '6555ca664b13023f93493776': 1279,\n",
       " '6555c7e24b13023f9348e9df': 1930,\n",
       " '651dd33da662d76276b7da5d': 520,\n",
       " '653169011e5cc42b1b13c893': 757,\n",
       " '651deefca662d76276b822ad': 494,\n",
       " '6555cbd04b13023f934a1b56': 1619,\n",
       " '651de999a662d76276b81478': 214,\n",
       " '6555ca784b13023f93493d0d': 1261,\n",
       " '651dcf77a662d76276b7cf6d': 1162,\n",
       " '653168691e5cc42b1b13ab45': 623,\n",
       " '651de70da662d76276b80def': 1148,\n",
       " '65316f3b1e5cc42b1b13f4c5': 1118,\n",
       " '65316fd91e5cc42b1b14211d': 1967,\n",
       " '6555cbac4b13023f934a0367': 783,\n",
       " '6555cc6f4b13023f934a8ed9': 562,\n",
       " '6555cca14b13023f934ab140': 1540,\n",
       " '651e0555a662d76276b8598b': 1069,\n",
       " '6555cc5d4b13023f934a8183': 739,\n",
       " '6555cc074b13023f934a42fb': 1070,\n",
       " '653225a31e5cc42b1b143884': 209,\n",
       " '6555c7ed4b13023f9348eed4': 495,\n",
       " '6555cccd4b13023f934ad566': 420,\n",
       " '6555ca934b13023f934948be': 919,\n",
       " '6555cae94b13023f9349815b': 1801,\n",
       " '6531ed691e5cc42b1b143761': 279,\n",
       " '6555cbd64b13023f934a1faf': 755,\n",
       " '6531691b1e5cc42b1b13d05b': 697,\n",
       " '6555b52f4b13023f9348b9cc': 1924,\n",
       " '6555cc344b13023f934a63e2': 531,\n",
       " '6555c8124b13023f93490460': 41,\n",
       " '652ebbc81e5cc42b1b139a77': 764,\n",
       " '6531684d1e5cc42b1b13a918': 573,\n",
       " '655c55a7eee55a44e0ac1e5f': 367,\n",
       " '6555ccc34b13023f934acc8e': 390,\n",
       " '6555c80c4b13023f9349007e': 1383,\n",
       " '6555bf094b13023f9348c620': 692,\n",
       " '65316f611e5cc42b1b13fc8f': 2031,\n",
       " '6540c8a92936d70acf71ed57': 674,\n",
       " '6555c8284b13023f93491342': 605,\n",
       " '651dd023a662d76276b7d14f': 172,\n",
       " '6555c7c34b13023f9348e067': 797,\n",
       " '6555cadc4b13023f93497836': 979,\n",
       " '6555c49a4b13023f9348d92f': 334,\n",
       " '651de6f4a662d76276b80daf': 1298,\n",
       " '6555ca554b13023f93493377': 1412,\n",
       " '6555cc0e4b13023f934a4783': 486,\n",
       " '653169f11e5cc42b1b13dae4': 324,\n",
       " '655c5588eee55a44e0ac1e39': 1143,\n",
       " '6555c8124b13023f93490447': 777,\n",
       " '651df231a662d76276b82b11': 601,\n",
       " '653169391e5cc42b1b13d6ca': 961,\n",
       " '6555c8074b13023f9348fd17': 1367,\n",
       " '6555c84e4b13023f93492551': 799,\n",
       " '6555cb8e4b13023f9349ef10': 861,\n",
       " '651e19f0a662d76276b8899d': 298,\n",
       " '6538bd0b1e5cc42b1b14448e': 1024,\n",
       " '651dd1bfa662d76276b7d5e9': 632,\n",
       " '6555c2f04b13023f9348d335': 1182,\n",
       " '6555c4364b13023f9348d798': 461,\n",
       " '651dc561a662d76276b7b3fb': 534,\n",
       " '65316f4a1e5cc42b1b13f7c6': 1805,\n",
       " '6555cc454b13023f934a707f': 818,\n",
       " '651de104a662d76276b7fddc': 183,\n",
       " '6555cab14b13023f93495a57': 609,\n",
       " '651dcffea662d76276b7d0e6': 459,\n",
       " '6555c18c4b13023f9348cffb': 318,\n",
       " '652fd2851e5cc42b1b13a4bf': 979,\n",
       " '6555c47e4b13023f9348d8be': 473,\n",
       " '6555c3294b13023f9348d3a3': 831,\n",
       " '6555caaa4b13023f9349559c': 1386,\n",
       " '65316faa1e5cc42b1b141020': 829,\n",
       " '6555cbaa4b13023f934a023a': 1440,\n",
       " '6555cc0b4b13023f934a45c6': 931,\n",
       " '6536801d1e5cc42b1b14404b': 806,\n",
       " '651defa9a662d76276b82464': 932,\n",
       " '6531691c1e5cc42b1b13d0bf': 625,\n",
       " '6555caaa4b13023f934955c5': 816,\n",
       " '65236cedcd871c6ac1cde049': 830,\n",
       " '651dca9aa662d76276b7c222': 367,\n",
       " '65316fa81e5cc42b1b140f8b': 666,\n",
       " '6555cace4b13023f93496e03': 1630,\n",
       " '6555cca04b13023f934ab07a': 1179,\n",
       " '652fd2681e5cc42b1b13a4b2': 1088,\n",
       " '6555cc2f4b13023f934a606e': 1786,\n",
       " '6555cc894b13023f934aa0b8': 579,\n",
       " '653170011e5cc42b1b143139': 952,\n",
       " '651df941a662d76276b83b4c': 464,\n",
       " '651e0f51a662d76276b870cc': 659,\n",
       " '6555ca724b13023f93493af9': 1060,\n",
       " '653168c41e5cc42b1b13b8c4': 658,\n",
       " '6525a723598c6618f06087b8': 282,\n",
       " '6555cbdf4b13023f934a2673': 560,\n",
       " '6555c4464b13023f9348d7dc': 1436,\n",
       " '6555cadd4b13023f9349789b': 700,\n",
       " '65367fe71e5cc42b1b143ca6': 1159,\n",
       " '65316fac1e5cc42b1b141095': 459,\n",
       " '65316e721e5cc42b1b13e524': 233,\n",
       " '6555c8114b13023f93490419': 607,\n",
       " '6536801e1e5cc42b1b14406d': 1275,\n",
       " '6555ccd64b13023f934adccb': 1213,\n",
       " '6555cccc4b13023f934ad446': 671,\n",
       " '653680151e5cc42b1b143f9d': 2050,\n",
       " '654856d1dc4fa72a6c403a3d': 1862,\n",
       " '65316f521e5cc42b1b13f949': 2120,\n",
       " '6555c8194b13023f934908fb': 1113,\n",
       " '6531692b1e5cc42b1b13d476': 895,\n",
       " '651dd203a662d76276b7d6c2': 577,\n",
       " '6555cadb4b13023f9349776a': 802,\n",
       " '6555b5b54b13023f9348bebf': 1795,\n",
       " '651e209fa662d76276b89966': 704,\n",
       " '6555cc274b13023f934a59e8': 443,\n",
       " '6555cc094b13023f934a4450': 655,\n",
       " '6555cb084b13023f9349963d': 514,\n",
       " '6555c0844b13023f9348cba1': 819,\n",
       " '6555cc764b13023f934a9418': 830,\n",
       " '6555bf5f4b13023f9348c712': 463,\n",
       " '6555cba54b13023f9349fec9': 540,\n",
       " '6555cb504b13023f9349c489': 733,\n",
       " '651dda38a662d76276b7ebbb': 498,\n",
       " '651df6d0a662d76276b83683': 862,\n",
       " '6555c7fe4b13023f9348f7c5': 1026,\n",
       " '651debdaa662d76276b81a72': 281,\n",
       " '6555ccaf4b13023f934abbcd': 365,\n",
       " '65316f921e5cc42b1b1408e3': 517,\n",
       " '6555c4bd4b13023f9348d9d1': 904,\n",
       " '651e1ca6a662d76276b88fd5': 416,\n",
       " '6555cc794b13023f934a95b9': 679,\n",
       " '6555cc594b13023f934a7f47': 438,\n",
       " '6531691c1e5cc42b1b13d0a5': 509,\n",
       " '6525a6d2598c6618f0608551': 508,\n",
       " '6555c0934b13023f9348cbe5': 431,\n",
       " '651dc715a662d76276b7b84d': 849,\n",
       " '6555ccb24b13023f934abe46': 250,\n",
       " '6531686d1e5cc42b1b13abaf': 862,\n",
       " '6555c8234b13023f93490f91': 1386,\n",
       " '651e035fa662d76276b85496': 467,\n",
       " '65316ff01e5cc42b1b1429ec': 1590,\n",
       " '6555c7b74b13023f9348de73': 1359,\n",
       " '6555cab84b13023f93495eea': 1075,\n",
       " '6554345a4b13023f9348b4e4': 227,\n",
       " '651decc9a662d76276b81cd0': 288,\n",
       " '653169231e5cc42b1b13d299': 482,\n",
       " '6555c8494b13023f93492496': 641,\n",
       " '651e0a35a662d76276b864df': 429,\n",
       " '6555cbd44b13023f934a1e7d': 1154,\n",
       " '653168ee1e5cc42b1b13c336': 248,\n",
       " '6554344c4b13023f9348b491': 216,\n",
       " '6555cbe94b13023f934a2d81': 1517,\n",
       " '6555b5c74b13023f9348bfc8': 376,\n",
       " '6555c16b4b13023f9348cf85': 1136,\n",
       " '652ebba71e5cc42b1b139977': 832,\n",
       " '6555cc254b13023f934a58d3': 428,\n",
       " '6531684e1e5cc42b1b13a92c': 1992,\n",
       " '655c1d5e4b13023f934af4af': 767,\n",
       " '651df231a662d76276b82b0e': 436,\n",
       " '6555c7c14b13023f9348dff5': 851,\n",
       " '6555cc734b13023f934a9192': 400,\n",
       " '6555cad74b13023f934974fa': 1508,\n",
       " '6555ca944b13023f93494940': 1136,\n",
       " '651de466a662d76276b806f4': 154,\n",
       " '653169321e5cc42b1b13d5b9': 459,\n",
       " '6555ccc14b13023f934acac6': 584,\n",
       " '6555cb454b13023f9349bcdd': 986,\n",
       " '651e0d73a662d76276b86c6b': 817,\n",
       " '6555cccf4b13023f934ad701': 929,\n",
       " '651dd211a662d76276b7d6ec': 236,\n",
       " '653168b01e5cc42b1b13b50a': 975,\n",
       " '6555cbb34b13023f934a0846': 1419,\n",
       " '6525a749598c6618f0608a24': 775,\n",
       " '6555cbe34b13023f934a293d': 728,\n",
       " '65316a3a1e5cc42b1b13dba4': 702,\n",
       " '651dda0da662d76276b7eb59': 725,\n",
       " '651deedea662d76276b82260': 1367,\n",
       " '651de3a8a662d76276b8050b': 280,\n",
       " '653168bb1e5cc42b1b13b701': 1655,\n",
       " '652e311b5669b40a3b5ab76c': 755,\n",
       " '6531691b1e5cc42b1b13d077': 528,\n",
       " '6531691d1e5cc42b1b13d106': 644,\n",
       " '6555cc024b13023f934a3f6a': 364,\n",
       " '6555cc604b13023f934a8410': 510,\n",
       " '652ebbda1e5cc42b1b139b60': 917,\n",
       " '651e0166a662d76276b84f8a': 108,\n",
       " '6555cc324b13023f934a6257': 675,\n",
       " '65316f751e5cc42b1b140149': 445,\n",
       " '6555cc304b13023f934a60bc': 1669,\n",
       " '6555cc774b13023f934a9451': 575,\n",
       " '6555c7ff4b13023f9348f83d': 1126,\n",
       " '6555c2db4b13023f9348d30b': 1756,\n",
       " '6555cc964b13023f934aa908': 380,\n",
       " '6555cbe74b13023f934a2c3b': 589,\n",
       " '655191454b13023f9348b35a': 228,\n",
       " '652fca061e5cc42b1b13a0b9': 2002,\n",
       " '6525a726598c6618f06087d7': 283,\n",
       " '65316c241e5cc42b1b13dfe9': 1187,\n",
       " '6555cc214b13023f934a556a': 590,\n",
       " '651ded68a662d76276b81e79': 387,\n",
       " '651df012a662d76276b82564': 430,\n",
       " '6555c3a04b13023f9348d505': 563,\n",
       " '653169081e5cc42b1b13ca95': 1162,\n",
       " '653169101e5cc42b1b13cd02': 768,\n",
       " '6555ca604b13023f934935d2': 492,\n",
       " '652ebbca1e5cc42b1b139a8e': 573,\n",
       " '65316ed71e5cc42b1b13e7f9': 283,\n",
       " '653168b91e5cc42b1b13b6ae': 303,\n",
       " '6555c7c64b13023f9348e0fe': 1589,\n",
       " '6555cb654b13023f9349d275': 424,\n",
       " '653680061e5cc42b1b143e6a': 984,\n",
       " '651de560a662d76276b80970': 468,\n",
       " '651e18b3a662d76276b886cb': 1063,\n",
       " '651dd553a662d76276b7df9e': 695,\n",
       " '65316efc1e5cc42b1b13eb66': 317,\n",
       " '6555c1144b13023f9348ce0a': 787,\n",
       " '65316f3c1e5cc42b1b13f50a': 779,\n",
       " '6555c3c24b13023f9348d583': 825,\n",
       " '651def85a662d76276b8240b': 358,\n",
       " '65316b811e5cc42b1b13dee2': 1162,\n",
       " '65316fa81e5cc42b1b140f81': 1984,\n",
       " '6555b5394b13023f9348ba03': 1752,\n",
       " '6555c30c4b13023f9348d368': 1152,\n",
       " '651e22eca662d76276b89ee1': 554,\n",
       " '6555c1564b13023f9348cf2d': 487,\n",
       " '65316f191e5cc42b1b13ef39': 2369,\n",
       " '6555bfdb4b13023f9348c8b7': 690,\n",
       " '651de0b9a662d76276b7fd1d': 395,\n",
       " '6540c8a72936d70acf71eccb': 380,\n",
       " '651dd504a662d76276b7deed': 619,\n",
       " '6555c83f4b13023f934922d0': 933,\n",
       " '651e0f0aa662d76276b8701e': 909,\n",
       " '652ebbe01e5cc42b1b139bbf': 620,\n",
       " '6531693d1e5cc42b1b13d769': 618,\n",
       " '6555c7e74b13023f9348ebfc': 1535,\n",
       " '655585d34b13023f9348b5c9': 217,\n",
       " '6555ca904b13023f93494702': 566,\n",
       " '6555cc7f4b13023f934a99e0': 363,\n",
       " '651dee77a662d76276b82154': 1334,\n",
       " '6555c4e44b13023f9348da78': 145,\n",
       " '653169151e5cc42b1b13cea2': 629,\n",
       " '6555c1f84b13023f9348d105': 563,\n",
       " '655c1d514b13023f934af40e': 203,\n",
       " '6555ca994b13023f93494c06': 1064,\n",
       " '6555cc6c4b13023f934a8d26': 345,\n",
       " '653168701e5cc42b1b13ac08': 593,\n",
       " '651e2420a662d76276b8a1be': 717,\n",
       " '6555c0f94b13023f9348cd95': 360,\n",
       " '653169231e5cc42b1b13d2ab': 1022,\n",
       " '6555cc604b13023f934a83a0': 487,\n",
       " '6531690b1e5cc42b1b13cb8e': 553,\n",
       " '65316fa61e5cc42b1b140ec0': 1040,\n",
       " '6555c8184b13023f93490868': 790,\n",
       " '6555c7f74b13023f9348f41c': 540,\n",
       " '6555cc2a4b13023f934a5c76': 744,\n",
       " '651df20aa662d76276b82aa5': 169,\n",
       " '6555cc4f4b13023f934a7818': 576,\n",
       " '6555ca694b13023f9349384b': 1233,\n",
       " '6555cace4b13023f93496e9c': 137,\n",
       " '6531700c1e5cc42b1b14356c': 850,\n",
       " '652ebbc81e5cc42b1b139a7e': 832,\n",
       " '6555cc584b13023f934a7e5d': 545,\n",
       " '6555cc814b13023f934a9b25': 1353,\n",
       " '6555cc7b4b13023f934a96f1': 612,\n",
       " '6555cae14b13023f93497b9b': 764,\n",
       " '6555caec4b13023f9349836a': 1861,\n",
       " '651dd999a662d76276b7ea31': 968,\n",
       " '651e25f8a662d76276b8a619': 559,\n",
       " '651dd993a662d76276b7ea20': 398,\n",
       " '6536525f1e5cc42b1b143b8f': 721,\n",
       " '651dd29ea662d76276b7d88e': 431,\n",
       " '6555c81e4b13023f93490c29': 370,\n",
       " '652ebb801e5cc42b1b1398d4': 632,\n",
       " '6555cb324b13023f9349b0cd': 1027,\n",
       " '651e259ca662d76276b8a54a': 428,\n",
       " '6555c8034b13023f9348fa96': 1085,\n",
       " '651dd956a662d76276b7e97b': 945,\n",
       " '651dd7a8a662d76276b7e525': 591,\n",
       " '6555c7cc4b13023f9348e2a2': 1433,\n",
       " '6531695c1e5cc42b1b13d99a': 551,\n",
       " '651dc54ca662d76276b7b3c6': 263,\n",
       " '651dd111a662d76276b7d3ec': 186,\n",
       " '653169991e5cc42b1b13d9f2': 1139,\n",
       " '6536800b1e5cc42b1b143ec3': 1528,\n",
       " '65316f661e5cc42b1b13fdab': 1076,\n",
       " '651dfcada662d76276b843a3': 998,\n",
       " '6555ca5c4b13023f934934f1': 1135,\n",
       " '65316ca31e5cc42b1b13e0d5': 724,\n",
       " '651e1b6aa662d76276b88cef': 632,\n",
       " '651dff8da662d76276b84abf': 147,\n",
       " '651dec50a662d76276b81ba0': 1116,\n",
       " '6555ca9f4b13023f93494f30': 1273,\n",
       " '6555c5254b13023f9348db95': 460,\n",
       " '65316c5a1e5cc42b1b13e03e': 539,\n",
       " '6555ccd44b13023f934adadc': 414,\n",
       " '653169b61e5cc42b1b13da2e': 571,\n",
       " '651dddf1a662d76276b7f57e': 1093,\n",
       " '6555ca994b13023f93494b91': 1033,\n",
       " '653169a81e5cc42b1b13da0b': 653,\n",
       " '6536802f1e5cc42b1b14423d': 1865,\n",
       " '651e1b1da662d76276b88c44': 430,\n",
       " '653168c21e5cc42b1b13b880': 470,\n",
       " '651df698a662d76276b83604': 594,\n",
       " '6555bedc4b13023f9348c59d': 206,\n",
       " '651e0fafa662d76276b871ae': 327,\n",
       " '6555cc284b13023f934a5ab7': 1016,\n",
       " '6555c7fb4b13023f9348f5f6': 1619,\n",
       " '65316bb41e5cc42b1b13df37': 981,\n",
       " '6555c7cb4b13023f9348e226': 1070,\n",
       " '65316b431e5cc42b1b13de37': 551,\n",
       " '6531693f1e5cc42b1b13d792': 531,\n",
       " '6555c7f74b13023f9348f403': 1170,\n",
       " '652f4a711e5cc42b1b139cf1': 249,\n",
       " '651defb1a662d76276b82478': 720,\n",
       " '651dd5bfa662d76276b7e09b': 706,\n",
       " '6555cc1a4b13023f934a5012': 292,\n",
       " '651dc524a662d76276b7b36a': 909,\n",
       " '651dcbb2a662d76276b7c511': 297,\n",
       " '651e2475a662d76276b8a28c': 547,\n",
       " '6536802c1e5cc42b1b1441d9': 1351,\n",
       " '652fc5901e5cc42b1b139e96': 2147,\n",
       " '651dcb41a662d76276b7c3ea': 378,\n",
       " '6535e20d1e5cc42b1b143ae9': 239,\n",
       " '6555c0644b13023f9348cb19': 496,\n",
       " '651dcc66a662d76276b7c6f6': 702,\n",
       " '651e199aa662d76276b888d9': 581,\n",
       " '651df69ba662d76276b83609': 478,\n",
       " '653169201e5cc42b1b13d1dc': 508,\n",
       " '65316f531e5cc42b1b13f99f': 613,\n",
       " '653168821e5cc42b1b13ae1d': 529,\n",
       " '6555cc7e4b13023f934a98f9': 1266,\n",
       " '651df14ca662d76276b8289a': 1184,\n",
       " '6555c3884b13023f9348d4b1': 1110,\n",
       " '653168c81e5cc42b1b13b9aa': 492,\n",
       " '6555cc9b4b13023f934aacda': 1272,\n",
       " '65316f411e5cc42b1b13f5df': 1277,\n",
       " '6553534c4b13023f9348b482': 758,\n",
       " '6555c1224b13023f9348ce3e': 643,\n",
       " '6555c8384b13023f93491ead': 894,\n",
       " '6531687c1e5cc42b1b13ad69': 449,\n",
       " '651dc70ea662d76276b7b838': 837,\n",
       " '6555cb474b13023f9349be96': 1393,\n",
       " '653168281e5cc42b1b13a79c': 463,\n",
       " '65316c161e5cc42b1b13dfd5': 699,\n",
       " '651de216a662d76276b8009d': 296,\n",
       " '652fc80e1e5cc42b1b139fc2': 1480,\n",
       " '651e0efea662d76276b86fff': 933,\n",
       " '6555cc6b4b13023f934a8c39': 1049,\n",
       " '653169191e5cc42b1b13cfb6': 423,\n",
       " '651de856a662d76276b81141': 787,\n",
       " '652fd3131e5cc42b1b13a506': 726,\n",
       " '6555be974b13023f9348c48e': 980,\n",
       " '651dcf33a662d76276b7ceb5': 599,\n",
       " '651dc7a3a662d76276b7b9f1': 480,\n",
       " '653169471e5cc42b1b13d874': 670,\n",
       " '651df18ca662d76276b82949': 475,\n",
       " '6555c2954b13023f9348d27e': 385,\n",
       " '6555cb2b4b13023f9349ac92': 1128,\n",
       " '6555bee84b13023f9348c5c3': 625,\n",
       " '651ddd09a662d76276b7f333': 542,\n",
       " '6555c80f4b13023f93490240': 1413,\n",
       " '65316a1f1e5cc42b1b13db4a': 392,\n",
       " '65316fba1e5cc42b1b141567': 732,\n",
       " '65316f611e5cc42b1b13fc87': 772,\n",
       " '6531692e1e5cc42b1b13d4f8': 456,\n",
       " '651de0ffa662d76276b7fdd1': 250,\n",
       " '6555cb5a4b13023f9349cb1c': 1141,\n",
       " '6555cb5d4b13023f9349cd3d': 994,\n",
       " '652fcada1e5cc42b1b13a126': 1680,\n",
       " '651e252ea662d76276b8a458': 432,\n",
       " '6555c7f14b13023f9348f0cd': 1364,\n",
       " '6555c7d94b13023f9348e69e': 494,\n",
       " '653168771e5cc42b1b13acc1': 700,\n",
       " '651de991a662d76276b81465': 517,\n",
       " '6555b4854b13023f9348b65f': 545,\n",
       " '652df90b5669b40a3b5ab718': 239,\n",
       " '65316f871e5cc42b1b1405dd': 875,\n",
       " '6555c4774b13023f9348d8a5': 418,\n",
       " '6555cc3c4b13023f934a6a44': 650,\n",
       " '6555cca74b13023f934ab5ad': 515,\n",
       " '655b3c524b13023f934af39b': 571,\n",
       " '651dd3b3a662d76276b7db8b': 551,\n",
       " '6555ccd14b13023f934ad932': 478,\n",
       " '6555caa04b13023f93494ffb': 2081,\n",
       " '6555c7fd4b13023f9348f76d': 1665,\n",
       " '653169201e5cc42b1b13d1c6': 378,\n",
       " '6555ca944b13023f93494913': 427,\n",
       " '651dc9b7a662d76276b7bfb6': 556,\n",
       " '6525a746598c6618f06089f0': 609,\n",
       " '6531692f1e5cc42b1b13d52e': 595,\n",
       " '655c1d604b13023f934af4cb': 227,\n",
       " '6555ccb94b13023f934ac3c2': 1381,\n",
       " '6555ca614b13023f9349363e': 1804,\n",
       " '652fc8021e5cc42b1b139fbc': 1911,\n",
       " '6555cbfe4b13023f934a3c82': 872,\n",
       " '651dcbf3a662d76276b7c5c0': 307,\n",
       " '653169281e5cc42b1b13d3c6': 426,\n",
       " '651df20ca662d76276b82aac': 545,\n",
       " '6536801f1e5cc42b1b14408c': 1309,\n",
       " '651e0369a662d76276b854b3': 330,\n",
       " '653168ec1e5cc42b1b13c2c6': 256,\n",
       " '6555c7d94b13023f9348e66a': 1990,\n",
       " '6555c8104b13023f9349032c': 1683,\n",
       " '6555b5dd4b13023f9348c3cd': 1132,\n",
       " '6555cac44b13023f93496732': 1339,\n",
       " '6555c82e4b13023f934917a8': 654,\n",
       " '651dc567a662d76276b7b406': 645,\n",
       " '653169331e5cc42b1b13d5f0': 987,\n",
       " '653169481e5cc42b1b13d893': 521,\n",
       " '655434584b13023f9348b4ca': 240,\n",
       " '6535e1f71e5cc42b1b143a19': 249,\n",
       " '651e05d6a662d76276b85ab5': 626,\n",
       " '651df248a662d76276b82b4f': 448,\n",
       " '65316f9b1e5cc42b1b140b59': 527,\n",
       " '651ddf82a662d76276b7f9c9': 403,\n",
       " '65316a231e5cc42b1b13db58': 824,\n",
       " '65316efb1e5cc42b1b13eb53': 732,\n",
       " '651df702a662d76276b836fa': 600,\n",
       " '6555c0284b13023f9348ca15': 857,\n",
       " '6555c7be4b13023f9348df7d': 850,\n",
       " '6536800f1e5cc42b1b143f21': 1515,\n",
       " '652ebbc61e5cc42b1b139a65': 763,\n",
       " '6555cc314b13023f934a613a': 395,\n",
       " '65316d5c1e5cc42b1b13e25a': 1178,\n",
       " '651de394a662d76276b804d4': 362,\n",
       " '6555cc414b13023f934a6dcc': 286,\n",
       " '651dfb1aa662d76276b83fbf': 737,\n",
       " '6540de492936d70acf71edec': 1891,\n",
       " '65367fdd1e5cc42b1b143c43': 1136,\n",
       " '6555cb744b13023f9349dcfb': 655,\n",
       " '6555c9c24b13023f93492baf': 622,\n",
       " '652fc61d1e5cc42b1b139ed5': 1801,\n",
       " '65316f121e5cc42b1b13ee32': 444,\n",
       " '6555cc1f4b13023f934a5462': 1502,\n",
       " '653169031e5cc42b1b13c914': 838,\n",
       " '651deadea662d76276b817e6': 448,\n",
       " '6555c8154b13023f93490622': 743,\n",
       " '652ebbd21e5cc42b1b139aea': 988,\n",
       " '6555c1c04b13023f9348d07b': 1005,\n",
       " '651e03a4a662d76276b8554a': 287,\n",
       " '6555c8134b13023f93490527': 1052,\n",
       " '651e1dbea662d76276b89284': 1673,\n",
       " '653168b91e5cc42b1b13b6b6': 557,\n",
       " '6555c8264b13023f934911cd': 777,\n",
       " '6555cc7b4b13023f934a96ce': 399,\n",
       " '652ebb9b1e5cc42b1b13993b': 810,\n",
       " '653168cd1e5cc42b1b13bab5': 613,\n",
       " '651e2307a662d76276b89f27': 958,\n",
       " '6555cacd4b13023f93496d75': 1111,\n",
       " '65316fad1e5cc42b1b14110d': 545,\n",
       " '651dd0a3a662d76276b7d2b8': 640,\n",
       " '6555cccc4b13023f934ad42d': 947,\n",
       " '654b6a4cdc4fa72a6c403d0b': 1296,\n",
       " '653169251e5cc42b1b13d340': 261,\n",
       " '6555cc154b13023f934a4cb5': 1413,\n",
       " '651e1054a662d76276b8732b': 589,\n",
       " '6555cc2b4b13023f934a5cea': 584,\n",
       " '651ddbd1a662d76276b7efec': 804,\n",
       " '65316f791e5cc42b1b14023b': 1061,\n",
       " '6555cb594b13023f9349ca89': 523,\n",
       " '6531691a1e5cc42b1b13d032': 1331,\n",
       " '651dfeb6a662d76276b848ae': 518,\n",
       " '6555cca94b13023f934ab786': 1361,\n",
       " '651e0fc1a662d76276b871d5': 552,\n",
       " '65316f7e1e5cc42b1b140378': 1464,\n",
       " '6555c9de4b13023f93492c98': 451,\n",
       " '651ddbb6a662d76276b7efa2': 617,\n",
       " '654310d6dc4fa72a6c4037e9': 223,\n",
       " '651dceaca662d76276b7cd36': 1430,\n",
       " '6555cc3f4b13023f934a6c7c': 916,\n",
       " '6525a6f7598c6618f06085f5': 389,\n",
       " '651e1d86a662d76276b891fb': 438,\n",
       " '65316dc91e5cc42b1b13e38c': 574,\n",
       " '651e1558a662d76276b87edc': 152,\n",
       " '651dcfa2a662d76276b7cfe7': 405,\n",
       " '6555c7fe4b13023f9348f808': 1110,\n",
       " '6555cc954b13023f934aa7ee': 1499,\n",
       " '651e12a3a662d76276b878b5': 392,\n",
       " '651e0286a662d76276b85279': 589,\n",
       " '6555cb3f4b13023f9349b914': 1126,\n",
       " '65316ffd1e5cc42b1b142f31': 652,\n",
       " '6555cc364b13023f934a655f': 1003,\n",
       " '6531687b1e5cc42b1b13ad40': 472,\n",
       " '65316d921e5cc42b1b13e330': 491,\n",
       " '653169421e5cc42b1b13d7ff': 603,\n",
       " '652ebbbf1e5cc42b1b139a20': 622,\n",
       " '6555c5624b13023f9348dc9c': 942,\n",
       " '651e25b4a662d76276b8a580': 811,\n",
       " '652fc54f1e5cc42b1b139e76': 2107,\n",
       " '651e22a3a662d76276b89e2a': 577,\n",
       " '6555cb394b13023f9349b53c': 291,\n",
       " '6555b4914b13023f9348b696': 1903,\n",
       " '6555cabf4b13023f934963ff': 1028,\n",
       " '651e2257a662d76276b89d73': 858,\n",
       " '6555ccc44b13023f934acd61': 1075,\n",
       " '651e1299a662d76276b8789e': 620,\n",
       " '651e2446a662d76276b8a216': 398,\n",
       " '65316ede1e5cc42b1b13e889': 268,\n",
       " '6555ca634b13023f934936bc': 673,\n",
       " '651dedaca662d76276b81f2e': 384,\n",
       " '6555cbf24b13023f934a343b': 388,\n",
       " '65316f2a1e5cc42b1b13f1ee': 606,\n",
       " '65316f851e5cc42b1b140569': 604,\n",
       " '6555c8054b13023f9348fc56': 873,\n",
       " '651def13a662d76276b822e9': 664,\n",
       " '6555bf2f4b13023f9348c68b': 511,\n",
       " '651dd1e9a662d76276b7d670': 838,\n",
       " '65316f341e5cc42b1b13f393': 633,\n",
       " '6555cc0b4b13023f934a453e': 1514,\n",
       " '6555cad84b13023f93497517': 635,\n",
       " '6555c7c94b13023f9348e1aa': 1057,\n",
       " '653170041e5cc42b1b14328a': 836,\n",
       " '65316f6e1e5cc42b1b13ff89': 993,\n",
       " '6555c80d4b13023f9349016d': 1277,\n",
       " '65316ed41e5cc42b1b13e7bd': 1034,\n",
       " '652fd1681e5cc42b1b13a432': 1409,\n",
       " '6531693f1e5cc42b1b13d7a5': 426,\n",
       " '653168a31e5cc42b1b13b2e3': 387,\n",
       " '6531690f1e5cc42b1b13ccad': 557,\n",
       " '6555cb624b13023f9349d09d': 771,\n",
       " '655c20694b13023f934af5a4': 518,\n",
       " '6556d7654b13023f934aec8b': 444,\n",
       " '65316f8e1e5cc42b1b14079c': 637,\n",
       " '6557482a4b13023f934aef37': 552,\n",
       " '6555c7d94b13023f9348e6a9': 1061,\n",
       " '65316f181e5cc42b1b13ef14': 746,\n",
       " '6555cc7c4b13023f934a97c5': 847,\n",
       " '6536800e1e5cc42b1b143f03': 1227,\n",
       " '653169361e5cc42b1b13d664': 297,\n",
       " '651dee7da662d76276b82162': 612,\n",
       " '6555caa14b13023f93495056': 705,\n",
       " '6555cc314b13023f934a6173': 642,\n",
       " '6555cbfa4b13023f934a39af': 1141,\n",
       " '6555cc784b13023f934a9510': 594,\n",
       " '653168f81e5cc42b1b13c5e8': 280,\n",
       " '6555c4e34b13023f9348da71': 732,\n",
       " '651e160da662d76276b88084': 1194,\n",
       " '6531687d1e5cc42b1b13ad81': 603,\n",
       " '6555c7fd4b13023f9348f75e': 1845,\n",
       " '6555cbf34b13023f934a347e': 939,\n",
       " '652fc78a1e5cc42b1b139f83': 2001,\n",
       " '65316f471e5cc42b1b13f714': 1072,\n",
       " '652ebb981e5cc42b1b139931': 768,\n",
       " '652ebbb71e5cc42b1b1399dd': 785,\n",
       " '653680131e5cc42b1b143f80': 510,\n",
       " '6555cace4b13023f93496e57': 457,\n",
       " '6555c7f24b13023f9348f12d': 379,\n",
       " '6555cbc44b13023f934a1365': 1559,\n",
       " '651e1538a662d76276b87e8f': 476,\n",
       " '651e0a4ea662d76276b86518': 591,\n",
       " '6555c7fb4b13023f9348f68b': 1251,\n",
       " '6555ccc04b13023f934ac9d7': 773,\n",
       " '651dc928a662d76276b7be2e': 638,\n",
       " '651e1728a662d76276b88322': 465,\n",
       " '6555c7f64b13023f9348f387': 816,\n",
       " '6555c8324b13023f93491a3f': 1171,\n",
       " '651dd9bca662d76276b7ea8a': 593,\n",
       " '6555c8364b13023f93491d3f': 954,\n",
       " '6555caa94b13023f9349551c': 428,\n",
       " '6531688f1e5cc42b1b13afca': 745,\n",
       " '6555c80f4b13023f93490234': 1020,\n",
       " '6555cc8c4b13023f934aa226': 547,\n",
       " '653680191e5cc42b1b143ff4': 1768,\n",
       " '65316f5f1e5cc42b1b13fc0b': 994,\n",
       " '651dd25aa662d76276b7d7c5': 362,\n",
       " '65316e621e5cc42b1b13e4e9': 1063,\n",
       " '653169191e5cc42b1b13cfb2': 414,\n",
       " '6555cc1b4b13023f934a516b': 368,\n",
       " '6555bff64b13023f9348c933': 395,\n",
       " '651de47fa662d76276b8073a': 662,\n",
       " '65316f321e5cc42b1b13f342': 569,\n",
       " '652fccc81e5cc42b1b13a225': 2097,\n",
       " '651de5daa662d76276b80aad': 713,\n",
       " '6555cbf14b13023f934a3377': 478,\n",
       " '653169b71e5cc42b1b13da31': 805,\n",
       " '651e1d4da662d76276b8916f': 399,\n",
       " '6555cc344b13023f934a63e9': 869,\n",
       " '6555cc794b13023f934a95e0': 415,\n",
       " '6555cbde4b13023f934a25b9': 1200,\n",
       " '6555cb704b13023f9349da78': 935,\n",
       " '6555c7ac4b13023f9348dd90': 1810,\n",
       " '653168ae1e5cc42b1b13b49c': 1106,\n",
       " '651e0729a662d76276b85df1': 573,\n",
       " '6555c7f24b13023f9348f196': 1188,\n",
       " '651dd40aa662d76276b7dc73': 1086,\n",
       " '6555c7e24b13023f9348ea00': 1221,\n",
       " '6555cb364b13023f9349b381': 1006,\n",
       " '6555cc1d4b13023f934a52ed': 334,\n",
       " '6531683f1e5cc42b1b13a85b': 465,\n",
       " '653168ba1e5cc42b1b13b6e0': 497,\n",
       " '65367b2f1e5cc42b1b143baa': 529,\n",
       " '653168491e5cc42b1b13a8e2': 541,\n",
       " '6549a84edc4fa72a6c403b48': 233,\n",
       " '651e1c24a662d76276b88e98': 670,\n",
       " '6555cb7e4b13023f9349e3e2': 227,\n",
       " '6555cc584b13023f934a7e4c': 309,\n",
       " '6555cc2b4b13023f934a5d81': 436,\n",
       " '651de797a662d76276b80f52': 398,\n",
       " '65316a781e5cc42b1b13dc73': 998,\n",
       " '6555c7c14b13023f9348dff6': 1382,\n",
       " '653168751e5cc42b1b13ac7f': 315,\n",
       " '6555cb964b13023f9349f470': 2141,\n",
       " '6555cbaa4b13023f934a0205': 383,\n",
       " '6555cc294b13023f934a5bca': 594,\n",
       " '65316e4b1e5cc42b1b13e4aa': 254,\n",
       " '6555cc054b13023f934a4199': 232,\n",
       " '6555cae14b13023f93497b8d': 2150,\n",
       " '65316f4b1e5cc42b1b13f7ca': 496,\n",
       " '653168861e5cc42b1b13ae90': 737,\n",
       " '65316f351e5cc42b1b13f3be': 368,\n",
       " '6555c3854b13023f9348d4a7': 393,\n",
       " '651ddb28a662d76276b7ee33': 1533,\n",
       " '6555ccc94b13023f934ad169': 509,\n",
       " '651df2f1a662d76276b82d1a': 524,\n",
       " '6555ca654b13023f93493739': 1382,\n",
       " '6555ccde4b13023f934ae282': 896,\n",
       " '6531690e1e5cc42b1b13cc64': 717,\n",
       " '6555cbcf4b13023f934a1a8c': 642,\n",
       " '653680101e5cc42b1b143f26': 1086,\n",
       " '65316f8b1e5cc42b1b1406ce': 578,\n",
       " '651dffcea662d76276b84b66': 1212,\n",
       " '6555cc4a4b13023f934a7442': 1244,\n",
       " '651e07b0a662d76276b85f29': 508,\n",
       " '6555c34f4b13023f9348d3fa': 498,\n",
       " '65367ff11e5cc42b1b143d23': 557,\n",
       " '651dd37aa662d76276b7dafb': 345,\n",
       " '651e236ea662d76276b8a01a': 1801,\n",
       " '652fd1b01e5cc42b1b13a456': 1958,\n",
       " '6536801b1e5cc42b1b144023': 994,\n",
       " '6555cacd4b13023f93496dba': 941,\n",
       " '651dd467a662d76276b7dd66': 402,\n",
       " '651e0ae5a662d76276b8667e': 940,\n",
       " '6555b4914b13023f9348b697': 1748,\n",
       " '6555c7fb4b13023f9348f651': 1342,\n",
       " '651dfc2fa662d76276b8426f': 512,\n",
       " '6555c8094b13023f9348fea9': 1114,\n",
       " '655c1e874b13023f934af580': 793,\n",
       " '6555cae24b13023f93497c90': 271,\n",
       " '6555c7c74b13023f9348e142': 229,\n",
       " '6555cb804b13023f9349e549': 990,\n",
       " '6536802f1e5cc42b1b14422e': 790,\n",
       " '6555cc384b13023f934a66ae': 1980,\n",
       " '651df5caa662d76276b83427': 1149,\n",
       " '651dec9ca662d76276b81c5e': 384,\n",
       " '6555c7f04b13023f9348f047': 1266,\n",
       " '65316f891e5cc42b1b14066b': 1358,\n",
       " '6555cab54b13023f93495d4e': 488,\n",
       " '651de2a2a662d76276b80212': 301,\n",
       " '6555cac24b13023f93496649': 646,\n",
       " '6555cbc44b13023f934a139d': 1076,\n",
       " '6555b5a34b13023f9348bdec': 911,\n",
       " '6555cb604b13023f9349cf0e': 427,\n",
       " '6555ccbc4b13023f934ac6a5': 790,\n",
       " '6540c8a72936d70acf71ecc8': 458,\n",
       " '6555cbe24b13023f934a28cf': 695,\n",
       " '65316a311e5cc42b1b13db91': 977,\n",
       " '6555fe3a4b13023f934aeb61': 872,\n",
       " '65316f691e5cc42b1b13fe47': 587,\n",
       " '653168911e5cc42b1b13b02a': 1170,\n",
       " '6555cc674b13023f934a8954': 571,\n",
       " '6555c0f24b13023f9348cd72': 394,\n",
       " '6555cc344b13023f934a642a': 711,\n",
       " '6555c3f84b13023f9348d666': 422,\n",
       " '651dfcf5a662d76276b84451': 268,\n",
       " '6555cb134b13023f93499d52': 531,\n",
       " '6555c8124b13023f93490479': 1956,\n",
       " '6540c8a72936d70acf71ece1': 514,\n",
       " '6555cc4b4b13023f934a74e6': 415,\n",
       " '651df23ea662d76276b82b34': 1451,\n",
       " '651dd3dea662d76276b7dbf8': 517,\n",
       " '6525a735598c6618f06088bf': 715,\n",
       " '651dcdc4a662d76276b7caa8': 458,\n",
       " '6555bee94b13023f9348c5c9': 615,\n",
       " '651e00eea662d76276b84e56': 455,\n",
       " '6555ca5e4b13023f93493580': 1751,\n",
       " '6555cae94b13023f93498142': 1943,\n",
       " '6555f64d4b13023f934aeb0f': 549,\n",
       " '6555cb8f4b13023f9349ef6b': 895,\n",
       " '6555cc064b13023f934a423d': 428,\n",
       " '6555cc214b13023f934a55a7': 551,\n",
       " '652fc7ca1e5cc42b1b139fa2': 1950,\n",
       " '651dea03a662d76276b8158d': 988,\n",
       " '6555ccb84b13023f934ac379': 345,\n",
       " '653169081e5cc42b1b13ca8d': 698,\n",
       " '652fd3561e5cc42b1b13a526': 2349,\n",
       " '651df51ba662d76276b83284': 1707,\n",
       " '652fd2ff1e5cc42b1b13a4fc': 1743,\n",
       " '652fcbae1e5cc42b1b13a193': 1150,\n",
       " '6555cc874b13023f934a9f67': 596,\n",
       " '651de6d4a662d76276b80d5f': 1222,\n",
       " '6555caab4b13023f934956df': 517,\n",
       " '651e103ea662d76276b872f6': 533,\n",
       " '653169201e5cc42b1b13d1b1': 380,\n",
       " '651e2632a662d76276b8a69e': 348,\n",
       " '6555cc7e4b13023f934a9911': 692,\n",
       " '6555cbe04b13023f934a2746': 1456,\n",
       " '6555cbf54b13023f934a3604': 395,\n",
       " '653169191e5cc42b1b13cfac': 987,\n",
       " '651dcd90a662d76276b7ca27': 268,\n",
       " '6555cc744b13023f934a926a': 727,\n",
       " '651e19d3a662d76276b88957': 426,\n",
       " '6555c7d94b13023f9348e684': 1482,\n",
       " '6555c7f54b13023f9348f2ed': 1296,\n",
       " '6555cb914b13023f9349f0d8': 971,\n",
       " '653169271e5cc42b1b13d3bd': 553,\n",
       " '6555cc9d4b13023f934aae3e': 1266,\n",
       " '65316f0d1e5cc42b1b13ed84': 542,\n",
       " '6531691f1e5cc42b1b13d178': 663,\n",
       " '653169311e5cc42b1b13d58c': 896,\n",
       " '6555cc464b13023f934a716a': 920,\n",
       " '651df9b1a662d76276b83c5d': 235,\n",
       " '6555c80f4b13023f934902c7': 990,\n",
       " '651e1a2ea662d76276b88a28': 382,\n",
       " '6555cbcb4b13023f934a1878': 550,\n",
       " '6555cb714b13023f9349dade': 2080,\n",
       " '652fcd311e5cc42b1b13a25b': 1845,\n",
       " '6555b5cd4b13023f9348c059': 1062,\n",
       " '651e1fada662d76276b89734': 805,\n",
       " '6555caae4b13023f934958a2': 1394,\n",
       " '6555ca6c4b13023f9349391d': 1386,\n",
       " '6555ca6a4b13023f9349388b': 697,\n",
       " '6555cc2f4b13023f934a5fe5': 455,\n",
       " '65316f431e5cc42b1b13f657': 586,\n",
       " '653169ee1e5cc42b1b13dade': 606,\n",
       " '6555cbe44b13023f934a29b8': 454,\n",
       " '653168d11e5cc42b1b13bbb3': 754,\n",
       " '6531700d1e5cc42b1b1435af': 395,\n",
       " '6555cc204b13023f934a54c0': 694,\n",
       " '6555be974b13023f9348c48d': 900,\n",
       " '651e0719a662d76276b85dc8': 1038,\n",
       " '651dd2f1a662d76276b7d981': 295,\n",
       " '651dfb8da662d76276b840d0': 1010,\n",
       " '6555c4a14b13023f9348d94c': 477,\n",
       " '6555ca964b13023f93494a79': 810,\n",
       " '65316d161e5cc42b1b13e1d2': 710,\n",
       " '6555ccd64b13023f934adc8b': 562,\n",
       " '65316dfd1e5cc42b1b13e3f8': 986,\n",
       " '651de502a662d76276b80882': 501,\n",
       " '6555cc864b13023f934a9e0d': 540,\n",
       " '652df9085669b40a3b5ab6f9': 256,\n",
       " '6555c7f54b13023f9348f31a': 1123,\n",
       " '6555c8284b13023f934912bb': 1013,\n",
       " '652e31165669b40a3b5ab75f': 134,\n",
       " '65546c8b4b13023f9348b55a': 530,\n",
       " '651ddfe4a662d76276b7fada': 758,\n",
       " '653170071e5cc42b1b1433ba': 565,\n",
       " '6555c83b4b13023f934920e0': 1490,\n",
       " '65316eea1e5cc42b1b13e994': 264,\n",
       " '6555c1c34b13023f9348d082': 429,\n",
       " '6525a74a598c6618f0608a3b': 1287,\n",
       " '6555caec4b13023f934983ad': 507,\n",
       " '6555cc404b13023f934a6cf3': 702,\n",
       " '651e0ef2a662d76276b86fe0': 252,\n",
       " '651de69fa662d76276b80cc9': 166,\n",
       " '65316f081e5cc42b1b13eccf': 821,\n",
       " '653680031e5cc42b1b143e39': 1810,\n",
       " '6555c9d94b13023f93492c5f': 676,\n",
       " '6555cb844b13023f9349e7b8': 928,\n",
       " '651e1912a662d76276b887a0': 571,\n",
       " '6555c8254b13023f9349109d': 458,\n",
       " '6555cc324b13023f934a6245': 332,\n",
       " '6555c81b4b13023f93490a2b': 1569,\n",
       " '6555c7ff4b13023f9348f88e': 1291,\n",
       " '6555cbe74b13023f934a2c71': 432,\n",
       " '65316a351e5cc42b1b13db99': 693,\n",
       " '65316f8a1e5cc42b1b1406bb': 742,\n",
       " '653168981e5cc42b1b13b108': 614,\n",
       " '6555cbdd4b13023f934a24eb': 1697,\n",
       " '6555c0174b13023f9348c9cd': 621,\n",
       " '6531690b1e5cc42b1b13cb90': 950,\n",
       " '651de081a662d76276b7fc81': 629,\n",
       " '6555caca4b13023f93496bd1': 567,\n",
       " '651df803a662d76276b838e9': 496,\n",
       " '651e0ae4a662d76276b8667a': 345,\n",
       " '6540c7462936d70acf71e39f': 2223,\n",
       " '65367fe11e5cc42b1b143c6f': 1601,\n",
       " '653168c31e5cc42b1b13b896': 1274,\n",
       " '651ddda2a662d76276b7f4b5': 1239,\n",
       " '652ebbd61e5cc42b1b139b24': 891,\n",
       " '651e15daa662d76276b8800f': 327,\n",
       " '6555c3c84b13023f9348d5a5': 694,\n",
       " '6555c81b4b13023f93490a84': 770,\n",
       " '655c1d494b13023f934af3e0': 206,\n",
       " '6555c80e4b13023f934901aa': 1630,\n",
       " '65316f2f1e5cc42b1b13f2d0': 93,\n",
       " '6555c8d44b13023f9349279b': 399,\n",
       " '6555cadf4b13023f93497a68': 1289,\n",
       " '6555cba24b13023f9349fcbd': 893,\n",
       " '651de056a662d76276b7fc0b': 287,\n",
       " '651e1d5aa662d76276b8918c': 754,\n",
       " '65367ff11e5cc42b1b143d25': 1839,\n",
       " '6555bfdc4b13023f9348c8bb': 646,\n",
       " '651dc5b4a662d76276b7b4c1': 594,\n",
       " '651dea6da662d76276b816b8': 240,\n",
       " '65316ea91e5cc42b1b13e602': 1257,\n",
       " '65316ff91e5cc42b1b142ddc': 514,\n",
       " '651dfd67a662d76276b84577': 358,\n",
       " '6555c80e4b13023f934901e7': 1655,\n",
       " '651defa6a662d76276b8245a': 468,\n",
       " '6555c82a4b13023f934914d6': 585,\n",
       " '6555ccb54b13023f934ac033': 453,\n",
       " '651e0205a662d76276b85128': 315,\n",
       " '6555cbe54b13023f934a2a7a': 931,\n",
       " '652ebbae1e5cc42b1b13999f': 775,\n",
       " '65316fc11e5cc42b1b1417db': 1078,\n",
       " '653170041e5cc42b1b143264': 267,\n",
       " '6555cba74b13023f934a0025': 635,\n",
       " '651de10ea662d76276b7fdf7': 602,\n",
       " '6555c4754b13023f9348d89a': 747,\n",
       " '6555cac24b13023f934965db': 2163,\n",
       " '6555c7c24b13023f9348e045': 952,\n",
       " '6555c8044b13023f9348fbaa': 1270,\n",
       " '65316fad1e5cc42b1b141129': 764,\n",
       " '6555c8074b13023f9348fd11': 1873,\n",
       " '654310cfdc4fa72a6c40378f': 237,\n",
       " '651e0c83a662d76276b86a39': 693,\n",
       " '655c8dd9f1c0ed6a1e042295': 906,\n",
       " '6555c8114b13023f93490394': 780,\n",
       " '6555cad64b13023f934973ee': 918,\n",
       " '6555b4bc4b13023f9348b775': 1715,\n",
       " '653170081e5cc42b1b143443': 526,\n",
       " '65316f9b1e5cc42b1b140b85': 406,\n",
       " '6555cc1f4b13023f934a53cf': 920,\n",
       " '6531685f1e5cc42b1b13aa78': 545,\n",
       " '651dffefa662d76276b84bbd': 935,\n",
       " '6555c8204b13023f93490d7a': 526,\n",
       " '653680181e5cc42b1b143fe4': 184,\n",
       " '6555cc6e4b13023f934a8e4c': 775,\n",
       " '6555c0e44b13023f9348cd38': 1133,\n",
       " '651dc6faa662d76276b7b7fd': 994,\n",
       " '6555cbf54b13023f934a361b': 901,\n",
       " '6555c1e04b13023f9348d0c7': 431,\n",
       " '651de75da662d76276b80eb7': 400,\n",
       " '6555b4cf4b13023f9348b7dc': 1482,\n",
       " '6555cc794b13023f934a95f9': 570,\n",
       " '6540c8aa2936d70acf71ed82': 579,\n",
       " '6555cc2e4b13023f934a5f4f': 966,\n",
       " '6555ccbb4b13023f934ac5b7': 1028,\n",
       " '653169a21e5cc42b1b13da01': 785,\n",
       " '6555cc964b13023f934aa88e': 1521,\n",
       " '6555c1554b13023f9348cf2b': 1663,\n",
       " '651dfca3a662d76276b8438a': 575,\n",
       " '65316b661e5cc42b1b13deaf': 1029,\n",
       " '651dd22aa662d76276b7d737': 767,\n",
       " '6555cc9e4b13023f934aaf0f': 477,\n",
       " '6555be7c4b13023f9348c42b': 432,\n",
       " '651de815a662d76276b81094': 425,\n",
       " '6555bf8f4b13023f9348c78b': 484,\n",
       " '6555cac94b13023f93496b32': 1053,\n",
       " '652ebb961e5cc42b1b139925': 712,\n",
       " '6555caf94b13023f93498bf8': 708,\n",
       " '653168581e5cc42b1b13a9dd': 700,\n",
       " '651dd870a662d76276b7e730': 195,\n",
       " '6531690a1e5cc42b1b13cb36': 495,\n",
       " '651e22cea662d76276b89e93': 437,\n",
       " '6555ccc04b13023f934ac9f4': 491,\n",
       " '651de3a1a662d76276b804f8': 457,\n",
       " '651dca24a662d76276b7c0da': 476,\n",
       " '6555cc334b13023f934a632c': 570,\n",
       " '6531688d1e5cc42b1b13af76': 449,\n",
       " '6555cac14b13023f93496556': 1626,\n",
       " '65367fe81e5cc42b1b143cb6': 751,\n",
       " '651e0c73a662d76276b86a15': 444,\n",
       " '6555c7c14b13023f9348dff3': 323,\n",
       " '6555cac14b13023f93496514': 1103,\n",
       " '654856d8dc4fa72a6c403a83': 225,\n",
       " '65316f9b1e5cc42b1b140b56': 693,\n",
       " '6555cc2f4b13023f934a5ff5': 825,\n",
       " '652ebbbb1e5cc42b1b1399ff': 664,\n",
       " '65316f011e5cc42b1b13ec0e': 251,\n",
       " '65316f911e5cc42b1b1408ba': 566,\n",
       " '6555caa14b13023f9349503b': 1450,\n",
       " '65316faa1e5cc42b1b14100c': 1470,\n",
       " '65316fa21e5cc42b1b140db4': 788,\n",
       " '651e0533a662d76276b85936': 465,\n",
       " '6555ca444b13023f934930d8': 1057,\n",
       " '6555cc294b13023f934a5b49': 391,\n",
       " '6555c3b74b13023f9348d55f': 1277,\n",
       " '6531693b1e5cc42b1b13d71e': 991,\n",
       " '65316ec41e5cc42b1b13e6d9': 508,\n",
       " '6555c8304b13023f934918d3': 283,\n",
       " '6555cbd54b13023f934a1ee8': 514,\n",
       " '651e06b3a662d76276b85cd0': 320,\n",
       " '65316f701e5cc42b1b13fff8': 575,\n",
       " '651ddca2a662d76276b7f229': 661,\n",
       " '65316eca1e5cc42b1b13e720': 1226,\n",
       " '651dcec9a662d76276b7cd8c': 902,\n",
       " '651e151ba662d76276b87e4c': 468,\n",
       " '651df90aa662d76276b83ac9': 264,\n",
       " '6555c8164b13023f9349073b': 498,\n",
       " '6555c10d4b13023f9348cdeb': 1133,\n",
       " '6531692f1e5cc42b1b13d547': 716,\n",
       " '6555c11b4b13023f9348ce26': 434,\n",
       " '65316d801e5cc42b1b13e2db': 272,\n",
       " '65316fd51e5cc42b1b141f83': 615,\n",
       " '651e01b2a662d76276b8505c': 614,\n",
       " '653169321e5cc42b1b13d5c5': 1101,\n",
       " '6555c2e34b13023f9348d320': 729,\n",
       " '652ebba21e5cc42b1b13995f': 590,\n",
       " '65316fc41e5cc42b1b14191f': 839,\n",
       " '6555c39a4b13023f9348d4ef': 665,\n",
       " '6531700d1e5cc42b1b1435cc': 860,\n",
       " '6555cb6f4b13023f9349d9aa': 388,\n",
       " '6555cbd04b13023f934a1b7b': 872,\n",
       " '6555cc034b13023f934a400d': 1037,\n",
       " '651dd9fba662d76276b7eb2e': 1073,\n",
       " '6555b5aa4b13023f9348be32': 1851,\n",
       " '653168611e5cc42b1b13aaa0': 502,\n",
       " '6555cc124b13023f934a4a5f': 687,\n",
       " '6555c5744b13023f9348dce8': 822,\n",
       " '6555caf74b13023f93498acd': 835,\n",
       " '6555ccd24b13023f934ad9de': 426,\n",
       " '651dee44a662d76276b820cc': 693,\n",
       " '65316ff81e5cc42b1b142d4b': 527,\n",
       " '653169e01e5cc42b1b13dac1': 1260,\n",
       " '6555c8054b13023f9348fc1a': 803,\n",
       " '653168991e5cc42b1b13b13d': 472,\n",
       " '65316e451e5cc42b1b13e491': 509,\n",
       " '65316f891e5cc42b1b140662': 1075,\n",
       " '651e0444a662d76276b856dd': 535,\n",
       " '6531ed711e5cc42b1b1437e1': 254,\n",
       " '651deaafa662d76276b8176e': 423,\n",
       " '6555cc474b13023f934a7207': 775,\n",
       " '655acbce4b13023f934af1a8': 216,\n",
       " '653168b91e5cc42b1b13b6bc': 552,\n",
       " '65316f571e5cc42b1b13fa6c': 731,\n",
       " '651e120ca662d76276b87736': 350,\n",
       " '65316fad1e5cc42b1b1410e9': 321,\n",
       " '651e1c53a662d76276b88f0a': 809,\n",
       " '65316f6d1e5cc42b1b13ff52': 1976,\n",
       " '651e225fa662d76276b89d86': 1076,\n",
       " '6555cb654b13023f9349d258': 1437,\n",
       " '651decb5a662d76276b81ca0': 536,\n",
       " '6555bfb84b13023f9348c81e': 1182,\n",
       " '655585d74b13023f9348b602': 235,\n",
       " '65316f701e5cc42b1b140006': 2188,\n",
       " '6555b5b34b13023f9348bea6': 1839,\n",
       " '65367feb1e5cc42b1b143cd6': 1072,\n",
       " '652fc9831e5cc42b1b13a075': 1276,\n",
       " '65316f391e5cc42b1b13f489': 728,\n",
       " '65316fb31e5cc42b1b1412ec': 1077,\n",
       " '651dca8aa662d76276b7c1f7': 1383,\n",
       " '6555cb664b13023f9349d31d': 1426,\n",
       " '6531694c1e5cc42b1b13d8d7': 481,\n",
       " '651dfcd8a662d76276b8440e': 494,\n",
       " '652fce771e5cc42b1b13a305': 1419,\n",
       " '65316e201e5cc42b1b13e438': 278,\n",
       " '651ddc84a662d76276b7f1da': 904,\n",
       " '651de7c1a662d76276b80fb5': 659,\n",
       " '651e220ea662d76276b89cc6': 293,\n",
       " '6555ccd84b13023f934ade2e': 1732,\n",
       " '653169c01e5cc42b1b13da4e': 703,\n",
       " '651dfc1ea662d76276b84243': 479,\n",
       " '651e0f45a662d76276b870ae': 897,\n",
       " '6555c4974b13023f9348d922': 404,\n",
       " '651e21eea662d76276b89c7f': 426,\n",
       " '6531692c1e5cc42b1b13d4c3': 592,\n",
       " '652fcd671e5cc42b1b13a277': 1617,\n",
       " '653680201e5cc42b1b1440a6': 2031,\n",
       " ...}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98debfa6-57b3-4fdc-a66f-611d926f9aa7",
   "metadata": {},
   "source": [
    "#### Finding the token limit for articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec554d1f-f427-4429-8564-0aee5ab3acde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1733"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_template = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\" '|article_start|\\n'{''}'\\n|article_end|'\\n\"}]\n",
    "\n",
    "OUTPUT_TOKEN_LIMIT = 1024 # set based on the distribution of completion tokens from gpt4\n",
    "INSTRUCTION_TOKENS = len(tokenizer.apply_chat_template(message_template, add_generation_prompt=True))\n",
    "BUFFER_TOKENS = 10\n",
    "ARTICLE_TOKEN_LIMIT = 4096 - OUTPUT_TOKEN_LIMIT - INSTRUCTION_TOKENS - BUFFER_TOKENS\n",
    "ARTICLE_TOKEN_LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d7b8d29-b7bc-4f86-bfd6-6b822822fe0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame.from_dict(cleaned_train_set).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c8bc982-31b7-4c31-8d30-e18dc922c63b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65316a3a1e5cc42b1b13dba4    {'analysis_of_financial_or_business_news': 'Th...\n",
       "6555cb8b4b13023f9349ecdd    {'analysis_of_financial_or_business_news': 'Th...\n",
       "653168771e5cc42b1b13acc1    {'analysis_of_financial_or_business_news': 'Th...\n",
       "651dfeb6a662d76276b848ae    {'analysis_of_financial_or_business_news': 'Th...\n",
       "655c20fc4b13023f934af5cc    {'analysis_of_financial_or_business_news': 'Th...\n",
       "6555c16b4b13023f9348cf85    {'analysis_of_financial_or_business_news': 'Th...\n",
       "6555c7fb4b13023f9348f68b    {'analysis_of_financial_or_business_news': 'Th...\n",
       "651df698a662d76276b83604    {'analysis_of_financial_or_business_news': 'Th...\n",
       "6555c7fd4b13023f9348f71d    {'analysis_of_financial_or_business_news': 'Th...\n",
       "651dc7a3a662d76276b7b9f1    {'analysis_of_financial_or_business_news': 'Th...\n",
       "Name: attributes, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['attributes'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "705ed650-a113-4414-a7e4-b39024eb4373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67c030-895d-4c7d-bbe8-6ea32104ce76",
   "metadata": {},
   "source": [
    "### Setting up prompt in ChatML Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "33af3259-0675-4233-b63c-6484ea3aa555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_text_response_as_prompt(train_row):\n",
    "    truncated_content = truncate_text_to_token_limit(text=train_row['content'], encoder=tokenizer, token_limit=ARTICLE_TOKEN_LIMIT)\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{truncated_content}\\n\"}]\n",
    "    context_prompt = tokenizer.decode(tokenizer.apply_chat_template(messages, add_generation_prompt=True))\n",
    "    prompt = context_prompt + json.dumps(train_row['attributes'])\n",
    "    prompt = re.sub(r'\\n+','\\n',prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cba3d686-d495-420c-8545-ccc70cfd1256",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|> system\\nYou are the chief editor for a leading Indian financial and business news website. You evaluate critical attributes of articles to gate keep content quality. For many attributes, you will first provide a brief analysis of 15 to 30 words, followed by assessment.\\n1. analysis_of_financial_or_business_news (short text) : <analyse if article pertains to finance/business or not. government policies directly impacting indian corporations or investors are ok, but not if aren\\'t>\\n2. financial_or_business_news (True or False) : <True or False based on previous attribute>\\n3. analysis_of_relevant_for_india (short text) : <analyse if article is relevant for indians. for example international articles about 401k or small foreign companies won\\'t be relevant for india. however changes to fed interest rates or nasdaq or important news of large multinational corporations will be relevant>\\n4. relevant_for_india (True or False) : <True or False based on previous attribute>\\n5. analysis_of_article_validity_duration (short text) : <analyse relevance duration. Be stingy: Stock fluctuations, 1 day; significant policy changes - few days or a week; educational content with references to any regulations is 30 unless there are none - in which case is timeless. International news in India has shorter lifespan. breaking news are usually not timeless; quarterly analysis or results are usually valid for a 3 days, yearly analysis or results for a weeks and a much longer one for a month.>\\n6. article_validity_duration (one of 1, 3, 7, 14, 30, -1) : <calculate number of days based on previous attribute. -1: timeless. 1: article is relevant only for that day. 3: for a couple of days. 7: for a week. 14: for a couple of weeks. 30: for a month>\\n7. analysis_of_popularity (short text) : <analyse likely popularity of article - if its for niche audience, moderate_popularity or should be part of breaking_news section, depending on number of people who will be impacted by the news and the scale of the event. foreign entities known in india but not very popular will be mostly niche or rarely moderately popular. articles targeted to very specific business or pratices will be niche. infotainment business and financial articles with some drama are likely to be more popular. articles with a list of rules without compelling story-telling will be for niche audience>\\n8. popularity (one of niche, moderately_popular, breaking_news) : <based on previous attribute>\\n9. analysis_of_article_type (short text) : <analyse if the article is majorly factual, is an opinion piece, analysis, educational or likely sponsored. factual articles pass on information on events. opinion pieces have inferences or predictions either from the author or from statements without data. analysis pieces have substantial data to justify their inferences or predictions. if an article is overly zealous on certain stock and seems like an ad, then it is sponsored>\\n10. article_type (one of fact, opinion, analysis, educational, sponsored) : <based on previous attribute>\\n11. analysis_of_article_sentiment (short_text): <analyse if the sentiment of the article is bullish, bearish or NA. balanced is NA>\\n12. article_sentiment (one of bull, bear, na): <based on previous attribute>\\n13. headline_suggestion (short text) : <Write a headline based on the content of the article>\\n14. first_attempt_summary (text of 60 words) : <Generate concise, entity-dense summary. The summary should become highly dense but easily understood without the Article. limit it to no more than 60 words>\\n15. improved_summary (text of 60 words): <Identify contents of the article which are missing from the previous summary but are important part of the article>\\n16. final_summary (text of 60 words): <The finalised summary which is a mixture of first_attempt_summary and improved_summary. Don\\'t critique the summary. This summary should be very concise but also all the important information of the article and yet concise.>\\n17. top_categories (5 semi colon seperated categories): <Hierarchy of 5 categories to which this article belongs. Start with a generic category and make it progressively specific. Select only 5 and seperate them by (;). Don\\'t use either single or double quotes at any cost to avoid json.loads() failure>\\nyour response should be a json structure with all the 17 above keys without missing any key. It is very important that the response is directly readable with json.loads(). no preamble or postamble. respond in the exact following structure:\\n{\\n\"analysis_of_financial_or_business_news\": \"\",\\n\"financial_or_business_news\": \"\",\\n\"analysis_of_relevant_for_india\": \"\",\\n\"relevant_for_india\": \"\",\\n\"analysis_of_article_validity_duration\": \"\",\\n\"article_validity_duration\": \"\",\\n\"analysis_of_popularity\": \"\",\\n\"popularity\": \"\",\\n\"analysis_of_article_type\": \"\",\\n\"article_type\": \"\",\\n\"analysis_of_article_sentiment\": \"\",\\n\"article_sentiment\": \"\",\\n\"headline_suggestion\": \"\",\\n\"first_attempt_summary\": \"\",\\n\"improved_summary\": \"\",\\n\"final_summary\": \"\",\\n\"top_categories\": \"\"\\n}\\n<|im_end|> \\n<|im_start|> user\\nTata Motors cars to get costlier from today. Details here  Mint:  Tata Motors cars will become costlier from today as the automaker has raised the prices of passenger vehicles. The prices of Tata cars will be increased by an average of 0.6% depending upon the variants and models. The increase in prices of its vehicle is to partially offset the increase in input costs. In an official statement Tata Motors said the company has been absorbing a significant portion of the increased costs on account of regulatory changes and a rise in overall input costs. Therefore it is compelled to pass on some proportion through this hike. The price increase is a result of the transition to BS6 Phase 2 emission norms that came into force on 1st April 2023. All automakers are working to launch E20 fuel-ready compliant models thus resulting in a hike in the prices of the cars. This will be the second price hike by the company for its passenger vehicles after it had increased in February. The automaker had increased prices across its internal combustion engine (ICE) portfolio of passenger vehicles at an average of 1.2%. Last month Tata Motors announced price increases of up to 5% on its commercial vehicles. Tata Motors prominent car models such as Tiago Tigor Punach Harrier Nexon and Safari will become expensive from 1 May. Tata Motors aforementioned passenger vehicles have prices ranging from ₹ 5.54 lakh and ₹ 25 lakh. Not just Tata Motors other renowned automakers in India also increased the prices of passenger vehicles earlier this year. From Maruti to Hyundai to Honda carmakers escalated the prices of their cars anywhere between ₹ 2000 to ₹ 15000 depending upon the variant. \\n<|im_end|> \\n<|im_start|> assistant\\n{\"analysis_of_financial_or_business_news\": \"The article covers the cost increase of Tata Motors\\' cars due to regulatory changes and rising input costs.\", \"financial_or_business_news\": true, \"analysis_of_relevant_for_india\": \"As it is about the price change of one of the largest automakers in India, the information is directly relevant to Indian consumers and investors.\", \"relevant_for_india\": true, \"analysis_of_article_validity_duration\": \"This information is relevant for the day and possibly a few days later, until the price hike is completely factored in for consumers and investors.\", \"article_validity_duration\": 3, \"analysis_of_popularity\": \"Given the impact on potential car buyers and investors, this piece is likely to be moderately popular.\", \"popularity\": \"moderately_popular\", \"analysis_of_article_type\": \"This article is factual, stating the cost increase and reason behind it.\", \"article_type\": \"fact\", \"analysis_of_article_sentiment\": \"The sentiment in the article is neutral; it presents factual information without favoring a bullish or bearish view.\", \"article_sentiment\": \"na\", \"headline_suggestion\": \"Tata Motors Hikes Car Prices by Average of 0.6% Due to Rising Input Costs\", \"first_attempt_summary\": \"Tata Motors raises prices of passenger vehicles by 0.6% on average due to increased regulatory changes and input costs. This follows an earlier price hike in February, and other automakers have also escalated car prices earlier this year. The price change affects popular models like the Tiago, Tigor, Punach, Harrier, Nexon, and Safari.\", \"improved_summary\": \"Apart from the price rise due to input costs, the transition to BS6 Phase 2 emission norms also impacts the price. Tata Motors has also previously increased its commercial vehicles\\' prices. Renowned automakers like Maruti, Hyundai, and Honda have also increased car prices.\", \"final_summary\": \"Car prices increase by Tata Motors is averaged at 0.6%, influenced by both the implementation of BS6 phase 2 emission norms and increased input costs. The price hike impacts popular Tata models like Tiago, Tigor, Punach, Harrier, Nexon, and Safari. This follows another increase in February and is in line with cost hikes by other automakers such as Maruti, Hyundai, and Honda.\", \"top_categories\": \"Business;Automobiles;Tata Motors;Car Prices;Indian Market\"}'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_text_response_as_prompt(train_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8976a6-b82f-4312-a525-07006a113bcc",
   "metadata": {},
   "source": [
    "### Create chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d92af3f3-4bc7-4684-bcc5-6b7161db8f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7e2ba02-cea3-4573-9161-068fac132a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a9a817fbce48d2b9fb6c6389c6ddec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d2cc3bde634eee9ccd020aea94fe3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking dataset into chunks of 4096 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cbc3ac262e46af9a5b28a157c45386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 821\n",
      "Total number of samples: 821\n"
     ]
    }
   ],
   "source": [
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_text_response_as_prompt(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(template_dataset)\n",
    "# tokenize dataset\n",
    "dataset = dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(dataset.features)\n",
    ")\n",
    "# chunk dataset\n",
    "lm_dataset = pack_dataset(dataset, chunk_length=4096) # We use 4096 as the maximum length for packing\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9a2a6-93a3-44eb-bc71-fa78ef5994f1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><|im_start|>  system\\nYou are the chief editor for a leading Indian financial and business news website. You evaluate critical attributes of articles to gate keep content quality. For many attributes, you will first provide a brief analysis of 15 to 30 words, followed by assessment.\\n1. analysis_of_financial_or_business_news (short text) : <analyse if article pertains to finance/business or not. government policies directly impacting indian corporations or investors are ok, but not if aren\\'t>\\n2. financial_or_business_news (True or False) : <True or False based on previous attribute>\\n3. analysis_of_relevant_for_india (short text) : <analyse if article is relevant for indians. for example international articles about 401k or small foreign companies won\\'t be relevant for india. however changes to fed interest rates or nasdaq or important news of large multinational corporations will be relevant>\\n4. relevant_for_india (True or False) : <True or False based on previous attribute>\\n5. analysis_of_article_validity_duration (short text) : <analyse relevance duration. Be stingy: Stock fluctuations, 1 day; significant policy changes - few days or a week; educational content with references to any regulations is 30 unless there are none - in which case is timeless. International news in India has shorter lifespan. breaking news are usually not timeless; quarterly analysis or results are usually valid for a 3 days, yearly analysis or results for a weeks and a much longer one for a month.>\\n6. article_validity_duration (one of 1, 3, 7, 14, 30, -1) : <calculate number of days based on previous attribute. -1: timeless. 1: article is relevant only for that day. 3: for a couple of days. 7: for a week. 14: for a couple of weeks. 30: for a month>\\n7. analysis_of_popularity (short text) : <analyse likely popularity of article - if its for niche audience, moderate_popularity or should be part of breaking_news section, depending on number of people who will be impacted by the news and the scale of the event. foreign entities known in india but not very popular will be mostly niche or rarely moderately popular. articles targeted to very specific business or pratices will be niche. infotainment business and financial articles with some drama are likely to be more popular. articles with a list of rules without compelling story-telling will be for niche audience>\\n8. popularity (one of niche, moderately_popular, breaking_news) : <based on previous attribute>\\n9. analysis_of_article_type (short text) : <analyse if the article is majorly factual, is an opinion piece, analysis, educational or likely sponsored. factual articles pass on information on events. opinion pieces have inferences or predictions either from the author or from statements without data. analysis pieces have substantial data to justify their inferences or predictions. if an article is overly zealous on certain stock and seems like an ad, then it is sponsored>\\n10. article_type (one of fact, opinion, analysis, educational, sponsored) : <based on previous attribute>\\n11. analysis_of_article_sentiment (short_text): <analyse if the sentiment of the article is bullish, bearish or NA. balanced is NA>\\n12. article_sentiment (one of bull, bear, na): <based on previous attribute>\\n13. headline_suggestion (short text) : <Write a headline based on the content of the article>\\n14. first_attempt_summary (text of 60 words) : <Generate concise, entity-dense summary. The summary should become highly dense but easily understood without the Article. limit it to no more than 60 words>\\n15. improved_summary (text of 60 words): <Identify contents of the article which are missing from the previous summary but are important part of the article>\\n16. final_summary (text of 60 words): <The finalised summary which is a mixture of first_attempt_summary and improved_summary. Don\\'t critique the summary. This summary should be very concise but also all the important information of the article and yet concise.>\\n17. top_categories (5 semi colon seperated categories): <Hierarchy of 5 categories to which this article belongs. Start with a generic category and make it progressively specific. Select only 5 and seperate them by (;). Don\\'t use either single or double quotes at any cost to avoid json.loads() failure>\\nyour response should be a json structure with all the 17 above keys without missing any key. It is very important that the response is directly readable with json.loads(). no preamble or postamble. respond in the exact following structure:\\n{\\n\"analysis_of_financial_or_business_news\": \"\",\\n\"financial_or_business_news\": \"\",\\n\"analysis_of_relevant_for_india\": \"\",\\n\"relevant_for_india\": \"\",\\n\"analysis_of_article_validity_duration\": \"\",\\n\"article_validity_duration\": \"\",\\n\"analysis_of_popularity\": \"\",\\n\"popularity\": \"\",\\n\"analysis_of_article_type\": \"\",\\n\"article_type\": \"\",\\n\"analysis_of_article_sentiment\": \"\",\\n\"article_sentiment\": \"\",\\n\"headline_suggestion\": \"\",\\n\"first_attempt_summary\": \"\",\\n\"improved_summary\": \"\",\\n\"final_summary\": \"\",\\n\"top_categories\": \"\"\\n}\\n<|im_end|>  \\n<|im_start|>  user\\nTata Motors cars to get costlier from today. Details here  Mint:  Tata Motors cars will become costlier from today as the automaker has raised the prices of passenger vehicles. The prices of Tata cars will be increased by an average of 0.6% depending upon the variants and models. The increase in prices of its vehicle is to partially offset the increase in input costs. In an official statement Tata Motors said the company has been absorbing a significant portion of the increased costs on account of regulatory changes and a rise in overall input costs. Therefore it is compelled to pass on some proportion through this hike. The price increase is a result of the transition to BS6 Phase 2 emission norms that came into force on 1st April 2023. All automakers are working to launch E20 fuel-ready compliant models thus resulting in a hike in the prices of the cars. This will be the second price hike by the company for its passenger vehicles after it had increased in February. The automaker had increased prices across its internal combustion engine (ICE) portfolio of passenger vehicles at an average of 1.2%. Last month Tata Motors announced price increases of up to 5% on its commercial vehicles. Tata Motors prominent car models such as Tiago Tigor Punach Harrier Nexon and Safari will become expensive from 1 May. Tata Motors aforementioned passenger vehicles have prices ranging from ₹ 5.54 lakh and ₹ 25 lakh. Not just Tata Motors other renowned automakers in India also increased the prices of passenger vehicles earlier this year. From Maruti to Hyundai to Honda carmakers escalated the prices of their cars anywhere between ₹ 2000 to ₹ 15000 depending upon the variant. \\n<|im_end|>  \\n<|im_start|>  assistant\\n{\"analysis_of_article_sentiment\": \"The sentiment in the article is neutral; it presents factual information without favoring a bullish or bearish view.\", \"analysis_of_article_type\": \"This article is factual, stating the cost increase and reason behind it.\", \"analysis_of_article_validity_duration\": \"This information is relevant for the day and possibly a few days later, until the price hike is completely factored in for consumers and investors.\", \"analysis_of_financial_or_business_news\": \"The article covers the cost increase of Tata Motors\\' cars due to regulatory changes and rising input costs.\", \"analysis_of_popularity\": \"Given the impact on potential car buyers and investors, this piece is likely to be moderately popular.\", \"analysis_of_relevant_for_india\": \"As it is about the price change of one of the largest automakers in India, the information is directly relevant to Indian consumers and investors.\", \"article_sentiment\": \"na\", \"article_type\": \"fact\", \"article_validity_duration\": 3, \"final_summary\": \"Car prices increase by Tata Motors is averaged at 0.6%, influenced by both the implementation of BS6 phase 2 emission norms and increased input costs. The price hike impacts popular Tata models like Tiago, Tigor, Punach, Harrier, Nexon, and Safari. This follows another increase in February and is in line with cost hikes by other automakers such as Maruti, Hyundai, and Honda.\", \"financial_or_business_news\": true, \"first_attempt_summary\": \"Tata Motors raises prices of passenger vehicles by 0.6% on average due to increased regulatory changes and input costs. This follows an earlier price hike in February, and other automakers have also escalated car prices earlier this year. The price change affects popular models like the Tiago, Tigor, Punach, Harrier, Nexon, and Safari.\", \"headline_suggestion\": \"Tata Motors Hikes Car Prices by Average of 0.6% Due to Rising Input Costs\", \"improved_summary\": \"Apart from the price rise due to input costs, the transition to BS6 Phase 2 emission norms also impacts the price. Tata Motors has also previously increased its commercial vehicles\\' prices. Renowned automakers like Maruti, Hyundai, and Honda have also increased car prices.\", \"popularity\": \"moderately_popular\", \"relevant_for_india\": true, \"top_categories\": \"Business;Automobiles;Tata Motors;Car Prices;Indian Market\"}<|im_end|><s><|im_start|>  system\\nYou are the chief editor for a leading Indian financial and business news website. You evaluate critical attributes of articles to gate keep content quality. For many attributes, you will first provide a brief analysis of 15 to 30 words, followed by assessment.\\n1. analysis_of_financial_or_business_news (short text) : <analyse if article pertains to finance/business or not. government policies directly impacting indian corporations or investors are ok, but not if aren\\'t>\\n2. financial_or_business_news (True or False) : <True or False based on previous attribute>\\n3. analysis_of_relevant_for_india (short text) : <analyse if article is relevant for indians. for example international articles about 401k or small foreign companies won\\'t be relevant for india. however changes to fed interest rates or nasdaq or important news of large multinational corporations will be relevant>\\n4. relevant_for_india (True or False) : <True or False based on previous attribute>\\n5. analysis_of_article_validity_duration (short text) : <analyse relevance duration. Be stingy: Stock fluctuations, 1 day; significant policy changes - few days or a week; educational content with references to any regulations is 30 unless there are none - in which case is timeless. International news in India has shorter lifespan. breaking news are usually not timeless; quarterly analysis or results are usually valid for a 3 days, yearly analysis or results for a weeks and a much longer one for a month.>\\n6. article_validity_duration (one of 1, 3, 7, 14, 30, -1) : <calculate number of days based on previous attribute. -1: timeless. 1: article is relevant only for that day. 3: for a couple of days. 7: for a week. 14: for a couple of weeks. 30: for a month>\\n7. analysis_of_popularity (short text) : <analyse likely popularity of article - if its for niche audience, moderate_popularity or should be part of breaking_news section, depending on number of people who will be impacted by the news and the scale of the event. foreign entities known in india but not very popular will be mostly niche or rarely moderately popular. articles targeted to very specific business or pratices will be niche. infotainment business and financial articles with some drama are likely to be more popular. articles with a list of rules without compelling story-telling will be for niche audience>\\n8. popularity (one of niche, moderately_popular, breaking_news) : <based on previous attribute>\\n9. analysis_of_article_type (short text) : <analyse if the article is majorly factual, is an opinion piece, analysis, educational or likely sponsored. factual articles pass on information on events. opinion pieces have inferences or predictions either from the author or from statements without data. analysis pieces have substantial data to justify their inferences or predictions. if an article is overly zealous on certain stock and seems like an ad, then it is sponsored>\\n10. article_type (one of fact, opinion, analysis, educational, sponsored) : <based on previous attribute>\\n11. analysis_of_article_sentiment (short_text): <analyse if the sentiment of the article is bullish, bearish or NA. balanced is NA>\\n12. article_sentiment (one of bull, bear, na): <based on previous attribute>\\n13. headline_suggestion (short text) : <Write a headline based on the content of the article>\\n14. first_attempt_summary (text of 60 words) : <Generate concise, entity-dense summary. The summary should become highly dense but easily understood without the Article. limit it to no more than 60 words>\\n15. improved_summary (text of 60 words): <Identify contents of the article which are missing from the previous summary but are important part of the article>\\n16. final_summary (text of 60 words): <The finalised summary which is a mixture of first_attempt_summary and improved_summary. Don\\'t critique the summary. This summary should be very concise but also all the important information of the article and yet concise.>\\n17. top_categories (5 semi colon seperated categories): <Hierarchy of 5 categories to which this article belongs. Start with a generic category and make it progressively specific. Select only 5 and seperate them by (;). Don\\'t use either single or double quotes at any cost to avoid json.loads() failure>\\nyour response should be a json structure with all the 17 above keys without missing any key. It is very important that the response is directly readable with json.loads(). no preamble or postamble. respond in the exact following structure:\\n{\\n\"analysis_of_financial_or_business_news\": \"\",\\n\"financial_or_business_news\": \"\",\\n\"analysis_of_relevant_for_india\": \"\",\\n\"relevant_for_india\": \"\",\\n\"analysis_of_article_validity_duration\": \"\",\\n\"article_validity_duration\": \"\",\\n\"analysis_of_popularity\": \"\",\\n\"popularity\": \"\",\\n\"analysis_of_article_type\": \"\",\\n\"article_type\": \"\",\\n\"analysis_of_article_sentiment\": \"\",\\n\"article_sentiment\": \"\",\\n\"headline_suggestion\": \"\",\\n\"first_attempt_summary\": \"\",\\n\"improved_summary\": \"\",\\n\"final_summary\": \"\",\\n\"top_categories\": \"\"\\n}\\n<|im_end|>  \\n<|im_start|>  user\\nDont have a PAN or Aadhaar number You cannot claim an income tax refund  Mint:  My mother is a senior citizen. She had made fixed deposits with various banks. She had submitted a 15G form also for no deduction of tax at source but the bank has deducted tax  20% on interest as she does not have PAN. The bank has advised us to file her ITR to claim the refund. What should we do to get the refund Can she file her income tax return without a PAN card Answer: As per Section 206AA since your mother does not have a PAN number the bank is obliged to deduct tax  20% on the interest even if your mother has submitted form No.15G. Since your mother is a senior citizen she is required to submit form No. 15H and not 15G. A senior citizen who is a resident can only submit from No. 15 H if the total tax on his income is nil. For claiming the refund of tax already deducted by the bank it is necessary to file her income tax return (ITR). Please note that your mother can not file her ITR in case she does not have a PAN. Since your mother does not have a PAN first of all you have to apply for a PAN. However in case she has an Aadhaar Number the same can be used in place of PAN. She can submit the same to the bank with a request to revise the TDS return submitted by them to mention her PAN/Aadhaar number against her name. Please note that unless the bank carries out this correction your mother will not get credit for the tax deducted by the bank. Moreover even if your mother submits from No. 15H she has to furnish her PAN/Aadhaar failing which the bank will again deduct tax  20% on the whole of the interest. Please note that it is not mandatory to file your income tax return just because you have a PAN unless you satisfy the basic conditions requiring one to file his ITR. Balwant Jain is a tax and investment expert and can be reached at jainbalwantgmail.com and jainbalwant on'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ab7caa25-3523-4ffe-a3d3-967ccd989aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('words.txt','r') as f:\n",
    "    words = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b8d29aa2-b527-415e-8686-59994661f4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ea003389-99b6-4a68-b4cf-d6ecd7bb283a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_id = ''.join(np.random.choice(words, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cb593874-f0fb-4773-bcd2-515390d900fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9ac2a490-16c7-40ad-9f8f-fb6611e44584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-12-03'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strftime(datetime.today(),'%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9433667-f5f6-4c9a-a6a3-e19c9f50cd26",
   "metadata": {},
   "source": [
    "### Saving training data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7ac00c83-a9f6-4628-9ea4-d4679d830aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_dataset_config = {'finetune_id': finetune_id,\n",
    "                          'date': datetime.strftime(datetime.today(),'%Y-%m-%d'),\n",
    "                          'num_datapoints': len(train_set),\n",
    "                            'data_source': 'gpt4',\n",
    "                          'prompt': system_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1a4a33ee-bb12-4bc5-bd8b-c8f5fc1fc517",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WatermelonSapphireZipline'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_dataset_config['finetune_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "02d91b51-a693-47eb-b24d-3f3c715e7785",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead5ab7f884e4d4ab9497a999e139b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/821 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n",
      "training dataset to: s3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2023-12-03-WatermelonSapphireZipline\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/fine_tuning_datasets/{finetune_dataset_config[\"date\"]}-{finetune_dataset_config[\"finetune_id\"]}'\n",
    "lm_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "print(f\"training dataset to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2d38214b-3b12-4628-a7e7-e8ae50e7e7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 821\n",
       "})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a2533-b2d1-476e-bad8-1b51ecb3bdb1",
   "metadata": {},
   "source": [
    "### Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "44304c47-94f8-48db-ad95-a6a66ffb35a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'num_train_epochs': 1,                            # number of training epochs\n",
    "  'per_device_train_batch_size': 3,                 # batch size for training\n",
    "  'gradient_accumulation_steps': 2,                 # Number of updates steps to accumulate\n",
    "  'gradient_checkpointing': True,                   # save memory but slower backward pass\n",
    "  'bf16': True,                                     # use bfloat16 precision\n",
    "  'tf32': True,                                     # use tf32 precision\n",
    "  'learning_rate': 2e-4,                            # learning rate\n",
    "  'max_grad_norm': 0.3,                             # Maximum norm (for gradient clipping)\n",
    "  'warmup_ratio': 0.03,                             # warmup ratio\n",
    "  \"lr_scheduler_type\":\"cosine_with_restarts\",                   # learning rate scheduler\n",
    "  'save_strategy': \"epoch\",                         # save strategy for checkpoints\n",
    "  \"logging_steps\": 10,                              # log every x steps\n",
    "  'merge_adapters': True,                           # wether to merge LoRA into the model (needs more memory)\n",
    "  'use_flash_attn': True,                           # Whether to use Flash Attention\n",
    "  'output_dir': '/tmp/run',                         # output directory, where to save assets during training\n",
    "                                                    # could be used for checkpointing. The final trained\n",
    "                                                    # model will always be saved to s3 at the end of training\n",
    "}\n",
    "\n",
    "if HfFolder.get_token() is not None:\n",
    "    hyperparameters['hf_token'] = HfFolder.get_token() # huggingface token to access gated models, e.g. llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6908d813-bb59-4f10-9b5a-79c8830e3f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f'huggingface-qlora-{hyperparameters[\"model_id\"].replace(\"/\",\"-\").replace(\".\",\"-\")}-{finetune_dataset_config[\"finetune_id\"]}'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_qlora.py',    # train script\n",
    "    source_dir           = '../utils/',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.4xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 6*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    "    disable_output_compression = True         # not compress output to save training time and cost\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe723b0-2ef5-4f09-a59a-21162e453b6a",
   "metadata": {},
   "source": [
    "### Training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "16ae277e-1468-4629-af41-63d3400280a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-teknium-OpenHermes-2--2023-12-03-07-38-05-843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2023-12-03 07:38:07 Starting - Starting the training job...\n",
      "2023-12-03 07:38:21 Starting - Preparing the instances for training......\n",
      "2023-12-03 07:39:28 Downloading - Downloading input data...\n",
      "2023-12-03 07:39:48 Training - Downloading the training image.....................\n",
      "2023-12-03 07:43:39 Training - Training image download completed. Training in progress.......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:38,999 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:39,017 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:39,026 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:39,028 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:40,336 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.35.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 82.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.5.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 22.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting optimum==1.14.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl (398 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 398.9/398.9 kB 66.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.23.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.1/258.1 kB 29.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.41.2.post2-py3-none-any.whl (92.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.6/92.6 MB 19.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.3 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 77.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.12.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 311.7/311.7 kB 54.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 98.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting coloredlogs (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 13.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers[sentencepiece]>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (4.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (2.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (0.1.99)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 23.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (12.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (3.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.9.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: bitsandbytes, safetensors, humanfriendly, huggingface-hub, coloredlogs, tokenizers, accelerate, transformers, peft, optimum\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.14.1\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.14.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.14.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.23.0 bitsandbytes-0.41.2.post2 coloredlogs-15.0.1 huggingface-hub-0.19.4 humanfriendly-10.0 optimum-1.14.0 peft-0.5.0 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.35.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:52,968 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:52,968 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:53,010 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:53,038 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:53,066 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:53,076 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"gradient_accumulation_steps\": 2,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"cosine_with_restarts\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"teknium/OpenHermes-2.5-Mistral-7B\",\n",
      "        \"num_train_epochs\": 1,\n",
      "        \"output_dir\": \"/tmp/run\",\n",
      "        \"per_device_train_batch_size\": 3,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"use_flash_attn\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-teknium-OpenHermes-2--2023-12-03-07-38-05-843\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2023-12-03-07-38-05-843/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_qlora\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_qlora.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":2,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":0.0002,\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":1,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":3,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_qlora.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_qlora\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2023-12-03-07-38-05-843/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":2,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":0.0002,\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":1,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":3,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-teknium-OpenHermes-2--2023-12-03-07-38-05-843\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2023-12-03-07-38-05-843/source/sourcedir.tar.gz\",\"module_name\":\"run_qlora\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_qlora.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training\",\"--gradient_accumulation_steps\",\"2\",\"--gradient_checkpointing\",\"True\",\"--hf_token\",\"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\",\"--learning_rate\",\"0.0002\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"cosine_with_restarts\",\"--max_grad_norm\",\"0.3\",\"--merge_adapters\",\"True\",\"--model_id\",\"teknium/OpenHermes-2.5-Mistral-7B\",\"--num_train_epochs\",\"1\",\"--output_dir\",\"/tmp/run\",\"--per_device_train_batch_size\",\"3\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--use_flash_attn\",\"True\",\"--warmup_ratio\",\"0.03\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=2\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0002\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=cosine_with_restarts\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=teknium/OpenHermes-2.5-Mistral-7B\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/run\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=3\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FLASH_ATTN=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 2 --gradient_checkpointing True --hf_token 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 --learning_rate 0.0002 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters True --model_id teknium/OpenHermes-2.5-Mistral-7B --num_train_epochs 1 --output_dir /tmp/run --per_device_train_batch_size 3 --save_strategy epoch --tf32 True --use_flash_attn True --warmup_ratio 0.03\u001b[0m\n",
      "\u001b[34m2023-12-03 07:44:53,104 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flash-attn in /opt/conda/lib/python3.10/site-packages (0.2.8)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.3.6.tar.gz (2.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 37.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.3.6-cp310-cp310-linux_x86_64.whl size=56556525 sha256=1c918d84ff042582d547e4c9c7ec24ec9f3975589ca28cc4e6cbd15486b74f2a\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/24/5f/16/5044cdddb6dfb3331dfbffa28ab6096ec2900777af5cb0253a\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mSuccessfully installed flash-attn-2.3.6\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mLogging into the Hugging Face Hub with token hf_NjVkEqg...\u001b[0m\n",
      "\u001b[34mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\u001b[0m\n",
      "\u001b[34mToken is valid (permission: write).\u001b[0m\n",
      "\u001b[34mYour token has been saved to /root/.cache/huggingface/token\u001b[0m\n",
      "\u001b[34mLogin successful\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/624 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 624/624 [00:00<00:00, 6.12MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin.index.json: 100%|██████████| 23.9k/23.9k [00:00<00:00, 122MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   0%|          | 21.0M/9.94G [00:00<00:52, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   1%|          | 52.4M/9.94G [00:00<00:41, 241MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   1%|          | 105M/9.94G [00:00<00:30, 327MB/s] #033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   1%|▏         | 147M/9.94G [00:00<00:31, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   2%|▏         | 178M/9.94G [00:00<00:34, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   2%|▏         | 210M/9.94G [00:00<00:36, 265MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   2%|▏         | 241M/9.94G [00:00<00:34, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   3%|▎         | 273M/9.94G [00:00<00:34, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   3%|▎         | 325M/9.94G [00:01<00:28, 332MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   4%|▍         | 377M/9.94G [00:01<00:28, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   4%|▍         | 419M/9.94G [00:01<00:26, 354MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   5%|▍         | 472M/9.94G [00:01<00:24, 384MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   5%|▌         | 524M/9.94G [00:01<00:23, 408MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   6%|▌         | 577M/9.94G [00:01<00:22, 421MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   6%|▋         | 629M/9.94G [00:01<00:21, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   7%|▋         | 682M/9.94G [00:02<00:26, 345MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   7%|▋         | 724M/9.94G [00:02<00:27, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   8%|▊         | 776M/9.94G [00:02<00:24, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   8%|▊         | 818M/9.94G [00:02<00:26, 347MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   9%|▉         | 870M/9.94G [00:02<00:24, 376MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   9%|▉         | 923M/9.94G [00:02<00:22, 401MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  10%|▉         | 975M/9.94G [00:02<00:21, 421MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  10%|█         | 1.03G/9.94G [00:02<00:20, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  11%|█         | 1.08G/9.94G [00:02<00:20, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  11%|█▏        | 1.13G/9.94G [00:03<00:22, 392MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  12%|█▏        | 1.17G/9.94G [00:03<00:25, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  12%|█▏        | 1.23G/9.94G [00:03<00:24, 360MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  13%|█▎        | 1.27G/9.94G [00:03<00:26, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  13%|█▎        | 1.31G/9.94G [00:03<00:24, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  14%|█▎        | 1.35G/9.94G [00:03<00:29, 291MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  14%|█▍        | 1.39G/9.94G [00:04<00:29, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  14%|█▍        | 1.43G/9.94G [00:04<00:29, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  15%|█▍        | 1.48G/9.94G [00:04<00:25, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  15%|█▌        | 1.52G/9.94G [00:04<00:25, 332MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  16%|█▌        | 1.56G/9.94G [00:04<00:25, 333MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  16%|█▌        | 1.61G/9.94G [00:04<00:22, 368MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  17%|█▋        | 1.67G/9.94G [00:04<00:20, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  17%|█▋        | 1.72G/9.94G [00:04<00:19, 414MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  18%|█▊        | 1.77G/9.94G [00:04<00:19, 429MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  18%|█▊        | 1.82G/9.94G [00:05<00:18, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  19%|█▉        | 1.88G/9.94G [00:05<00:20, 387MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  19%|█▉        | 1.92G/9.94G [00:05<00:21, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  20%|█▉        | 1.97G/9.94G [00:05<00:20, 393MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  20%|██        | 2.02G/9.94G [00:05<00:19, 412MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  21%|██        | 2.08G/9.94G [00:05<00:19, 399MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  21%|██▏       | 2.12G/9.94G [00:05<00:21, 370MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  22%|██▏       | 2.16G/9.94G [00:06<00:23, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  22%|██▏       | 2.20G/9.94G [00:06<00:25, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  23%|██▎       | 2.25G/9.94G [00:06<00:22, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  23%|██▎       | 2.30G/9.94G [00:06<00:25, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  24%|██▎       | 2.34G/9.94G [00:06<00:25, 299MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  24%|██▍       | 2.37G/9.94G [00:06<00:27, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  24%|██▍       | 2.41G/9.94G [00:06<00:25, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  25%|██▍       | 2.46G/9.94G [00:07<00:21, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  25%|██▌       | 2.52G/9.94G [00:07<00:19, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  26%|██▌       | 2.56G/9.94G [00:07<00:26, 280MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  26%|██▋       | 2.61G/9.94G [00:07<00:22, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  27%|██▋       | 2.66G/9.94G [00:07<00:20, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  27%|██▋       | 2.72G/9.94G [00:07<00:18, 384MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  28%|██▊       | 2.77G/9.94G [00:07<00:17, 403MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  28%|██▊       | 2.82G/9.94G [00:07<00:17, 418MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  29%|██▉       | 2.87G/9.94G [00:08<00:20, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  29%|██▉       | 2.92G/9.94G [00:08<00:19, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  30%|██▉       | 2.97G/9.94G [00:08<00:17, 389MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  30%|███       | 3.02G/9.94G [00:08<00:16, 408MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  31%|███       | 3.07G/9.94G [00:08<00:16, 417MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  31%|███▏      | 3.12G/9.94G [00:08<00:18, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  32%|███▏      | 3.18G/9.94G [00:08<00:17, 390MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  32%|███▏      | 3.23G/9.94G [00:09<00:16, 408MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  33%|███▎      | 3.28G/9.94G [00:09<00:16, 409MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  34%|███▎      | 3.33G/9.94G [00:09<00:19, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  34%|███▍      | 3.38G/9.94G [00:09<00:19, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  34%|███▍      | 3.42G/9.94G [00:09<00:20, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  35%|███▍      | 3.46G/9.94G [00:09<00:22, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  35%|███▌      | 3.49G/9.94G [00:09<00:24, 268MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  35%|███▌      | 3.52G/9.94G [00:10<00:32, 196MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  36%|███▌      | 3.55G/9.94G [00:10<00:31, 201MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  36%|███▋      | 3.61G/9.94G [00:10<00:25, 252MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  37%|███▋      | 3.64G/9.94G [00:10<00:26, 237MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  37%|███▋      | 3.68G/9.94G [00:10<00:24, 254MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  37%|███▋      | 3.71G/9.94G [00:11<00:26, 239MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  38%|███▊      | 3.74G/9.94G [00:11<00:26, 234MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  38%|███▊      | 3.80G/9.94G [00:11<00:21, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  39%|███▊      | 3.85G/9.94G [00:11<00:18, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  39%|███▉      | 3.90G/9.94G [00:11<00:17, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  40%|███▉      | 3.94G/9.94G [00:11<00:16, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  40%|████      | 3.98G/9.94G [00:11<00:18, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  40%|████      | 4.03G/9.94G [00:11<00:20, 288MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  41%|████      | 4.07G/9.94G [00:12<00:19, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  41%|████▏     | 4.11G/9.94G [00:12<00:20, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  42%|████▏     | 4.15G/9.94G [00:12<00:18, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  42%|████▏     | 4.19G/9.94G [00:12<00:17, 333MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  43%|████▎     | 4.24G/9.94G [00:12<00:18, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  43%|████▎     | 4.28G/9.94G [00:12<00:16, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  44%|████▎     | 4.33G/9.94G [00:12<00:16, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  44%|████▍     | 4.37G/9.94G [00:13<00:17, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  44%|████▍     | 4.41G/9.94G [00:13<00:17, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  45%|████▍     | 4.47G/9.94G [00:13<00:15, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  45%|████▌     | 4.51G/9.94G [00:13<00:15, 347MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  46%|████▌     | 4.55G/9.94G [00:13<00:17, 316MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  46%|████▌     | 4.59G/9.94G [00:13<00:16, 320MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  47%|████▋     | 4.63G/9.94G [00:13<00:17, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  47%|████▋     | 4.68G/9.94G [00:13<00:16, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  47%|████▋     | 4.72G/9.94G [00:14<00:16, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  48%|████▊     | 4.76G/9.94G [00:14<00:16, 324MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  48%|████▊     | 4.80G/9.94G [00:14<00:15, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  49%|████▊     | 4.84G/9.94G [00:14<00:15, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  49%|████▉     | 4.89G/9.94G [00:14<00:16, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  49%|████▉     | 4.92G/9.94G [00:14<00:18, 277MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  50%|████▉     | 4.96G/9.94G [00:14<00:17, 288MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  50%|█████     | 5.00G/9.94G [00:15<00:15, 316MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  51%|█████     | 5.04G/9.94G [00:15<00:16, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  51%|█████     | 5.08G/9.94G [00:15<00:16, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  51%|█████▏    | 5.11G/9.94G [00:15<00:16, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.14G/9.94G [00:15<00:16, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.17G/9.94G [00:15<00:17, 276MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.20G/9.94G [00:15<00:18, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.24G/9.94G [00:15<00:15, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.30G/9.94G [00:16<00:13, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  54%|█████▎    | 5.34G/9.94G [00:16<00:14, 315MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.38G/9.94G [00:16<00:14, 309MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  55%|█████▍    | 5.43G/9.94G [00:16<00:12, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  55%|█████▌    | 5.48G/9.94G [00:16<00:11, 380MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.53G/9.94G [00:16<00:12, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.57G/9.94G [00:16<00:13, 333MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  56%|█████▋    | 5.61G/9.94G [00:16<00:14, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.65G/9.94G [00:17<00:15, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.69G/9.94G [00:17<00:14, 299MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.75G/9.94G [00:17<00:12, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.80G/9.94G [00:17<00:11, 375MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.85G/9.94G [00:17<00:10, 397MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.90G/9.94G [00:17<00:09, 405MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  60%|█████▉    | 5.95G/9.94G [00:17<00:10, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  60%|██████    | 6.00G/9.94G [00:18<00:10, 386MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  61%|██████    | 6.05G/9.94G [00:18<00:09, 408MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  61%|██████▏   | 6.10G/9.94G [00:18<00:09, 423MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.16G/9.94G [00:18<00:09, 404MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.20G/9.94G [00:18<00:10, 355MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.25G/9.94G [00:18<00:09, 384MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.29G/9.94G [00:18<00:09, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  64%|██████▎   | 6.33G/9.94G [00:18<00:12, 300MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.39G/9.94G [00:19<00:10, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  65%|██████▍   | 6.43G/9.94G [00:19<00:11, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  65%|██████▌   | 6.48G/9.94G [00:19<00:10, 333MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.53G/9.94G [00:19<00:09, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.57G/9.94G [00:19<00:09, 347MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.63G/9.94G [00:19<00:08, 380MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.68G/9.94G [00:19<00:08, 400MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.73G/9.94G [00:19<00:07, 421MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.78G/9.94G [00:20<00:07, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.84G/9.94G [00:20<00:10, 292MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.88G/9.94G [00:20<00:10, 288MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  70%|██████▉   | 6.92G/9.94G [00:20<00:10, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  70%|███████   | 6.96G/9.94G [00:20<00:09, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  71%|███████   | 7.01G/9.94G [00:20<00:08, 349MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  71%|███████   | 7.07G/9.94G [00:21<00:07, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.12G/9.94G [00:21<00:06, 408MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.17G/9.94G [00:21<00:07, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.21G/9.94G [00:21<00:08, 316MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.27G/9.94G [00:21<00:07, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  74%|███████▎  | 7.32G/9.94G [00:21<00:06, 380MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.37G/9.94G [00:21<00:06, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  75%|███████▍  | 7.41G/9.94G [00:22<00:07, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  75%|███████▌  | 7.47G/9.94G [00:22<00:06, 373MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.52G/9.94G [00:22<00:06, 395MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.57G/9.94G [00:22<00:06, 383MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.61G/9.94G [00:22<00:06, 381MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.65G/9.94G [00:22<00:07, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.70G/9.94G [00:22<00:07, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.75G/9.94G [00:23<00:06, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.79G/9.94G [00:23<00:07, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.83G/9.94G [00:23<00:06, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.89G/9.94G [00:23<00:05, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  80%|███████▉  | 7.94G/9.94G [00:23<00:05, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  80%|████████  | 7.99G/9.94G [00:23<00:04, 417MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  81%|████████  | 8.04G/9.94G [00:23<00:04, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  81%|████████▏ | 8.10G/9.94G [00:23<00:04, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.15G/9.94G [00:23<00:03, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.20G/9.94G [00:24<00:03, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.25G/9.94G [00:24<00:04, 418MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  84%|████████▎ | 8.30G/9.94G [00:24<00:04, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.35G/9.94G [00:24<00:04, 352MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.39G/9.94G [00:24<00:05, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  85%|████████▍ | 8.43G/9.94G [00:24<00:05, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  85%|████████▌ | 8.47G/9.94G [00:24<00:04, 309MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.52G/9.94G [00:25<00:04, 345MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  86%|████████▋ | 8.58G/9.94G [00:25<00:03, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.63G/9.94G [00:25<00:03, 402MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.67G/9.94G [00:25<00:03, 356MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.72G/9.94G [00:25<00:03, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.77G/9.94G [00:25<00:03, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  89%|████████▊ | 8.81G/9.94G [00:25<00:03, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.85G/9.94G [00:26<00:03, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.88G/9.94G [00:26<00:03, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  90%|████████▉ | 8.92G/9.94G [00:26<00:03, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  90%|█████████ | 8.97G/9.94G [00:26<00:03, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  91%|█████████ | 9.02G/9.94G [00:26<00:02, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  91%|█████████ | 9.06G/9.94G [00:26<00:02, 317MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.10G/9.94G [00:26<00:02, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.15G/9.94G [00:26<00:02, 365MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.20G/9.94G [00:27<00:02, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.24G/9.94G [00:27<00:02, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.28G/9.94G [00:27<00:02, 269MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.32G/9.94G [00:27<00:02, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.37G/9.94G [00:27<00:01, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  95%|█████████▍| 9.42G/9.94G [00:27<00:01, 353MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  95%|█████████▌| 9.47G/9.94G [00:27<00:01, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.51G/9.94G [00:28<00:01, 333MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.56G/9.94G [00:28<00:01, 365MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.60G/9.94G [00:28<00:00, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.65G/9.94G [00:28<00:00, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.69G/9.94G [00:28<00:00, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.73G/9.94G [00:28<00:00, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.77G/9.94G [00:28<00:00, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  99%|█████████▊| 9.81G/9.94G [00:29<00:00, 304MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.86G/9.94G [00:29<00:00, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.89G/9.94G [00:29<00:00, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin: 100%|█████████▉| 9.93G/9.94G [00:29<00:00, 320MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin: 100%|██████████| 9.94G/9.94G [00:29<00:00, 338MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 1/2 [00:29<00:29, 29.93s/it]\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   1%|          | 31.5M/4.54G [00:00<00:16, 269MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   1%|▏         | 62.9M/4.54G [00:00<00:15, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   2%|▏         | 105M/4.54G [00:00<00:13, 340MB/s] #033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   3%|▎         | 157M/4.54G [00:00<00:11, 393MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   4%|▍         | 199M/4.54G [00:00<00:17, 243MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   5%|▌         | 241M/4.54G [00:00<00:15, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   6%|▌         | 283M/4.54G [00:00<00:14, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   7%|▋         | 325M/4.54G [00:01<00:14, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   8%|▊         | 367M/4.54G [00:01<00:13, 316MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   9%|▉         | 419M/4.54G [00:01<00:11, 353MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  10%|█         | 461M/4.54G [00:01<00:12, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  11%|█▏        | 514M/4.54G [00:01<00:11, 358MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  12%|█▏        | 556M/4.54G [00:01<00:11, 343MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  13%|█▎        | 598M/4.54G [00:01<00:12, 321MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  14%|█▍        | 640M/4.54G [00:02<00:13, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  15%|█▍        | 671M/4.54G [00:02<00:13, 287MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  16%|█▌        | 713M/4.54G [00:02<00:12, 313MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  17%|█▋        | 755M/4.54G [00:02<00:13, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  18%|█▊        | 807M/4.54G [00:02<00:11, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  19%|█▉        | 860M/4.54G [00:02<00:10, 352MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  20%|█▉        | 902M/4.54G [00:02<00:11, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  21%|██        | 944M/4.54G [00:02<00:10, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  22%|██▏       | 986M/4.54G [00:03<00:11, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  23%|██▎       | 1.03G/4.54G [00:03<00:11, 317MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  24%|██▎       | 1.07G/4.54G [00:03<00:12, 287MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  24%|██▍       | 1.11G/4.54G [00:03<00:11, 306MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  25%|██▌       | 1.15G/4.54G [00:03<00:11, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  27%|██▋       | 1.21G/4.54G [00:03<00:09, 347MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  28%|██▊       | 1.26G/4.54G [00:03<00:08, 382MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  29%|██▉       | 1.31G/4.54G [00:04<00:07, 408MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  30%|███       | 1.36G/4.54G [00:04<00:09, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  31%|███       | 1.42G/4.54G [00:04<00:08, 371MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  32%|███▏      | 1.47G/4.54G [00:04<00:07, 396MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  33%|███▎      | 1.51G/4.54G [00:04<00:08, 369MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  34%|███▍      | 1.55G/4.54G [00:04<00:09, 302MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  35%|███▌      | 1.59G/4.54G [00:04<00:09, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  36%|███▋      | 1.65G/4.54G [00:05<00:08, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  37%|███▋      | 1.70G/4.54G [00:05<00:07, 368MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  38%|███▊      | 1.74G/4.54G [00:05<00:07, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  39%|███▉      | 1.78G/4.54G [00:05<00:08, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  40%|████      | 1.84G/4.54G [00:05<00:07, 375MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  42%|████▏     | 1.89G/4.54G [00:05<00:06, 392MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  42%|████▏     | 1.93G/4.54G [00:05<00:07, 347MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  44%|████▎     | 1.98G/4.54G [00:05<00:06, 370MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  45%|████▍     | 2.03G/4.54G [00:06<00:06, 396MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  46%|████▌     | 2.09G/4.54G [00:06<00:05, 411MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  47%|████▋     | 2.14G/4.54G [00:06<00:05, 411MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  48%|████▊     | 2.18G/4.54G [00:06<00:06, 362MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  49%|████▉     | 2.22G/4.54G [00:06<00:07, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  50%|█████     | 2.28G/4.54G [00:06<00:06, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  51%|█████▏    | 2.33G/4.54G [00:06<00:05, 378MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  52%|█████▏    | 2.38G/4.54G [00:07<00:05, 404MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  54%|█████▎    | 2.43G/4.54G [00:07<00:05, 418MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  55%|█████▍    | 2.49G/4.54G [00:07<00:04, 433MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  56%|█████▌    | 2.54G/4.54G [00:07<00:04, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  57%|█████▋    | 2.59G/4.54G [00:07<00:05, 381MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  58%|█████▊    | 2.64G/4.54G [00:07<00:04, 398MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  59%|█████▉    | 2.69G/4.54G [00:07<00:04, 421MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  61%|██████    | 2.75G/4.54G [00:07<00:04, 432MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  62%|██████▏   | 2.80G/4.54G [00:08<00:04, 400MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  63%|██████▎   | 2.84G/4.54G [00:08<00:04, 376MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  64%|██████▎   | 2.88G/4.54G [00:08<00:04, 372MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  64%|██████▍   | 2.93G/4.54G [00:08<00:05, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  65%|██████▌   | 2.97G/4.54G [00:08<00:04, 330MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  66%|██████▋   | 3.01G/4.54G [00:08<00:05, 288MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  67%|██████▋   | 3.04G/4.54G [00:08<00:05, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  68%|██████▊   | 3.08G/4.54G [00:09<00:05, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  69%|██████▉   | 3.14G/4.54G [00:09<00:04, 338MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  70%|██████▉   | 3.18G/4.54G [00:09<00:04, 334MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  71%|███████   | 3.22G/4.54G [00:09<00:04, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  72%|███████▏  | 3.27G/4.54G [00:09<00:03, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  73%|███████▎  | 3.31G/4.54G [00:09<00:04, 288MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  74%|███████▍  | 3.36G/4.54G [00:09<00:03, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  75%|███████▍  | 3.40G/4.54G [00:09<00:03, 322MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  76%|███████▌  | 3.44G/4.54G [00:10<00:03, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  77%|███████▋  | 3.48G/4.54G [00:10<00:03, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  78%|███████▊  | 3.52G/4.54G [00:10<00:03, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  79%|███████▊  | 3.58G/4.54G [00:10<00:02, 363MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  80%|███████▉  | 3.63G/4.54G [00:10<00:02, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  81%|████████  | 3.68G/4.54G [00:10<00:02, 413MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  82%|████████▏ | 3.73G/4.54G [00:11<00:02, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  83%|████████▎ | 3.77G/4.54G [00:11<00:02, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  84%|████████▍ | 3.83G/4.54G [00:11<00:02, 305MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  85%|████████▌ | 3.87G/4.54G [00:11<00:02, 318MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  86%|████████▌ | 3.91G/4.54G [00:11<00:02, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  87%|████████▋ | 3.96G/4.54G [00:11<00:01, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  88%|████████▊ | 4.02G/4.54G [00:11<00:01, 372MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  90%|████████▉ | 4.07G/4.54G [00:11<00:01, 365MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  91%|█████████ | 4.11G/4.54G [00:12<00:01, 297MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  91%|█████████▏| 4.15G/4.54G [00:12<00:01, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  92%|█████████▏| 4.19G/4.54G [00:12<00:01, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  93%|█████████▎| 4.24G/4.54G [00:12<00:01, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  94%|█████████▍| 4.28G/4.54G [00:12<00:00, 292MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  95%|█████████▌| 4.33G/4.54G [00:12<00:00, 332MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  96%|█████████▋| 4.37G/4.54G [00:13<00:00, 311MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  97%|█████████▋| 4.41G/4.54G [00:13<00:00, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  98%|█████████▊| 4.45G/4.54G [00:13<00:00, 262MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  99%|█████████▉| 4.49G/4.54G [00:13<00:00, 272MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin: 100%|█████████▉| 4.52G/4.54G [00:13<00:00, 262MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin: 100%|██████████| 4.54G/4.54G [00:13<00:00, 331MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:44<00:00, 20.67s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:44<00:00, 22.06s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.54s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.76s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.03s/it]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 120/120 [00:00<00:00, 784kB/s]\u001b[0m\n",
      "\u001b[34mFound 7 modules to quantize: ['v_proj', 'gate_proj', 'down_proj', 'o_proj', 'q_proj', 'k_proj', 'up_proj']\u001b[0m\n",
      "\u001b[34mtrainable params: 167,772,160 || all params: 7,409,520,640 || trainable%: 2.2642781922259414\u001b[0m\n",
      "\u001b[34m0%|          | 0/137 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34m1%|          | 1/137 [00:36<1:22:12, 36.26s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 2/137 [01:12<1:21:00, 36.00s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 3/137 [01:47<1:20:13, 35.93s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 4/137 [02:23<1:19:33, 35.89s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 5/137 [02:59<1:18:54, 35.87s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 6/137 [03:35<1:18:17, 35.86s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 7/137 [04:11<1:17:40, 35.85s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 8/137 [04:47<1:17:03, 35.84s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 9/137 [05:22<1:16:27, 35.84s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 10/137 [05:58<1:15:51, 35.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1459, 'learning_rate': 0.00019929278846732884, 'epoch': 0.07}\u001b[0m\n",
      "\u001b[34m7%|▋         | 10/137 [05:58<1:15:51, 35.84s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 11/137 [06:34<1:15:15, 35.84s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 12/137 [07:10<1:14:39, 35.84s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 13/137 [07:46<1:14:03, 35.83s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 14/137 [08:22<1:13:27, 35.83s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 15/137 [08:57<1:12:51, 35.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 16/137 [09:33<1:12:15, 35.83s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 17/137 [10:09<1:11:39, 35.83s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 18/137 [10:45<1:11:04, 35.83s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 19/137 [11:21<1:10:28, 35.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 20/137 [11:57<1:09:52, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7831, 'learning_rate': 0.0001936949724999762, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34m15%|█▍        | 20/137 [11:57<1:09:52, 35.83s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 21/137 [12:32<1:09:16, 35.83s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 22/137 [13:08<1:08:40, 35.83s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 23/137 [13:44<1:08:05, 35.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 24/137 [14:20<1:07:29, 35.83s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 25/137 [14:56<1:06:53, 35.83s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 26/137 [15:32<1:06:17, 35.83s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 27/137 [16:07<1:05:41, 35.83s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 28/137 [16:43<1:05:05, 35.83s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 29/137 [17:19<1:04:29, 35.83s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 30/137 [17:55<1:03:54, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7929, 'learning_rate': 0.00018281492787113708, 'epoch': 0.22}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 30/137 [17:55<1:03:54, 35.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 31/137 [18:31<1:03:18, 35.83s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 32/137 [19:07<1:02:42, 35.83s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 33/137 [19:42<1:02:07, 35.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 34/137 [20:18<1:01:31, 35.84s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 35/137 [20:54<1:00:55, 35.84s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 36/137 [21:30<1:00:19, 35.84s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 37/137 [22:06<59:43, 35.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 38/137 [22:42<59:07, 35.83s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 39/137 [23:17<58:31, 35.83s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 40/137 [23:53<57:55, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8115, 'learning_rate': 0.00016726603737012529, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34m29%|██▉       | 40/137 [23:53<57:55, 35.83s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 41/137 [24:29<57:19, 35.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 42/137 [25:05<56:44, 35.83s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 43/137 [25:41<56:08, 35.83s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 44/137 [26:17<55:32, 35.83s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 45/137 [26:52<54:56, 35.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 46/137 [27:28<54:20, 35.83s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 47/137 [28:04<53:45, 35.83s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 48/137 [28:40<53:09, 35.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 49/137 [29:16<52:33, 35.83s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 50/137 [29:52<51:57, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7888, 'learning_rate': 0.0001479248986720057, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34m36%|███▋      | 50/137 [29:52<51:57, 35.83s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 51/137 [30:27<51:21, 35.83s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 52/137 [31:03<50:45, 35.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 53/137 [31:39<50:10, 35.83s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 54/137 [32:15<49:34, 35.83s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 55/137 [32:51<48:58, 35.83s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 56/137 [33:27<48:22, 35.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 57/137 [34:02<47:46, 35.83s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 58/137 [34:38<47:10, 35.83s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 59/137 [35:14<46:35, 35.83s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 60/137 [35:50<45:59, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7765, 'learning_rate': 0.00012588190451025207, 'epoch': 0.44}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 60/137 [35:50<45:59, 35.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 61/137 [36:26<45:23, 35.83s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 62/137 [37:02<44:47, 35.83s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 63/137 [37:37<44:11, 35.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 64/137 [38:13<43:35, 35.83s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 65/137 [38:49<42:59, 35.83s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 66/137 [39:25<42:24, 35.83s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 67/137 [40:01<41:48, 35.83s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 68/137 [40:37<41:12, 35.83s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 69/137 [41:12<40:36, 35.83s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 70/137 [41:48<40:00, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7647, 'learning_rate': 0.00010237976975461075, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34m51%|█████     | 70/137 [41:48<40:00, 35.83s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 71/137 [42:24<39:25, 35.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 72/137 [43:00<38:49, 35.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 73/137 [43:36<38:13, 35.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 74/137 [44:12<37:37, 35.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 75/137 [44:47<37:01, 35.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 76/137 [45:23<36:25, 35.83s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 77/137 [45:59<35:49, 35.83s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 78/137 [46:35<35:14, 35.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 79/137 [47:11<34:38, 35.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 80/137 [47:47<34:02, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7459, 'learning_rate': 7.874347104470234e-05, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 80/137 [47:47<34:02, 35.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 81/137 [48:22<33:26, 35.83s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 82/137 [48:58<32:50, 35.83s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 83/137 [49:34<32:14, 35.83s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 84/137 [50:10<31:39, 35.83s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 85/137 [50:46<31:03, 35.83s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 86/137 [51:22<30:27, 35.83s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 87/137 [51:57<29:51, 35.83s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 88/137 [52:33<29:15, 35.83s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 89/137 [53:09<28:40, 35.83s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 90/137 [53:45<28:04, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7365, 'learning_rate': 5.630554876306407e-05, 'epoch': 0.66}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 90/137 [53:45<28:04, 35.83s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 91/137 [54:21<27:28, 35.83s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 92/137 [54:57<26:52, 35.83s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 93/137 [55:32<26:16, 35.83s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 94/137 [56:08<25:40, 35.83s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 95/137 [56:44<25:05, 35.84s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 96/137 [57:20<24:29, 35.84s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 97/137 [57:56<23:53, 35.83s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 98/137 [58:32<23:17, 35.83s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 99/137 [59:07<22:41, 35.83s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 100/137 [59:43<22:05, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7126, 'learning_rate': 3.6330982588091186e-05, 'epoch': 0.73}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 100/137 [59:43<22:05, 35.83s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 101/137 [1:00:19<21:30, 35.83s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 102/137 [1:00:55<20:54, 35.83s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 103/137 [1:01:31<20:18, 35.83s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 104/137 [1:02:07<19:42, 35.83s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 105/137 [1:02:42<19:06, 35.83s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 106/137 [1:03:18<18:30, 35.83s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 107/137 [1:03:54<17:55, 35.83s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 108/137 [1:04:30<17:19, 35.83s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 109/137 [1:05:06<16:43, 35.83s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 110/137 [1:05:42<16:07, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7745, 'learning_rate': 1.994587590756397e-05, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m80%|████████  | 110/137 [1:05:42<16:07, 35.83s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 111/137 [1:06:17<15:31, 35.83s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 112/137 [1:06:53<14:55, 35.83s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 113/137 [1:07:29<14:20, 35.83s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 114/137 [1:08:05<13:44, 35.83s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 115/137 [1:08:41<13:08, 35.83s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 116/137 [1:09:17<12:32, 35.83s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 117/137 [1:09:52<11:56, 35.83s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 118/137 [1:10:28<11:20, 35.83s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 119/137 [1:11:04<10:45, 35.83s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 120/137 [1:11:40<10:09, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7703, 'learning_rate': 8.073969641833445e-06, 'epoch': 0.88}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 120/137 [1:11:40<10:09, 35.83s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 121/137 [1:12:16<09:33, 35.83s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 122/137 [1:12:52<08:57, 35.83s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 123/137 [1:13:27<08:21, 35.83s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 124/137 [1:14:03<07:45, 35.83s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 125/137 [1:14:39<07:10, 35.83s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 126/137 [1:15:15<06:34, 35.83s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 127/137 [1:15:51<05:58, 35.83s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 128/137 [1:16:27<05:22, 35.83s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 129/137 [1:17:02<04:46, 35.83s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 130/137 [1:17:38<04:10, 35.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7396, 'learning_rate': 1.3845646281813507e-06, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 130/137 [1:17:38<04:10, 35.83s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 131/137 [1:18:14<03:35, 35.83s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 132/137 [1:18:50<02:59, 35.83s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 133/137 [1:19:26<02:23, 35.83s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 134/137 [1:20:02<01:47, 35.83s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 135/137 [1:20:37<01:11, 35.83s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 136/137 [1:21:13<00:35, 35.83s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 137/137 [1:21:43<00:00, 34.10s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 4904.8061, 'train_samples_per_second': 0.167, 'train_steps_per_second': 0.028, 'train_loss': 0.7907319277742483, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 137/137 [1:21:44<00:00, 34.10s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 137/137 [1:21:44<00:00, 35.80s/it]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 150MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 41.9M/9.94G [00:00<00:24, 399MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 94.4M/9.94G [00:00<00:22, 434MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|▏         | 147M/9.94G [00:00<00:21, 448MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 199M/9.94G [00:00<00:21, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 252M/9.94G [00:00<00:21, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 304M/9.94G [00:00<00:20, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▎         | 357M/9.94G [00:00<00:20, 471MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▍         | 409M/9.94G [00:00<00:20, 473MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▍         | 461M/9.94G [00:00<00:20, 471MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▌         | 514M/9.94G [00:01<00:20, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 566M/9.94G [00:01<00:20, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 619M/9.94G [00:01<00:20, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 671M/9.94G [00:01<00:20, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 724M/9.94G [00:01<00:20, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 776M/9.94G [00:01<00:20, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 828M/9.94G [00:01<00:19, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 881M/9.94G [00:01<00:19, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 933M/9.94G [00:02<00:19, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|▉         | 986M/9.94G [00:02<00:19, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|█         | 1.04G/9.94G [00:02<00:18, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█         | 1.09G/9.94G [00:02<00:18, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█▏        | 1.14G/9.94G [00:02<00:18, 471MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.20G/9.94G [00:02<00:18, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.25G/9.94G [00:02<00:18, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.30G/9.94G [00:02<00:18, 466MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▎        | 1.35G/9.94G [00:02<00:18, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 1.41G/9.94G [00:03<00:18, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▍        | 1.46G/9.94G [00:03<00:18, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▌        | 1.51G/9.94G [00:03<00:18, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.56G/9.94G [00:03<00:18, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.61G/9.94G [00:03<00:17, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.67G/9.94G [00:03<00:17, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.72G/9.94G [00:03<00:17, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.77G/9.94G [00:03<00:17, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.82G/9.94G [00:03<00:17, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.88G/9.94G [00:04<00:17, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.93G/9.94G [00:04<00:17, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|█▉        | 1.98G/9.94G [00:04<00:17, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|██        | 2.03G/9.94G [00:04<00:17, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.09G/9.94G [00:04<00:17, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.14G/9.94G [00:04<00:16, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.19G/9.94G [00:04<00:16, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.24G/9.94G [00:04<00:16, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.30G/9.94G [00:04<00:16, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▎       | 2.35G/9.94G [00:05<00:16, 468MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▍       | 2.40G/9.94G [00:05<00:16, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▍       | 2.45G/9.94G [00:05<00:16, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▌       | 2.51G/9.94G [00:05<00:15, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.56G/9.94G [00:05<00:15, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▋       | 2.61G/9.94G [00:05<00:15, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.66G/9.94G [00:05<00:15, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.72G/9.94G [00:05<00:15, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.77G/9.94G [00:05<00:15, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.82G/9.94G [00:06<00:15, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.87G/9.94G [00:06<00:15, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.93G/9.94G [00:06<00:14, 475MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|██▉       | 2.98G/9.94G [00:06<00:14, 478MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|███       | 3.03G/9.94G [00:06<00:14, 480MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 3.08G/9.94G [00:06<00:14, 479MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.14G/9.94G [00:06<00:14, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.19G/9.94G [00:06<00:14, 477MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.24G/9.94G [00:06<00:14, 479MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.29G/9.94G [00:07<00:13, 478MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▎      | 3.34G/9.94G [00:07<00:13, 475MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▍      | 3.40G/9.94G [00:07<00:13, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▍      | 3.45G/9.94G [00:07<00:13, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▌      | 3.50G/9.94G [00:07<00:13, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.55G/9.94G [00:07<00:13, 473MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▋      | 3.61G/9.94G [00:07<00:13, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.66G/9.94G [00:07<00:13, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.71G/9.94G [00:07<00:13, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.76G/9.94G [00:08<00:13, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.82G/9.94G [00:08<00:12, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.87G/9.94G [00:08<00:12, 473MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.92G/9.94G [00:08<00:12, 478MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|███▉      | 3.97G/9.94G [00:08<00:12, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|████      | 4.03G/9.94G [00:08<00:12, 476MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.08G/9.94G [00:08<00:12, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.13G/9.94G [00:08<00:12, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.18G/9.94G [00:09<00:14, 409MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.24G/9.94G [00:09<00:13, 430MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.29G/9.94G [00:09<00:12, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▎     | 4.34G/9.94G [00:09<00:12, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▍     | 4.39G/9.94G [00:09<00:12, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▍     | 4.45G/9.94G [00:09<00:12, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▌     | 4.50G/9.94G [00:09<00:11, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.55G/9.94G [00:09<00:11, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▋     | 4.60G/9.94G [00:09<00:11, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.66G/9.94G [00:10<00:17, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.71G/9.94G [00:10<00:15, 337MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.76G/9.94G [00:10<00:14, 368MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.81G/9.94G [00:10<00:13, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▉     | 4.87G/9.94G [00:10<00:12, 413MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▉     | 4.92G/9.94G [00:10<00:11, 431MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|████▉     | 4.97G/9.94G [00:10<00:11, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.02G/9.94G [00:11<00:10, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.08G/9.94G [00:11<00:10, 453MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.13G/9.94G [00:11<00:10, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.18G/9.94G [00:11<00:10, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.23G/9.94G [00:11<00:10, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.28G/9.94G [00:11<00:10, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▎    | 5.34G/9.94G [00:11<00:10, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▍    | 5.39G/9.94G [00:11<00:09, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▍    | 5.44G/9.94G [00:11<00:09, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▌    | 5.49G/9.94G [00:12<00:09, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.55G/9.94G [00:12<00:09, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▋    | 5.60G/9.94G [00:12<00:09, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.65G/9.94G [00:12<00:09, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.70G/9.94G [00:12<00:09, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.76G/9.94G [00:12<00:09, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.81G/9.94G [00:12<00:09, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.86G/9.94G [00:12<00:08, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.91G/9.94G [00:12<00:08, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|██████    | 5.97G/9.94G [00:13<00:08, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.02G/9.94G [00:13<00:08, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.07G/9.94G [00:13<00:08, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.12G/9.94G [00:13<00:08, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.18G/9.94G [00:13<00:07, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.23G/9.94G [00:13<00:07, 473MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.28G/9.94G [00:13<00:07, 475MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▎   | 6.33G/9.94G [00:13<00:07, 471MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.39G/9.94G [00:13<00:07, 473MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.44G/9.94G [00:14<00:07, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.49G/9.94G [00:14<00:07, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.54G/9.94G [00:14<00:07, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▋   | 6.60G/9.94G [00:14<00:07, 473MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.65G/9.94G [00:14<00:07, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.70G/9.94G [00:14<00:08, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.75G/9.94G [00:14<00:08, 389MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.81G/9.94G [00:14<00:07, 409MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.86G/9.94G [00:15<00:07, 423MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.91G/9.94G [00:15<00:07, 431MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 6.96G/9.94G [00:15<00:06, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.01G/9.94G [00:15<00:06, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.07G/9.94G [00:15<00:06, 453MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.12G/9.94G [00:15<00:06, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.17G/9.94G [00:15<00:06, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.22G/9.94G [00:15<00:05, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.28G/9.94G [00:15<00:05, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▎  | 7.33G/9.94G [00:16<00:05, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.38G/9.94G [00:16<00:05, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▍  | 7.43G/9.94G [00:16<00:05, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▌  | 7.49G/9.94G [00:16<00:05, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.54G/9.94G [00:16<00:05, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▋  | 7.59G/9.94G [00:16<00:05, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.64G/9.94G [00:16<00:05, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.70G/9.94G [00:16<00:05, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.75G/9.94G [00:16<00:04, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.80G/9.94G [00:17<00:04, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.85G/9.94G [00:17<00:04, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.91G/9.94G [00:17<00:04, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 7.96G/9.94G [00:17<00:04, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.01G/9.94G [00:17<00:04, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.06G/9.94G [00:17<00:04, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.12G/9.94G [00:17<00:03, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.17G/9.94G [00:17<00:03, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.22G/9.94G [00:18<00:03, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.27G/9.94G [00:18<00:03, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▎ | 8.33G/9.94G [00:18<00:03, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.38G/9.94G [00:18<00:03, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.43G/9.94G [00:18<00:03, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.48G/9.94G [00:18<00:03, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.54G/9.94G [00:18<00:02, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▋ | 8.59G/9.94G [00:18<00:02, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.64G/9.94G [00:18<00:02, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.69G/9.94G [00:19<00:02, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.75G/9.94G [00:19<00:02, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.80G/9.94G [00:19<00:02, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.85G/9.94G [00:19<00:02, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.90G/9.94G [00:19<00:02, 471MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 8.95G/9.94G [00:19<00:02, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.01G/9.94G [00:19<00:01, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.06G/9.94G [00:19<00:01, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.11G/9.94G [00:19<00:01, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.16G/9.94G [00:20<00:01, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.22G/9.94G [00:20<00:01, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.27G/9.94G [00:20<00:01, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.32G/9.94G [00:20<00:01, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.37G/9.94G [00:20<00:01, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.43G/9.94G [00:20<00:01, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.48G/9.94G [00:20<00:00, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.53G/9.94G [00:20<00:00, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▋| 9.58G/9.94G [00:20<00:00, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.64G/9.94G [00:21<00:00, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.69G/9.94G [00:21<00:00, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.74G/9.94G [00:21<00:00, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.79G/9.94G [00:21<00:00, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.85G/9.94G [00:21<00:00, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.90G/9.94G [00:21<00:00, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|██████████| 9.94G/9.94G [00:21<00:00, 458MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 1/2 [00:21<00:21, 21.95s/it]\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   1%|          | 41.9M/4.54G [00:00<00:10, 416MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   2%|▏         | 94.4M/4.54G [00:00<00:09, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   3%|▎         | 147M/4.54G [00:00<00:09, 462MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   4%|▍         | 199M/4.54G [00:00<00:09, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   6%|▌         | 252M/4.54G [00:00<00:09, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   7%|▋         | 304M/4.54G [00:00<00:09, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   8%|▊         | 357M/4.54G [00:00<00:09, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▉         | 409M/4.54G [00:00<00:08, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|█         | 461M/4.54G [00:01<00:08, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  11%|█▏        | 514M/4.54G [00:01<00:08, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 566M/4.54G [00:01<00:08, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  14%|█▎        | 619M/4.54G [00:01<00:08, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▍        | 671M/4.54G [00:01<00:08, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▌        | 724M/4.54G [00:01<00:08, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 776M/4.54G [00:01<00:08, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 828M/4.54G [00:01<00:08, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  19%|█▉        | 881M/4.54G [00:01<00:07, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██        | 933M/4.54G [00:02<00:07, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  22%|██▏       | 986M/4.54G [00:02<00:07, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  23%|██▎       | 1.04G/4.54G [00:02<00:07, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 1.09G/4.54G [00:02<00:07, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  25%|██▌       | 1.14G/4.54G [00:02<00:07, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  26%|██▋       | 1.20G/4.54G [00:02<00:07, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  27%|██▋       | 1.25G/4.54G [00:02<00:11, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  29%|██▊       | 1.30G/4.54G [00:03<00:09, 327MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|██▉       | 1.35G/4.54G [00:03<00:08, 357MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  31%|███       | 1.41G/4.54G [00:03<00:08, 381MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  32%|███▏      | 1.46G/4.54G [00:03<00:07, 404MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  33%|███▎      | 1.51G/4.54G [00:03<00:07, 421MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  34%|███▍      | 1.56G/4.54G [00:03<00:06, 432MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▌      | 1.61G/4.54G [00:03<00:06, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 1.67G/4.54G [00:03<00:06, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  38%|███▊      | 1.72G/4.54G [00:03<00:06, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.77G/4.54G [00:04<00:06, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  40%|████      | 1.82G/4.54G [00:04<00:06, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  41%|████▏     | 1.88G/4.54G [00:04<00:06, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.93G/4.54G [00:04<00:05, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  44%|████▎     | 1.98G/4.54G [00:04<00:05, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▍     | 2.03G/4.54G [00:04<00:05, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▌     | 2.09G/4.54G [00:04<00:05, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 2.14G/4.54G [00:04<00:05, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.19G/4.54G [00:05<00:05, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 2.24G/4.54G [00:05<00:04, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████     | 2.30G/4.54G [00:05<00:05, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 2.35G/4.54G [00:05<00:04, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  53%|█████▎    | 2.40G/4.54G [00:05<00:04, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  54%|█████▍    | 2.45G/4.54G [00:05<00:04, 429MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▌    | 2.51G/4.54G [00:05<00:04, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  56%|█████▋    | 2.56G/4.54G [00:05<00:04, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.61G/4.54G [00:05<00:04, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  59%|█████▊    | 2.66G/4.54G [00:06<00:04, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  60%|█████▉    | 2.72G/4.54G [00:06<00:03, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.77G/4.54G [00:06<00:03, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.82G/4.54G [00:06<00:03, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.87G/4.54G [00:06<00:03, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▍   | 2.93G/4.54G [00:06<00:03, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  66%|██████▌   | 2.98G/4.54G [00:06<00:03, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.03G/4.54G [00:06<00:03, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 3.08G/4.54G [00:07<00:03, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  69%|██████▉   | 3.14G/4.54G [00:07<00:03, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  70%|███████   | 3.19G/4.54G [00:07<00:02, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████▏  | 3.24G/4.54G [00:07<00:02, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.29G/4.54G [00:08<00:11, 109MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.33G/4.54G [00:10<00:20, 58.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▍  | 3.37G/4.54G [00:11<00:24, 47.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▍  | 3.39G/4.54G [00:12<00:26, 42.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▌  | 3.41G/4.54G [00:12<00:29, 39.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▌  | 3.42G/4.54G [00:13<00:30, 37.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.43G/4.54G [00:13<00:31, 35.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.44G/4.54G [00:14<00:32, 34.2MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.45G/4.54G [00:14<00:33, 32.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.46G/4.54G [00:14<00:34, 31.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▋  | 3.47G/4.54G [00:15<00:34, 30.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.48G/4.54G [00:15<00:35, 30.2MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.49G/4.54G [00:15<00:35, 29.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.50G/4.54G [00:16<00:35, 29.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.51G/4.54G [00:16<00:35, 29.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.52G/4.54G [00:16<00:35, 29.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.53G/4.54G [00:17<00:34, 28.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.54G/4.54G [00:17<00:34, 28.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.55G/4.54G [00:18<00:34, 28.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▊  | 3.57G/4.54G [00:18<00:34, 28.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▊  | 3.58G/4.54G [00:18<00:33, 28.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▉  | 3.59G/4.54G [00:19<00:33, 28.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▉  | 3.60G/4.54G [00:19<00:33, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▉  | 3.61G/4.54G [00:19<00:32, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|███████▉  | 3.62G/4.54G [00:20<00:32, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|███████▉  | 3.63G/4.54G [00:20<00:32, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|████████  | 3.64G/4.54G [00:21<00:31, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|████████  | 3.65G/4.54G [00:21<00:31, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████  | 3.66G/4.54G [00:21<00:30, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████  | 3.67G/4.54G [00:22<00:31, 27.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████  | 3.68G/4.54G [00:22<00:29, 28.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████▏ | 3.69G/4.54G [00:22<00:29, 28.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.70G/4.54G [00:23<00:29, 28.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.71G/4.54G [00:23<00:29, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.72G/4.54G [00:23<00:28, 28.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.73G/4.54G [00:24<00:28, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.74G/4.54G [00:24<00:27, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.75G/4.54G [00:25<00:27, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.76G/4.54G [00:25<00:30, 25.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.77G/4.54G [00:25<00:29, 26.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.79G/4.54G [00:26<00:28, 26.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▎ | 3.80G/4.54G [00:26<00:27, 27.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▍ | 3.81G/4.54G [00:27<00:26, 27.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▍ | 3.82G/4.54G [00:27<00:25, 27.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▍ | 3.83G/4.54G [00:27<00:25, 28.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▍ | 3.84G/4.54G [00:28<00:24, 28.2MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▍ | 3.85G/4.54G [00:28<00:24, 28.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▍ | 3.86G/4.54G [00:28<00:24, 28.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▌ | 3.87G/4.54G [00:29<00:23, 28.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▌ | 3.88G/4.54G [00:29<00:23, 28.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.89G/4.54G [00:30<00:22, 28.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.90G/4.54G [00:30<00:22, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.91G/4.54G [00:30<00:22, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▋ | 3.92G/4.54G [00:31<00:21, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.93G/4.54G [00:31<00:21, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.94G/4.54G [00:31<00:20, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.95G/4.54G [00:32<00:20, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.96G/4.54G [00:32<00:20, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 3.97G/4.54G [00:32<00:19, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 3.98G/4.54G [00:33<00:19, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 4.00G/4.54G [00:33<00:19, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 4.01G/4.54G [00:34<00:18, 28.5MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 4.02G/4.54G [00:34<00:18, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▊ | 4.03G/4.54G [00:34<00:18, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 4.04G/4.54G [00:35<00:17, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 4.05G/4.54G [00:35<00:17, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 4.06G/4.54G [00:35<00:16, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|████████▉ | 4.07G/4.54G [00:36<00:16, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|████████▉ | 4.08G/4.54G [00:36<00:16, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|█████████ | 4.09G/4.54G [00:37<00:15, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|█████████ | 4.10G/4.54G [00:37<00:15, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.11G/4.54G [00:37<00:15, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.12G/4.54G [00:38<00:14, 28.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.13G/4.54G [00:38<00:14, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.14G/4.54G [00:38<00:13, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████▏| 4.15G/4.54G [00:39<00:13, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.16G/4.54G [00:39<00:13, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.17G/4.54G [00:39<00:12, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.18G/4.54G [00:40<00:12, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.19G/4.54G [00:40<00:12, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.20G/4.54G [00:41<00:11, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.22G/4.54G [00:41<00:11, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.23G/4.54G [00:41<00:11, 28.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.24G/4.54G [00:42<00:10, 28.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▎| 4.25G/4.54G [00:42<00:10, 28.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.26G/4.54G [00:43<00:11, 24.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.27G/4.54G [00:43<00:11, 22.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.28G/4.54G [00:43<00:10, 24.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.29G/4.54G [00:44<00:11, 22.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▍| 4.30G/4.54G [00:45<00:11, 21.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▍| 4.31G/4.54G [00:45<00:10, 22.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▌| 4.32G/4.54G [00:46<00:10, 21.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▌| 4.33G/4.54G [00:46<00:09, 23.2MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 4.34G/4.54G [00:46<00:09, 22.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 4.35G/4.54G [00:47<00:08, 23.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 4.36G/4.54G [00:47<00:07, 24.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▋| 4.37G/4.54G [00:48<00:07, 22.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.38G/4.54G [00:48<00:06, 24.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.39G/4.54G [00:49<00:06, 22.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.40G/4.54G [00:49<00:05, 23.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.41G/4.54G [00:49<00:05, 25.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.42G/4.54G [00:50<00:05, 23.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.44G/4.54G [00:50<00:04, 24.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.45G/4.54G [00:51<00:03, 25.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.46G/4.54G [00:51<00:03, 23.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.47G/4.54G [00:52<00:03, 24.5MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▊| 4.48G/4.54G [00:52<00:02, 22.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▉| 4.49G/4.54G [00:52<00:02, 24.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▉| 4.50G/4.54G [00:53<00:01, 25.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▉| 4.51G/4.54G [00:53<00:01, 23.2MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|█████████▉| 4.52G/4.54G [00:54<00:00, 24.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|█████████▉| 4.53G/4.54G [00:54<00:00, 25.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|█████████▉| 4.54G/4.54G [00:55<00:00, 23.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|██████████| 4.54G/4.54G [00:55<00:00, 82.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [01:17<00:00, 41.64s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [01:17<00:00, 38.69s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.25s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.01s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 1.60k/1.60k [00:00<00:00, 18.3MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 502MB/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json: 100%|██████████| 51.0/51.0 [00:00<00:00, 448kB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 101/101 [00:00<00:00, 917kB/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m2023-12-03 09:12:58,357 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-12-03 09:12:58,358 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-12-03 09:12:58,358 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-12-03 09:13:59 Uploading - Uploading generated training model\n",
      "2023-12-03 09:14:30 Completed - Training job completed\n",
      "Training seconds: 5701\n",
      "Billable seconds: 5701\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_input_path}\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9cb916-6469-4746-b97b-6c2ba4e96922",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7a185fae-6b17-45bd-96aa-73e005c40e68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py39\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: gpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"1.1.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7b3444f4-9c5d-45c6-9cb6-a01b7fa21c97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e457d6f3-2023-43c5-81ac-6b294aef5182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0863cbb-9c81-429e-bf67-3a42eb21d49d",
   "metadata": {},
   "source": [
    "#### Download model to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f77dc39d-8448-4486-b99f-cf004d2c3238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize a boto3 S3 client\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d3fe2c7f-c46f-4656-aea4-dc0a40e73b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-tgi-inference-2023-12-03-10-21-58-396'"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "442df457-92f1-4714-80c5-5c63a8af3a61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize a boto3 S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# S3 bucket and folder details\n",
    "bucket_name = 'sagemaker-ap-south-1-005418323977'\n",
    "s3_folder = 's3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2023-12-03-07-38-05-843'\n",
    "\n",
    "# Local directory to save files\n",
    "local_folder = './OpenHermes_WatermelonSapphireZipline/'\n",
    "\n",
    "# List objects within the specified S3 folder\n",
    "objects = s3.list_objects_v2(Bucket=bucket_name, Prefix=s3_folder)\n",
    "\n",
    "# Download each file in the folder\n",
    "for obj in objects.get('Contents', []):\n",
    "    s3_file_path = obj['Key']\n",
    "    local_file_path = os.path.join(local_folder, s3_file_path[len(s3_folder):])\n",
    "    os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "    s3.download_file(bucket_name, s3_file_path, local_file_path)\n",
    "    print(f'Downloaded {s3_file_path} to {local_file_path}')\n",
    "# Remember to replace 'your-bucket-name', 'your-folder-name/', and 'path/to/local/folder/' with your actual bucket name, S3 folder, and local folder path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0987420a-1b54-4a7f-9e9c-a6d47040dc6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dadea77f-af0e-4af4-86b1-fe89bdab5460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "from huggingface_hub import HfFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a50e7d2-750a-4a5e-a290-e9af74556410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4404f88-4c84-44bf-9a97-3bca77d85a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.35.2'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f39327ad-1171-49c8-9044-e7e270735244",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /private/var/folders/d4/cgyr_gnj7nn2wy_hq40gkq8c0000gq/T/pip-req-build-fvqwwsub\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /private/var/folders/d4/cgyr_gnj7nn2wy_hq40gkq8c0000gq/T/pip-req-build-fvqwwsub\n",
      "  Resolved https://github.com/huggingface/transformers to commit 3bc50d81e6c70d63e59d635106bac6a561b47681\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (2023.7.22)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.36.0.dev0-py3-none-any.whl size=8048947 sha256=38109c4d4a4b05baf5d143f483a397e952fdded8c2a4b4dc9c36e75e3483b40d\n",
      "  Stored in directory: /private/var/folders/d4/cgyr_gnj7nn2wy_hq40gkq8c0000gq/T/pip-ephem-wheel-cache-pab9gusl/wheels/14/a0/7b/8f6b25ba4110aa215fcb8d6aedd6cd4f9b9b6619190999ac2b\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.35.2\n",
      "    Uninstalling transformers-4.35.2:\n",
      "      Successfully uninstalled transformers-4.35.2\n",
      "Successfully installed transformers-4.36.0.dev0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134d41c8-83a2-4c58-bb55-6aec92acf4a5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/username/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88278256-a9cd-4662-84db-439006947434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3aa33-dc5d-414b-92c6-fc9dd5b9237b",
   "metadata": {},
   "source": [
    "### Upload to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee7ff3fb-d610-4cbb-9328-ab06b8ed2c49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05414f7ba934c368ebd1b36467ab559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('./hermes_finetuned_model/', local_files_only = True, torch_dtype = torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8bcbba1-e789-4e44-8d4b-e03010095a34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7564bd269a534e2cabc63a556841bb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520568007bb848f68e0013ca617b4686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b4c8cc9f33444192f555c5c3ee3582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f431aa46fd455c89e1f588953abedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/WintWealth/partial_finetuned_open_hermes_2.5/commit/e48ca5f4ad711b31dfa6ea52d45a0e548e5a9adb', commit_message='Upload model', commit_description='', oid='e48ca5f4ad711b31dfa6ea52d45a0e548e5a9adb', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('WintWealth/partial_finetuned_open_hermes_2.5', token = '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', private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a11fb8-3e67-4687-9583-23b9383c4fe3",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "608ba764-b86a-498f-8993-ba0772c55b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3328"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4096 - 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "4cac6727-ce20-47d8-814a-03f6a92d48e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "374d6a4a-d8c1-4d29-89cd-efe957961bfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2023-12-03-07-38-05-843/output/model/'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "ed934755-bf78-48db-a105-7650556ea5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# s3 path where the model will be uploaded\n",
    "# if you try to deploy the model to a different time add the s3 path here\n",
    "# model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(3072), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(4096), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data={'S3DataSource':{'S3Uri': model_s3_path,'S3DataType': 'S3Prefix','CompressionType': 'None'}},\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "85bad177-3c5d-443c-8a96-c01483c77b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-tgi-inference-2023-12-06-06-56-59-809\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-tgi-inference-2023-12-06-06-57-00-520\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-tgi-inference-2023-12-06-06-57-00-520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=6,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b0b5c259-76aa-4b58-bcb7-092213d613b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = llm.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "bc4dd5da-517c-4f6c-b4e8-ab416b9907e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-tgi-inference-2023-12-06-06-57-00-520'"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "31d280be-9338-4ca3-90e3-a681b3038830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_article_for_prompt(article_text):\n",
    "    truncated_content = truncate_text_to_token_limit(text=article_text, encoder=tokenizer, token_limit=ARTICLE_TOKEN_LIMIT)\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{truncated_content}\\n\"}]\n",
    "    context_prompt = tokenizer.decode(tokenizer.apply_chat_template(messages, add_generation_prompt=True))\n",
    "    prompt = re.sub(r'\\n+','\\n',context_prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa2f11-5610-4328-b4e2-6a3bfd871347",
   "metadata": {},
   "source": [
    "#### Testing for a few articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a831fe67-6f4e-4401-9cf7-60675244c074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/username/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/username/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/username/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/username/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "parent_folder = '/Users/username/Desktop/ML/Recommendations/arcane/'\n",
    "from hydra import compose, initialize\n",
    "import os\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('../../../conf/application.run.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "envs_element = root.find('./configuration/envs')\n",
    "for variable in envs_element.findall('env'):\n",
    "    name = variable.get('name')\n",
    "    value = variable.get('value')\n",
    "    os.environ[name] = value\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/username/Desktop/ML/Recommendations/arcane/')\n",
    "\n",
    "from src._utils import load_bertopic_model_from_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "69d9220b-4ccf-4593-a333-58ef589b3041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.articles.ArticleService import ArticleService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "71442e8b-9f4b-4501-9f7f-8a1813c2ffe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "art = ArticleService.get_article_json_from_s3_and_api('651e1c48a662d76276b88eee')\n",
    "\n",
    "art['title'] + art['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "cf33b9a6-20e4-468e-a220-23e784d9a508",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "# Configure the max_pool_connections\n",
    "my_config = Config(\n",
    "    region_name = 'ap-south-1',\n",
    "    retries = {\n",
    "        'max_attempts': 10,\n",
    "        'mode': 'standard'\n",
    "    },\n",
    "    max_pool_connections = 40  # Increase the pool size\n",
    ")\n",
    "\n",
    "# Create a SageMaker Runtime client with the custom configuration\n",
    "sess1 = boto3.session.Session()\n",
    "smr1 = sess1.client(\"sagemaker-runtime\", config=my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8fe49eea-05f0-4a19-a66d-586abb6754c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smr = sess.boto_session.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ff32630e-f97c-45a7-a2b8-ace8fa765707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.8,\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"repetition_penalty\": 1.03,\n",
    "    \"stop\": [\"###\", \"</s>\", tokenizer.eos_token],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a06151fc-7aa9-4c4b-a4b3-a6133e4d9925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5718c160-92f4-44e0-9744-5a9f251f1d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "art = ArticleService.get_article_json_from_s3_and_api('651e1c48a662d76276b88eee')\n",
    "content = art['title'] + art['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a98efc3e-a332-405a-a957-10ec95ce2a40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Chelsea vs Real Madrid: Live streaming, where to watch Champions League matchChelsea will play Real Madrid in a crucial Champions League quarterfinal second-leg on April 18 at Stamford Bridge. The first-leg in Madrid saw the Blues suffer a 2-0 defeat, as Karim Benzema and Marco Asensio scored to give the defending champions a comfortable win at Santiago Bernabeu.For Chelsea, the return leg marks a pivotal moment in their season, with a Champions League exit ending their hopes of silverware. However, the team under Frank Lampard's management has struggled lately, with three consecutive defeats, making their task even more daunting.Fortunately, fans worldwide will have the chance to stream the game online. The Sporting News has provided all the necessary details on how to do so.Chelsea vs Real Madrid Live StreamChampions League streaming coverage will be offered by beIN Sports in Singapore, Hong Kong, and Malaysia, while JioTV and Sony LIV will be the streaming options available in India.These two teams have both won the Champions League in the last two seasons, and they have defeated each other on their path to becoming European champions.Benzema has played a pivotal role in their recent encounters, notably scoring a magnificent hat-trick against Chelsea at Stamford Bridge in 2022.Chelsea vs Real Madrid timing, channel Date Kickoff time StreamingIndia Wednesday, Apr. 19 00:30 IST JioTV, Sony LIVUK Tue, Apr. 18 20:00 BST BT Sport site/appUSA Tue, Apr. 18 15:00 ET Fubo, Paramount+, ViXFAQsQ1: When is the Chelsea vs Real Madrid match scheduled?A: The Chelsea vs Real Madrid match is scheduled for today, April 18, 2023.Q2: What time will the match begin?A: The match will begin at 8:00 PM GMT.\""
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "b21e7476-4f65-4891-b5de-88b4e58c403d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = {\"inputs\": format_article_for_prompt(content), \"parameters\": parameters, \"stream\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0f4bf468-a28d-4d75-afd5-d7847bb534ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp = smr.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(request),\n",
    "    ContentType=\"application/json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a3f6aa10-92e3-4c31-b393-29807fa29c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = resp['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "77780bcc-18c0-4d98-947a-fc8f8f8639a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis_of_article_sentiment': 'The sentiment is neutral as it presents a factual report of the upcoming match.',\n",
       " 'analysis_of_article_type': 'The article is factual, providing information about the upcoming Champions League game between Chelsea and Real Madrid.',\n",
       " 'analysis_of_article_validity_duration': \"The article contains information about an upcoming game, so it's valid until the event happens. After that, it's irrelevant.\",\n",
       " 'analysis_of_financial_or_business_news': 'The article is not directly related to finance or business, but it discusses a high-profile football match and provides information about streaming options.',\n",
       " 'analysis_of_popularity': 'The article would be popular among football fans and sports enthusiasts, especially those interested in the Champions League.',\n",
       " 'analysis_of_relevant_for_india': 'This is a Champions League football match between Chelsea and Real Madrid, which might be of interest to Indian football fans. It will be broadcast on Sony LIV.',\n",
       " 'article_sentiment': 'na',\n",
       " 'article_type': 'fact',\n",
       " 'article_validity_duration': 1,\n",
       " 'final_summary': 'Scheduled for April 18, Chelsea and Real Madrid will face off in a crucial Champions League quarterfinal second-leg match. With the Blues looking to avoid a Champions League exit, the game promises to be a nail-biting encounter. Viewers can catch the live stream on Sony LIV in India and other streaming options globally.',\n",
       " 'financial_or_business_news': False,\n",
       " 'first_attempt_summary': 'In a crucial Champions League quarterfinal second-leg game, Chelsea and Real Madrid will face off on April 18. Chelsea will need a turnaround to prevent a Champions League exit, while Real Madrid looks to maintain their momentum. The game will be streamed globally, including Sony LIV in India.',\n",
       " 'headline_suggestion': 'Champions League Quarterfinal Second-Leg: Chelsea vs Real Madrid: Live Stream Details',\n",
       " 'improved_summary': 'Chelsea and Real Madrid will play their Champions League quarterfinal second-leg game on April 18. The Blues will seek to avoid an early Champions League exit as they take on the defending champions. A variety of live streaming options are available globally.',\n",
       " 'popularity': 'moderately_popular',\n",
       " 'relevant_for_india': True,\n",
       " 'top_categories': 'Sports; Football; Champions League; Chelsea; Real Madrid'}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json.loads(k)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "1f3ef1de-e90e-4e25-aaf2-09770e0b8d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WatermelonSapphireZipline'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e6cefe54-bec3-4273-bb76-cfb902ea8b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-tgi-inference-2023-12-03-10-21-59-120'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f689c553-5c3e-42dd-9322-b7c0297cb259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_articles = ['651de546a662d76276b80931',\n",
    " '651e2409a662d76276b8a181',\n",
    " '651dfe88a662d76276b84838',\n",
    " '651e0d14a662d76276b86b88',\n",
    " '651e2286a662d76276b89de1',\n",
    " '656719c9207bb033b910ea11',\n",
    " '651df8e1a662d76276b83a66',\n",
    " '651dca8aa662d76276b7c1f8',\n",
    " '651e0f43a662d76276b870aa',\n",
    " '6566a94f39bfc8784efe5b7c',\n",
    " '651e1c48a662d76276b88eee',\n",
    " '651dc511a662d76276b7b33e',\n",
    " '6555c17a4b13023f9348cfc5',\n",
    " '651de912a662d76276b81322',\n",
    " '6555c1f84b13023f9348d104',\n",
    " '65683309207bb033b910ed9e',\n",
    " '656557db1fc4586a032ad63e',\n",
    " '651e093aa662d76276b862ab',\n",
    " '651dd514a662d76276b7df16',\n",
    " '651e14c8a662d76276b87d8a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f274b98d-1bf5-4292-9376-4152f6545ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_endpoint_name = 'OpenHermes-Finetune-WatermelonSapphireZipline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1224f5f1-4591-4c0e-a55a-1bda6fd53c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y, z = get_attributes_from_llm('6555c17a4b13023f9348cfc5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8e97eb40-091e-4ecd-8460-e75a9a846142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_attributes_from_llm(article_id):\n",
    "    try:\n",
    "        article = ArticleService.get_article_json_from_s3_and_api(article_id)\n",
    "    except:\n",
    "        return article_id, ''\n",
    "    full_content = article['title'] + article['cleaned_text']\n",
    "    full_input = format_article_for_prompt(full_content)\n",
    "    request = {\"inputs\": full_input, \"parameters\": parameters, \"stream\": False}\n",
    "    try:\n",
    "        resp = smr1.invoke_endpoint(\n",
    "            EndpointName=new_endpoint_name,\n",
    "            Body=json.dumps(request),\n",
    "            ContentType=\"application/json\",\n",
    "            )\n",
    "        k = resp['Body'].read()\n",
    "        try:\n",
    "            attributes = json.loads(json.loads(k)[0]['generated_text'])\n",
    "            return article_id, attributes\n",
    "        except:\n",
    "            return article_id, ''\n",
    "    except:\n",
    "        print(article_id, 'some error')\n",
    "        article_id, ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e072751-bb19-4459-9aa9-93752e5adaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary.createFromBase64('W3siZ2VuZXJhdGVkX3RleHQiOiJ7XCJhbmFseXNpc19vZl9hcnRpY2xlX3NlbnRpbWVudFwiOiBcIlRoZSBzZW50aW1lbnQgaXMg…', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f79969ab-1e77-4ef6-b26d-36197d28f8aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fd696e4f-184d-4cc2-a812-8d16b93546ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "111506c3-2dfd-4769-8d94-ebef59588ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 IDs in 93.18964195251465 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "responses = {}\n",
    "valid_attributes = {}\n",
    "invalid_response_ids = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(get_attributes_from_llm, art_id) for art_id in test_articles]\n",
    "    for future in as_completed(futures):\n",
    "        art_id, response = future.result()\n",
    "        responses[art_id] = response\n",
    "            # invalid_response_ids.append(art_id)\n",
    "\n",
    "print(f'Processed {len(test_articles)} IDs in {time.time() - start_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ae5d2-3078-484e-8eb8-33e029c88c4f",
   "metadata": {},
   "source": [
    "### Running the results for all the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "9cb5d2bb-6b6c-4aa5-99c6-c9781ecc32e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sql.PostgresDatabaseOperation import PostgresDatabaseOperation\n",
    "\n",
    "with PostgresDatabaseOperation() as cursor:\n",
    "    sql = 'SELECT DISTINCT article_id FROM embeddings'\n",
    "    cursor.execute(sql)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "all_article_ids = [x[0] for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "1506388d-53b2-4739-a37e-32937fb21e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118008"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_article_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4aa14d46-b3d8-4f31-b0e2-129384d46fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "eac94904-9cdc-468c-92cd-bcdd714f5e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_chunks = (len(all_article_ids)//chunk_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cdaf58ff-9a8e-4c7f-ba86-4d242376e8c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(columns = ['article_id', 'attributes']).to_csv(f'all_article_attributes_{finetune_id}.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ce1a5d27-e3c2-4850-9f7d-5554d53cd289",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1e46f14c-a045-4848-b861-938868117c92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('OpenHermes_WatermelonSapphireZipline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "45761c4d-7abe-44bd-8581-a9797d075a45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WatermelonSapphireZipline'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "72fa6031-3ce1-455c-98d7-bc56e9f671c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "f785fa12-1fcb-4611-84c0-f6a93d168606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7dc3da97-5b07-4eb2-88b7-49f94ad8ecec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'652fd0311e5cc42b1b13a398'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(all_article_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "79663c58-f918-4eda-993e-24c3a68b97e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('652fd0311e5cc42b1b13a398', '')"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attributes_from_llm('652fd0311e5cc42b1b13a398')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60dce05-664c-4a75-be35-5c3bfb22c753",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(30, num_chunks):\n",
    "    cur_article_ids = all_article_ids[i * chunk_size: (i+1)*chunk_size]\n",
    "    start_time = time.time()\n",
    "    completed = 0\n",
    "    with ThreadPoolExecutor(max_workers=40) as executor:\n",
    "        futures = [executor.submit(get_attributes_from_llm, art_id) for art_id in cur_article_ids]\n",
    "        for future in as_completed(futures):\n",
    "            if future.result():\n",
    "                art_id, response = future.result()\n",
    "                if response:\n",
    "                    pd.DataFrame([(art_id, json.dumps(response))]).to_csv('all_article_attributes_WatermelonSapphireZipline.csv',mode='a',index=False,header = False)\n",
    "                    completed += 1\n",
    "            # invalid_response_ids.append(art_id)\n",
    "    print(f'Processed {completed} IDs in {time.time() - start_time} seconds in chunk number {i} at {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692f27c-ec9c-487a-b3d2-71c48293d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes_for_article_ids(article_ids, max_retries=0, retry_count=0):\n",
    "    start_time = time.time()\n",
    "    responses = {}\n",
    "    valid_attributes = {}\n",
    "    invalid_response_ids = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(get_attributes_from_llm, art_id) for art_id in article_ids]\n",
    "        print(f'completed in {time.time() - start_time} seconds')\n",
    "        for future in as_completed(futures):\n",
    "            art_id, response = future.result()\n",
    "            if response is None:  # Timeout or other errors\n",
    "                invalid_response_ids.append(art_id)\n",
    "                continue\n",
    "\n",
    "            responses[art_id] = response\n",
    "            try:\n",
    "                valid_attributes[art_id] = json.loads(response['llm_attributes'])\n",
    "            except:\n",
    "                return response\n",
    "                # invalid_response_ids.append(art_id)\n",
    "\n",
    "    print(f'Attempt {retry_count + 1}: Processed {len(article_ids)} IDs in {time.time() - start_time} seconds')\n",
    "\n",
    "    if invalid_response_ids and retry_count < max_retries:\n",
    "        print(f'Retrying for {len(invalid_response_ids)} invalid IDs')\n",
    "        valid_attributes_retry = get_attributes_for_article_ids(invalid_response_ids, max_retries, retry_count + 1)\n",
    "        valid_attributes.update(valid_attributes_retry)\n",
    "\n",
    "    return valid_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6c9c5b46-d656-4174-a2e6-aaae0bf2ae89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt = '''\n",
    "The article highlights the challenges faced by the Indian stock market in light of global economic issues. Despite India's strong economy and positive corporate earnings growth, foreign institutional investors (FIIs) are selling their shares due to the global economic deceleration. The contraction in the global economy, led by Europe's recession and China's decelerating economy, is affecting the Indian market. The recent fall in the stock market is attributed to global factors, not intrinsic structural issues within India. The article concludes by stating that despite the challenges, the Indian stock market has maintained a high valuation, which is leading to consolidation in prices and valuations\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138da96c-85c5-4475-b1d0-dc8cb99379c4",
   "metadata": {},
   "source": [
    "### Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71437896-8e59-44ae-9d73-7b3e9b5644cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoenv",
   "language": "python",
   "name": "recoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
