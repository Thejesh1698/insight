{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dae8e0e-fd24-4870-9f7f-6f2d8757aa16",
   "metadata": {},
   "source": [
    "## Defining sagemaker roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82bc8e0f-2ba5-4e0c-8ed3-c238c3de48c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AmazonSageMaker-ExecutionRole-20231030T210397'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "iam = boto3.client('iam')\n",
    "response = iam.list_roles()\n",
    "sagemaker_roles = [role for role in response['Roles'] if 'SageMaker' in role['RoleName']]\n",
    "sagemaker_roles[0]['RoleName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5c85d3a-5038-4664-8233-54f715e2ebfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ravi.tej/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ravi.tej/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ravi.tej/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name ravi_tej to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ravi.tej/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20231030T210397')['Role']['Arn']\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46d1dce9-a30e-41c2-95d5-c11788987a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "from random import randint\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from pack_dataset import pack_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca8391-3908-49fb-8623-3a2ace44c45e",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88b5ca-85d3-477b-9979-c1a0d5dafb20",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68482869-4c3a-44d8-92fc-9cfe23275ab2",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0d12915-99b3-49b0-a53d-fa4e1d31626a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravi.tej/anaconda3/envs/recoenv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0da848-579d-46d0-9990-ea3784aad418",
   "metadata": {},
   "source": [
    "### GPT responses EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50a65873-2dc5-405a-a21a-e9b104c98886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('gpt-4-responses-1-dec-with-headers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efdecf01-cfba-4a8d-8801-448f9798737a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns = {'0', '1', 'has_text', 'json_generated'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25b13416-9e16-4a63-967b-ee3678b0d429",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prompt.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "761890da-068f-42a4-8525-111f7bc1d2db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>full_content</th>\n",
       "      <th>model</th>\n",
       "      <th>attributes</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>article_id</th>\n",
       "      <th>validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Amazon workers walk out over lack of trust in ...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Ar...</td>\n",
       "      <td>2304</td>\n",
       "      <td>458</td>\n",
       "      <td>6555c8194b13023f9349092e</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Laid off by Qualcomm Indian techie on H1B visa...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1638</td>\n",
       "      <td>470</td>\n",
       "      <td>653169231e5cc42b1b13d2be</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Best Places to Exchange Currency in Los Angele...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>2488</td>\n",
       "      <td>484</td>\n",
       "      <td>6555cc364b13023f934a655c</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  \\nYou are the chief editor for a leading India...   \n",
       "1  \\nYou are the chief editor for a leading India...   \n",
       "2  \\nYou are the chief editor for a leading India...   \n",
       "\n",
       "                                        full_content       model  \\\n",
       "0  Amazon workers walk out over lack of trust in ...  gpt-4-0613   \n",
       "1  Laid off by Qualcomm Indian techie on H1B visa...  gpt-4-0613   \n",
       "2  Best Places to Exchange Currency in Los Angele...  gpt-4-0613   \n",
       "\n",
       "                                          attributes  prompt_tokens  \\\n",
       "0  {\"analysis_is_financial_or_business_news\": \"Ar...           2304   \n",
       "1  {\"analysis_is_financial_or_business_news\": \"Th...           1638   \n",
       "2  {\"analysis_is_financial_or_business_news\": \"Th...           2488   \n",
       "\n",
       "   completion_tokens                article_id validity  \n",
       "0                458  6555c8194b13023f9349092e        7  \n",
       "1                470  653169231e5cc42b1b13d2be        7  \n",
       "2                484  6555cc364b13023f934a655c       30  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a9f35aaf-6f23-49f9-8651-0b3aaa62c17a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "res = []\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        res.append(json.loads(df.iloc[i]['attributes'])['article_validity_duration'])\n",
    "    except:\n",
    "        res.append(ast.literal_eval(json.loads(df.iloc[i]['attributes']))['article_validity_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "baa47576-95c1-45ca-b94b-57608f75156b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['validity'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6b30a52-ba57-4230-8adc-26e7d60243c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validity\n",
       "-1    150\n",
       "1     195\n",
       "3     175\n",
       "7     297\n",
       "14    110\n",
       "30    303\n",
       "90      2\n",
       "-1     37\n",
       "1      39\n",
       "14     32\n",
       "3      37\n",
       "30     78\n",
       "7      60\n",
       "90      2\n",
       "Name: validity, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('validity')['validity'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "875bdf3a-bb44-48a0-9b7e-859d2db5d8b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set_df = df.sample(frac = 0.85)\n",
    "train_set_df.to_csv('train-set-gpt-4-responses-1-dec.csv', index = False)\n",
    "test_set_df = df[~df.article_id.isin(train_set.article_id.unique())]\n",
    "test_set_df.to_csv('test-set-gpt-4-responses-1-dec.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9eeccbaf-d59c-43fb-ae3c-07ee7df56b43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>full_content</th>\n",
       "      <th>model</th>\n",
       "      <th>attributes</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>article_id</th>\n",
       "      <th>validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Tata Motors cars to get costlier from today. D...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1486</td>\n",
       "      <td>517</td>\n",
       "      <td>65316c4d1e5cc42b1b13e030</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Dont have a PAN or Aadhaar number You cannot c...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_of_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1580</td>\n",
       "      <td>500</td>\n",
       "      <td>653169051e5cc42b1b13c9ce</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Air services from Kanpur to Delhi will begin s...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_of_financial_or_business_news\": \"Ar...</td>\n",
       "      <td>1545</td>\n",
       "      <td>513</td>\n",
       "      <td>651e12bca662d76276b878ec</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Cholamandalam Finance April 2023 NCD Public Is...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>2963</td>\n",
       "      <td>618</td>\n",
       "      <td>652fd3151e5cc42b1b13a507</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Survey Shows Real Estate Is Americans Favorite...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1361</td>\n",
       "      <td>529</td>\n",
       "      <td>6555cc9e4b13023f934aaf30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Why Would a Company Perform a Reverse Stock Sp...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>2260</td>\n",
       "      <td>484</td>\n",
       "      <td>6555c81b4b13023f93490a5f</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>How To Open Fixed Deposit Account In Post Offi...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>2663</td>\n",
       "      <td>500</td>\n",
       "      <td>652fc74a1e5cc42b1b139f64</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Pizza Hut to continue aggressive expansion spr...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1950</td>\n",
       "      <td>530</td>\n",
       "      <td>651de972a662d76276b81416</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>Key considerations to know in real estate inve...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>2025</td>\n",
       "      <td>475</td>\n",
       "      <td>6555c0904b13023f9348cbde</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>\\nYou are the chief editor for a leading India...</td>\n",
       "      <td>BJP high command summons Yediyurappa to Delhi ...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"analysis_is_financial_or_business_news\": \"Th...</td>\n",
       "      <td>1811</td>\n",
       "      <td>508</td>\n",
       "      <td>651e04b2a662d76276b85800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1289 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  \\\n",
       "115   \\nYou are the chief editor for a leading India...   \n",
       "387   \\nYou are the chief editor for a leading India...   \n",
       "723   \\nYou are the chief editor for a leading India...   \n",
       "1079  \\nYou are the chief editor for a leading India...   \n",
       "131   \\nYou are the chief editor for a leading India...   \n",
       "...                                                 ...   \n",
       "1045  \\nYou are the chief editor for a leading India...   \n",
       "315   \\nYou are the chief editor for a leading India...   \n",
       "1186  \\nYou are the chief editor for a leading India...   \n",
       "1093  \\nYou are the chief editor for a leading India...   \n",
       "849   \\nYou are the chief editor for a leading India...   \n",
       "\n",
       "                                           full_content       model  \\\n",
       "115   Tata Motors cars to get costlier from today. D...  gpt-4-0613   \n",
       "387   Dont have a PAN or Aadhaar number You cannot c...  gpt-4-0613   \n",
       "723   Air services from Kanpur to Delhi will begin s...  gpt-4-0613   \n",
       "1079  Cholamandalam Finance April 2023 NCD Public Is...  gpt-4-0613   \n",
       "131   Survey Shows Real Estate Is Americans Favorite...  gpt-4-0613   \n",
       "...                                                 ...         ...   \n",
       "1045  Why Would a Company Perform a Reverse Stock Sp...  gpt-4-0613   \n",
       "315   How To Open Fixed Deposit Account In Post Offi...  gpt-4-0613   \n",
       "1186  Pizza Hut to continue aggressive expansion spr...  gpt-4-0613   \n",
       "1093  Key considerations to know in real estate inve...  gpt-4-0613   \n",
       "849   BJP high command summons Yediyurappa to Delhi ...  gpt-4-0613   \n",
       "\n",
       "                                             attributes  prompt_tokens  \\\n",
       "115   {\"analysis_is_financial_or_business_news\": \"Th...           1486   \n",
       "387   {\"analysis_of_financial_or_business_news\": \"Th...           1580   \n",
       "723   {\"analysis_of_financial_or_business_news\": \"Ar...           1545   \n",
       "1079  {\"analysis_is_financial_or_business_news\": \"Th...           2963   \n",
       "131   {\"analysis_is_financial_or_business_news\": \"Th...           1361   \n",
       "...                                                 ...            ...   \n",
       "1045  {\"analysis_is_financial_or_business_news\": \"Th...           2260   \n",
       "315   {\"analysis_is_financial_or_business_news\": \"Th...           2663   \n",
       "1186  {\"analysis_is_financial_or_business_news\": \"Th...           1950   \n",
       "1093  {\"analysis_is_financial_or_business_news\": \"Th...           2025   \n",
       "849   {\"analysis_is_financial_or_business_news\": \"Th...           1811   \n",
       "\n",
       "      completion_tokens                article_id validity  \n",
       "115                 517  65316c4d1e5cc42b1b13e030        3  \n",
       "387                 500  653169051e5cc42b1b13c9ce       30  \n",
       "723                 513  651e12bca662d76276b878ec       30  \n",
       "1079                618  652fd3151e5cc42b1b13a507       30  \n",
       "131                 529  6555cc9e4b13023f934aaf30       30  \n",
       "...                 ...                       ...      ...  \n",
       "1045                484  6555c81b4b13023f93490a5f       -1  \n",
       "315                 500  652fc74a1e5cc42b1b139f64       30  \n",
       "1186                530  651de972a662d76276b81416       30  \n",
       "1093                475  6555c0904b13023f9348cbde       30  \n",
       "849                 508  651e04b2a662d76276b85800        1  \n",
       "\n",
       "[1289 rows x 8 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1f193a00-8c2d-4e5a-b57e-cd1fd7d748a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1289.000000\n",
       "mean      506.780450\n",
       "std        47.484215\n",
       "min       327.000000\n",
       "25%       475.000000\n",
       "50%       504.000000\n",
       "75%       537.000000\n",
       "max       675.000000\n",
       "Name: completion_tokens, dtype: float64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_df['completion_tokens'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a76aa1b2-3afd-450e-b719-097907da563f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# structuring the format\n",
    "train_set = {}\n",
    "for row in train_set_df.itertuples():\n",
    "    res = row.attributes\n",
    "    train_set[row.article_id] = {'content': row.full_content, 'response': {}}\n",
    "    train_set[row.article_id]['attributes'] = json.loads(res)\n",
    "    # train_set[art_id]['response']['summaries'] = res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9222904e-2d62-4307-a983-f9f4456e50f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert train_set_df.article_id.nunique() == len(train_set.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca3bd827-0185-4db4-873f-c5ba4a62bc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correct_validity_duration(val):\n",
    "    val = int(val)\n",
    "    valid_days = [-1, 1, 3, 7, 14, 30]\n",
    "    if val in valid_days:\n",
    "        return val\n",
    "    else:\n",
    "        for i in valid_days:\n",
    "            if val > i:\n",
    "                valid_value = i\n",
    "        return valid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a65ecfd4-c9a8-4b28-8a4d-293944bcd6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ac61e5f1-315d-4db8-a0bc-da49cd5df1d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_keys = sorted(list(train_set['652ebbdb1e5cc42b1b139b67']['attributes'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "980ce52b-a43a-464d-af5a-365971dcec68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['analysis_of_article_sentiment',\n",
       " 'analysis_of_article_type',\n",
       " 'analysis_of_article_validity_duration',\n",
       " 'analysis_of_financial_or_business_news',\n",
       " 'analysis_of_popularity',\n",
       " 'analysis_of_relevant_for_india',\n",
       " 'article_sentiment',\n",
       " 'article_type',\n",
       " 'article_validity_duration',\n",
       " 'final_summary',\n",
       " 'financial_or_business_news',\n",
       " 'first_attempt_summary',\n",
       " 'headline_suggestion',\n",
       " 'improved_summary',\n",
       " 'popularity',\n",
       " 'relevant_for_india',\n",
       " 'top_categories']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ef7f115-7fc7-4856-9e3b-dc1f892f3a58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_keys == sorted(list(train_set['653169151e5cc42b1b13ce9e']['attributes'].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85f0c9-cf95-4c37-9b06-a881b2ee51e8",
   "metadata": {},
   "source": [
    "### Cleaning the responses from GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "08159380-f16a-4788-93a8-88556bd2feee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "malformed = []\n",
    "cleaned_train_set = {}\n",
    "for art_id in train_set:\n",
    "    cleaned_train_set[art_id] = {}\n",
    "    try:\n",
    "        attributes = train_set[art_id]['attributes']\n",
    "        if 'analysis_is_financial_or_business_news' in attributes:\n",
    "            attributes['analysis_of_financial_or_business_news'] = attributes['analysis_is_financial_or_business_news']\n",
    "            attributes.pop('analysis_is_financial_or_business_news')\n",
    "        if 'is_financial_or_business_news' in attributes:\n",
    "            attributes['financial_or_business_news'] = attributes['is_financial_or_business_news']\n",
    "            attributes.pop('is_financial_or_business_news')\n",
    "        keys = sorted(list(attributes.keys()))\n",
    "        if not keys == expected_keys:\n",
    "            malformed.append(art_id)\n",
    "            cleaned_train_set.pop(art_id)\n",
    "            continue\n",
    "        cleaned_train_set[art_id] = {'content': train_set[art_id]['content'], 'attributes': deepcopy(attributes)}\n",
    "        cleaned_train_set[art_id]['attributes']['financial_or_business_news'] = True if bool(attributes['financial_or_business_news']) == 1 else False if bool(attributes['financial_or_business_news']) == 0 else None\n",
    "        cleaned_train_set[art_id]['attributes']['relevant_for_india'] = True if bool(attributes['relevant_for_india']) == 1 else False if bool(attributes['relevant_for_india']) == 0 else None\n",
    "        cleaned_train_set[art_id]['attributes']['article_validity_duration'] = correct_validity_duration(attributes['article_validity_duration'])\n",
    "    except:\n",
    "        malformed.append(art_id)\n",
    "        cleaned_train_set.pop(art_id)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a5d72b19-f73a-4686-b358-381c1c140ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False, True}"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['financial_or_business_news'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6ac7e77b-ca5a-4dd2-be95-8c1811112f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False, True}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['relevant_for_india'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "5b5e5641-cb85-43b2-be06-5d8db95fccd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 1, 3, 7, 14, 30}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_validity_duration'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6f7734d3-3f7e-41b2-807f-533460a8850f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NA', 'bear', 'bearish', 'bull'}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_sentiment'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3874a132-054f-4677-91e9-ab84081cc305",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fact', 'analysis', 'educational', 'fact', 'factual', 'opinion', 'sponsored'}"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_type'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "8ec2bae8-89f2-4f99-851f-801f6f0b4c58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Breaking_news', 'breaking_news', 'moderately_popular', 'niche'}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['popularity'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c9a53-90ad-4084-8ad7-d114fcd2f829",
   "metadata": {},
   "source": [
    "### casting incorrect values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "15d87389-c8d7-4c94-89d8-0826d0b5ee78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for art_id in cleaned_train_set:\n",
    "    attributes = cleaned_train_set[art_id]['attributes']\n",
    "    for key in ['article_sentiment', 'article_type', 'popularity']:\n",
    "        attributes[key] = attributes[key].lower()\n",
    "        if attributes['article_sentiment'] == 'bearish':\n",
    "            attributes['article_sentiment'] = 'bear'\n",
    "        if attributes['article_type'] in ('fact', 'Fact', 'factual'):\n",
    "            attributes['article_type'] = 'fact'\n",
    "        if attributes['popularity'] in ('Breaking_news'):\n",
    "            attributes['popularity'] = 'breaking_news'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8b66d841-b464-4e71-b2d2-955f339d3a15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bear', 'bull', 'na'}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_sentiment'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4c0391ee-da3b-49e4-90db-755df5321e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis', 'educational', 'fact', 'opinion', 'sponsored'}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_type'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9712acce-d1db-4d6f-9cbb-5aa6883ff45f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'breaking_news', 'moderately_popular', 'niche'}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['popularity'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4e052ead-30c2-4c86-8e4c-2baf4020c387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1246"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "28e11ff6-85af-4d22-85ba-aa075873c116",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1287"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d11d53cd-4d8b-4c79-93b4-c6e78859961c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(malformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473eabf-cb04-4824-98b5-2f1871e3e945",
   "metadata": {},
   "source": [
    "### Properly ordering the train dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "16c3d0b5-61aa-45b7-bcc7-b92239d94c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train_set_copy = deepcopy(cleaned_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "01773674-7cd6-4ee4-a3a7-d259f622edd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_dict_structure = {\"analysis_of_financial_or_business_news\": \"\",\n",
    "\"financial_or_business_news\": \"\",\n",
    "\"analysis_of_relevant_for_india\": \"\",\n",
    "\"relevant_for_india\": \"\",\n",
    "\"analysis_of_article_validity_duration\": \"\",\n",
    "\"article_validity_duration\": \"\",\n",
    "\"analysis_of_popularity\": \"\",\n",
    "\"popularity\": \"\",\n",
    "\"analysis_of_article_type\": \"\",\n",
    "\"article_type\": \"\",\n",
    "\"analysis_of_article_sentiment\": \"\",\n",
    "\"article_sentiment\": \"\",\n",
    "\"headline_suggestion\": \"\",\n",
    "\"first_attempt_summary\": \"\",\n",
    "\"improved_summary\": \"\",\n",
    "\"final_summary\": \"\",\n",
    "\"top_categories\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "1ccefa23-e7e5-4899-ac09-376c3f3fb6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['analysis_of_financial_or_business_news', 'financial_or_business_news', 'analysis_of_relevant_for_india', 'relevant_for_india', 'analysis_of_article_validity_duration', 'article_validity_duration', 'analysis_of_popularity', 'popularity', 'analysis_of_article_type', 'article_type', 'analysis_of_article_sentiment', 'article_sentiment', 'headline_suggestion', 'first_attempt_summary', 'improved_summary', 'final_summary', 'top_categories'])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_dict_structure.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "7ff12b2b-be2e-4f6c-9118-d27edc12a43c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train_set = {article_id: {'content': cleaned_train_set_copy[article_id]['content'], \n",
    "                                  'attributes': {k: cleaned_train_set_copy[article_id]['attributes'][k] for k in expected_dict_structure}} for article_id in cleaned_train_set_copy.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "5a70f71e-7403-4c60-885e-1d502324f109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['65316c4d1e5cc42b1b13e030',\n",
       " '653169051e5cc42b1b13c9ce',\n",
       " '651e12bca662d76276b878ec',\n",
       " '652fd3151e5cc42b1b13a507',\n",
       " '6555cc9e4b13023f934aaf30',\n",
       " '6555bed64b13023f9348c585',\n",
       " '653169401e5cc42b1b13d7aa',\n",
       " '651dfa41a662d76276b83da7',\n",
       " '65316e9b1e5cc42b1b13e5b9',\n",
       " '653169151e5cc42b1b13ce9e']"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cleaned_train_set.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "21d7c1d9-9984-4ca0-8550-ee3c24df1392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "malformed_top_categories = [article_id for article_id in cleaned_train_set if isinstance(cleaned_train_set[article_id]['attributes']['top_categories'], list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "4da254a2-3857-4446-868e-c0e377b6e01d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train_set = {k: cleaned_train_set[k] for k in cleaned_train_set.keys() if k not in malformed_top_categories}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957d6c8-05b4-4581-82c8-bb073b9b59cc",
   "metadata": {},
   "source": [
    "### Article Truncation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9bd04673-53bb-4759-af8f-5188844be617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_tokens(text, encoder):  # Placeholder for your actual token calculation function\n",
    "    # Your implementation will go here.\n",
    "    return len(encoder.encode(text))  # Example: counting characters as tokens\n",
    "\n",
    "def truncate_text_to_token_limit(text,encoder, token_limit):\n",
    "    # First, check if the whole text is under the token limit\n",
    "    if calculate_tokens(text, encoder) <= token_limit:\n",
    "        return text  # The entire text is within the limit\n",
    "\n",
    "    def is_under_limit(index):\n",
    "        # Use the provided function to calculate tokens for the substring\n",
    "        return calculate_tokens(text[:index], encoder) <= token_limit\n",
    "\n",
    "    left, right = 0, len(text)\n",
    "    valid_limit = 0  # This will hold the index of the last valid token position\n",
    "\n",
    "    # Binary search to find the token limit\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2  # Find the midpoint\n",
    "        if is_under_limit(mid):\n",
    "            # If the midpoint is under the limit, store it as a valid limit\n",
    "            valid_limit = mid\n",
    "            left = mid + 1  # Move the left boundary to the right\n",
    "        else:\n",
    "            right = mid - 1  # Move the right boundary to the left\n",
    "\n",
    "    # Find the last space before the valid_limit to ensure we're at a word boundary\n",
    "    space_index = text.rfind(' ', 0, valid_limit)\n",
    "    if space_index == -1:\n",
    "        # If there's no space, we've hit the start of the text\n",
    "        return text[:valid_limit]  # Return up to the valid limit even if mid-word\n",
    "\n",
    "    # Return the text up to the last word within the token limit\n",
    "    return text[:space_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5e64a-ded8-46c1-b748-e0b54599ce48",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "7d10e768-b5fc-4a83-aad9-61f0d32270a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt =  '''\n",
    "You are the chief editor for a leading Indian financial and business news website. You evaluate critical attributes of articles to gate keep content quality. For many attributes, you will first provide a brief analysis of 15 to 30 words, followed by assessment.\n",
    "\n",
    "1. analysis_of_financial_or_business_news (short text) : <analyse if article pertains to finance/business or not. government policies directly impacting indian corporations or investors are ok, but not if aren't>\n",
    "2. financial_or_business_news (True or False) : <True or False based on previous attribute>\n",
    "3. analysis_of_relevant_for_india (short text) : <analyse if article is relevant for indians. for example international articles about 401k or small foreign companies won't be relevant for india. however changes to fed interest rates or nasdaq or important news of large multinational corporations will be relevant>\n",
    "4. relevant_for_india (True or False) : <True or False based on previous attribute>\n",
    "5. analysis_of_article_validity_duration (short text) : <analyse relevance duration. Be stingy: Stock fluctuations, 1 day; significant policy changes - few days or a week; educational content with references to any regulations is 30 unless there are none - in which case is timeless. International news in India has shorter lifespan. breaking news are usually not timeless; quarterly analysis or results are usually valid for a 3 days, yearly analysis or results for a weeks and a much longer one for a month.>\n",
    "6. article_validity_duration (one of 1, 3, 7, 14, 30, -1) : <calculate number of days based on previous attribute. -1: timeless. 1: article is relevant only for that day. 3: for a couple of days. 7: for a week. 14: for a couple of weeks. 30: for a month>\n",
    "7. analysis_of_popularity (short text) : <analyse likely popularity of article - if its for niche audience, moderate_popularity or should be part of breaking_news section, depending on number of people who will be impacted by the news and the scale of the event. foreign entities known in india but not very popular will be mostly niche or rarely moderately popular. articles targeted to very specific business or pratices will be niche. infotainment business and financial articles with some drama are likely to be more popular. articles with a list of rules without compelling story-telling will be for niche audience>\n",
    "8. popularity (one of niche, moderately_popular, breaking_news) : <based on previous attribute>\n",
    "9. analysis_of_article_type (short text) : <analyse if the article is majorly factual, is an opinion piece, analysis, educational or likely sponsored. factual articles pass on information on events. opinion pieces have inferences or predictions either from the author or from statements without data. analysis pieces have substantial data to justify their inferences or predictions. if an article is overly zealous on certain stock and seems like an ad, then it is sponsored>\n",
    "10. article_type (one of fact, opinion, analysis, educational, sponsored) : <based on previous attribute>\n",
    "11. analysis_of_article_sentiment (short_text): <analyse if the sentiment of the article is bullish, bearish or NA. balanced is NA>\n",
    "12. article_sentiment (one of bull, bear, na): <based on previous attribute>\n",
    "13. headline_suggestion (short text) : <Write a headline based on the content of the article>\n",
    "14. first_attempt_summary (text of 60 words) : <Generate concise, entity-dense summary. The summary should become highly dense but easily understood without the Article. Don't keep the summary too short, but limit it to no more than 60 words>\n",
    "15. improved_summary (text of 60 words): <Identify contents of the article which are missing from the previous summary but are important part of the article>\n",
    "16. final_summary (text of 60 words): <The finalised summary which is a mixture of first_attempt_summary and improved_summary. This summary should be very dense and also all the important information of the article and yet concise. By reading this in most cases the users need not read the article>\n",
    "17. categories_hierarchy (5 semi colon seperated categories): <Hierarchy of 5 categories or keywords. Start with a generic category and make it progressively specific. Select only 5 and seperate them by (;). Don't use either single or double quotes at any cost to avoid json.loads() failure>\n",
    "\n",
    "your response should be a json structure with all the 17 above keys without missing any key. It is very important that the response is directly readable with json.loads(). no preamble or postamble. respond in the exact following structure:\n",
    "\n",
    "{\n",
    "\"analysis_of_financial_or_business_news\": \"\",\n",
    "\"financial_or_business_news\": \"\",\n",
    "\"analysis_of_relevant_for_india\": \"\",\n",
    "\"relevant_for_india\": \"\",\n",
    "\"analysis_of_article_validity_duration\": \"\",\n",
    "\"article_validity_duration\": \"\",\n",
    "\"analysis_of_popularity\": \"\",\n",
    "\"popularity\": \"\",\n",
    "\"analysis_of_article_type\": \"\",\n",
    "\"article_type\": \"\",\n",
    "\"analysis_of_article_sentiment\": \"\",\n",
    "\"article_sentiment\": \"\",\n",
    "\"headline_suggestion\": \"\",\n",
    "\"first_attempt_summary\": \"\",\n",
    "\"improved_summary\": \"\",\n",
    "\"final_summary\": \"\",\n",
    "\"top_categories\": \"\"\n",
    "}\n",
    "\n",
    "|article_start|\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d85f6-f780-4ebe-91f1-2b6068561d4a",
   "metadata": {},
   "source": [
    "### Article Size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7c46f5d5-fc39-4c48-a913-17f812c060b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "article_sizes = {k: len(tokenizer.encode(cleaned_train_set[k]['content'])) for k in cleaned_train_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1cb55561-2e1b-4fe4-a74f-d448a5519efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'65316c4d1e5cc42b1b13e030': 401,\n",
       " '653169051e5cc42b1b13c9ce': 485,\n",
       " '651e12bca662d76276b878ec': 475,\n",
       " '652fd3151e5cc42b1b13a507': 2323,\n",
       " '6555cc9e4b13023f934aaf30': 251,\n",
       " '6555bed64b13023f9348c585': 1994,\n",
       " '653169401e5cc42b1b13d7aa': 506,\n",
       " '651dfa41a662d76276b83da7': 476,\n",
       " '65316e9b1e5cc42b1b13e5b9': 1488,\n",
       " '653169151e5cc42b1b13ce9e': 516,\n",
       " '651e0776a662d76276b85eac': 512,\n",
       " '652ebbdb1e5cc42b1b139b67': 837,\n",
       " '6555ccd54b13023f934adbf9': 374,\n",
       " '655c20fc4b13023f934af5cc': 440,\n",
       " '651dcd68a662d76276b7c9b2': 587,\n",
       " '653680111e5cc42b1b143f48': 1194,\n",
       " '65316f731e5cc42b1b1400aa': 1593,\n",
       " '65316f411e5cc42b1b13f5ed': 518,\n",
       " '651e0a35a662d76276b864e1': 1008,\n",
       " '6555ccc64b13023f934acf58': 184,\n",
       " '6555c84a4b13023f934924d6': 497,\n",
       " '6555cc6c4b13023f934a8d15': 544,\n",
       " '651dfeeaa662d76276b84929': 323,\n",
       " '6555c8144b13023f934905df': 459,\n",
       " '6531687f1e5cc42b1b13add0': 604,\n",
       " '651de5aaa662d76276b80a31': 434,\n",
       " '651e18d3a662d76276b88714': 649,\n",
       " '65316f6c1e5cc42b1b13ff04': 1602,\n",
       " '651dd58fa662d76276b7e02c': 272,\n",
       " '6555c7fc4b13023f9348f6a6': 559,\n",
       " '651dc721a662d76276b7b870': 1478,\n",
       " '65316a011e5cc42b1b13db03': 211,\n",
       " '65316d031e5cc42b1b13e199': 1106,\n",
       " '651dedb6a662d76276b81f4b': 1017,\n",
       " '6531692e1e5cc42b1b13d523': 486,\n",
       " '65316eb81e5cc42b1b13e66b': 423,\n",
       " '6555cab14b13023f93495aa5': 448,\n",
       " '6555cbbf4b13023f934a104a': 1873,\n",
       " '651def1ea662d76276b82308': 421,\n",
       " '651e1b88a662d76276b88d2f': 234,\n",
       " '651dc9f6a662d76276b7c05e': 957,\n",
       " '6555cafd4b13023f93498e94': 1132,\n",
       " '652ebbc51e5cc42b1b139a58': 817,\n",
       " '651dc79fa662d76276b7b9e4': 231,\n",
       " '653168cc1e5cc42b1b13baae': 499,\n",
       " '6555ca664b13023f93493776': 1279,\n",
       " '6555c7e24b13023f9348e9df': 1930,\n",
       " '651dd33da662d76276b7da5d': 520,\n",
       " '653169011e5cc42b1b13c893': 757,\n",
       " '651deefca662d76276b822ad': 494,\n",
       " '6555cbd04b13023f934a1b56': 1619,\n",
       " '651de999a662d76276b81478': 214,\n",
       " '6555ca784b13023f93493d0d': 1261,\n",
       " '651dcf77a662d76276b7cf6d': 1162,\n",
       " '653168691e5cc42b1b13ab45': 623,\n",
       " '651de70da662d76276b80def': 1148,\n",
       " '65316f3b1e5cc42b1b13f4c5': 1118,\n",
       " '65316fd91e5cc42b1b14211d': 1967,\n",
       " '6555cbac4b13023f934a0367': 783,\n",
       " '6555cc6f4b13023f934a8ed9': 562,\n",
       " '6555cca14b13023f934ab140': 1540,\n",
       " '651e0555a662d76276b8598b': 1069,\n",
       " '6555cc5d4b13023f934a8183': 739,\n",
       " '6555cc074b13023f934a42fb': 1070,\n",
       " '653225a31e5cc42b1b143884': 209,\n",
       " '6555c7ed4b13023f9348eed4': 495,\n",
       " '6555cccd4b13023f934ad566': 420,\n",
       " '6555ca934b13023f934948be': 919,\n",
       " '6555cae94b13023f9349815b': 1801,\n",
       " '6531ed691e5cc42b1b143761': 279,\n",
       " '6555cbd64b13023f934a1faf': 755,\n",
       " '6531691b1e5cc42b1b13d05b': 697,\n",
       " '6555b52f4b13023f9348b9cc': 1924,\n",
       " '6555cc344b13023f934a63e2': 531,\n",
       " '6555c8124b13023f93490460': 41,\n",
       " '652ebbc81e5cc42b1b139a77': 764,\n",
       " '6531684d1e5cc42b1b13a918': 573,\n",
       " '655c55a7eee55a44e0ac1e5f': 367,\n",
       " '6555ccc34b13023f934acc8e': 390,\n",
       " '6555c80c4b13023f9349007e': 1383,\n",
       " '6555bf094b13023f9348c620': 692,\n",
       " '65316f611e5cc42b1b13fc8f': 2031,\n",
       " '6540c8a92936d70acf71ed57': 674,\n",
       " '6555c8284b13023f93491342': 605,\n",
       " '651dd023a662d76276b7d14f': 172,\n",
       " '6555c7c34b13023f9348e067': 797,\n",
       " '6555cadc4b13023f93497836': 979,\n",
       " '6555c49a4b13023f9348d92f': 334,\n",
       " '651de6f4a662d76276b80daf': 1298,\n",
       " '6555ca554b13023f93493377': 1412,\n",
       " '6555cc0e4b13023f934a4783': 486,\n",
       " '653169f11e5cc42b1b13dae4': 324,\n",
       " '655c5588eee55a44e0ac1e39': 1143,\n",
       " '6555c8124b13023f93490447': 777,\n",
       " '651df231a662d76276b82b11': 601,\n",
       " '653169391e5cc42b1b13d6ca': 961,\n",
       " '6555c8074b13023f9348fd17': 1367,\n",
       " '6555c84e4b13023f93492551': 799,\n",
       " '6555cb8e4b13023f9349ef10': 861,\n",
       " '651e19f0a662d76276b8899d': 298,\n",
       " '6538bd0b1e5cc42b1b14448e': 1024,\n",
       " '651dd1bfa662d76276b7d5e9': 632,\n",
       " '6555c2f04b13023f9348d335': 1182,\n",
       " '6555c4364b13023f9348d798': 461,\n",
       " '651dc561a662d76276b7b3fb': 534,\n",
       " '65316f4a1e5cc42b1b13f7c6': 1805,\n",
       " '6555cc454b13023f934a707f': 818,\n",
       " '651de104a662d76276b7fddc': 183,\n",
       " '6555cab14b13023f93495a57': 609,\n",
       " '651dcffea662d76276b7d0e6': 459,\n",
       " '6555c18c4b13023f9348cffb': 318,\n",
       " '652fd2851e5cc42b1b13a4bf': 979,\n",
       " '6555c47e4b13023f9348d8be': 473,\n",
       " '6555c3294b13023f9348d3a3': 831,\n",
       " '6555caaa4b13023f9349559c': 1386,\n",
       " '65316faa1e5cc42b1b141020': 829,\n",
       " '6555cbaa4b13023f934a023a': 1440,\n",
       " '6555cc0b4b13023f934a45c6': 931,\n",
       " '6536801d1e5cc42b1b14404b': 806,\n",
       " '651defa9a662d76276b82464': 932,\n",
       " '6531691c1e5cc42b1b13d0bf': 625,\n",
       " '6555caaa4b13023f934955c5': 816,\n",
       " '65236cedcd871c6ac1cde049': 830,\n",
       " '651dca9aa662d76276b7c222': 367,\n",
       " '65316fa81e5cc42b1b140f8b': 666,\n",
       " '6555cace4b13023f93496e03': 1630,\n",
       " '6555cca04b13023f934ab07a': 1179,\n",
       " '652fd2681e5cc42b1b13a4b2': 1088,\n",
       " '6555cc2f4b13023f934a606e': 1786,\n",
       " '6555cc894b13023f934aa0b8': 579,\n",
       " '653170011e5cc42b1b143139': 952,\n",
       " '651df941a662d76276b83b4c': 464,\n",
       " '651e0f51a662d76276b870cc': 659,\n",
       " '6555ca724b13023f93493af9': 1060,\n",
       " '653168c41e5cc42b1b13b8c4': 658,\n",
       " '6525a723598c6618f06087b8': 282,\n",
       " '6555cbdf4b13023f934a2673': 560,\n",
       " '6555c4464b13023f9348d7dc': 1436,\n",
       " '6555cadd4b13023f9349789b': 700,\n",
       " '65367fe71e5cc42b1b143ca6': 1159,\n",
       " '65316fac1e5cc42b1b141095': 459,\n",
       " '65316e721e5cc42b1b13e524': 233,\n",
       " '6555c8114b13023f93490419': 607,\n",
       " '6536801e1e5cc42b1b14406d': 1275,\n",
       " '6555ccd64b13023f934adccb': 1213,\n",
       " '6555cccc4b13023f934ad446': 671,\n",
       " '653680151e5cc42b1b143f9d': 2050,\n",
       " '654856d1dc4fa72a6c403a3d': 1862,\n",
       " '65316f521e5cc42b1b13f949': 2120,\n",
       " '6555c8194b13023f934908fb': 1113,\n",
       " '6531692b1e5cc42b1b13d476': 895,\n",
       " '651dd203a662d76276b7d6c2': 577,\n",
       " '6555cadb4b13023f9349776a': 802,\n",
       " '6555b5b54b13023f9348bebf': 1795,\n",
       " '651e209fa662d76276b89966': 704,\n",
       " '6555cc274b13023f934a59e8': 443,\n",
       " '6555cc094b13023f934a4450': 655,\n",
       " '6555cb084b13023f9349963d': 514,\n",
       " '6555c0844b13023f9348cba1': 819,\n",
       " '6555cc764b13023f934a9418': 830,\n",
       " '6555bf5f4b13023f9348c712': 463,\n",
       " '6555cba54b13023f9349fec9': 540,\n",
       " '6555cb504b13023f9349c489': 733,\n",
       " '651dda38a662d76276b7ebbb': 498,\n",
       " '651df6d0a662d76276b83683': 862,\n",
       " '6555c7fe4b13023f9348f7c5': 1026,\n",
       " '651debdaa662d76276b81a72': 281,\n",
       " '6555ccaf4b13023f934abbcd': 365,\n",
       " '65316f921e5cc42b1b1408e3': 517,\n",
       " '6555c4bd4b13023f9348d9d1': 904,\n",
       " '651e1ca6a662d76276b88fd5': 416,\n",
       " '6555cc794b13023f934a95b9': 679,\n",
       " '6555cc594b13023f934a7f47': 438,\n",
       " '6531691c1e5cc42b1b13d0a5': 509,\n",
       " '6525a6d2598c6618f0608551': 508,\n",
       " '6555c0934b13023f9348cbe5': 431,\n",
       " '651dc715a662d76276b7b84d': 849,\n",
       " '6555ccb24b13023f934abe46': 250,\n",
       " '6531686d1e5cc42b1b13abaf': 862,\n",
       " '6555c8234b13023f93490f91': 1386,\n",
       " '651e035fa662d76276b85496': 467,\n",
       " '65316ff01e5cc42b1b1429ec': 1590,\n",
       " '6555c7b74b13023f9348de73': 1359,\n",
       " '6555cab84b13023f93495eea': 1075,\n",
       " '6554345a4b13023f9348b4e4': 227,\n",
       " '651decc9a662d76276b81cd0': 288,\n",
       " '653169231e5cc42b1b13d299': 482,\n",
       " '6555c8494b13023f93492496': 641,\n",
       " '651e0a35a662d76276b864df': 429,\n",
       " '6555cbd44b13023f934a1e7d': 1154,\n",
       " '653168ee1e5cc42b1b13c336': 248,\n",
       " '6554344c4b13023f9348b491': 216,\n",
       " '6555cbe94b13023f934a2d81': 1517,\n",
       " '6555b5c74b13023f9348bfc8': 376,\n",
       " '6555c16b4b13023f9348cf85': 1136,\n",
       " '652ebba71e5cc42b1b139977': 832,\n",
       " '6555cc254b13023f934a58d3': 428,\n",
       " '6531684e1e5cc42b1b13a92c': 1992,\n",
       " '655c1d5e4b13023f934af4af': 767,\n",
       " '651df231a662d76276b82b0e': 436,\n",
       " '6555c7c14b13023f9348dff5': 851,\n",
       " '6555cc734b13023f934a9192': 400,\n",
       " '6555cad74b13023f934974fa': 1508,\n",
       " '6555ca944b13023f93494940': 1136,\n",
       " '651de466a662d76276b806f4': 154,\n",
       " '653169321e5cc42b1b13d5b9': 459,\n",
       " '6555ccc14b13023f934acac6': 584,\n",
       " '6555cb454b13023f9349bcdd': 986,\n",
       " '651e0d73a662d76276b86c6b': 817,\n",
       " '6555cccf4b13023f934ad701': 929,\n",
       " '651dd211a662d76276b7d6ec': 236,\n",
       " '653168b01e5cc42b1b13b50a': 975,\n",
       " '6555cbb34b13023f934a0846': 1419,\n",
       " '6525a749598c6618f0608a24': 775,\n",
       " '6555cbe34b13023f934a293d': 728,\n",
       " '65316a3a1e5cc42b1b13dba4': 702,\n",
       " '651dda0da662d76276b7eb59': 725,\n",
       " '651deedea662d76276b82260': 1367,\n",
       " '651de3a8a662d76276b8050b': 280,\n",
       " '653168bb1e5cc42b1b13b701': 1655,\n",
       " '652e311b5669b40a3b5ab76c': 755,\n",
       " '6531691b1e5cc42b1b13d077': 528,\n",
       " '6531691d1e5cc42b1b13d106': 644,\n",
       " '6555cc024b13023f934a3f6a': 364,\n",
       " '6555cc604b13023f934a8410': 510,\n",
       " '652ebbda1e5cc42b1b139b60': 917,\n",
       " '651e0166a662d76276b84f8a': 108,\n",
       " '6555cc324b13023f934a6257': 675,\n",
       " '65316f751e5cc42b1b140149': 445,\n",
       " '6555cc304b13023f934a60bc': 1669,\n",
       " '6555cc774b13023f934a9451': 575,\n",
       " '6555c7ff4b13023f9348f83d': 1126,\n",
       " '6555c2db4b13023f9348d30b': 1756,\n",
       " '6555cc964b13023f934aa908': 380,\n",
       " '6555cbe74b13023f934a2c3b': 589,\n",
       " '655191454b13023f9348b35a': 228,\n",
       " '652fca061e5cc42b1b13a0b9': 2002,\n",
       " '6525a726598c6618f06087d7': 283,\n",
       " '65316c241e5cc42b1b13dfe9': 1187,\n",
       " '6555cc214b13023f934a556a': 590,\n",
       " '651ded68a662d76276b81e79': 387,\n",
       " '651df012a662d76276b82564': 430,\n",
       " '6555c3a04b13023f9348d505': 563,\n",
       " '653169081e5cc42b1b13ca95': 1162,\n",
       " '653169101e5cc42b1b13cd02': 768,\n",
       " '6555ca604b13023f934935d2': 492,\n",
       " '652ebbca1e5cc42b1b139a8e': 573,\n",
       " '65316ed71e5cc42b1b13e7f9': 283,\n",
       " '653168b91e5cc42b1b13b6ae': 303,\n",
       " '6555c7c64b13023f9348e0fe': 1589,\n",
       " '6555cb654b13023f9349d275': 424,\n",
       " '653680061e5cc42b1b143e6a': 984,\n",
       " '651de560a662d76276b80970': 468,\n",
       " '651e18b3a662d76276b886cb': 1063,\n",
       " '651dd553a662d76276b7df9e': 695,\n",
       " '65316efc1e5cc42b1b13eb66': 317,\n",
       " '6555c1144b13023f9348ce0a': 787,\n",
       " '65316f3c1e5cc42b1b13f50a': 779,\n",
       " '6555c3c24b13023f9348d583': 825,\n",
       " '651def85a662d76276b8240b': 358,\n",
       " '65316b811e5cc42b1b13dee2': 1162,\n",
       " '65316fa81e5cc42b1b140f81': 1984,\n",
       " '6555b5394b13023f9348ba03': 1752,\n",
       " '6555c30c4b13023f9348d368': 1152,\n",
       " '651e22eca662d76276b89ee1': 554,\n",
       " '6555c1564b13023f9348cf2d': 487,\n",
       " '65316f191e5cc42b1b13ef39': 2369,\n",
       " '6555bfdb4b13023f9348c8b7': 690,\n",
       " '651de0b9a662d76276b7fd1d': 395,\n",
       " '6540c8a72936d70acf71eccb': 380,\n",
       " '651dd504a662d76276b7deed': 619,\n",
       " '6555c83f4b13023f934922d0': 933,\n",
       " '651e0f0aa662d76276b8701e': 909,\n",
       " '652ebbe01e5cc42b1b139bbf': 620,\n",
       " '6531693d1e5cc42b1b13d769': 618,\n",
       " '6555c7e74b13023f9348ebfc': 1535,\n",
       " '655585d34b13023f9348b5c9': 217,\n",
       " '6555ca904b13023f93494702': 566,\n",
       " '6555cc7f4b13023f934a99e0': 363,\n",
       " '651dee77a662d76276b82154': 1334,\n",
       " '6555c4e44b13023f9348da78': 145,\n",
       " '653169151e5cc42b1b13cea2': 629,\n",
       " '6555c1f84b13023f9348d105': 563,\n",
       " '655c1d514b13023f934af40e': 203,\n",
       " '6555ca994b13023f93494c06': 1064,\n",
       " '6555cc6c4b13023f934a8d26': 345,\n",
       " '653168701e5cc42b1b13ac08': 593,\n",
       " '651e2420a662d76276b8a1be': 717,\n",
       " '6555c0f94b13023f9348cd95': 360,\n",
       " '653169231e5cc42b1b13d2ab': 1022,\n",
       " '6555cc604b13023f934a83a0': 487,\n",
       " '6531690b1e5cc42b1b13cb8e': 553,\n",
       " '65316fa61e5cc42b1b140ec0': 1040,\n",
       " '6555c8184b13023f93490868': 790,\n",
       " '6555c7f74b13023f9348f41c': 540,\n",
       " '6555cc2a4b13023f934a5c76': 744,\n",
       " '651df20aa662d76276b82aa5': 169,\n",
       " '6555cc4f4b13023f934a7818': 576,\n",
       " '6555ca694b13023f9349384b': 1233,\n",
       " '6555cace4b13023f93496e9c': 137,\n",
       " '6531700c1e5cc42b1b14356c': 850,\n",
       " '652ebbc81e5cc42b1b139a7e': 832,\n",
       " '6555cc584b13023f934a7e5d': 545,\n",
       " '6555cc814b13023f934a9b25': 1353,\n",
       " '6555cc7b4b13023f934a96f1': 612,\n",
       " '6555cae14b13023f93497b9b': 764,\n",
       " '6555caec4b13023f9349836a': 1861,\n",
       " '651dd999a662d76276b7ea31': 968,\n",
       " '651e25f8a662d76276b8a619': 559,\n",
       " '651dd993a662d76276b7ea20': 398,\n",
       " '6536525f1e5cc42b1b143b8f': 721,\n",
       " '651dd29ea662d76276b7d88e': 431,\n",
       " '6555c81e4b13023f93490c29': 370,\n",
       " '652ebb801e5cc42b1b1398d4': 632,\n",
       " '6555cb324b13023f9349b0cd': 1027,\n",
       " '651e259ca662d76276b8a54a': 428,\n",
       " '6555c8034b13023f9348fa96': 1085,\n",
       " '651dd956a662d76276b7e97b': 945,\n",
       " '651dd7a8a662d76276b7e525': 591,\n",
       " '6555c7cc4b13023f9348e2a2': 1433,\n",
       " '6531695c1e5cc42b1b13d99a': 551,\n",
       " '651dc54ca662d76276b7b3c6': 263,\n",
       " '651dd111a662d76276b7d3ec': 186,\n",
       " '653169991e5cc42b1b13d9f2': 1139,\n",
       " '6536800b1e5cc42b1b143ec3': 1528,\n",
       " '65316f661e5cc42b1b13fdab': 1076,\n",
       " '651dfcada662d76276b843a3': 998,\n",
       " '6555ca5c4b13023f934934f1': 1135,\n",
       " '65316ca31e5cc42b1b13e0d5': 724,\n",
       " '651e1b6aa662d76276b88cef': 632,\n",
       " '651dff8da662d76276b84abf': 147,\n",
       " '651dec50a662d76276b81ba0': 1116,\n",
       " '6555ca9f4b13023f93494f30': 1273,\n",
       " '6555c5254b13023f9348db95': 460,\n",
       " '65316c5a1e5cc42b1b13e03e': 539,\n",
       " '6555ccd44b13023f934adadc': 414,\n",
       " '653169b61e5cc42b1b13da2e': 571,\n",
       " '651dddf1a662d76276b7f57e': 1093,\n",
       " '6555ca994b13023f93494b91': 1033,\n",
       " '653169a81e5cc42b1b13da0b': 653,\n",
       " '6536802f1e5cc42b1b14423d': 1865,\n",
       " '651e1b1da662d76276b88c44': 430,\n",
       " '653168c21e5cc42b1b13b880': 470,\n",
       " '651df698a662d76276b83604': 594,\n",
       " '6555bedc4b13023f9348c59d': 206,\n",
       " '651e0fafa662d76276b871ae': 327,\n",
       " '6555cc284b13023f934a5ab7': 1016,\n",
       " '6555c7fb4b13023f9348f5f6': 1619,\n",
       " '65316bb41e5cc42b1b13df37': 981,\n",
       " '6555c7cb4b13023f9348e226': 1070,\n",
       " '65316b431e5cc42b1b13de37': 551,\n",
       " '6531693f1e5cc42b1b13d792': 531,\n",
       " '6555c7f74b13023f9348f403': 1170,\n",
       " '652f4a711e5cc42b1b139cf1': 249,\n",
       " '651defb1a662d76276b82478': 720,\n",
       " '651dd5bfa662d76276b7e09b': 706,\n",
       " '6555cc1a4b13023f934a5012': 292,\n",
       " '651dc524a662d76276b7b36a': 909,\n",
       " '651dcbb2a662d76276b7c511': 297,\n",
       " '651e2475a662d76276b8a28c': 547,\n",
       " '6536802c1e5cc42b1b1441d9': 1351,\n",
       " '652fc5901e5cc42b1b139e96': 2147,\n",
       " '651dcb41a662d76276b7c3ea': 378,\n",
       " '6535e20d1e5cc42b1b143ae9': 239,\n",
       " '6555c0644b13023f9348cb19': 496,\n",
       " '651dcc66a662d76276b7c6f6': 702,\n",
       " '651e199aa662d76276b888d9': 581,\n",
       " '651df69ba662d76276b83609': 478,\n",
       " '653169201e5cc42b1b13d1dc': 508,\n",
       " '6555cb124b13023f93499c28': 1392,\n",
       " '65316f531e5cc42b1b13f99f': 613,\n",
       " '653168821e5cc42b1b13ae1d': 529,\n",
       " '6555cc7e4b13023f934a98f9': 1266,\n",
       " '651df14ca662d76276b8289a': 1184,\n",
       " '6555c3884b13023f9348d4b1': 1110,\n",
       " '653168c81e5cc42b1b13b9aa': 492,\n",
       " '6555cc9b4b13023f934aacda': 1272,\n",
       " '65316f411e5cc42b1b13f5df': 1277,\n",
       " '6553534c4b13023f9348b482': 758,\n",
       " '6555c1224b13023f9348ce3e': 643,\n",
       " '6555c8384b13023f93491ead': 894,\n",
       " '6531687c1e5cc42b1b13ad69': 449,\n",
       " '651dc70ea662d76276b7b838': 837,\n",
       " '6555cb474b13023f9349be96': 1393,\n",
       " '653168281e5cc42b1b13a79c': 463,\n",
       " '65316c161e5cc42b1b13dfd5': 699,\n",
       " '651de216a662d76276b8009d': 296,\n",
       " '652fc80e1e5cc42b1b139fc2': 1480,\n",
       " '651e0efea662d76276b86fff': 933,\n",
       " '6555cc6b4b13023f934a8c39': 1049,\n",
       " '653169191e5cc42b1b13cfb6': 423,\n",
       " '651de856a662d76276b81141': 787,\n",
       " '652fd3131e5cc42b1b13a506': 726,\n",
       " '6555be974b13023f9348c48e': 980,\n",
       " '651dcf33a662d76276b7ceb5': 599,\n",
       " '651dc7a3a662d76276b7b9f1': 480,\n",
       " '653169471e5cc42b1b13d874': 670,\n",
       " '651df18ca662d76276b82949': 475,\n",
       " '6555c2954b13023f9348d27e': 385,\n",
       " '6555cb2b4b13023f9349ac92': 1128,\n",
       " '6555bee84b13023f9348c5c3': 625,\n",
       " '651ddd09a662d76276b7f333': 542,\n",
       " '6555c80f4b13023f93490240': 1413,\n",
       " '65316a1f1e5cc42b1b13db4a': 392,\n",
       " '65316fba1e5cc42b1b141567': 732,\n",
       " '65316f611e5cc42b1b13fc87': 772,\n",
       " '6531692e1e5cc42b1b13d4f8': 456,\n",
       " '651de0ffa662d76276b7fdd1': 250,\n",
       " '6555cb5a4b13023f9349cb1c': 1141,\n",
       " '6555cb5d4b13023f9349cd3d': 994,\n",
       " '652fcada1e5cc42b1b13a126': 1680,\n",
       " '651e252ea662d76276b8a458': 432,\n",
       " '6555c7f14b13023f9348f0cd': 1364,\n",
       " '6555c7d94b13023f9348e69e': 494,\n",
       " '653168771e5cc42b1b13acc1': 700,\n",
       " '651de991a662d76276b81465': 517,\n",
       " '6555b4854b13023f9348b65f': 545,\n",
       " '652df90b5669b40a3b5ab718': 239,\n",
       " '65316f871e5cc42b1b1405dd': 875,\n",
       " '6555c4774b13023f9348d8a5': 418,\n",
       " '6555cc3c4b13023f934a6a44': 650,\n",
       " '6555cca74b13023f934ab5ad': 515,\n",
       " '655b3c524b13023f934af39b': 571,\n",
       " '651dd3b3a662d76276b7db8b': 551,\n",
       " '6555ccd14b13023f934ad932': 478,\n",
       " '6555caa04b13023f93494ffb': 2081,\n",
       " '6555c7fd4b13023f9348f76d': 1665,\n",
       " '653169201e5cc42b1b13d1c6': 378,\n",
       " '6555ca944b13023f93494913': 427,\n",
       " '651dc9b7a662d76276b7bfb6': 556,\n",
       " '6525a746598c6618f06089f0': 609,\n",
       " '6531692f1e5cc42b1b13d52e': 595,\n",
       " '655c1d604b13023f934af4cb': 227,\n",
       " '6555ccb94b13023f934ac3c2': 1381,\n",
       " '6555ca614b13023f9349363e': 1804,\n",
       " '652fc8021e5cc42b1b139fbc': 1911,\n",
       " '6555cbfe4b13023f934a3c82': 872,\n",
       " '651dcbf3a662d76276b7c5c0': 307,\n",
       " '653169281e5cc42b1b13d3c6': 426,\n",
       " '651df20ca662d76276b82aac': 545,\n",
       " '6536801f1e5cc42b1b14408c': 1309,\n",
       " '651e0369a662d76276b854b3': 330,\n",
       " '653168ec1e5cc42b1b13c2c6': 256,\n",
       " '6555c7d94b13023f9348e66a': 1990,\n",
       " '6555c8104b13023f9349032c': 1683,\n",
       " '6555b5dd4b13023f9348c3cd': 1132,\n",
       " '6555cac44b13023f93496732': 1339,\n",
       " '6555c82e4b13023f934917a8': 654,\n",
       " '651dc567a662d76276b7b406': 645,\n",
       " '653169331e5cc42b1b13d5f0': 987,\n",
       " '65316faa1e5cc42b1b141003': 377,\n",
       " '653169481e5cc42b1b13d893': 521,\n",
       " '655434584b13023f9348b4ca': 240,\n",
       " '6535e1f71e5cc42b1b143a19': 249,\n",
       " '651e05d6a662d76276b85ab5': 626,\n",
       " '651df248a662d76276b82b4f': 448,\n",
       " '65316f9b1e5cc42b1b140b59': 527,\n",
       " '651ddf82a662d76276b7f9c9': 403,\n",
       " '65316a231e5cc42b1b13db58': 824,\n",
       " '65316efb1e5cc42b1b13eb53': 732,\n",
       " '651df702a662d76276b836fa': 600,\n",
       " '6555c0284b13023f9348ca15': 857,\n",
       " '6555c7be4b13023f9348df7d': 850,\n",
       " '6536800f1e5cc42b1b143f21': 1515,\n",
       " '652ebbc61e5cc42b1b139a65': 763,\n",
       " '6555cc314b13023f934a613a': 395,\n",
       " '65316d5c1e5cc42b1b13e25a': 1178,\n",
       " '651de394a662d76276b804d4': 362,\n",
       " '6555cc414b13023f934a6dcc': 286,\n",
       " '651dfb1aa662d76276b83fbf': 737,\n",
       " '6540de492936d70acf71edec': 1891,\n",
       " '65367fdd1e5cc42b1b143c43': 1136,\n",
       " '6555cb744b13023f9349dcfb': 655,\n",
       " '6555c9c24b13023f93492baf': 622,\n",
       " '652fc61d1e5cc42b1b139ed5': 1801,\n",
       " '65316f121e5cc42b1b13ee32': 444,\n",
       " '6555cc1f4b13023f934a5462': 1502,\n",
       " '653169031e5cc42b1b13c914': 838,\n",
       " '651deadea662d76276b817e6': 448,\n",
       " '6555c8154b13023f93490622': 743,\n",
       " '652ebbd21e5cc42b1b139aea': 988,\n",
       " '6555c1c04b13023f9348d07b': 1005,\n",
       " '651e03a4a662d76276b8554a': 287,\n",
       " '6555c8134b13023f93490527': 1052,\n",
       " '651e1dbea662d76276b89284': 1673,\n",
       " '653168b91e5cc42b1b13b6b6': 557,\n",
       " '6555c8264b13023f934911cd': 777,\n",
       " '6555cc7b4b13023f934a96ce': 399,\n",
       " '652ebb9b1e5cc42b1b13993b': 810,\n",
       " '653168cd1e5cc42b1b13bab5': 613,\n",
       " '651e2307a662d76276b89f27': 958,\n",
       " '6555cacd4b13023f93496d75': 1111,\n",
       " '65316fad1e5cc42b1b14110d': 545,\n",
       " '651dd0a3a662d76276b7d2b8': 640,\n",
       " '6555cccc4b13023f934ad42d': 947,\n",
       " '654b6a4cdc4fa72a6c403d0b': 1296,\n",
       " '653169251e5cc42b1b13d340': 261,\n",
       " '6555cc154b13023f934a4cb5': 1413,\n",
       " '651e1054a662d76276b8732b': 589,\n",
       " '6555cc2b4b13023f934a5cea': 584,\n",
       " '651ddbd1a662d76276b7efec': 804,\n",
       " '65316f791e5cc42b1b14023b': 1061,\n",
       " '6555cb594b13023f9349ca89': 523,\n",
       " '6531691a1e5cc42b1b13d032': 1331,\n",
       " '651dfeb6a662d76276b848ae': 518,\n",
       " '6555cca94b13023f934ab786': 1361,\n",
       " '651e0fc1a662d76276b871d5': 552,\n",
       " '65316f7e1e5cc42b1b140378': 1464,\n",
       " '651e169ca662d76276b881d9': 510,\n",
       " '6555c9de4b13023f93492c98': 451,\n",
       " '651ddbb6a662d76276b7efa2': 617,\n",
       " '654310d6dc4fa72a6c4037e9': 223,\n",
       " '651dceaca662d76276b7cd36': 1430,\n",
       " '6555cc3f4b13023f934a6c7c': 916,\n",
       " '6525a6f7598c6618f06085f5': 389,\n",
       " '651e1d86a662d76276b891fb': 438,\n",
       " '65316dc91e5cc42b1b13e38c': 574,\n",
       " '651e1558a662d76276b87edc': 152,\n",
       " '651dcfa2a662d76276b7cfe7': 405,\n",
       " '6555c7fe4b13023f9348f808': 1110,\n",
       " '6555cc954b13023f934aa7ee': 1499,\n",
       " '651e12a3a662d76276b878b5': 392,\n",
       " '651e0286a662d76276b85279': 589,\n",
       " '6555cb3f4b13023f9349b914': 1126,\n",
       " '65316ffd1e5cc42b1b142f31': 652,\n",
       " '6555cc364b13023f934a655f': 1003,\n",
       " '6531687b1e5cc42b1b13ad40': 472,\n",
       " '65316d921e5cc42b1b13e330': 491,\n",
       " '653169421e5cc42b1b13d7ff': 603,\n",
       " '652ebbbf1e5cc42b1b139a20': 622,\n",
       " '6555c5624b13023f9348dc9c': 942,\n",
       " '651e25b4a662d76276b8a580': 811,\n",
       " '652fc54f1e5cc42b1b139e76': 2107,\n",
       " '651e22a3a662d76276b89e2a': 577,\n",
       " '6555cb394b13023f9349b53c': 291,\n",
       " '6555b4914b13023f9348b696': 1903,\n",
       " '6555cabf4b13023f934963ff': 1028,\n",
       " '651e2257a662d76276b89d73': 858,\n",
       " '6555ccc44b13023f934acd61': 1075,\n",
       " '651e1299a662d76276b8789e': 620,\n",
       " '651e2446a662d76276b8a216': 398,\n",
       " '65316ede1e5cc42b1b13e889': 268,\n",
       " '6555ca634b13023f934936bc': 673,\n",
       " '651dedaca662d76276b81f2e': 384,\n",
       " '6555cbf24b13023f934a343b': 388,\n",
       " '65316f2a1e5cc42b1b13f1ee': 606,\n",
       " '65316f851e5cc42b1b140569': 604,\n",
       " '6555c8054b13023f9348fc56': 873,\n",
       " '651def13a662d76276b822e9': 664,\n",
       " '6555bf2f4b13023f9348c68b': 511,\n",
       " '651dd1e9a662d76276b7d670': 838,\n",
       " '65316f341e5cc42b1b13f393': 633,\n",
       " '6555cc0b4b13023f934a453e': 1514,\n",
       " '6555cad84b13023f93497517': 635,\n",
       " '6555c7c94b13023f9348e1aa': 1057,\n",
       " '653170041e5cc42b1b14328a': 836,\n",
       " '65316f6e1e5cc42b1b13ff89': 993,\n",
       " '6555c80d4b13023f9349016d': 1277,\n",
       " '65316ed41e5cc42b1b13e7bd': 1034,\n",
       " '652fd1681e5cc42b1b13a432': 1409,\n",
       " '6531693f1e5cc42b1b13d7a5': 426,\n",
       " '653168a31e5cc42b1b13b2e3': 387,\n",
       " '6531690f1e5cc42b1b13ccad': 557,\n",
       " '6555cb624b13023f9349d09d': 771,\n",
       " '655c20694b13023f934af5a4': 518,\n",
       " '6556d7654b13023f934aec8b': 444,\n",
       " '65316f8e1e5cc42b1b14079c': 637,\n",
       " '6557482a4b13023f934aef37': 552,\n",
       " '6555c7d94b13023f9348e6a9': 1061,\n",
       " '65316f181e5cc42b1b13ef14': 746,\n",
       " '6555cc7c4b13023f934a97c5': 847,\n",
       " '6536800e1e5cc42b1b143f03': 1227,\n",
       " '653169361e5cc42b1b13d664': 297,\n",
       " '651dee7da662d76276b82162': 612,\n",
       " '6555caa14b13023f93495056': 705,\n",
       " '6555cc314b13023f934a6173': 642,\n",
       " '6555cbfa4b13023f934a39af': 1141,\n",
       " '6555cc784b13023f934a9510': 594,\n",
       " '653168f81e5cc42b1b13c5e8': 280,\n",
       " '6555c4e34b13023f9348da71': 732,\n",
       " '651e160da662d76276b88084': 1194,\n",
       " '6531687d1e5cc42b1b13ad81': 603,\n",
       " '6555c7fd4b13023f9348f75e': 1845,\n",
       " '6555cbf34b13023f934a347e': 939,\n",
       " '652fc78a1e5cc42b1b139f83': 2001,\n",
       " '65316f471e5cc42b1b13f714': 1072,\n",
       " '652ebb981e5cc42b1b139931': 768,\n",
       " '652ebbb71e5cc42b1b1399dd': 785,\n",
       " '653680131e5cc42b1b143f80': 510,\n",
       " '6555cace4b13023f93496e57': 457,\n",
       " '6555c7f24b13023f9348f12d': 379,\n",
       " '6555cbc44b13023f934a1365': 1559,\n",
       " '651e1538a662d76276b87e8f': 476,\n",
       " '651e0a4ea662d76276b86518': 591,\n",
       " '6555c7fb4b13023f9348f68b': 1251,\n",
       " '6555ccc04b13023f934ac9d7': 773,\n",
       " '651dc928a662d76276b7be2e': 638,\n",
       " '651e1728a662d76276b88322': 465,\n",
       " '6555c7f64b13023f9348f387': 816,\n",
       " '6555c8324b13023f93491a3f': 1171,\n",
       " '651dd9bca662d76276b7ea8a': 593,\n",
       " '6555c8364b13023f93491d3f': 954,\n",
       " '6555caa94b13023f9349551c': 428,\n",
       " '6531688f1e5cc42b1b13afca': 745,\n",
       " '6555c80f4b13023f93490234': 1020,\n",
       " '6555cc8c4b13023f934aa226': 547,\n",
       " '653680191e5cc42b1b143ff4': 1768,\n",
       " '65316f5f1e5cc42b1b13fc0b': 994,\n",
       " '651dd25aa662d76276b7d7c5': 362,\n",
       " '65316e621e5cc42b1b13e4e9': 1063,\n",
       " '653169191e5cc42b1b13cfb2': 414,\n",
       " '6555cc1b4b13023f934a516b': 368,\n",
       " '6555bff64b13023f9348c933': 395,\n",
       " '651de47fa662d76276b8073a': 662,\n",
       " '65316f321e5cc42b1b13f342': 569,\n",
       " '652fccc81e5cc42b1b13a225': 2097,\n",
       " '651de5daa662d76276b80aad': 713,\n",
       " '6555cbf14b13023f934a3377': 478,\n",
       " '653169b71e5cc42b1b13da31': 805,\n",
       " '651e1d4da662d76276b8916f': 399,\n",
       " '6555cc344b13023f934a63e9': 869,\n",
       " '6555cc794b13023f934a95e0': 415,\n",
       " '6555cbde4b13023f934a25b9': 1200,\n",
       " '6555cb704b13023f9349da78': 935,\n",
       " '6555c7ac4b13023f9348dd90': 1810,\n",
       " '653168ae1e5cc42b1b13b49c': 1106,\n",
       " '651e0729a662d76276b85df1': 573,\n",
       " '6555c7f24b13023f9348f196': 1188,\n",
       " '651dd40aa662d76276b7dc73': 1086,\n",
       " '6555c7e24b13023f9348ea00': 1221,\n",
       " '6555cb364b13023f9349b381': 1006,\n",
       " '6555cc1d4b13023f934a52ed': 334,\n",
       " '6531683f1e5cc42b1b13a85b': 465,\n",
       " '653168ba1e5cc42b1b13b6e0': 497,\n",
       " '65367b2f1e5cc42b1b143baa': 529,\n",
       " '653168491e5cc42b1b13a8e2': 541,\n",
       " '6549a84edc4fa72a6c403b48': 233,\n",
       " '651e1c24a662d76276b88e98': 670,\n",
       " '6555cb7e4b13023f9349e3e2': 227,\n",
       " '6555cc584b13023f934a7e4c': 309,\n",
       " '6555cc2b4b13023f934a5d81': 436,\n",
       " '651de797a662d76276b80f52': 398,\n",
       " '65316a781e5cc42b1b13dc73': 998,\n",
       " '6555c7c14b13023f9348dff6': 1382,\n",
       " '653168751e5cc42b1b13ac7f': 315,\n",
       " '6555cb964b13023f9349f470': 2141,\n",
       " '6555cbaa4b13023f934a0205': 383,\n",
       " '6555cc294b13023f934a5bca': 594,\n",
       " '65316e4b1e5cc42b1b13e4aa': 254,\n",
       " '6555cc054b13023f934a4199': 232,\n",
       " '6555cae14b13023f93497b8d': 2150,\n",
       " '65316f4b1e5cc42b1b13f7ca': 496,\n",
       " '653168861e5cc42b1b13ae90': 737,\n",
       " '653169221e5cc42b1b13d279': 535,\n",
       " '65316f351e5cc42b1b13f3be': 368,\n",
       " '6555c3854b13023f9348d4a7': 393,\n",
       " '651ddb28a662d76276b7ee33': 1533,\n",
       " '6555ccc94b13023f934ad169': 509,\n",
       " '651df2f1a662d76276b82d1a': 524,\n",
       " '6555ca654b13023f93493739': 1382,\n",
       " '6555ccde4b13023f934ae282': 896,\n",
       " '6531690e1e5cc42b1b13cc64': 717,\n",
       " '6555cbcf4b13023f934a1a8c': 642,\n",
       " '653680101e5cc42b1b143f26': 1086,\n",
       " '65316f8b1e5cc42b1b1406ce': 578,\n",
       " '651dffcea662d76276b84b66': 1212,\n",
       " '6555cc4a4b13023f934a7442': 1244,\n",
       " '651e07b0a662d76276b85f29': 508,\n",
       " '6555c34f4b13023f9348d3fa': 498,\n",
       " '65367ff11e5cc42b1b143d23': 557,\n",
       " '651dd37aa662d76276b7dafb': 345,\n",
       " '651e236ea662d76276b8a01a': 1801,\n",
       " '652fd1b01e5cc42b1b13a456': 1958,\n",
       " '6536801b1e5cc42b1b144023': 994,\n",
       " '6555cacd4b13023f93496dba': 941,\n",
       " '651dd467a662d76276b7dd66': 402,\n",
       " '651e0ae5a662d76276b8667e': 940,\n",
       " '6555b4914b13023f9348b697': 1748,\n",
       " '6555c7fb4b13023f9348f651': 1342,\n",
       " '651dfc2fa662d76276b8426f': 512,\n",
       " '6555c8094b13023f9348fea9': 1114,\n",
       " '655c1e874b13023f934af580': 793,\n",
       " '6555cae24b13023f93497c90': 271,\n",
       " '6555c7c74b13023f9348e142': 229,\n",
       " '6555cb804b13023f9349e549': 990,\n",
       " '6536802f1e5cc42b1b14422e': 790,\n",
       " '6555cc384b13023f934a66ae': 1980,\n",
       " '651df5caa662d76276b83427': 1149,\n",
       " '651dec9ca662d76276b81c5e': 384,\n",
       " '6555c7f04b13023f9348f047': 1266,\n",
       " '65316f891e5cc42b1b14066b': 1358,\n",
       " '6555cab54b13023f93495d4e': 488,\n",
       " '651de2a2a662d76276b80212': 301,\n",
       " '6555cac24b13023f93496649': 646,\n",
       " '6555cbc44b13023f934a139d': 1076,\n",
       " '6555b5a34b13023f9348bdec': 911,\n",
       " '6555cb604b13023f9349cf0e': 427,\n",
       " '6555ccbc4b13023f934ac6a5': 790,\n",
       " '6540c8a72936d70acf71ecc8': 458,\n",
       " '6555cbe24b13023f934a28cf': 695,\n",
       " '65316a311e5cc42b1b13db91': 977,\n",
       " '6555fe3a4b13023f934aeb61': 872,\n",
       " '65316f691e5cc42b1b13fe47': 587,\n",
       " '653168911e5cc42b1b13b02a': 1170,\n",
       " '6555cc674b13023f934a8954': 571,\n",
       " '6555c0f24b13023f9348cd72': 394,\n",
       " '6555cc344b13023f934a642a': 711,\n",
       " '6555c3f84b13023f9348d666': 422,\n",
       " '651dfcf5a662d76276b84451': 268,\n",
       " '6555cb134b13023f93499d52': 531,\n",
       " '6555c8124b13023f93490479': 1956,\n",
       " '6540c8a72936d70acf71ece1': 514,\n",
       " '6555cc4b4b13023f934a74e6': 415,\n",
       " '651df23ea662d76276b82b34': 1451,\n",
       " '651dd3dea662d76276b7dbf8': 517,\n",
       " '6525a735598c6618f06088bf': 715,\n",
       " '651dcdc4a662d76276b7caa8': 458,\n",
       " '6555bee94b13023f9348c5c9': 615,\n",
       " '651e00eea662d76276b84e56': 455,\n",
       " '6555ca5e4b13023f93493580': 1751,\n",
       " '6555cae94b13023f93498142': 1943,\n",
       " '6555f64d4b13023f934aeb0f': 549,\n",
       " '6555cb8f4b13023f9349ef6b': 895,\n",
       " '6555cc064b13023f934a423d': 428,\n",
       " '6555cc214b13023f934a55a7': 551,\n",
       " '652fc7ca1e5cc42b1b139fa2': 1950,\n",
       " '651dea03a662d76276b8158d': 988,\n",
       " '6555ccb84b13023f934ac379': 345,\n",
       " '653169081e5cc42b1b13ca8d': 698,\n",
       " '652fd3561e5cc42b1b13a526': 2349,\n",
       " '651df51ba662d76276b83284': 1707,\n",
       " '652fd2ff1e5cc42b1b13a4fc': 1743,\n",
       " '652fcbae1e5cc42b1b13a193': 1150,\n",
       " '6555cc874b13023f934a9f67': 596,\n",
       " '651de6d4a662d76276b80d5f': 1222,\n",
       " '6555caab4b13023f934956df': 517,\n",
       " '651e103ea662d76276b872f6': 533,\n",
       " '653169201e5cc42b1b13d1b1': 380,\n",
       " '651e2632a662d76276b8a69e': 348,\n",
       " '6555cc7e4b13023f934a9911': 692,\n",
       " '6555cbe04b13023f934a2746': 1456,\n",
       " '6555cbf54b13023f934a3604': 395,\n",
       " '653169191e5cc42b1b13cfac': 987,\n",
       " '651dcd90a662d76276b7ca27': 268,\n",
       " '6555cc744b13023f934a926a': 727,\n",
       " '651e19d3a662d76276b88957': 426,\n",
       " '6555c7d94b13023f9348e684': 1482,\n",
       " '6555c7f54b13023f9348f2ed': 1296,\n",
       " '6555cb914b13023f9349f0d8': 971,\n",
       " '653169271e5cc42b1b13d3bd': 553,\n",
       " '6555cc9d4b13023f934aae3e': 1266,\n",
       " '65316f0d1e5cc42b1b13ed84': 542,\n",
       " '6531691f1e5cc42b1b13d178': 663,\n",
       " '653169311e5cc42b1b13d58c': 896,\n",
       " '6555cc464b13023f934a716a': 920,\n",
       " '651df9b1a662d76276b83c5d': 235,\n",
       " '6555c80f4b13023f934902c7': 990,\n",
       " '651e1a2ea662d76276b88a28': 382,\n",
       " '6555cbcb4b13023f934a1878': 550,\n",
       " '6555cb714b13023f9349dade': 2080,\n",
       " '652fcd311e5cc42b1b13a25b': 1845,\n",
       " '6555b5cd4b13023f9348c059': 1062,\n",
       " '651e1fada662d76276b89734': 805,\n",
       " '6555caae4b13023f934958a2': 1394,\n",
       " '6555ca6c4b13023f9349391d': 1386,\n",
       " '6555ca6a4b13023f9349388b': 697,\n",
       " '6555cc2f4b13023f934a5fe5': 455,\n",
       " '65316f431e5cc42b1b13f657': 586,\n",
       " '653169ee1e5cc42b1b13dade': 606,\n",
       " '6555cbe44b13023f934a29b8': 454,\n",
       " '653168d11e5cc42b1b13bbb3': 754,\n",
       " '6531700d1e5cc42b1b1435af': 395,\n",
       " '6555cc204b13023f934a54c0': 694,\n",
       " '6555be974b13023f9348c48d': 900,\n",
       " '651e0719a662d76276b85dc8': 1038,\n",
       " '651dd2f1a662d76276b7d981': 295,\n",
       " '651dfb8da662d76276b840d0': 1010,\n",
       " '6555c4a14b13023f9348d94c': 477,\n",
       " '6555ca964b13023f93494a79': 810,\n",
       " '65316d161e5cc42b1b13e1d2': 710,\n",
       " '6555ccd64b13023f934adc8b': 562,\n",
       " '65316dfd1e5cc42b1b13e3f8': 986,\n",
       " '651de502a662d76276b80882': 501,\n",
       " '6555cc864b13023f934a9e0d': 540,\n",
       " '652df9085669b40a3b5ab6f9': 256,\n",
       " '6555c7f54b13023f9348f31a': 1123,\n",
       " '6555c8284b13023f934912bb': 1013,\n",
       " '652e31165669b40a3b5ab75f': 134,\n",
       " '65546c8b4b13023f9348b55a': 530,\n",
       " '651ddfe4a662d76276b7fada': 758,\n",
       " '653170071e5cc42b1b1433ba': 565,\n",
       " '6555c83b4b13023f934920e0': 1490,\n",
       " '65316eea1e5cc42b1b13e994': 264,\n",
       " '6555c1c34b13023f9348d082': 429,\n",
       " '6525a74a598c6618f0608a3b': 1287,\n",
       " '6555caec4b13023f934983ad': 507,\n",
       " '6555cc404b13023f934a6cf3': 702,\n",
       " '651e0ef2a662d76276b86fe0': 252,\n",
       " '651de69fa662d76276b80cc9': 166,\n",
       " '65316f081e5cc42b1b13eccf': 821,\n",
       " '653680031e5cc42b1b143e39': 1810,\n",
       " '6555c9d94b13023f93492c5f': 676,\n",
       " '6555cb844b13023f9349e7b8': 928,\n",
       " '651e1912a662d76276b887a0': 571,\n",
       " '6555c8254b13023f9349109d': 458,\n",
       " '6555cc324b13023f934a6245': 332,\n",
       " '6555c81b4b13023f93490a2b': 1569,\n",
       " '6555c7ff4b13023f9348f88e': 1291,\n",
       " '6555cbe74b13023f934a2c71': 432,\n",
       " '65316a351e5cc42b1b13db99': 693,\n",
       " '65316f8a1e5cc42b1b1406bb': 742,\n",
       " '653168981e5cc42b1b13b108': 614,\n",
       " '6555cbdd4b13023f934a24eb': 1697,\n",
       " '6555c0174b13023f9348c9cd': 621,\n",
       " '6531690b1e5cc42b1b13cb90': 950,\n",
       " '651de081a662d76276b7fc81': 629,\n",
       " '6555caca4b13023f93496bd1': 567,\n",
       " '651df803a662d76276b838e9': 496,\n",
       " '651e0ae4a662d76276b8667a': 345,\n",
       " '6540c7462936d70acf71e39f': 2223,\n",
       " '65367fe11e5cc42b1b143c6f': 1601,\n",
       " '653168c31e5cc42b1b13b896': 1274,\n",
       " '651ddda2a662d76276b7f4b5': 1239,\n",
       " '652ebbd61e5cc42b1b139b24': 891,\n",
       " '651e15daa662d76276b8800f': 327,\n",
       " '6555c3c84b13023f9348d5a5': 694,\n",
       " '6555c81b4b13023f93490a84': 770,\n",
       " '655c1d494b13023f934af3e0': 206,\n",
       " '6555c80e4b13023f934901aa': 1630,\n",
       " '65316f2f1e5cc42b1b13f2d0': 93,\n",
       " '6555c8d44b13023f9349279b': 399,\n",
       " '6555cadf4b13023f93497a68': 1289,\n",
       " '6555cba24b13023f9349fcbd': 893,\n",
       " '651de056a662d76276b7fc0b': 287,\n",
       " '651e1d5aa662d76276b8918c': 754,\n",
       " '65367ff11e5cc42b1b143d25': 1839,\n",
       " '6555bfdc4b13023f9348c8bb': 646,\n",
       " '651dc5b4a662d76276b7b4c1': 594,\n",
       " '651dea6da662d76276b816b8': 240,\n",
       " '65316ea91e5cc42b1b13e602': 1257,\n",
       " '65316ff91e5cc42b1b142ddc': 514,\n",
       " '651dfd67a662d76276b84577': 358,\n",
       " '6555c80e4b13023f934901e7': 1655,\n",
       " '651defa6a662d76276b8245a': 468,\n",
       " '6555c82a4b13023f934914d6': 585,\n",
       " '6555ccb54b13023f934ac033': 453,\n",
       " '651e0205a662d76276b85128': 315,\n",
       " '6555cbe54b13023f934a2a7a': 931,\n",
       " '652ebbae1e5cc42b1b13999f': 775,\n",
       " '65316fc11e5cc42b1b1417db': 1078,\n",
       " '653170041e5cc42b1b143264': 267,\n",
       " '6555cba74b13023f934a0025': 635,\n",
       " '651de10ea662d76276b7fdf7': 602,\n",
       " '6555c4754b13023f9348d89a': 747,\n",
       " '6555cac24b13023f934965db': 2163,\n",
       " '6555c7c24b13023f9348e045': 952,\n",
       " '6555c8044b13023f9348fbaa': 1270,\n",
       " '65316fad1e5cc42b1b141129': 764,\n",
       " '6555c8074b13023f9348fd11': 1873,\n",
       " '654310cfdc4fa72a6c40378f': 237,\n",
       " '651e0c83a662d76276b86a39': 693,\n",
       " '655c8dd9f1c0ed6a1e042295': 906,\n",
       " '6555c8114b13023f93490394': 780,\n",
       " '6555cad64b13023f934973ee': 918,\n",
       " '6555b4bc4b13023f9348b775': 1715,\n",
       " '653170081e5cc42b1b143443': 526,\n",
       " '65316f9b1e5cc42b1b140b85': 406,\n",
       " '6555cc1f4b13023f934a53cf': 920,\n",
       " '6531685f1e5cc42b1b13aa78': 545,\n",
       " '651dffefa662d76276b84bbd': 935,\n",
       " '6555c8204b13023f93490d7a': 526,\n",
       " '653680181e5cc42b1b143fe4': 184,\n",
       " '6555cc6e4b13023f934a8e4c': 775,\n",
       " '6555c0e44b13023f9348cd38': 1133,\n",
       " '651dc6faa662d76276b7b7fd': 994,\n",
       " '6555cbf54b13023f934a361b': 901,\n",
       " '6555c1e04b13023f9348d0c7': 431,\n",
       " '651de75da662d76276b80eb7': 400,\n",
       " '6555b4cf4b13023f9348b7dc': 1482,\n",
       " '6555cc794b13023f934a95f9': 570,\n",
       " '6540c8aa2936d70acf71ed82': 579,\n",
       " '6555cc2e4b13023f934a5f4f': 966,\n",
       " '6555ccbb4b13023f934ac5b7': 1028,\n",
       " '653169a21e5cc42b1b13da01': 785,\n",
       " '6555cc964b13023f934aa88e': 1521,\n",
       " '6555c1554b13023f9348cf2b': 1663,\n",
       " '651dfca3a662d76276b8438a': 575,\n",
       " '65316b661e5cc42b1b13deaf': 1029,\n",
       " '651dd22aa662d76276b7d737': 767,\n",
       " '6555cc9e4b13023f934aaf0f': 477,\n",
       " '6555be7c4b13023f9348c42b': 432,\n",
       " '651de815a662d76276b81094': 425,\n",
       " '6555bf8f4b13023f9348c78b': 484,\n",
       " '6555cac94b13023f93496b32': 1053,\n",
       " '652ebb961e5cc42b1b139925': 712,\n",
       " '6555caf94b13023f93498bf8': 708,\n",
       " '653168581e5cc42b1b13a9dd': 700,\n",
       " '651dd870a662d76276b7e730': 195,\n",
       " '6531690a1e5cc42b1b13cb36': 495,\n",
       " '651e22cea662d76276b89e93': 437,\n",
       " '6555ccc04b13023f934ac9f4': 491,\n",
       " '651de3a1a662d76276b804f8': 457,\n",
       " '651dca24a662d76276b7c0da': 476,\n",
       " '6555cc334b13023f934a632c': 570,\n",
       " '6531688d1e5cc42b1b13af76': 449,\n",
       " '6555cac14b13023f93496556': 1626,\n",
       " '65367fe81e5cc42b1b143cb6': 751,\n",
       " '651e0c73a662d76276b86a15': 444,\n",
       " '6555c7c14b13023f9348dff3': 323,\n",
       " '6555cac14b13023f93496514': 1103,\n",
       " '654856d8dc4fa72a6c403a83': 225,\n",
       " '65316f9b1e5cc42b1b140b56': 693,\n",
       " '6555cc2f4b13023f934a5ff5': 825,\n",
       " '652ebbbb1e5cc42b1b1399ff': 664,\n",
       " '65316f011e5cc42b1b13ec0e': 251,\n",
       " '65316f911e5cc42b1b1408ba': 566,\n",
       " '6555caa14b13023f9349503b': 1450,\n",
       " '65316faa1e5cc42b1b14100c': 1470,\n",
       " '65316fa21e5cc42b1b140db4': 788,\n",
       " '651e0533a662d76276b85936': 465,\n",
       " '6555ca444b13023f934930d8': 1057,\n",
       " '6555cc294b13023f934a5b49': 391,\n",
       " '6555c3b74b13023f9348d55f': 1277,\n",
       " '6531693b1e5cc42b1b13d71e': 991,\n",
       " '65316ec41e5cc42b1b13e6d9': 508,\n",
       " '6555c8304b13023f934918d3': 283,\n",
       " '6555cbd54b13023f934a1ee8': 514,\n",
       " '651e06b3a662d76276b85cd0': 320,\n",
       " '65316f701e5cc42b1b13fff8': 575,\n",
       " '651ddca2a662d76276b7f229': 661,\n",
       " '65316eca1e5cc42b1b13e720': 1226,\n",
       " '651dcec9a662d76276b7cd8c': 902,\n",
       " '651e151ba662d76276b87e4c': 468,\n",
       " '651df90aa662d76276b83ac9': 264,\n",
       " '6555c8164b13023f9349073b': 498,\n",
       " '6555c10d4b13023f9348cdeb': 1133,\n",
       " '6531692f1e5cc42b1b13d547': 716,\n",
       " '6555c11b4b13023f9348ce26': 434,\n",
       " '65316d801e5cc42b1b13e2db': 272,\n",
       " '65316fd51e5cc42b1b141f83': 615,\n",
       " '651e01b2a662d76276b8505c': 614,\n",
       " '653169321e5cc42b1b13d5c5': 1101,\n",
       " '6555c2e34b13023f9348d320': 729,\n",
       " '652ebba21e5cc42b1b13995f': 590,\n",
       " '65316fc41e5cc42b1b14191f': 839,\n",
       " '6555c39a4b13023f9348d4ef': 665,\n",
       " '6531700d1e5cc42b1b1435cc': 860,\n",
       " '6555cb6f4b13023f9349d9aa': 388,\n",
       " '6555cbd04b13023f934a1b7b': 872,\n",
       " '6555cc034b13023f934a400d': 1037,\n",
       " '651dd9fba662d76276b7eb2e': 1073,\n",
       " '6555b5aa4b13023f9348be32': 1851,\n",
       " '653168611e5cc42b1b13aaa0': 502,\n",
       " '6555cc124b13023f934a4a5f': 687,\n",
       " '6555c5744b13023f9348dce8': 822,\n",
       " '6555caf74b13023f93498acd': 835,\n",
       " '6555ccd24b13023f934ad9de': 426,\n",
       " '651dee44a662d76276b820cc': 693,\n",
       " '65316ff81e5cc42b1b142d4b': 527,\n",
       " '653169e01e5cc42b1b13dac1': 1260,\n",
       " '6555c8054b13023f9348fc1a': 803,\n",
       " '653168991e5cc42b1b13b13d': 472,\n",
       " '65316e451e5cc42b1b13e491': 509,\n",
       " '65316f891e5cc42b1b140662': 1075,\n",
       " '651e0444a662d76276b856dd': 535,\n",
       " '6531ed711e5cc42b1b1437e1': 254,\n",
       " '651deaafa662d76276b8176e': 423,\n",
       " '6555cc474b13023f934a7207': 775,\n",
       " '655acbce4b13023f934af1a8': 216,\n",
       " '653168b91e5cc42b1b13b6bc': 552,\n",
       " '65316f571e5cc42b1b13fa6c': 731,\n",
       " '651e120ca662d76276b87736': 350,\n",
       " '65316fad1e5cc42b1b1410e9': 321,\n",
       " '651e1c53a662d76276b88f0a': 809,\n",
       " '65316f6d1e5cc42b1b13ff52': 1976,\n",
       " '651e225fa662d76276b89d86': 1076,\n",
       " '6555cb654b13023f9349d258': 1437,\n",
       " '651decb5a662d76276b81ca0': 536,\n",
       " '6555bfb84b13023f9348c81e': 1182,\n",
       " '655585d74b13023f9348b602': 235,\n",
       " '65316f701e5cc42b1b140006': 2188,\n",
       " '6555b5b34b13023f9348bea6': 1839,\n",
       " '65367feb1e5cc42b1b143cd6': 1072,\n",
       " '652fc9831e5cc42b1b13a075': 1276,\n",
       " '65316f391e5cc42b1b13f489': 728,\n",
       " '65316fb31e5cc42b1b1412ec': 1077,\n",
       " '651dca8aa662d76276b7c1f7': 1383,\n",
       " '6555cb664b13023f9349d31d': 1426,\n",
       " '6531694c1e5cc42b1b13d8d7': 481,\n",
       " '651dfcd8a662d76276b8440e': 494,\n",
       " '652fce771e5cc42b1b13a305': 1419,\n",
       " '65316e201e5cc42b1b13e438': 278,\n",
       " '651ddc84a662d76276b7f1da': 904,\n",
       " '651de7c1a662d76276b80fb5': 659,\n",
       " '651e220ea662d76276b89cc6': 293,\n",
       " '6555ccd84b13023f934ade2e': 1732,\n",
       " '653169c01e5cc42b1b13da4e': 703,\n",
       " '651dfc1ea662d76276b84243': 479,\n",
       " '651e0f45a662d76276b870ae': 897,\n",
       " '6555c4974b13023f9348d922': 404,\n",
       " ...}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98debfa6-57b3-4fdc-a66f-611d926f9aa7",
   "metadata": {},
   "source": [
    "#### Finding the token limit for articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ec554d1f-f427-4429-8564-0aee5ab3acde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1970"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_template = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"|article_start|\\n {''}\\n|article_end|\\n\"}]\n",
    "\n",
    "OUTPUT_TOKEN_LIMIT = 768 # set based on the distribution of completion tokens from gpt4\n",
    "INSTRUCTION_TOKENS = len(tokenizer.apply_chat_template(message_template, add_generation_prompt=True))\n",
    "BUFFER_TOKENS = 10\n",
    "ARTICLE_TOKEN_LIMIT = 4096 - OUTPUT_TOKEN_LIMIT - INSTRUCTION_TOKENS - BUFFER_TOKENS\n",
    "ARTICLE_TOKEN_LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "27fc8b53-9acd-4cfd-985d-965be38cbfc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_text_response_as_prompt(train_row):\n",
    "    truncated_content = truncate_text_to_token_limit(text=train_row['content'], encoder=tokenizer, token_limit=ARTICLE_TOKEN_LIMIT)\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"|article_start|\\n {truncated_content}\\n|article_end|\\n\"}]\n",
    "    context_prompt = tokenizer.decode(tokenizer.apply_chat_template(messages, add_generation_prompt=True))\n",
    "    prompt = context_prompt + train_row['attributes']\n",
    "    prompt = re.sub(r'\\n+','\\n',prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2d7b8d29-b7bc-4f86-bfd6-6b822822fe0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame.from_dict(cleaned_train_set).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6c8bc982-31b7-4c31-8d30-e18dc922c63b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6553534c4b13023f9348b482    {'analysis_of_financial_or_business_news': 'Th...\n",
       "6555bfb84b13023f9348c81e    {'analysis_of_financial_or_business_news': 'Th...\n",
       "6555cc294b13023f934a5b49    {'analysis_of_financial_or_business_news': 'Th...\n",
       "6555ca694b13023f9349384b    {'analysis_of_financial_or_business_news': 'Th...\n",
       "651dd553a662d76276b7df9e    {'analysis_of_financial_or_business_news': 'Th...\n",
       "6531691d1e5cc42b1b13d106    {'analysis_of_financial_or_business_news': 'Th...\n",
       "6555cbc64b13023f934a151d    {'analysis_of_financial_or_business_news': 'Th...\n",
       "6555ca934b13023f934948be    {'analysis_of_financial_or_business_news': 'Ar...\n",
       "651def13a662d76276b822e9    {'analysis_of_financial_or_business_news': 'Th...\n",
       "6555ca6a4b13023f9349388b    {'analysis_of_financial_or_business_news': 'Th...\n",
       "Name: attributes, dtype: object"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['attributes'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4570863f-0252-478f-b89c-18addffc8156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis_of_financial_or_business_news': 'Article deals with the gold prices fluctuation in relation to US credit rating downgrade by Fitch',\n",
       " 'financial_or_business_news': True,\n",
       " 'analysis_of_relevant_for_india': 'Gold prices are dictated by international events, the Fitch rating downgrade of US is hence relevant to Indian investors.',\n",
       " 'relevant_for_india': True,\n",
       " 'analysis_of_article_validity_duration': 'Article deals with daily gold prices, so the relevance duration is one day.',\n",
       " 'article_validity_duration': 1,\n",
       " 'analysis_of_popularity': 'This news is going to be important to all investors who have invested or are thinking of investing in gold.',\n",
       " 'popularity': 'breaking_news',\n",
       " 'analysis_of_article_type': 'The article is a combination of facts and analysis as it provides factual data and draws inferences for investors.',\n",
       " 'article_type': 'analysis',\n",
       " 'analysis_of_article_sentiment': 'NA as the article is presenting the current state of affairs without any bullish or bearish sentiment.',\n",
       " 'article_sentiment': 'na',\n",
       " 'headline_suggestion': 'Gold Prices Rise on Fitch US Credit Downgrade; Implications for Indian Investors',\n",
       " 'first_attempt_summary': 'Gold prices are on the rise in the wake of Fitch Ratings downgrading the US credit rating. The downgrade can impact the US economy and investor confidence, leading to a weaker dollar, ultimately boosting the value of gold. Investors prefer gold in times of economic uncertainty. These fluctuations are crucial for Indian investors to follow.',\n",
       " 'improved_summary': \"As gold prices rise due to Fitch Ratings downgrading the US credit rating and denting the US economy's confidence, experts suggest possible investment strategies. A weaker dollar typically boosts gold's value, making it a preferred investment option during economic instability. Indian investors should carefully observe these fluctuations.\",\n",
       " 'final_summary': 'After US credit rating downgrade by Fitch Ratings, gold prices have risen due to dented confidence in the US economy, triggering a weaker dollar and strengthening gold. Experts outline investment strategies for these economically unstable times making this situation noteworthy for Indian investors.',\n",
       " 'top_categories': 'Finance; Commodities; Investment; Gold; Credit Ratings'}"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.attributes.sample(10).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "705ed650-a113-4414-a7e4-b39024eb4373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67c030-895d-4c7d-bbe8-6ea32104ce76",
   "metadata": {},
   "source": [
    "### Setting up prompt in ChatML Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "33af3259-0675-4233-b63c-6484ea3aa555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_text_response_as_prompt(train_row):\n",
    "    truncated_content = truncate_text_to_token_limit(text=train_row['content'], encoder=tokenizer, token_limit=ARTICLE_TOKEN_LIMIT)\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"|article_start|\\n {truncated_content}\\n|article_end|\\n\"}]\n",
    "    context_prompt = tokenizer.decode(tokenizer.apply_chat_template(messages, add_generation_prompt=True))\n",
    "    prompt = context_prompt + json.dumps(train_row['attributes'])\n",
    "    prompt = re.sub(r'\\n+','\\n',prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8976a6-b82f-4312-a525-07006a113bcc",
   "metadata": {},
   "source": [
    "### Create chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e7e2ba02-cea3-4573-9161-068fac132a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a976fa18374463bf47384f9bfe04de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175e3cadbf404f329b48307a7f99346c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking dataset into chunks of 4096 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "553ea1dfd8274eeb81bd91c6ab90f8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1241 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 834\n",
      "Total number of samples: 834\n"
     ]
    }
   ],
   "source": [
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_text_response_as_prompt(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(template_dataset)\n",
    "# tokenize dataset\n",
    "dataset = dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(dataset.features)\n",
    ")\n",
    "# chunk dataset\n",
    "lm_dataset = pack_dataset(dataset, chunk_length=4096) # We use 4096 as the maximum length for packing\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9433667-f5f6-4c9a-a6a3-e19c9f50cd26",
   "metadata": {},
   "source": [
    "### Saving training data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "02d91b51-a693-47eb-b24d-3f3c715e7785",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b49abf5a46749d3a8b292e077794d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/834 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n",
      "training dataset to: s3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/gpt4-samples/train-full-1-dec\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/fine_tuning_datasets/gpt4-samples/train-full-1-dec'\n",
    "lm_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "print(f\"training dataset to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2d38214b-3b12-4628-a7e7-e8ae50e7e7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 834\n",
       "})"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a2533-b2d1-476e-bad8-1b51ecb3bdb1",
   "metadata": {},
   "source": [
    "### Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "44304c47-94f8-48db-ad95-a6a66ffb35a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'num_train_epochs': 2,                            # number of training epochs\n",
    "  'per_device_train_batch_size': 5,                 # batch size for training\n",
    "  'gradient_accumulation_steps': 3,                 # Number of updates steps to accumulate\n",
    "  'gradient_checkpointing': True,                   # save memory but slower backward pass\n",
    "  'bf16': True,                                     # use bfloat16 precision\n",
    "  'tf32': True,                                     # use tf32 precision\n",
    "  'learning_rate': 5e-4,                            # learning rate\n",
    "  'max_grad_norm': 0.3,                             # Maximum norm (for gradient clipping)\n",
    "  'warmup_ratio': 0.03,                             # warmup ratio\n",
    "  \"lr_scheduler_type\":\"cosine_with_restarts\",                   # learning rate scheduler\n",
    "    'weight_decay': 0.1,\n",
    "  'save_strategy': \"epoch\",                         # save strategy for checkpoints\n",
    "  \"logging_steps\": 10,                              # log every x steps\n",
    "  'merge_adapters': True,                           # wether to merge LoRA into the model (needs more memory)\n",
    "  'use_flash_attn': True,                           # Whether to use Flash Attention\n",
    "  'output_dir': '/tmp/run',                         # output directory, where to save assets during training\n",
    "                                                    # could be used for checkpointing. The final trained\n",
    "                                                    # model will always be saved to s3 at the end of training\n",
    "}\n",
    "\n",
    "if HfFolder.get_token() is not None:\n",
    "    hyperparameters['hf_token'] = HfFolder.get_token() # huggingface token to access gated models, e.g. llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "6908d813-bb59-4f10-9b5a-79c8830e3f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ravi.tej/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f'huggingface-qlora-{hyperparameters[\"model_id\"].replace(\"/\",\"-\").replace(\".\",\"-\")}-full-1-dec-packed'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_qlora.py',    # train script\n",
    "    source_dir           = '../utils/',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.12xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 6*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 300,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    "    disable_output_compression = True         # not compress output to save training time and cost\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe723b0-2ef5-4f09-a59a-21162e453b6a",
   "metadata": {},
   "source": [
    "### Training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "16ae277e-1468-4629-af41-63d3400280a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-teknium-OpenHermes-2--2023-12-01-04-00-29-947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-01 04:00:31 Starting - Starting the training job......\n",
      "2023-12-01 04:01:15 Starting - Preparing the instances for training......\n",
      "2023-12-01 04:02:30 Downloading - Downloading input data...\n",
      "2023-12-01 04:02:50 Training - Downloading the training image...........................\n",
      "2023-12-01 04:07:36 Training - Training image download completed. Training in progress.......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:30,266 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:30,326 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:30,335 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:30,336 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:31,649 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.35.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 105.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.5.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 25.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting optimum==1.14.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl (398 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 398.9/398.9 kB 65.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.23.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.1/258.1 kB 53.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.41.2.post2-py3-none-any.whl (92.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.6/92.6 MB 16.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.3 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 81.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.12.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 311.7/311.7 kB 59.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 117.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting coloredlogs (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 10.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers[sentencepiece]>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (4.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (2.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (0.1.99)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 28.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (12.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (3.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.9.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: bitsandbytes, safetensors, humanfriendly, huggingface-hub, coloredlogs, tokenizers, accelerate, transformers, peft, optimum\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.14.1\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.14.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.14.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.23.0 bitsandbytes-0.41.2.post2 coloredlogs-15.0.1 huggingface-hub-0.19.4 humanfriendly-10.0 optimum-1.14.0 peft-0.5.0 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.35.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:45,069 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:45,069 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:45,130 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:45,200 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:45,270 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:45,281 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"gradient_accumulation_steps\": 3,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"learning_rate\": 0.0005,\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"cosine_with_restarts\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"teknium/OpenHermes-2.5-Mistral-7B\",\n",
      "        \"num_train_epochs\": 2,\n",
      "        \"output_dir\": \"/tmp/run\",\n",
      "        \"per_device_train_batch_size\": 5,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"use_flash_attn\": true,\n",
      "        \"warmup_ratio\": 0.03,\n",
      "        \"weight_decay\": 0.1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-teknium-OpenHermes-2--2023-12-01-04-00-29-947\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2023-12-01-04-00-29-947/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_qlora\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_qlora.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":3,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":0.0005,\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":5,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03,\"weight_decay\":0.1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_qlora.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.12xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_qlora\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2023-12-01-04-00-29-947/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.12xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":3,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":0.0005,\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":5,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03,\"weight_decay\":0.1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-teknium-OpenHermes-2--2023-12-01-04-00-29-947\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2023-12-01-04-00-29-947/source/sourcedir.tar.gz\",\"module_name\":\"run_qlora\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_qlora.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training\",\"--gradient_accumulation_steps\",\"3\",\"--gradient_checkpointing\",\"True\",\"--hf_token\",\"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\",\"--learning_rate\",\"0.0005\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"cosine_with_restarts\",\"--max_grad_norm\",\"0.3\",\"--merge_adapters\",\"True\",\"--model_id\",\"teknium/OpenHermes-2.5-Mistral-7B\",\"--num_train_epochs\",\"2\",\"--output_dir\",\"/tmp/run\",\"--per_device_train_batch_size\",\"5\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--use_flash_attn\",\"True\",\"--warmup_ratio\",\"0.03\",\"--weight_decay\",\"0.1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=3\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0005\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=cosine_with_restarts\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=teknium/OpenHermes-2.5-Mistral-7B\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=2\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/run\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=5\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FLASH_ATTN=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 3 --gradient_checkpointing True --hf_token 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 --learning_rate 0.0005 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters True --model_id teknium/OpenHermes-2.5-Mistral-7B --num_train_epochs 2 --output_dir /tmp/run --per_device_train_batch_size 5 --save_strategy epoch --tf32 True --use_flash_attn True --warmup_ratio 0.03 --weight_decay 0.1\u001b[0m\n",
      "\u001b[34m2023-12-01 04:08:45,308 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flash-attn in /opt/conda/lib/python3.10/site-packages (0.2.8)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.3.6.tar.gz (2.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 41.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.3.6-cp310-cp310-linux_x86_64.whl size=56556525 sha256=1c918d84ff042582d547e4c9c7ec24ec9f3975589ca28cc4e6cbd15486b74f2a\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/24/5f/16/5044cdddb6dfb3331dfbffa28ab6096ec2900777af5cb0253a\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mSuccessfully installed flash-attn-2.3.6\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mLogging into the Hugging Face Hub with token hf_NjVkEqg...\u001b[0m\n",
      "\u001b[34mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\u001b[0m\n",
      "\u001b[34mToken is valid (permission: write).\u001b[0m\n",
      "\u001b[34mYour token has been saved to /root/.cache/huggingface/token\u001b[0m\n",
      "\u001b[34mLogin successful\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/624 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 624/624 [00:00<00:00, 6.41MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin.index.json: 100%|██████████| 23.9k/23.9k [00:00<00:00, 164MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   1%|          | 52.4M/9.94G [00:00<00:24, 405MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   1%|          | 94.4M/9.94G [00:00<00:25, 389MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   1%|▏         | 147M/9.94G [00:00<00:22, 433MB/s] #033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   2%|▏         | 199M/9.94G [00:00<00:21, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   3%|▎         | 252M/9.94G [00:00<00:20, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   3%|▎         | 315M/9.94G [00:00<00:19, 488MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   4%|▍         | 377M/9.94G [00:00<00:18, 509MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   4%|▍         | 440M/9.94G [00:00<00:17, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   5%|▌         | 503M/9.94G [00:01<00:17, 545MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   6%|▌         | 566M/9.94G [00:01<00:23, 400MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   6%|▋         | 629M/9.94G [00:01<00:21, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   7%|▋         | 692M/9.94G [00:01<00:19, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   8%|▊         | 755M/9.94G [00:01<00:18, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   8%|▊         | 818M/9.94G [00:01<00:17, 508MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   9%|▉         | 881M/9.94G [00:01<00:17, 521MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:   9%|▉         | 944M/9.94G [00:01<00:17, 528MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  10%|█         | 1.01G/9.94G [00:02<00:17, 519MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  11%|█         | 1.07G/9.94G [00:02<00:16, 537MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  11%|█▏        | 1.13G/9.94G [00:02<00:17, 499MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  12%|█▏        | 1.20G/9.94G [00:02<00:16, 517MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  13%|█▎        | 1.26G/9.94G [00:02<00:16, 536MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  13%|█▎        | 1.32G/9.94G [00:02<00:15, 546MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  14%|█▍        | 1.38G/9.94G [00:02<00:18, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  14%|█▍        | 1.44G/9.94G [00:03<00:20, 415MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  15%|█▌        | 1.50G/9.94G [00:03<00:18, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  16%|█▌        | 1.56G/9.94G [00:03<00:17, 479MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  16%|█▋        | 1.63G/9.94G [00:03<00:16, 506MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  17%|█▋        | 1.69G/9.94G [00:03<00:15, 521MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  18%|█▊        | 1.75G/9.94G [00:03<00:15, 539MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  18%|█▊        | 1.81G/9.94G [00:03<00:14, 546MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  19%|█▉        | 1.88G/9.94G [00:03<00:15, 532MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  20%|█▉        | 1.94G/9.94G [00:03<00:15, 507MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  20%|██        | 1.99G/9.94G [00:04<00:15, 507MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  21%|██        | 2.06G/9.94G [00:04<00:14, 528MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  21%|██▏       | 2.12G/9.94G [00:04<00:14, 541MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  22%|██▏       | 2.18G/9.94G [00:04<00:14, 541MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  23%|██▎       | 2.24G/9.94G [00:04<00:14, 546MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  23%|██▎       | 2.31G/9.94G [00:04<00:14, 523MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  24%|██▍       | 2.37G/9.94G [00:04<00:15, 502MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  24%|██▍       | 2.42G/9.94G [00:04<00:15, 487MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  25%|██▍       | 2.49G/9.94G [00:04<00:14, 513MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  26%|██▌       | 2.54G/9.94G [00:05<00:14, 510MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  26%|██▌       | 2.60G/9.94G [00:05<00:14, 524MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  27%|██▋       | 2.66G/9.94G [00:05<00:15, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  27%|██▋       | 2.72G/9.94G [00:05<00:15, 475MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  28%|██▊       | 2.78G/9.94G [00:05<00:14, 489MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  28%|██▊       | 2.83G/9.94G [00:05<00:14, 475MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  29%|██▉       | 2.88G/9.94G [00:05<00:15, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  30%|██▉       | 2.94G/9.94G [00:05<00:14, 482MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  30%|███       | 2.99G/9.94G [00:06<00:14, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  31%|███       | 3.04G/9.94G [00:06<00:14, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  31%|███       | 3.09G/9.94G [00:06<00:14, 489MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  32%|███▏      | 3.16G/9.94G [00:06<00:13, 504MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  32%|███▏      | 3.22G/9.94G [00:06<00:13, 509MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  33%|███▎      | 3.27G/9.94G [00:06<00:13, 508MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  34%|███▎      | 3.33G/9.94G [00:06<00:12, 520MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  34%|███▍      | 3.40G/9.94G [00:06<00:12, 524MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  35%|███▍      | 3.46G/9.94G [00:06<00:12, 533MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  35%|███▌      | 3.52G/9.94G [00:07<00:11, 540MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  36%|███▌      | 3.59G/9.94G [00:07<00:12, 529MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  37%|███▋      | 3.65G/9.94G [00:07<00:11, 539MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  37%|███▋      | 3.71G/9.94G [00:07<00:11, 538MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  38%|███▊      | 3.77G/9.94G [00:07<00:11, 539MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  39%|███▊      | 3.84G/9.94G [00:07<00:11, 539MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  39%|███▉      | 3.90G/9.94G [00:07<00:11, 535MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  40%|███▉      | 3.96G/9.94G [00:07<00:11, 541MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  40%|████      | 4.03G/9.94G [00:08<00:12, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  41%|████      | 4.09G/9.94G [00:08<00:12, 482MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  42%|████▏     | 4.15G/9.94G [00:08<00:11, 497MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  42%|████▏     | 4.22G/9.94G [00:08<00:11, 510MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  43%|████▎     | 4.28G/9.94G [00:08<00:10, 520MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  44%|████▎     | 4.34G/9.94G [00:08<00:10, 525MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  44%|████▍     | 4.40G/9.94G [00:08<00:11, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  45%|████▍     | 4.46G/9.94G [00:08<00:11, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  45%|████▌     | 4.52G/9.94G [00:09<00:10, 497MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  46%|████▌     | 4.58G/9.94G [00:09<00:10, 516MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  47%|████▋     | 4.65G/9.94G [00:09<00:10, 528MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  47%|████▋     | 4.71G/9.94G [00:09<00:09, 536MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  48%|████▊     | 4.77G/9.94G [00:09<00:09, 541MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  49%|████▊     | 4.83G/9.94G [00:09<00:09, 545MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  49%|████▉     | 4.90G/9.94G [00:09<00:09, 525MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  50%|████▉     | 4.96G/9.94G [00:09<00:09, 512MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  50%|█████     | 5.01G/9.94G [00:10<00:12, 406MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  51%|█████     | 5.06G/9.94G [00:10<00:11, 427MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.13G/9.94G [00:10<00:10, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  52%|█████▏    | 5.18G/9.94G [00:10<00:12, 380MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.24G/9.94G [00:10<00:11, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  53%|█████▎    | 5.31G/9.94G [00:10<00:10, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  54%|█████▍    | 5.37G/9.94G [00:10<00:09, 484MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  55%|█████▍    | 5.43G/9.94G [00:10<00:09, 485MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  55%|█████▌    | 5.48G/9.94G [00:11<00:09, 482MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  56%|█████▌    | 5.55G/9.94G [00:11<00:08, 502MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  56%|█████▋    | 5.61G/9.94G [00:11<00:08, 506MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  57%|█████▋    | 5.67G/9.94G [00:11<00:08, 519MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.74G/9.94G [00:11<00:07, 531MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  58%|█████▊    | 5.80G/9.94G [00:11<00:08, 491MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.85G/9.94G [00:11<00:10, 392MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  59%|█████▉    | 5.90G/9.94G [00:12<00:10, 378MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  60%|██████    | 5.97G/9.94G [00:12<00:09, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  61%|██████    | 6.03G/9.94G [00:12<00:08, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  61%|██████▏   | 6.09G/9.94G [00:12<00:08, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.14G/9.94G [00:12<00:08, 473MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  62%|██████▏   | 6.20G/9.94G [00:12<00:07, 483MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.25G/9.94G [00:12<00:07, 484MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  63%|██████▎   | 6.30G/9.94G [00:12<00:07, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.35G/9.94G [00:12<00:07, 453MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  64%|██████▍   | 6.41G/9.94G [00:13<00:08, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  65%|██████▍   | 6.46G/9.94G [00:13<00:08, 423MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  65%|██████▌   | 6.51G/9.94G [00:13<00:07, 432MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  66%|██████▌   | 6.57G/9.94G [00:13<00:07, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.63G/9.94G [00:13<00:07, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  67%|██████▋   | 6.69G/9.94G [00:13<00:06, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.75G/9.94G [00:13<00:06, 488MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  68%|██████▊   | 6.81G/9.94G [00:13<00:06, 483MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  69%|██████▉   | 6.87G/9.94G [00:14<00:06, 501MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  70%|██████▉   | 6.93G/9.94G [00:14<00:05, 515MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  70%|███████   | 6.99G/9.94G [00:14<00:05, 529MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  71%|███████   | 7.06G/9.94G [00:14<00:06, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.11G/9.94G [00:14<00:06, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  72%|███████▏  | 7.17G/9.94G [00:14<00:05, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.22G/9.94G [00:14<00:05, 478MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  73%|███████▎  | 7.29G/9.94G [00:14<00:05, 498MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  74%|███████▍  | 7.35G/9.94G [00:15<00:05, 518MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  75%|███████▍  | 7.41G/9.94G [00:15<00:04, 532MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  75%|███████▌  | 7.48G/9.94G [00:15<00:04, 541MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  76%|███████▌  | 7.54G/9.94G [00:15<00:04, 524MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  76%|███████▋  | 7.60G/9.94G [00:15<00:04, 495MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  77%|███████▋  | 7.67G/9.94G [00:15<00:04, 515MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.73G/9.94G [00:15<00:04, 532MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  78%|███████▊  | 7.79G/9.94G [00:15<00:04, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  79%|███████▉  | 7.85G/9.94G [00:16<00:04, 475MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  80%|███████▉  | 7.91G/9.94G [00:16<00:04, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  80%|████████  | 7.97G/9.94G [00:16<00:04, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  81%|████████  | 8.02G/9.94G [00:16<00:04, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  81%|████████  | 8.07G/9.94G [00:16<00:04, 397MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.14G/9.94G [00:16<00:04, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  82%|████████▏ | 8.20G/9.94G [00:16<00:03, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  83%|████████▎ | 8.26G/9.94G [00:16<00:03, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  84%|████████▎ | 8.32G/9.94G [00:17<00:03, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  84%|████████▍ | 8.38G/9.94G [00:17<00:03, 481MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  85%|████████▍ | 8.44G/9.94G [00:17<00:02, 504MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  85%|████████▌ | 8.49G/9.94G [00:17<00:03, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  86%|████████▌ | 8.55G/9.94G [00:17<00:03, 456MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  86%|████████▋ | 8.60G/9.94G [00:17<00:02, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  87%|████████▋ | 8.66G/9.94G [00:17<00:02, 488MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.71G/9.94G [00:17<00:02, 494MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  88%|████████▊ | 8.78G/9.94G [00:17<00:02, 508MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.84G/9.94G [00:18<00:02, 495MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  89%|████████▉ | 8.89G/9.94G [00:18<00:02, 428MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  90%|█████████ | 8.95G/9.94G [00:18<00:02, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  91%|█████████ | 9.01G/9.94G [00:18<00:02, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  91%|█████████ | 9.06G/9.94G [00:18<00:01, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.12G/9.94G [00:18<00:01, 489MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  92%|█████████▏| 9.19G/9.94G [00:18<00:01, 503MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  93%|█████████▎| 9.25G/9.94G [00:18<00:01, 515MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  94%|█████████▎| 9.31G/9.94G [00:19<00:01, 524MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  94%|█████████▍| 9.37G/9.94G [00:19<00:01, 525MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  95%|█████████▍| 9.44G/9.94G [00:19<00:01, 494MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  95%|█████████▌| 9.49G/9.94G [00:19<00:00, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  96%|█████████▌| 9.55G/9.94G [00:19<00:00, 504MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.62G/9.94G [00:19<00:00, 511MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  97%|█████████▋| 9.68G/9.94G [00:19<00:00, 519MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  98%|█████████▊| 9.74G/9.94G [00:19<00:00, 524MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  99%|█████████▊| 9.80G/9.94G [00:20<00:00, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin:  99%|█████████▉| 9.86G/9.94G [00:20<00:00, 428MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin: 100%|█████████▉| 9.92G/9.94G [00:20<00:00, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00001-of-00002.bin: 100%|██████████| 9.94G/9.94G [00:20<00:00, 487MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 1/2 [00:20<00:20, 20.90s/it]\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   1%|          | 31.5M/4.54G [00:00<00:15, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   2%|▏         | 73.4M/4.54G [00:00<00:12, 348MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   3%|▎         | 115M/4.54G [00:00<00:13, 327MB/s] #033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   4%|▎         | 168M/4.54G [00:00<00:11, 367MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   5%|▍         | 220M/4.54G [00:00<00:11, 388MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   6%|▌         | 262M/4.54G [00:00<00:11, 387MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   7%|▋         | 304M/4.54G [00:00<00:10, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   8%|▊         | 346M/4.54G [00:00<00:10, 395MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:   9%|▊         | 388M/4.54G [00:01<00:10, 401MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  10%|▉         | 440M/4.54G [00:01<00:09, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  11%|█         | 482M/4.54G [00:01<00:10, 390MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  12%|█▏        | 545M/4.54G [00:01<00:09, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  13%|█▎        | 608M/4.54G [00:01<00:08, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  15%|█▍        | 671M/4.54G [00:01<00:07, 489MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  16%|█▌        | 734M/4.54G [00:01<00:07, 509MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  17%|█▋        | 786M/4.54G [00:01<00:09, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  18%|█▊        | 839M/4.54G [00:02<00:11, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  19%|█▉        | 881M/4.54G [00:02<00:12, 296MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  20%|██        | 923M/4.54G [00:02<00:11, 320MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  21%|██        | 965M/4.54G [00:02<00:10, 329MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  23%|██▎       | 1.03G/4.54G [00:02<00:09, 389MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  24%|██▍       | 1.09G/4.54G [00:02<00:07, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  25%|██▌       | 1.15G/4.54G [00:02<00:07, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  27%|██▋       | 1.22G/4.54G [00:03<00:06, 502MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  28%|██▊       | 1.27G/4.54G [00:03<00:07, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  29%|██▉       | 1.32G/4.54G [00:03<00:07, 431MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  30%|███       | 1.38G/4.54G [00:03<00:06, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  32%|███▏      | 1.45G/4.54G [00:03<00:06, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  33%|███▎      | 1.51G/4.54G [00:03<00:06, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  34%|███▍      | 1.56G/4.54G [00:03<00:07, 375MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  35%|███▌      | 1.60G/4.54G [00:03<00:08, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  37%|███▋      | 1.67G/4.54G [00:04<00:06, 411MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  38%|███▊      | 1.73G/4.54G [00:04<00:06, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  39%|███▉      | 1.79G/4.54G [00:04<00:05, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  41%|████      | 1.86G/4.54G [00:04<00:05, 476MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  42%|████▏     | 1.91G/4.54G [00:04<00:05, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  43%|████▎     | 1.97G/4.54G [00:04<00:05, 478MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  45%|████▍     | 2.02G/4.54G [00:04<00:05, 423MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  46%|████▌     | 2.09G/4.54G [00:04<00:05, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  47%|████▋     | 2.15G/4.54G [00:05<00:04, 493MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  48%|████▊     | 2.20G/4.54G [00:05<00:04, 488MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  50%|████▉     | 2.25G/4.54G [00:05<00:04, 480MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  51%|█████     | 2.31G/4.54G [00:05<00:04, 489MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  52%|█████▏    | 2.37G/4.54G [00:05<00:04, 504MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  53%|█████▎    | 2.42G/4.54G [00:05<00:04, 505MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  55%|█████▍    | 2.47G/4.54G [00:05<00:04, 498MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  56%|█████▌    | 2.54G/4.54G [00:05<00:03, 511MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  57%|█████▋    | 2.59G/4.54G [00:05<00:03, 497MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  58%|█████▊    | 2.65G/4.54G [00:06<00:03, 510MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  60%|█████▉    | 2.72G/4.54G [00:06<00:03, 515MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  61%|██████    | 2.77G/4.54G [00:06<00:03, 517MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  62%|██████▏   | 2.83G/4.54G [00:06<00:03, 529MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  64%|██████▎   | 2.89G/4.54G [00:06<00:03, 545MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  65%|██████▌   | 2.96G/4.54G [00:06<00:02, 540MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  67%|██████▋   | 3.02G/4.54G [00:06<00:02, 532MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  68%|██████▊   | 3.08G/4.54G [00:06<00:02, 544MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  69%|██████▉   | 3.15G/4.54G [00:07<00:02, 519MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  71%|███████   | 3.21G/4.54G [00:07<00:02, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  72%|███████▏  | 3.27G/4.54G [00:07<00:02, 536MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  73%|███████▎  | 3.33G/4.54G [00:07<00:02, 509MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  75%|███████▍  | 3.40G/4.54G [00:07<00:02, 529MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  76%|███████▌  | 3.46G/4.54G [00:07<00:02, 527MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  78%|███████▊  | 3.52G/4.54G [00:07<00:01, 540MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  79%|███████▉  | 3.59G/4.54G [00:07<00:01, 550MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  80%|████████  | 3.65G/4.54G [00:07<00:01, 548MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  82%|████████▏ | 3.71G/4.54G [00:08<00:01, 533MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  83%|████████▎ | 3.77G/4.54G [00:08<00:01, 533MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  85%|████████▍ | 3.84G/4.54G [00:08<00:01, 488MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  86%|████████▌ | 3.89G/4.54G [00:08<00:01, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  87%|████████▋ | 3.94G/4.54G [00:08<00:01, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  88%|████████▊ | 4.00G/4.54G [00:08<00:01, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  89%|████████▉ | 4.05G/4.54G [00:08<00:01, 475MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  90%|█████████ | 4.10G/4.54G [00:08<00:00, 482MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  91%|█████████▏| 4.15G/4.54G [00:09<00:00, 484MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  93%|█████████▎| 4.22G/4.54G [00:09<00:00, 497MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  94%|█████████▍| 4.27G/4.54G [00:09<00:00, 499MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  95%|█████████▌| 4.32G/4.54G [00:09<00:00, 496MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  96%|█████████▋| 4.37G/4.54G [00:09<00:00, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  97%|█████████▋| 4.42G/4.54G [00:09<00:00, 494MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin:  99%|█████████▉| 4.49G/4.54G [00:09<00:00, 513MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin: 100%|██████████| 4.54G/4.54G [00:09<00:00, 510MB/s]#033[A\u001b[0m\n",
      "\u001b[34mpytorch_model-00002-of-00002.bin: 100%|██████████| 4.54G/4.54G [00:09<00:00, 463MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:31<00:00, 14.63s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:31<00:00, 15.57s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.32s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.60s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.86s/it]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 120/120 [00:00<00:00, 979kB/s]\u001b[0m\n",
      "\u001b[34mFound 7 modules to quantize: ['k_proj', 'up_proj', 'down_proj', 'o_proj', 'v_proj', 'q_proj', 'gate_proj']\u001b[0m\n",
      "\u001b[34mtrainable params: 167,772,160 || all params: 7,409,520,640 || trainable%: 2.2642781922259414\u001b[0m\n",
      "\u001b[34m0%|          | 0/110 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34m1%|          | 1/110 [01:28<2:41:35, 88.95s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 2/110 [02:57<2:39:44, 88.75s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 3/110 [04:26<2:38:08, 88.68s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 4/110 [05:54<2:36:36, 88.65s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 5/110 [07:23<2:35:06, 88.63s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 6/110 [08:51<2:33:36, 88.62s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 7/110 [10:20<2:32:07, 88.62s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 8/110 [11:49<2:30:38, 88.61s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 9/110 [13:17<2:29:09, 88.61s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 10/110 [14:46<2:27:40, 88.61s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1949, 'learning_rate': 0.0004960576444868992, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34m9%|▉         | 10/110 [14:46<2:27:40, 88.61s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 11/110 [16:14<2:26:12, 88.61s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 12/110 [17:43<2:24:43, 88.61s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 13/110 [19:12<2:23:14, 88.61s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 14/110 [20:40<2:21:46, 88.61s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 15/110 [22:09<2:20:17, 88.61s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 16/110 [23:38<2:18:48, 88.60s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 17/110 [25:06<2:17:20, 88.60s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 18/110 [26:35<2:15:51, 88.60s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 19/110 [28:03<2:14:22, 88.60s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 20/110 [29:32<2:12:54, 88.60s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8665, 'learning_rate': 0.00047241427274868686, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 20/110 [29:32<2:12:54, 88.60s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 21/110 [31:01<2:11:25, 88.60s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 22/110 [32:29<2:09:57, 88.60s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 23/110 [33:58<2:08:28, 88.60s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 24/110 [35:26<2:06:59, 88.60s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 25/110 [36:55<2:05:31, 88.60s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 26/110 [38:24<2:04:02, 88.60s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 27/110 [39:52<2:02:34, 88.60s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 28/110 [41:21<2:01:05, 88.60s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 29/110 [42:49<1:59:36, 88.60s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 30/110 [44:18<1:58:08, 88.60s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9427, 'learning_rate': 0.00042937681426108274, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 30/110 [44:18<1:58:08, 88.60s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 31/110 [45:47<1:56:39, 88.60s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 32/110 [47:15<1:55:11, 88.61s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 33/110 [48:44<1:53:42, 88.61s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 34/110 [50:12<1:52:14, 88.61s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 35/110 [51:41<1:50:45, 88.61s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 36/110 [53:10<1:49:16, 88.61s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 37/110 [54:38<1:47:48, 88.61s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 38/110 [56:07<1:46:19, 88.61s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 39/110 [57:35<1:44:51, 88.61s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 40/110 [59:04<1:43:22, 88.61s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.866, 'learning_rate': 0.00037069805068268627, 'epoch': 0.72}\u001b[0m\n",
      "\u001b[34m36%|███▋      | 40/110 [59:04<1:43:22, 88.61s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 41/110 [1:00:33<1:41:53, 88.60s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 42/110 [1:02:01<1:40:25, 88.60s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 43/110 [1:03:30<1:38:56, 88.60s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 44/110 [1:04:58<1:37:27, 88.60s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 45/110 [1:06:27<1:35:59, 88.60s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 46/110 [1:07:56<1:34:30, 88.60s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 47/110 [1:09:24<1:33:01, 88.60s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 48/110 [1:10:53<1:31:33, 88.60s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 49/110 [1:12:21<1:30:04, 88.60s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 50/110 [1:13:50<1:28:36, 88.60s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8503, 'learning_rate': 0.0003014946546852746, 'epoch': 0.9}\u001b[0m\n",
      "\u001b[34m45%|████▌     | 50/110 [1:13:50<1:28:36, 88.60s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 51/110 [1:15:19<1:27:07, 88.60s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 52/110 [1:16:47<1:25:38, 88.60s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 53/110 [1:18:16<1:24:10, 88.60s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 54/110 [1:19:44<1:22:41, 88.60s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 55/110 [1:21:13<1:21:13, 88.60s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 56/110 [1:22:37<1:18:28, 87.19s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 57/110 [1:24:06<1:17:23, 87.61s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 58/110 [1:25:34<1:16:11, 87.91s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 59/110 [1:27:03<1:14:53, 88.12s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 60/110 [1:28:31<1:13:33, 88.26s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7954, 'learning_rate': 0.00022780102616926632, 'epoch': 1.08}\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 60/110 [1:28:31<1:13:33, 88.26s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 61/110 [1:30:00<1:12:09, 88.37s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 62/110 [1:31:29<1:10:45, 88.44s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 63/110 [1:32:57<1:09:18, 88.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 64/110 [1:34:26<1:07:52, 88.52s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 65/110 [1:35:54<1:06:24, 88.55s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 66/110 [1:37:23<1:04:56, 88.56s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 67/110 [1:38:52<1:03:28, 88.57s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 68/110 [1:40:20<1:02:00, 88.58s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 69/110 [1:41:49<1:00:32, 88.59s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 70/110 [1:43:17<59:03, 88.59s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7305, 'learning_rate': 0.00015604310447144053, 'epoch': 1.26}\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 70/110 [1:43:17<59:03, 88.59s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 71/110 [1:44:46<57:35, 88.60s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 72/110 [1:46:15<56:06, 88.60s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 73/110 [1:47:43<54:38, 88.60s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 74/110 [1:49:12<53:09, 88.60s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 75/110 [1:50:40<51:40, 88.60s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 76/110 [1:52:09<50:12, 88.60s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 77/110 [1:53:38<48:43, 88.60s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 78/110 [1:55:06<47:15, 88.60s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 79/110 [1:56:35<45:46, 88.60s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 80/110 [1:58:03<44:17, 88.60s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7803, 'learning_rate': 9.247803910457226e-05, 'epoch': 1.44}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 80/110 [1:58:03<44:17, 88.60s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 81/110 [1:59:32<42:49, 88.60s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 82/110 [2:01:01<41:20, 88.60s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 83/110 [2:02:29<39:52, 88.60s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 84/110 [2:03:58<38:23, 88.60s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 85/110 [2:05:26<36:55, 88.60s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 86/110 [2:06:55<35:26, 88.60s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 87/110 [2:08:24<33:57, 88.60s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 88/110 [2:09:52<32:29, 88.60s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 89/110 [2:11:21<31:00, 88.60s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 90/110 [2:12:49<29:32, 88.60s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7642, 'learning_rate': 4.2648578637449556e-05, 'epoch': 1.62}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 90/110 [2:12:49<29:32, 88.60s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 91/110 [2:14:18<28:03, 88.60s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 92/110 [2:15:47<26:34, 88.60s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 93/110 [2:17:15<25:06, 88.60s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 94/110 [2:18:44<23:37, 88.60s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 95/110 [2:20:12<22:09, 88.60s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 96/110 [2:21:41<20:40, 88.60s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 97/110 [2:23:10<19:11, 88.60s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 98/110 [2:24:38<17:43, 88.60s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 99/110 [2:26:07<16:14, 88.60s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 100/110 [2:27:35<14:46, 88.60s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7227, 'learning_rate': 1.0899753930869394e-05, 'epoch': 1.8}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 100/110 [2:27:35<14:46, 88.60s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 101/110 [2:29:04<13:17, 88.60s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 102/110 [2:30:33<11:48, 88.60s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 103/110 [2:32:01<10:20, 88.60s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 104/110 [2:33:30<08:51, 88.60s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 105/110 [2:34:58<07:23, 88.61s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 106/110 [2:36:27<05:54, 88.61s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 107/110 [2:37:56<04:25, 88.61s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 108/110 [2:39:24<02:57, 88.61s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 109/110 [2:40:53<01:28, 88.61s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 110/110 [2:42:21<00:00, 88.61s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7657, 'learning_rate': 0.0, 'epoch': 1.98}\u001b[0m\n",
      "\u001b[34m100%|██████████| 110/110 [2:42:21<00:00, 88.61s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 9742.9483, 'train_samples_per_second': 0.171, 'train_steps_per_second': 0.011, 'train_loss': 0.843550239909779, 'epoch': 1.98}\u001b[0m\n",
      "\u001b[34m100%|██████████| 110/110 [2:42:22<00:00, 88.61s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 110/110 [2:42:22<00:00, 88.57s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.06s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.84s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.03s/it]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 1.60k/1.60k [00:00<00:00, 9.49MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 89.1MB/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json: 100%|██████████| 51.0/51.0 [00:00<00:00, 415kB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 101/101 [00:00<00:00, 823kB/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m2023-12-01 06:55:59,799 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-12-01 06:55:59,799 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-12-01 06:55:59,799 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-12-01 06:56:08 Uploading - Uploading generated training model\n",
      "2023-12-01 06:56:49 Completed - Training job completed\n",
      "Training seconds: 10460\n",
      "Billable seconds: 10460\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_input_path}\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9cb916-6469-4746-b97b-6c2ba4e96922",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "7a185fae-6b17-45bd-96aa-73e005c40e68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py39\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: gpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"1.1.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "7b3444f4-9c5d-45c6-9cb6-a01b7fa21c97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e457d6f3-2023-43c5-81ac-6b294aef5182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397'"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0863cbb-9c81-429e-bf67-3a42eb21d49d",
   "metadata": {},
   "source": [
    "#### Download model to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f77dc39d-8448-4486-b99f-cf004d2c3238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize a boto3 S3 client\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "442df457-92f1-4714-80c5-5c63a8af3a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 30] Read-only file system: '/debug-output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[181], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m s3_file_path \u001b[38;5;241m=\u001b[39m obj[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKey\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m local_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(local_folder, s3_file_path[\u001b[38;5;28mlen\u001b[39m(s3_folder):])\n\u001b[0;32m---> 21\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(local_file_path), exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     22\u001b[0m s3\u001b[38;5;241m.\u001b[39mdownload_file(bucket_name, s3_file_path, local_file_path)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms3_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/debug-output'"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize a boto3 S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# S3 bucket and folder details\n",
    "bucket_name = 'sagemaker-ap-south-1-005418323977'\n",
    "s3_folder = 'huggingface-qlora-teknium-OpenHermes-2--2023-11-29-05-23-47-562'\n",
    "\n",
    "# Local directory to save files\n",
    "local_folder = './hermes_full_finetuned_model/'\n",
    "\n",
    "# List objects within the specified S3 folder\n",
    "objects = s3.list_objects_v2(Bucket=bucket_name, Prefix=s3_folder)\n",
    "\n",
    "# Download each file in the folder\n",
    "for obj in objects.get('Contents', []):\n",
    "    s3_file_path = obj['Key']\n",
    "    local_file_path = os.path.join(local_folder, s3_file_path[len(s3_folder):])\n",
    "    os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "    s3.download_file(bucket_name, s3_file_path, local_file_path)\n",
    "    print(f'Downloaded {s3_file_path} to {local_file_path}')\n",
    "\n",
    "# Remember to replace 'your-bucket-name', 'your-folder-name/', and 'path/to/local/folder/' with your actual bucket name, S3 folder, and local folder path.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0987420a-1b54-4a7f-9e9c-a6d47040dc6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dadea77f-af0e-4af4-86b1-fe89bdab5460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "from huggingface_hub import HfFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a50e7d2-750a-4a5e-a290-e9af74556410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c4404f88-4c84-44bf-9a97-3bca77d85a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.35.2'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f39327ad-1171-49c8-9044-e7e270735244",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers\n",
      "  Cloning https://github.com/huggingface/transformers to /private/var/folders/d4/cgyr_gnj7nn2wy_hq40gkq8c0000gq/T/pip-req-build-fvqwwsub\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /private/var/folders/d4/cgyr_gnj7nn2wy_hq40gkq8c0000gq/T/pip-req-build-fvqwwsub\n",
      "  Resolved https://github.com/huggingface/transformers to commit 3bc50d81e6c70d63e59d635106bac6a561b47681\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (2023.7.22)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.36.0.dev0-py3-none-any.whl size=8048947 sha256=38109c4d4a4b05baf5d143f483a397e952fdded8c2a4b4dc9c36e75e3483b40d\n",
      "  Stored in directory: /private/var/folders/d4/cgyr_gnj7nn2wy_hq40gkq8c0000gq/T/pip-ephem-wheel-cache-pab9gusl/wheels/14/a0/7b/8f6b25ba4110aa215fcb8d6aedd6cd4f9b9b6619190999ac2b\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.35.2\n",
      "    Uninstalling transformers-4.35.2:\n",
      "      Successfully uninstalled transformers-4.35.2\n",
      "Successfully installed transformers-4.36.0.dev0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134d41c8-83a2-4c58-bb55-6aec92acf4a5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ravi.tej/anaconda3/envs/bertopicenv/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88278256-a9cd-4662-84db-439006947434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3aa33-dc5d-414b-92c6-fc9dd5b9237b",
   "metadata": {},
   "source": [
    "### Upload to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ee7ff3fb-d610-4cbb-9328-ab06b8ed2c49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05414f7ba934c368ebd1b36467ab559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('./hermes_finetuned_model/', local_files_only = True, torch_dtype = torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b8bcbba1-e789-4e44-8d4b-e03010095a34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7564bd269a534e2cabc63a556841bb12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520568007bb848f68e0013ca617b4686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b4c8cc9f33444192f555c5c3ee3582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f431aa46fd455c89e1f588953abedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/WintWealth/partial_finetuned_open_hermes_2.5/commit/e48ca5f4ad711b31dfa6ea52d45a0e548e5a9adb', commit_message='Upload model', commit_description='', oid='e48ca5f4ad711b31dfa6ea52d45a0e548e5a9adb', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('WintWealth/partial_finetuned_open_hermes_2.5', token = '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', private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a11fb8-3e67-4687-9583-23b9383c4fe3",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "608ba764-b86a-498f-8993-ba0772c55b7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3328"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4096 - 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ed934755-bf78-48db-a105-7650556ea5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ravi.tej/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ravi.tej/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# s3 path where the model will be uploaded\n",
    "# if you try to deploy the model to a different time add the s3 path here\n",
    "# model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.2xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(3328), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(4096), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data={'S3DataSource':{'S3Uri': model_s3_path,'S3DataType': 'S3Prefix','CompressionType': 'None'}},\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "8a559d8e-1ebc-43e8-bfd0-d1196456d4d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are the chief editor for a leading Indian financial and business news website. You evaluate critical attributes of articles to gate keep content quality. For many attributes, you will first provide a brief analysis of 15 to 30 words, followed by assessment.\\n\\n1. analysis_of_financial_or_business_news (short text) : <analyse if article pertains to finance/business or not. government policies directly impacting indian corporations or investors are ok, but not if aren\\'t>\\n2. financial_or_business_news (True or False) : <True or False based on previous attribute>\\n3. analysis_of_relevant_for_india (short text) : <analyse if article is relevant for indians. for example international articles about 401k or small foreign companies won\\'t be relevant for india. however changes to fed interest rates or nasdaq or important news of large multinational corporations will be relevant>\\n4. relevant_for_india (True or False) : <True or False based on previous attribute>\\n5. analysis_of_article_validity_duration (short text) : <analyse relevance duration. Be stingy: Stock fluctuations, 1 day; significant policy changes - few days or a week; educational content with references to any regulations is 30 unless there are none - in which case is timeless. International news in India has shorter lifespan. breaking news are usually not timeless; quarterly analysis or results are usually valid for a 3 days, yearly analysis or results for a weeks and a much longer one for a month.>\\n6. article_validity_duration (one of 1, 3, 7, 14, 30, -1) : <calculate number of days based on previous attribute. -1: timeless. 1: article is relevant only for that day. 3: for a couple of days. 7: for a week. 14: for a couple of weeks. 30: for a month>\\n7. analysis_of_popularity (short text) : <analyse likely popularity of article - if its for niche audience, moderate_popularity or should be part of breaking_news section, depending on number of people who will be impacted by the news and the scale of the event. foreign entities known in india but not very popular will be mostly niche or rarely moderately popular. articles targeted to very specific business or pratices will be niche. infotainment business and financial articles with some drama are likely to be more popular. articles with a list of rules without compelling story-telling will be for niche audience>\\n8. popularity (one of niche, moderately_popular, breaking_news) : <based on previous attribute>\\n9. analysis_of_article_type (short text) : <analyse if the article is majorly factual, is an opinion piece, analysis, educational or likely sponsored. factual articles pass on information on events. opinion pieces have inferences or predictions either from the author or from statements without data. analysis pieces have substantial data to justify their inferences or predictions. if an article is overly zealous on certain stock and seems like an ad, then it is sponsored>\\n10. article_type (one of fact, opinion, analysis, educational, sponsored) : <based on previous attribute>\\n11. analysis_of_article_sentiment (short_text): <analyse if the sentiment of the article is bullish, bearish or NA. balanced is NA>\\n12. article_sentiment (one of bull, bear, na): <based on previous attribute>\\n13. headline_suggestion (short text) : <Write a headline based on the content of the article>\\n14. first_attempt_summary (text of 60 words) : <Generate concise, entity-dense summary. The summary should become highly dense but easily understood without the Article. Don\\'t keep the summary too short, but limit it to no more than 60 words>\\n15. improved_summary (text of 60 words): <Identify contents of the article which are missing from the previous summary but are important part of the article>\\n16. final_summary (text of 60 words): <The finalised summary which is a mixture of first_attempt_summary and improved_summary. This summary should be very dense and also all the important information of the article and yet concise. By reading this in most cases the users need not read the article>\\n17. categories_hierarchy (5 semi colon seperated categories): <Hierarchy of 5 categories or keywords. Start with a generic category and make it progressively specific. Select only 5 and seperate them by (;). Don\\'t use either single or double quotes at any cost to avoid json.loads() failure>\\n\\nyour response should be a json structure with all the 17 above keys without missing any key. It is very important that the response is directly readable with json.loads(). no preamble or postamble. respond in the exact following structure:\\n\\n{\\n\"analysis_of_financial_or_business_news\": \"\",\\n\"financial_or_business_news\": \"\",\\n\"analysis_of_relevant_for_india\": \"\",\\n\"relevant_for_india\": \"\",\\n\"analysis_of_article_validity_duration\": \"\",\\n\"article_validity_duration\": \"\",\\n\"analysis_of_popularity\": \"\",\\n\"popularity\": \"\",\\n\"analysis_of_article_type\": \"\",\\n\"article_type\": \"\",\\n\"analysis_of_article_sentiment\": \"\",\\n\"article_sentiment\": \"\",\\n\"headline_suggestion\": \"\",\\n\"first_attempt_summary\": \"\",\\n\"improved_summary\": \"\",\\n\"final_summary\": \"\",\\n\"top_categories\": \"\"\\n}\\n\\n|article_start|\\n'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "85bad177-3c5d-443c-8a96-c01483c77b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-tgi-inference-2023-12-01-07-00-05-316\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-tgi-inference-2023-12-01-07-00-06-142\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-tgi-inference-2023-12-01-07-00-06-142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "b0b5c259-76aa-4b58-bcb7-092213d613b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = llm.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "bc4dd5da-517c-4f6c-b4e8-ab416b9907e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-tgi-inference-2023-12-01-07-00-06-142'"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dead63c4-0929-40e1-9888-97addf34644b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# endpoint_name = 'huggingface-pytorch-tgi-inference-2023-11-28-06-16-30-408'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "562d8821-3da7-4c60-9f7a-b1950acceccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# system_prompt = df.iloc[0].system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31d280be-9338-4ca3-90e3-a681b3038830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_article_for_prompt(article_text):\n",
    "    instruction = f\"<|im_start|>system\\n{new_system_prompt}<|im_end|>\\n\"\n",
    "    # not adding context as instruction ends with |actual_article|\n",
    "    context = f\"### <|im_start|>user\\n{article_text}|im_end|>\\n\"\n",
    "    response = f\"### <|im_start|>assistant\\n\"\n",
    "    prompt = \"\\n\\n\".join([i for i in [instruction, context, response] if i is not None])\n",
    "    prompt = re.sub(r'\\n+','\\n',prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a831fe67-6f4e-4401-9cf7-60675244c074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravi.tej/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/ravi.tej/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/ravi.tej/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/ravi.tej/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "parent_folder = '/Users/ravi.tej/Desktop/ML/Recommendations/arcane/'\n",
    "from hydra import compose, initialize\n",
    "import os\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('../../conf/application.run.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "envs_element = root.find('./configuration/envs')\n",
    "for variable in envs_element.findall('env'):\n",
    "    name = variable.get('name')\n",
    "    value = variable.get('value')\n",
    "    os.environ[name] = value\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/ravi.tej/Desktop/ML/Recommendations/arcane/')\n",
    "\n",
    "from src._utils import load_bertopic_model_from_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69d9220b-4ccf-4593-a333-58ef589b3041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.articles.ArticleService import ArticleService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5acfdf3b-192f-49e6-a98f-4f4815977070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "art = ArticleService._get_article_json_from_s3_and_api('652a045b50af0e25a9122fd2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e30584-3114-42bb-9af4-ba832b7626f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Parasitic, blood-sucking 'alien-like' wasp found in Amazon, eats host from inside outNEW DELHI: Scientists have identified a horrifying and dangerous new species of parasitic wasp that feeds on the blood of its host and devours it from the inside out. The Daily Star reports, this alien-like insect, named Capitojoppa amazonica, was discovered in the Amazon, specifically within the Allpahuayo-Mishana National Reserve in Peru. The parasitic wasp reaches a size of approximately 1.7cm and possesses a tube-like organ that injects an egg into the host's body. It usually targets caterpillars, beetles, and spiders.The wasp was discovered as part of an extensive, ongoing research project. The research team used specialized tent-like traps to capture flying insects in the rainforest. Capitojoppa amazonica is just one out of 109 newly discovered species.Brandon Claridge from Utah State University, who is also the lead author of the study that describes Capitojoppa amazonica, explained to Live Science  Once the host is located and mounted, the female will frantically stroke it with her antennae. If acceptable, the female will deposit a single egg inside the host by piercing it with her ovipositor. The larvae of the wasp consumes the host from the inside out, after the eggs are hatched. They subsequently develop within the deceased host's body before growing into adult wasps.Later, several other wasps gather to feed on the haemolymph, a fluid similar to blood, present inside the host after the expectant mother punctures it with her tube.Claridge stated,  Females will even stab the host with the ovipositor and feed without laying an egg as it helps with gaining nutrients for egg maturation”.Study co-author Ilari Sääksjärvi, from the University of Turku, said,  The species biodiversity of many organisms is highest on the whole planet at Allpahuayo-Mishana”.  Allpahuayo-Mishana is a part of the Amazon that has an unprecedented abundance of species, due to the region's complex geological history”, he added.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art['title'] + art['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fe49eea-05f0-4a19-a66d-586abb6754c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smr = sess.boto_session.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff32630e-f97c-45a7-a2b8-ace8fa765707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.8,\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"repetition_penalty\": 1.03,\n",
    "    \"stop\": [\"###\", \"</s>\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee9bcf0c-05d1-46ed-8c25-51f512d0762a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content = '''\n",
    "World economic issues cast shadow on Indian stock market, FIIs continue to sell\n",
    "The Indian stock market is facing challenges amid a contracting global landscape. Despite high valuations, factors like high inflation, bond yields, and geopolitical tensions are affecting market sustainability.\n",
    "\n",
    " Indian stock market under pressure due to FII selling (File photo)\n",
    "Indian stock market under pressure due to FII selling (File photo)\n",
    "It’s been a long journey for the Indian stock market. It has been growing well, generating superior wealth in the ongoing century. The Nifty 500, the broader equity index, has provided a decent CAGR of 13.6% over about 23 years. A one-time investment of ₹1 lakh in December 2000 would have been ₹21 lakh today. From the latest intra high of 17,754.05, dated September 12, it went down by 7.25% on October 26, and on November 3, Nifty 50 closed at 17,000.95, which is 4.25% lower. A short-term break in the long-term growing market.\n",
    "\n",
    "At the onset of the 21st century, the big picture for India was as a rising emerging market as the domestic economy had opened for world business. Initially, the focus was on infrastructure development, particularly in the areas of roads, power and realty, seen as basis fundamental to the new economy. However, it was often characterized as an elephant economy, substantial and steady, driven mainly by domestic demand, and not swiftly adapting to global opportunities. This placid perception has since shifted in the present decade, with the economy now recognized as a burgeoning force poised to become a global supply hub in the future. The multiplier effect is seen in varied sectors like Digital, Renewables, Electronics, Technology, Pharma to Chemical, while efficient working of government expenditure is also uplifting rural and domestic demand.\n",
    "\n",
    "The Indian economy & fiscal situation are as strong as they have ever been. Projections indicate a stable 6.5% YoY GDP growth from FY24 to FY26, alongside a 5.25% fiscal deficit, even amid global economic deceleration. H1FY24 corporate earnings growth has been bumper, with PAT growth of top 100 large cap estimates at 35% YoY. While no intrinsic structural issues have been identified within India, global circumstances have instigated fluctuations in the stock market, leading to currency volatility. INR has depreciated against USD, 83.270 Friday closing from 82.140 at March-end.\n",
    "\n",
    "The recent decline in the Indian stock market is predominantly driven by global factors. Notably, there is a conspicuous deceleration in the global economy, as evidenced by Europe's recession, with Germany, the region's foremost manufacturing hub, recording negative GDP growth for the past three quarters. In Asia, the engine growth of China is decelerating. Annual taker of 7% GDP growth, during pre-covid is forecast to settle to 4.5% in the future. It is leading the government to consider implementing a significant stimulus package to regain traction.\n",
    "\n",
    "Amid a contracting global landscape, two nations, the US and India, are decoupling. In 2022, the US was projected to enter a recession in the latter part of 2023, however, it managed to avert this scenario through the implementation of a comprehensive $8 trillion COVID assistance package, along with fiscal and monetary stimulus measures introduced by the government between 2020 and 2023. These initiatives had far-reaching benefits, extending support to households, states, healthcare, businesses, and other institutions. Consequently, the likelihood of a recession has now significantly diminished. However, a slowdown is forecast, the annual GDP growth is estimated to reduce from 2.3% in CY23 to 1% in CY24 due to high fiscal deficit, interest rate and quantitative tightening by the US FED.\n",
    "\n",
    "This is the primary issue of the global stock market, and the fallout of the world economy. The current global economic landscape stands in contrast to the elevated trajectory of the Indian stock market. It is becoming a challenge to hold the gains due to high FIIs selling in the last 3-4months. Even the optimistic H1 results are not supporting the market to sustain the momentum strong.\n",
    "\n",
    "Despite long-standing imbalances in the economy, including high inflation, elevated bond yields, geopolitical tensions, and supply constraints, the Indian stock market, like the main indices, has maintained a high valuation. For example, the MSCI India Index has been trading at an average one-year forward P/E of 20.5x above the long-term of 18x. Today at 19.6x, a dichotomy in context to dollar terms with elevated bond yield trading at decades high of 5%. FIIs are cautious as interest rates are expected to stay high, in-stroke to the hawkish central bank view, and economic slowdown and moderation in future earnings are warranting a consolidation in prices and valuations.\n",
    "\n",
    "The author, Vinod Nair is Head of Research at Geojit Financial Services\n",
    "\n",
    "Disclaimer: The views and recommendations made above are those of individual analysts or broking companies, and not of Mint. We advise investors to check with certified experts before taking any investment decisions.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "56c31b1b-cc2e-4e66-bb51-aa05d640d065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# request = {\"inputs\": format_article_for_prompt(art.full_content), \"parameters\": parameters, \"stream\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a06151fc-7aa9-4c4b-a4b3-a6133e4d9925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b21e7476-4f65-4891-b5de-88b4e58c403d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = {\"inputs\": format_article_for_prompt(content), \"parameters\": parameters, \"stream\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f4bf468-a28d-4d75-afd5-d7847bb534ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp = smr.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(request),\n",
    "    ContentType=\"application/json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3f6aa10-92e3-4c31-b393-29807fa29c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = resp['Body'].read()\n",
    "\n",
    "json.loads(json.loads(k)[0]['generated_text'])['summaries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c1184-2a04-4a59-968b-de37be3b02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6c9c5b46-d656-4174-a2e6-aaae0bf2ae89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt = '''\n",
    "The article highlights the challenges faced by the Indian stock market in light of global economic issues. Despite India's strong economy and positive corporate earnings growth, foreign institutional investors (FIIs) are selling their shares due to the global economic deceleration. The contraction in the global economy, led by Europe's recession and China's decelerating economy, is affecting the Indian market. The recent fall in the stock market is attributed to global factors, not intrinsic structural issues within India. The article concludes by stating that despite the challenges, the Indian stock market has maintained a high valuation, which is leading to consolidation in prices and valuations\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f76610c8-966d-42c9-a6ba-1a9b9e2c2c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c3a504dc-a766-422f-b970-ddc85df8a3dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sanghi Industries share price Today Live Updates : Sanghi Industries sees upward trend in trading  Mint:  On the last day Sanghi Industries stock opened at ₹ 123 and closed at ₹ 122.65. The stock reached its highest point of ₹ 123 and lowest point of ₹ 120.45 during the day. The market capitalization of the company is ₹ 3129.62 crore. The 52-week high and low for the stock are ₹ 131.9 and ₹ 51.55 respectively. The BSE volume for the stock was 6082 shares. Disclaimer: This is an AI-generated live blog and has not been edited by LiveMint staff. The current days low price of Sanghi Industries stock is ₹ 120.45 and the high price is ₹ 123. The current data for Sanghi Industries stock shows that the stock price is ₹ 122.7. There has been a 0.04 percent change in the stock price with a net change of 0.05. The current data for Sanghi Industries stock shows that the price is ₹ 121.3 with a percent change of -1.1 and a net change of -1.35. This indicates that the stock has decreased in value by 1.1% and has decreased by ₹ 1.35. The stock of Sanghi Industries reached a low of ₹ 120.45 and a high of ₹ 123 on the current day. On the last day Sanghi Industries had a trading volume of 6082 shares on the Bombay Stock Exchange (BSE). The closing price for the day was ₹ 122.65. Download the App to get 14 days of unlimited access to Mint Premium absolutely free '"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art.full_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138da96c-85c5-4475-b1d0-dc8cb99379c4",
   "metadata": {},
   "source": [
    "### Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71437896-8e59-44ae-9d73-7b3e9b5644cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoenv",
   "language": "python",
   "name": "recoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
