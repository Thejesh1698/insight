{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dae8e0e-fd24-4870-9f7f-6f2d8757aa16",
   "metadata": {},
   "source": [
    "## Defining sagemaker roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82bc8e0f-2ba5-4e0c-8ed3-c238c3de48c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AmazonSageMaker-ExecutionRole-20231030T210397'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "iam = boto3.client('iam')\n",
    "response = iam.list_roles()\n",
    "sagemaker_roles = [role for role in response['Roles'] if 'SageMaker' in role['RoleName']]\n",
    "sagemaker_roles[0]['RoleName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c85d3a-5038-4664-8233-54f715e2ebfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name username to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20231030T210397')['Role']['Arn']\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46d1dce9-a30e-41c2-95d5-c11788987a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "from random import randint\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from pack_dataset import pack_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ca8391-3908-49fb-8623-3a2ace44c45e",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c88b5ca-85d3-477b-9979-c1a0d5dafb20",
   "metadata": {},
   "source": [
    "### Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68482869-4c3a-44d8-92fc-9cfe23275ab2",
   "metadata": {},
   "source": [
    "### Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0d12915-99b3-49b0-a53d-fa4e1d31626a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/username/anaconda3/envs/recoenv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae33b4690dd54eeda75bdb3ef7d3ee8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c618a8632ce4ace9327bc0d68fc7348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52eee405a22a4233b07bea24ea177ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a8ee3ec2914f9dbe03fb6659151996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0da848-579d-46d0-9990-ea3784aad418",
   "metadata": {},
   "source": [
    "### GPT responses EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50a65873-2dc5-405a-a21a-e9b104c98886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('gpt-responses-29-dec-with-headers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efdecf01-cfba-4a8d-8801-448f9798737a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns = {'0', 'json_generated'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "761890da-068f-42a4-8525-111f7bc1d2db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>full_content</th>\n",
       "      <th>model</th>\n",
       "      <th>attributes</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65316d5c1e5cc42b1b13e25a</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: Mindless creation of brands has begu...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Brand Evolution**: Interbrand I...</td>\n",
       "      <td>2463</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65316ead1e5cc42b1b13e61a</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: Hero MotoCorp raises price of Harley...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Price Hike**: Hero MotoCorp has...</td>\n",
       "      <td>1869</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6555bf484b13023f9348c6db</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: Chinas Q3 GDP growth Sept activity s...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Growth Rate**: China's economy ...</td>\n",
       "      <td>2010</td>\n",
       "      <td>534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 article_id  \\\n",
       "0  65316d5c1e5cc42b1b13e25a   \n",
       "1  65316ead1e5cc42b1b13e61a   \n",
       "2  6555bf484b13023f9348c6db   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  \\nYou are an expert chief editor for a leading...   \n",
       "1  \\nYou are an expert chief editor for a leading...   \n",
       "2  \\nYou are an expert chief editor for a leading...   \n",
       "\n",
       "                                        full_content       model  \\\n",
       "0  headline: Mindless creation of brands has begu...  gpt-4-0613   \n",
       "1  headline: Hero MotoCorp raises price of Harley...  gpt-4-0613   \n",
       "2  headline: Chinas Q3 GDP growth Sept activity s...  gpt-4-0613   \n",
       "\n",
       "                                          attributes  prompt_tokens  \\\n",
       "0  {\"summary\": \"**Brand Evolution**: Interbrand I...           2463   \n",
       "1  {\"summary\": \"**Price Hike**: Hero MotoCorp has...           1869   \n",
       "2  {\"summary\": \"**Growth Rate**: China's economy ...           2010   \n",
       "\n",
       "   completion_tokens  \n",
       "0                587  \n",
       "1                537  \n",
       "2                534  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9f35aaf-6f23-49f9-8651-0b3aaa62c17a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "res = []\n",
    "for i in range(len(df)):\n",
    "    try:\n",
    "        res.append(json.loads(df.iloc[i]['attributes'])['article_validity_duration'])\n",
    "    except:\n",
    "        res.append(ast.literal_eval(json.loads(df.iloc[i]['attributes']))['article_validity_duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baa47576-95c1-45ca-b94b-57608f75156b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['validity'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aea6cb47-02cd-4f5b-a521-15a3edf2486e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_id           object\n",
       "prompt               object\n",
       "full_content         object\n",
       "model                object\n",
       "attributes           object\n",
       "prompt_tokens         int64\n",
       "completion_tokens     int64\n",
       "validity             object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6b30a52-ba57-4230-8adc-26e7d60243c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "validity\n",
       "-1     431\n",
       "1      142\n",
       "3      206\n",
       "5        1\n",
       "7      191\n",
       "14     283\n",
       "30     473\n",
       "60       1\n",
       "90      16\n",
       "180      1\n",
       "364      1\n",
       "365     19\n",
       "         8\n",
       "-1      69\n",
       "1       35\n",
       "14      56\n",
       "180      1\n",
       "3       43\n",
       "30      90\n",
       "365      7\n",
       "7       29\n",
       "90       1\n",
       "Name: validity, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('validity')['validity'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "047ad94a-460a-48f6-82e1-ed0202bea0fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>full_content</th>\n",
       "      <th>model</th>\n",
       "      <th>attributes</th>\n",
       "      <th>prompt_tokens</th>\n",
       "      <th>completion_tokens</th>\n",
       "      <th>validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>651dee50a662d76276b820ed</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: Russian strikes kill at least 8 civi...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Attacks**: Russian strikes on v...</td>\n",
       "      <td>1885</td>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>656476e496c80a0efa90f984</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: Should India impose a windfall tax  ...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Windfall Tax Debate**: Indian g...</td>\n",
       "      <td>2304</td>\n",
       "      <td>523</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>652ebbe21e5cc42b1b139be6</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: Detailed Trading Plans: The Ultimate...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Risk Control**: The article emp...</td>\n",
       "      <td>1944</td>\n",
       "      <td>486</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>657c31ca8f821120f67a0734</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: Dunki Advance Booking: Shah Rukh Kha...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Movie Release**: Rajkumar Hiran...</td>\n",
       "      <td>2018</td>\n",
       "      <td>561</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>6571c32325cc9a343f03e171</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: India inflation to return to comfort...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Inflation Insight**: According ...</td>\n",
       "      <td>1895</td>\n",
       "      <td>572</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>6560c2c3e1d8342798a44e1e</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: Indian companies sometimes face dela...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Payment delays**: Indian compan...</td>\n",
       "      <td>1582</td>\n",
       "      <td>496</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>6555c8034b13023f9348fafa</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: Bitcoin Gold: Distribution Protectio...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"\", \"summary_critique\": \"\", \"impro...</td>\n",
       "      <td>3275</td>\n",
       "      <td>143</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>652fd2b31e5cc42b1b13a4d6</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: Reasons Why the Card Issuer May Clos...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Issue Causes**: Multiple factor...</td>\n",
       "      <td>2966</td>\n",
       "      <td>732</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>651dca75a662d76276b7c1b5</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: Chaos in Assam assembly over allegat...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Allegation**: Company linked to...</td>\n",
       "      <td>1934</td>\n",
       "      <td>498</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>6555c00d4b13023f9348c98e</td>\n",
       "      <td>\\nYou are an expert chief editor for a leading...</td>\n",
       "      <td>headline: AIA eyeing to launch new fund next m...</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>{\"summary\": \"**Fund Launch**: AIA Philippines ...</td>\n",
       "      <td>2177</td>\n",
       "      <td>528</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    article_id  \\\n",
       "208   651dee50a662d76276b820ed   \n",
       "1146  656476e496c80a0efa90f984   \n",
       "1117  652ebbe21e5cc42b1b139be6   \n",
       "430   657c31ca8f821120f67a0734   \n",
       "1230  6571c32325cc9a343f03e171   \n",
       "1499  6560c2c3e1d8342798a44e1e   \n",
       "1770  6555c8034b13023f9348fafa   \n",
       "319   652fd2b31e5cc42b1b13a4d6   \n",
       "1729  651dca75a662d76276b7c1b5   \n",
       "760   6555c00d4b13023f9348c98e   \n",
       "\n",
       "                                                 prompt  \\\n",
       "208   \\nYou are an expert chief editor for a leading...   \n",
       "1146  \\nYou are an expert chief editor for a leading...   \n",
       "1117  \\nYou are an expert chief editor for a leading...   \n",
       "430   \\nYou are an expert chief editor for a leading...   \n",
       "1230  \\nYou are an expert chief editor for a leading...   \n",
       "1499  \\nYou are an expert chief editor for a leading...   \n",
       "1770  \\nYou are an expert chief editor for a leading...   \n",
       "319   \\nYou are an expert chief editor for a leading...   \n",
       "1729  \\nYou are an expert chief editor for a leading...   \n",
       "760   \\nYou are an expert chief editor for a leading...   \n",
       "\n",
       "                                           full_content       model  \\\n",
       "208   headline: Russian strikes kill at least 8 civi...  gpt-4-0613   \n",
       "1146  headline: Should India impose a windfall tax  ...  gpt-4-0613   \n",
       "1117  headline: Detailed Trading Plans: The Ultimate...  gpt-4-0613   \n",
       "430   headline: Dunki Advance Booking: Shah Rukh Kha...  gpt-4-0613   \n",
       "1230  headline: India inflation to return to comfort...  gpt-4-0613   \n",
       "1499  headline: Indian companies sometimes face dela...  gpt-4-0613   \n",
       "1770  headline: Bitcoin Gold: Distribution Protectio...  gpt-4-0613   \n",
       "319   headline: Reasons Why the Card Issuer May Clos...  gpt-4-0613   \n",
       "1729  headline: Chaos in Assam assembly over allegat...  gpt-4-0613   \n",
       "760   headline: AIA eyeing to launch new fund next m...  gpt-4-0613   \n",
       "\n",
       "                                             attributes  prompt_tokens  \\\n",
       "208   {\"summary\": \"**Attacks**: Russian strikes on v...           1885   \n",
       "1146  {\"summary\": \"**Windfall Tax Debate**: Indian g...           2304   \n",
       "1117  {\"summary\": \"**Risk Control**: The article emp...           1944   \n",
       "430   {\"summary\": \"**Movie Release**: Rajkumar Hiran...           2018   \n",
       "1230  {\"summary\": \"**Inflation Insight**: According ...           1895   \n",
       "1499  {\"summary\": \"**Payment delays**: Indian compan...           1582   \n",
       "1770  {\"summary\": \"\", \"summary_critique\": \"\", \"impro...           3275   \n",
       "319   {\"summary\": \"**Issue Causes**: Multiple factor...           2966   \n",
       "1729  {\"summary\": \"**Allegation**: Company linked to...           1934   \n",
       "760   {\"summary\": \"**Fund Launch**: AIA Philippines ...           2177   \n",
       "\n",
       "      completion_tokens validity  \n",
       "208                 550        1  \n",
       "1146                523       30  \n",
       "1117                486       -1  \n",
       "430                 561        7  \n",
       "1230                572        7  \n",
       "1499                496        7  \n",
       "1770                143           \n",
       "319                 732       -1  \n",
       "1729                498        3  \n",
       "760                 528       -1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a0dfb53-ef77-4c35-850f-4cb2cadc1d26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# structuring the format\n",
    "all_responses = {}\n",
    "for row in df.itertuples():\n",
    "    res = row.attributes\n",
    "    all_responses[row.article_id] = {'content': row.full_content, 'response': {}}\n",
    "    all_responses[row.article_id]['attributes'] = json.loads(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca3bd827-0185-4db4-873f-c5ba4a62bc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correct_validity_duration(val):\n",
    "    val = int(val)\n",
    "    valid_days = [-1, 1, 3, 7, 14, 30]\n",
    "    if val in valid_days:\n",
    "        return val\n",
    "    else:\n",
    "        for i in valid_days:\n",
    "            if val > i:\n",
    "                valid_value = i\n",
    "        return valid_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a65ecfd4-c9a8-4b28-8a4d-293944bcd6af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3dde016-f045-437a-b357-9f61b4a94a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['content', 'response', 'attributes'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_responses['6540c8a62936d70acf71ec52'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76ef4cb9-82ef-4461-85f3-245ed9b42c8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_responses['6540c8a62936d70acf71ec52']['attributes']['business_or_financial_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ef7f115-7fc7-4856-9e3b-dc1f892f3a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_dict_structure = {\n",
    "  \"summary\": \"\",\n",
    "  \"summary_critique\": \"\",\n",
    "  \"improved_summary\": \"\",\n",
    "  \"top_categories\": \"\",\n",
    "  \"business_or_financial_article\": \"\",\n",
    "  \"indian_or_international\": \"\",\n",
    "  \"relevant_for_indians\": \"\",\n",
    "  \"article_validity_duration_evaluation\": \"\",\n",
    "  \"article_validity_duration\": \"\",\n",
    "  \"popularity_evaluation\": \"\",\n",
    "  \"popularity_evaluation_critique\": \"\",\n",
    "  \"final_reader_interest_score\": \"\",\n",
    "  \"final_headline_effectiveness_score\": \"\",\n",
    "  \"final_event_novelty_score\": \"\",\n",
    "  \"final_emotional_impact_score\": \"\",\n",
    "  \"improved_headline\": \"\",\n",
    "  \"article_type\": \"\",\n",
    "  \"article_sentiment\": \"\"\n",
    "}\n",
    "expected_keys = sorted(list(expected_dict_structure.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85f0c9-cf95-4c37-9b06-a881b2ee51e8",
   "metadata": {},
   "source": [
    "### Cleaning the responses from GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08159380-f16a-4788-93a8-88556bd2feee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys are not the same 6571c2eb25cc9a343f03c5e2\n",
      "keys are not the same 6571c2f525cc9a343f03caf5\n",
      "keys are not the same 651e178ca662d76276b8841a\n",
      "keys are not the same 658d472a4b25ce4814fb365b\n",
      "keys are not the same 6560dc12e1d8342798a471b6\n",
      "keys are not the same 6555cc8d4b13023f934aa330\n",
      "keys are not the same 651e1b31a662d76276b88c70\n",
      "keys are not the same 653680061e5cc42b1b143e68\n",
      "keys are not the same 6564771f96c80a0efa90fe62\n",
      "keys are not the same 6555b5c94b13023f9348bff5\n",
      "keys are not the same 652fcaa11e5cc42b1b13a108\n",
      "keys are not the same 6571c36025cc9a343f040093\n",
      "keys are not the same 6571c2da25cc9a343f03bd2e\n",
      "keys are not the same 6571c025441fea11ec37f842\n",
      "keys are not the same 6571c033441fea11ec37f943\n",
      "keys are not the same 6555b5854b13023f9348bcae\n",
      "keys are not the same 657fee0a8dc7b10db3e78f71\n",
      "keys are not the same 651ddc75a662d76276b7f1b4\n",
      "keys are not the same 6571c33b25cc9a343f03ee36\n"
     ]
    }
   ],
   "source": [
    "malformed = []\n",
    "cleaned_train_set = {}\n",
    "for art_id in all_responses:\n",
    "    cleaned_train_set[art_id] = {}\n",
    "    try:\n",
    "        attributes = all_responses[art_id]['attributes']\n",
    "        keys = sorted(list(attributes.keys()))\n",
    "        if not keys == expected_keys:\n",
    "            print(f'keys are not the same {art_id}')\n",
    "            malformed.append(art_id)\n",
    "            cleaned_train_set.pop(art_id)\n",
    "            continue\n",
    "        cleaned_train_set[art_id] = {'content': all_responses[art_id]['content'], 'attributes': deepcopy(attributes)}\n",
    "        cleaned_train_set[art_id]['attributes']['business_or_financial_article'] = True if bool(attributes['business_or_financial_article']) == 1 else False if bool(attributes['business_or_financial_article']) == 0 else None\n",
    "        cleaned_train_set[art_id]['attributes']['relevant_for_indians'] = True if bool(attributes['relevant_for_indians']) == 1 else False if bool(attributes['relevant_for_indians']) == 0 else None\n",
    "        cleaned_train_set[art_id]['attributes']['article_validity_duration'] = correct_validity_duration(attributes['article_validity_duration'])\n",
    "    except:\n",
    "        malformed.append(art_id)\n",
    "        cleaned_train_set.pop(art_id)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9421003-c8bb-49f0-a186-c4f82529564e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(malformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffbb0576-1cec-4edd-ac4a-93f035862f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1958"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5d72b19-f73a-4686-b358-381c1c140ce1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False, True}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['business_or_financial_article'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ac7e77b-ca5a-4dd2-be95-8c1811112f7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{False, True}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['relevant_for_indians'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b5e5641-cb85-43b2-be06-5d8db95fccd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1, 1, 3, 7, 14, 30}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_validity_duration'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f7734d3-3f7e-41b2-807f-533460a8850f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bear', 'Bearish', 'Bull', 'NA', 'bear', 'bearish', 'bull', 'bullish'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_sentiment'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3874a132-054f-4677-91e9-ab84081cc305",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Analysis',\n",
       " 'Educational',\n",
       " 'Fact',\n",
       " 'NA',\n",
       " 'News',\n",
       " 'Review',\n",
       " 'advice',\n",
       " 'analysis',\n",
       " 'announcement',\n",
       " 'educational',\n",
       " 'fact',\n",
       " 'forecast',\n",
       " 'interview',\n",
       " 'investigation',\n",
       " 'news',\n",
       " 'opinion',\n",
       " 'personal',\n",
       " 'research',\n",
       " 'review',\n",
       " 'sponsored'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_type'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c9a53-90ad-4084-8ad7-d114fcd2f829",
   "metadata": {},
   "source": [
    "### casting incorrect values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15d87389-c8d7-4c94-89d8-0826d0b5ee78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for art_id in cleaned_train_set:\n",
    "    attributes = cleaned_train_set[art_id]['attributes']\n",
    "    for key in ['article_sentiment', 'article_type']:\n",
    "        attributes[key] = attributes[key].lower()\n",
    "        if attributes['article_sentiment'] == 'bearish':\n",
    "            attributes['article_sentiment'] = 'bear'\n",
    "        if attributes['article_sentiment'] == 'bullish':\n",
    "            attributes['article_sentiment'] = 'bull'\n",
    "        if attributes['article_type'] in ('fact', 'Fact', 'factual', 'announcement', 'news'):\n",
    "            attributes['article_type'] = 'fact'\n",
    "        if attributes['article_type'] in ('research', 'forecast', 'investigation', 'analysis', 'review'):\n",
    "            attributes['article_type'] = 'analysis'\n",
    "        if attributes['article_type'] in ('advice', 'opinion', 'interview', 'personal'):\n",
    "            attributes['article_type'] = 'opinion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b66d841-b464-4e71-b2d2-955f339d3a15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bear', 'bull', 'na'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_sentiment'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c0391ee-da3b-49e4-90db-755df5321e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis', 'educational', 'fact', 'na', 'opinion', 'sponsored'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([cleaned_train_set[art_id]['attributes']['article_type'] for art_id in cleaned_train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e052ead-30c2-4c86-8e4c-2baf4020c387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1958"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473eabf-cb04-4824-98b5-2f1871e3e945",
   "metadata": {},
   "source": [
    "### Properly ordering the train dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16c3d0b5-61aa-45b7-bcc7-b92239d94c98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train_set_copy = deepcopy(cleaned_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "01773674-7cd6-4ee4-a3a7-d259f622edd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_dict_structure = {\n",
    "  \"summary\": \"\",\n",
    "  \"summary_critique\": \"\",\n",
    "  \"improved_summary\": \"\",\n",
    "  \"top_categories\": \"\",\n",
    "  \"business_or_financial_article\": \"\",\n",
    "  \"indian_or_international\": \"\",\n",
    "  \"relevant_for_indians\": \"\",\n",
    "  \"article_validity_duration_evaluation\": \"\",\n",
    "  \"article_validity_duration\": \"\",\n",
    "  \"popularity_evaluation\": \"\",\n",
    "  \"popularity_evaluation_critique\": \"\",\n",
    "  \"final_reader_interest_score\": \"\",\n",
    "  \"final_headline_effectiveness_score\": \"\",\n",
    "  \"final_event_novelty_score\": \"\",\n",
    "  \"final_emotional_impact_score\": \"\",\n",
    "  \"improved_headline\": \"\",\n",
    "  \"article_type\": \"\",\n",
    "  \"article_sentiment\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ccefa23-e7e5-4899-ac09-376c3f3fb6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['summary', 'summary_critique', 'improved_summary', 'top_categories', 'business_or_financial_article', 'indian_or_international', 'relevant_for_indians', 'article_validity_duration_evaluation', 'article_validity_duration', 'popularity_evaluation', 'popularity_evaluation_critique', 'final_reader_interest_score', 'final_headline_effectiveness_score', 'final_event_novelty_score', 'final_emotional_impact_score', 'improved_headline', 'article_type', 'article_sentiment'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_dict_structure.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7ff12b2b-be2e-4f6c-9118-d27edc12a43c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train_set = {article_id: {'content': cleaned_train_set_copy[article_id]['content'], \n",
    "                                  'attributes': {k: cleaned_train_set_copy[article_id]['attributes'][k] for k in expected_dict_structure}} for article_id in cleaned_train_set_copy.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a70f71e-7403-4c60-885e-1d502324f109",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['65316d5c1e5cc42b1b13e25a',\n",
       " '65316ead1e5cc42b1b13e61a',\n",
       " '6555bf484b13023f9348c6db',\n",
       " '6555cb624b13023f9349d07e',\n",
       " '65316fd51e5cc42b1b141f53',\n",
       " '658d47214b25ce4814fb359e',\n",
       " '651e188aa662d76276b8866b',\n",
       " '6571c30625cc9a343f03d39e',\n",
       " '658d3c174b25ce4814fb30d6',\n",
       " '65367fff1e5cc42b1b143dec']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cleaned_train_set.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21d7c1d9-9984-4ca0-8550-ee3c24df1392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "malformed_top_categories = [article_id for article_id in cleaned_train_set if isinstance(cleaned_train_set[article_id]['attributes']['top_categories'], list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4da254a2-3857-4446-868e-c0e377b6e01d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train_set = {k: cleaned_train_set[k] for k in cleaned_train_set.keys() if k not in malformed_top_categories}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f957d6c8-05b4-4581-82c8-bb073b9b59cc",
   "metadata": {},
   "source": [
    "### Article Truncation logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bd04673-53bb-4759-af8f-5188844be617",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_tokens(text, encoder):  # Placeholder for your actual token calculation function\n",
    "    # Your implementation will go here.\n",
    "    return len(encoder.encode(text))  # Example: counting characters as tokens\n",
    "\n",
    "def truncate_text_to_token_limit(text,encoder, token_limit):\n",
    "    # First, check if the whole text is under the token limit\n",
    "    if calculate_tokens(text, encoder) <= token_limit:\n",
    "        return text  # The entire text is within the limit\n",
    "\n",
    "    def is_under_limit(index):\n",
    "        # Use the provided function to calculate tokens for the substring\n",
    "        return calculate_tokens(text[:index], encoder) <= token_limit\n",
    "\n",
    "    left, right = 0, len(text)\n",
    "    valid_limit = 0  # This will hold the index of the last valid token position\n",
    "\n",
    "    # Binary search to find the token limit\n",
    "    while left <= right:\n",
    "        mid = (left + right) // 2  # Find the midpoint\n",
    "        if is_under_limit(mid):\n",
    "            # If the midpoint is under the limit, store it as a valid limit\n",
    "            valid_limit = mid\n",
    "            left = mid + 1  # Move the left boundary to the right\n",
    "        else:\n",
    "            right = mid - 1  # Move the right boundary to the left\n",
    "\n",
    "    # Find the last space before the valid_limit to ensure we're at a word boundary\n",
    "    space_index = text.rfind(' ', 0, valid_limit)\n",
    "    if space_index == -1:\n",
    "        # If there's no space, we've hit the start of the text\n",
    "        return text[:valid_limit]  # Return up to the valid limit even if mid-word\n",
    "\n",
    "    # Return the text up to the last word within the token limit\n",
    "    return text[:space_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5e64a-ded8-46c1-b748-e0b54599ce48",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d10e768-b5fc-4a83-aad9-61f0d32270a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt =  '''\n",
    "You are an expert chief editor for a leading Indian business and financial content website. You evaluate critical attributes of articles to gatekeep content quality. The following are 18 attributes with the format of attribute (datatype): <instruction>\n",
    "\n",
    "1. summary (markdown text):  <Summarize the following article with following instructions.\n",
    "\n",
    "a. Readability: Follow proper grammar and maintain easy readability with no more than 2-3 points and up to 80 words. 2 points for short articles and 3 points for long articles\n",
    "b. Faithfulness: Don't mention any details which are not part of the article\n",
    "c. Accuracy: All the numbers, dates, events should have the correct attribution. Do not, at any cost mix up numbers or dates. \n",
    "d. Recall: No critical info should be missed\n",
    "e. structure: Each point should be only a single line. Prefix the point with a relevant label for that point. The points should overall capture the essence of the article. The labels should be human readable and don’t use any _ or programming symbols. \n",
    "f. format: the following markdown label point format. The labels are bolded followed by : and a point. New points are separated by \\n. We’ll call this format as _summary_markdown_format_\n",
    "\n",
    "\"**label1**: point1 \\n **label2**: point2 \\n …\"\n",
    "\n",
    "no preamble or postamble. Make sure that you adhere to the maximum limit of 3 points. It is very important that the format is a valid _summary_markdown_format_>\n",
    "\n",
    "2. summary_critique (short text): <critique the summary above by comparing with the article and the instructions. check for any important details missed or changes needed in Readability, Faithfulness, Accuracy and Recall of the expected format. Evaluate if there are too many or too few points based on article length. Assess the validity of the markdown format as well against _summary_markdown_format_>\n",
    "3. improved_summary (markdown text): <create an improved summary by considering summary and summary_critique in the same format as a valid _summary_markdown_format_>\n",
    "4. top_categories (5 semi colon separated words): <List 5 progressively general categories separated by semicolons (;), avoiding quotes to prevent json.loads() failures>\n",
    "5. business_or_financial_article (True/False) : <True or False, based on the article's relevance to Indian corporations, investors, and policies impacting them.>\n",
    "6. indian_or_international (indian/international): <is the article specific for india or is an international content>\n",
    "7. relevant_for_indians (True/False) : <True or False, considering the article's relevance and applicability to Indian readers, including international and multinational contexts.>\n",
    "8. article_validity_duration_evaluation (short text) : <analyse the factors for the relevance duration. stock fluctuations for 1 day; significant policy changes - few days; educational are timeless unless it references any regulations or acts, in which case a max of 30 days (regulations change). quarterly results valid for 3 days, yearly results for a 7>\n",
    "9. article_validity_duration (one of 1, 3, 7, 14, 30, -1) : <calculate number of days based on previous attribute among one of 1,3,7,14,30. -1 for timeless. Don’t provide any other number apart from these>\n",
    "10. popularity_evaluation (short text): <evaluate the likely popularity of the article based on the following criteria:\n",
    "\n",
    "a. reader_interest_score: how many people among casual business news readers are likely to be interested. Considering what score to give between 0 to 1\n",
    "b. headline_effectiveness: ability of headline to engage. Considering what score to give between 0 to 1\n",
    "c. event_novelty: how frequently the event occurs or this type of content is available. every few hours, days, weeks or months. Considering what score to give between 0 to 1. Anything which happens only every few quarters is more novel. \n",
    "d. emotional_impact: what is the most common emotion that readers are going to go through and how many readers will likely have the emotion. Considering what score to give between 0 to 1\n",
    "\n",
    "Be stingy in giving scores more than 0.4\n",
    ">\n",
    "11. popularity_evaluation_critique (short text): <critique the scores by relooking at the article and seeing if there is anything which is overrated or underrated>\n",
    "12. final_reader_interest_score (0-1): <0 to 1 float>\n",
    "13. final_headline_effectiveness_score (0-1): <0 to 1 float>\n",
    "14. final_event_novelty_score (0-1): <0 to 1 float>\n",
    "15. final_emotional_impact_score (0-1): <0 to 1 float>\n",
    "16. improved_headline (short text) : <Write a headline based on the content of the article to grab attention by evoking curiosity or an emotional/intellectual response, but avoid a clickbait headline>\n",
    "17. article_type (fact/opinion/analysis/educational/sponsored) : <Determine if the article is fact, opinion, analysis, educational, or sponsored, based on content and presentation. Predictions without sufficient data to backup is opinion, with data is analysis. >\n",
    "18. article_sentiment (bull/bear/NA): <sentiment of the article is bullish, bearish or NA. balanced is NA>\n",
    "\n",
    "\n",
    "your response should be a json structure with all the 18 above keys without missing any key. It is very important that the response is directly readable with json.loads(). no preamble or postamble. respond in the exact following structure:\n",
    " \n",
    "{\n",
    "  \"summary\": \"\",\n",
    "  \"summary_critique\": \"\",\n",
    "  \"improved_summary\": \"\",\n",
    "  \"top_categories\": \"\",\n",
    "  \"business_or_financial_article\": \"\",\n",
    "  \"indian_or_international\": \"\",\n",
    "  \"relevant_for_indians\": \"\",\n",
    "  \"article_validity_duration_evaluation\": \"\",\n",
    "  \"article_validity_duration\": \"\",\n",
    "  \"popularity_evaluation\": \"\",\n",
    "  \"popularity_evaluation_critique\": \"\",\n",
    "  \"final_reader_interest_score\": \"\",\n",
    "  \"final_headline_effectiveness_score\": \"\",\n",
    "  \"final_event_novelty_score\": \"\",\n",
    "  \"final_emotional_impact_score\": \"\",\n",
    "  \"improved_headline\": \"\",\n",
    "  \"article_type\": \"\",\n",
    "  \"article_sentiment\": \"\"\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7d85f6-f780-4ebe-91f1-2b6068561d4a",
   "metadata": {},
   "source": [
    "### Article Size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c46f5d5-fc39-4c48-a913-17f812c060b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "article_sizes = {k: len(tokenizer.encode(cleaned_train_set[k]['content'])) for k in cleaned_train_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1cb55561-2e1b-4fe4-a74f-d448a5519efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'65316d5c1e5cc42b1b13e25a': 1183,\n",
       " '65316ead1e5cc42b1b13e61a': 584,\n",
       " '6555bf484b13023f9348c6db': 684,\n",
       " '6555cb624b13023f9349d07e': 1738,\n",
       " '65316fd51e5cc42b1b141f53': 951,\n",
       " '658d47214b25ce4814fb359e': 720,\n",
       " '651e188aa662d76276b8866b': 825,\n",
       " '6571c30625cc9a343f03d39e': 1225,\n",
       " '658d3c174b25ce4814fb30d6': 962,\n",
       " '65367fff1e5cc42b1b143dec': 515,\n",
       " '6555c7ed4b13023f9348ef08': 718,\n",
       " '653170061e5cc42b1b143366': 2251,\n",
       " '6570424e53e8a6117bd30f14': 787,\n",
       " '652fcb261e5cc42b1b13a14d': 2740,\n",
       " '6555cc994b13023f934aaab0': 2192,\n",
       " '6555cb8f4b13023f9349ef90': 1829,\n",
       " '651deabda662d76276b81791': 614,\n",
       " '6571c2e125cc9a343f03c089': 1457,\n",
       " '651df15fa662d76276b828cd': 506,\n",
       " '6555cc5a4b13023f934a7f71': 389,\n",
       " '65316f141e5cc42b1b13ee9b': 1162,\n",
       " '6531690a1e5cc42b1b13cb26': 505,\n",
       " '651df86aa662d76276b8395c': 1828,\n",
       " '656476d996c80a0efa90f8b7': 1044,\n",
       " '652ebbae1e5cc42b1b1399a3': 935,\n",
       " '6555cb874b13023f9349e9e4': 145,\n",
       " '6555c3844b13023f9348d4a4': 1163,\n",
       " '6571c035441fea11ec37f98a': 2021,\n",
       " '6555c7fa4b13023f9348f5b7': 1449,\n",
       " '651df0dba662d76276b82768': 229,\n",
       " '6571c36525cc9a343f040331': 179,\n",
       " '65316a3a1e5cc42b1b13dba5': 628,\n",
       " '652fd2bf1e5cc42b1b13a4dc': 3173,\n",
       " '6564770096c80a0efa90fbf7': 685,\n",
       " '656dd34f9994965ac4b43a89': 766,\n",
       " '6555c5064b13023f9348db10': 484,\n",
       " '6555cb7c4b13023f9349e21e': 861,\n",
       " '658d47654b25ce4814fb3aa5': 687,\n",
       " '6571c2b025cc9a343f03a795': 729,\n",
       " '65829109683f430d8156614e': 595,\n",
       " '6564771196c80a0efa90fd5a': 2014,\n",
       " '6531688b1e5cc42b1b13af42': 757,\n",
       " '6560dfc2e1d8342798a47844': 525,\n",
       " '658d473f4b25ce4814fb37d8': 734,\n",
       " '652fcd1d1e5cc42b1b13a251': 1932,\n",
       " '657bf993857ad32209160260': 751,\n",
       " '6566a96439bfc8784efe5c9d': 454,\n",
       " '656e92a89994965ac4b4d839': 880,\n",
       " '657d12d28f821120f67a07a1': 841,\n",
       " '658c03d44b25ce4814fb2882': 1308,\n",
       " '657956815b3cac4e9dcc5b80': 541,\n",
       " '65316eeb1e5cc42b1b13e99c': 563,\n",
       " '6555cc3f4b13023f934a6c29': 591,\n",
       " '6571356553e8a6117bd31d4c': 310,\n",
       " '6588f051683f430d8156690d': 1370,\n",
       " '65316e211e5cc42b1b13e43e': 364,\n",
       " '6555ccbd4b13023f934ac732': 617,\n",
       " '6555cc804b13023f934a9a99': 733,\n",
       " '65316ffa1e5cc42b1b142e0c': 317,\n",
       " '657bf991857ad3220916024f': 956,\n",
       " '651ddae0a662d76276b7ed7e': 405,\n",
       " '6571c37025cc9a343f0408f1': 284,\n",
       " '651de5daa662d76276b80aad': 718,\n",
       " '65316e761e5cc42b1b13e536': 652,\n",
       " '65316f7c1e5cc42b1b14030d': 1804,\n",
       " '651ddc33a662d76276b7f0fd': 347,\n",
       " '6571c26c25cc9a343f03897e': 1433,\n",
       " '6555cb194b13023f9349a0f1': 861,\n",
       " '6555c8094b13023f9348fec3': 539,\n",
       " '6555b48d4b13023f9348b686': 1457,\n",
       " '6567fae2207bb033b910ec3c': 137,\n",
       " '6555cc3e4b13023f934a6b95': 465,\n",
       " '6555cc354b13023f934a6480': 774,\n",
       " '6571c32e25cc9a343f03e78a': 785,\n",
       " '6555b4834b13023f9348b65a': 386,\n",
       " '6555cc974b13023f934aa931': 468,\n",
       " '6555ccd24b13023f934ad9a0': 810,\n",
       " '6555b5df4b13023f9348c404': 636,\n",
       " '658177cc683f430d81565f2d': 827,\n",
       " '6555c81e4b13023f93490c60': 630,\n",
       " '6531692d1e5cc42b1b13d4e2': 799,\n",
       " '656476fe96c80a0efa90fbdc': 2091,\n",
       " '658d473d4b25ce4814fb37b3': 536,\n",
       " '6555cc954b13023f934aa7c3': 1547,\n",
       " '6555c8334b13023f93491b1a': 789,\n",
       " '658ba3e94b25ce4814fb284d': 897,\n",
       " '6555cc494b13023f934a7374': 2143,\n",
       " '6555caca4b13023f93496b99': 1433,\n",
       " '657040f153e8a6117bd30b7d': 896,\n",
       " '652ebbc51e5cc42b1b139a5a': 692,\n",
       " '651de7b1a662d76276b80f8c': 482,\n",
       " '65316ef81e5cc42b1b13eaf3': 1110,\n",
       " '652fc5ea1e5cc42b1b139ec0': 1940,\n",
       " '656dd5d39994965ac4b43fcf': 561,\n",
       " '6581079d683f430d81565e1b': 439,\n",
       " '6571c35925cc9a343f03fd3c': 427,\n",
       " '6555c9e34b13023f93492ce3': 1505,\n",
       " '6555cc424b13023f934a6ec1': 512,\n",
       " '65367ff71e5cc42b1b143d75': 489,\n",
       " '6571c25525cc9a343f03801a': 640,\n",
       " '6581074c683f430d81565cb1': 1019,\n",
       " '6555c8294b13023f934913b0': 1343,\n",
       " '651ddb76a662d76276b7eefa': 433,\n",
       " '658a41d7683f430d81566a31': 879,\n",
       " '6555c3394b13023f9348d3c9': 538,\n",
       " '65316eaa1e5cc42b1b13e607': 1186,\n",
       " '651e02b8a662d76276b852f2': 448,\n",
       " '6564771f96c80a0efa90fe58': 1787,\n",
       " '6555b5aa4b13023f9348be3c': 855,\n",
       " '6571c02d441fea11ec37f8a0': 2395,\n",
       " '6555c82c4b13023f934915e6': 295,\n",
       " '6555b5814b13023f9348bc89': 4620,\n",
       " '6564772996c80a0efa90ff3a': 994,\n",
       " '6555b58c4b13023f9348bd00': 2132,\n",
       " '65316f771e5cc42b1b1401df': 671,\n",
       " '6555b57d4b13023f9348bc5d': 2019,\n",
       " '6571c36c25cc9a343f04066e': 273,\n",
       " '65716db6441fea11ec37f740': 427,\n",
       " '653169481e5cc42b1b13d891': 814,\n",
       " '6555c0b04b13023f9348cc60': 1151,\n",
       " '6555cade4b13023f9349796a': 1611,\n",
       " '65316fb71e5cc42b1b14145f': 584,\n",
       " '655c8dd5f1c0ed6a1e042281': 598,\n",
       " '652fca671e5cc42b1b13a0eb': 1970,\n",
       " '65856c4f683f430d81566678': 967,\n",
       " '658d47544b25ce4814fb395b': 1231,\n",
       " '6555cc9f4b13023f934aaf3a': 408,\n",
       " '651dd455a662d76276b7dd32': 605,\n",
       " '651e14eda662d76276b87de3': 508,\n",
       " '656e92599994965ac4b4d668': 763,\n",
       " '653168fe1e5cc42b1b13c7da': 1286,\n",
       " '656dd5609994965ac4b43e5d': 567,\n",
       " '6555bf794b13023f9348c753': 1066,\n",
       " '652ebbd11e5cc42b1b139ade': 997,\n",
       " '656557e61fc4586a032ad725': 300,\n",
       " '6555b4ca4b13023f9348b7ca': 7041,\n",
       " '6560cfb7e1d8342798a4647a': 329,\n",
       " '652ebbd51e5cc42b1b139b14': 449,\n",
       " '651dff09a662d76276b84975': 498,\n",
       " '6571c26725cc9a343f03877b': 526,\n",
       " '658d47274b25ce4814fb361c': 689,\n",
       " '6555cca74b13023f934ab558': 934,\n",
       " '6555cbd34b13023f934a1db7': 240,\n",
       " '651ddfe8a662d76276b7fae4': 614,\n",
       " '651dee01a662d76276b82018': 367,\n",
       " '651dcb1aa662d76276b7c380': 952,\n",
       " '6555c0064b13023f9348c972': 904,\n",
       " '652fc6431e5cc42b1b139ee6': 2123,\n",
       " '656557de1fc4586a032ad67c': 940,\n",
       " '6555c2844b13023f9348d25d': 370,\n",
       " '6555cc6f4b13023f934a8ea2': 846,\n",
       " '653680131e5cc42b1b143f7b': 1246,\n",
       " '656476fc96c80a0efa90fb9d': 1968,\n",
       " '657d12dc8f821120f67a0802': 2023,\n",
       " '65316c441e5cc42b1b13e024': 505,\n",
       " '651dd3c6a662d76276b7dbba': 613,\n",
       " '65316f231e5cc42b1b13f0cf': 695,\n",
       " '6555c8164b13023f93490726': 846,\n",
       " '6571c036441fea11ec37f9a8': 2410,\n",
       " '6555cc724b13023f934a90df': 355,\n",
       " '6555cc8a4b13023f934aa130': 559,\n",
       " '651de056a662d76276b7fc0b': 292,\n",
       " '6571c2c125cc9a343f03b062': 1055,\n",
       " '6561634eaa3101769d151012': 537,\n",
       " '651dd0e3a662d76276b7d36e': 556,\n",
       " '658960c3683f430d8156696a': 814,\n",
       " '6571c32625cc9a343f03e341': 942,\n",
       " '6570401853e8a6117bd308e6': 607,\n",
       " '6571c34b25cc9a343f03f5ff': 278,\n",
       " '65316d161e5cc42b1b13e1d4': 841,\n",
       " '6555c8054b13023f9348fbff': 892,\n",
       " '6555cb404b13023f9349b9ca': 985,\n",
       " '6531700a1e5cc42b1b14350a': 482,\n",
       " '6566a96d39bfc8784efe5d83': 511,\n",
       " '65316ff41e5cc42b1b142be6': 630,\n",
       " '6583aa61683f430d81566312': 790,\n",
       " '651e0739a662d76276b85e18': 326,\n",
       " '6555cafc4b13023f93498e16': 1990,\n",
       " '651e2686a662d76276b8a767': 631,\n",
       " '6555b5a54b13023f9348be03': 311,\n",
       " '65316a631e5cc42b1b13dc1b': 465,\n",
       " '6555cc6f4b13023f934a8f14': 5515,\n",
       " '6555cc374b13023f934a668d': 818,\n",
       " '65864d52683f430d815666e2': 434,\n",
       " '6571c34425cc9a343f03f26c': 795,\n",
       " '6555b4964b13023f9348b6a9': 2084,\n",
       " '651df770a662d76276b83804': 354,\n",
       " '65316ec61e5cc42b1b13e6ee': 1116,\n",
       " '653168c01e5cc42b1b13b7f4': 711,\n",
       " '65316f411e5cc42b1b13f614': 462,\n",
       " '65813f80683f430d81565e4f': 823,\n",
       " '6560cfb8e1d8342798a464de': 442,\n",
       " '6555cbf54b13023f934a3645': 438,\n",
       " '6560cf8ae1d8342798a459b2': 322,\n",
       " '651dcc63a662d76276b7c6f1': 1619,\n",
       " '651e06c8a662d76276b85d04': 352,\n",
       " '652ebbb41e5cc42b1b1399c8': 732,\n",
       " '658177cc683f430d81565f31': 604,\n",
       " '6564770196c80a0efa90fc04': 109,\n",
       " '6560c3d2e1d8342798a44ebc': 895,\n",
       " '658d475c4b25ce4814fb3a02': 1395,\n",
       " '6571c26f25cc9a343f038aea': 1009,\n",
       " '65316e4b1e5cc42b1b13e4aa': 259,\n",
       " '653168a41e5cc42b1b13b2ed': 652,\n",
       " '653168831e5cc42b1b13ae40': 630,\n",
       " '6555c2964b13023f9348d280': 1191,\n",
       " '651dee50a662d76276b820ed': 537,\n",
       " '6555b50c4b13023f9348b904': 2435,\n",
       " '65367fea1e5cc42b1b143cc7': 810,\n",
       " '652fc7901e5cc42b1b139f86': 1655,\n",
       " '6555cc334b13023f934a6304': 1838,\n",
       " '6555b4a14b13023f9348b6e5': 1980,\n",
       " '6525a74c598c6618f0608a6a': 429,\n",
       " '6555cc5e4b13023f934a8263': 455,\n",
       " '655434604b13023f9348b53d': 479,\n",
       " '65316d8a1e5cc42b1b13e30b': 2048,\n",
       " '6564772a96c80a0efa90ff73': 871,\n",
       " '658d47544b25ce4814fb395f': 1344,\n",
       " '658d47264b25ce4814fb3606': 558,\n",
       " '651dda75a662d76276b7ec5f': 439,\n",
       " '65791e571678087a99296502': 621,\n",
       " '656eca969f528f16c001a7ef': 322,\n",
       " '656476db96c80a0efa90f8ea': 1973,\n",
       " '6535e1fd1e5cc42b1b143a4d': 233,\n",
       " '6571c2ff25cc9a343f03d048': 984,\n",
       " '651e1f43a662d76276b8962a': 462,\n",
       " '6560cf8ae1d8342798a459a1': 811,\n",
       " '651df212a662d76276b82ac0': 849,\n",
       " '6560cfa0e1d8342798a45dc1': 951,\n",
       " '6560cfaee1d8342798a4619a': 493,\n",
       " '6566a96539bfc8784efe5cbc': 659,\n",
       " '6564771196c80a0efa90fd5e': 1664,\n",
       " '651e1111a662d76276b874ef': 1631,\n",
       " '653169471e5cc42b1b13d879': 530,\n",
       " '6555cba24b13023f9349fc8f': 2693,\n",
       " '6555cc094b13023f934a43e2': 567,\n",
       " '65316b551e5cc42b1b13de84': 372,\n",
       " '6525a73e598c6618f0608947': 275,\n",
       " '6555ca444b13023f934930dd': 1369,\n",
       " '653680021e5cc42b1b143e1d': 1399,\n",
       " '652ebbc01e5cc42b1b139a2b': 549,\n",
       " '6564771496c80a0efa90fd87': 866,\n",
       " '656e92639994965ac4b4d752': 1249,\n",
       " '654856d8dc4fa72a6c403a6a': 228,\n",
       " '6555c7c94b13023f9348e19d': 941,\n",
       " '6571c33925cc9a343f03ed11': 1319,\n",
       " '6555cab54b13023f93495d32': 766,\n",
       " '6582c948683f430d815661b1': 1103,\n",
       " '657bf993857ad32209160261': 674,\n",
       " '6555cca24b13023f934ab223': 556,\n",
       " '65316ee01e5cc42b1b13e8a5': 1049,\n",
       " '65769200b8b4d445277ab842': 976,\n",
       " '6555cc614b13023f934a8465': 819,\n",
       " '6555ca814b13023f93494035': 715,\n",
       " '6571c2c125cc9a343f03b00b': 376,\n",
       " '65316f761e5cc42b1b140194': 1884,\n",
       " '6555cbe74b13023f934a2c4c': 536,\n",
       " '657135bc53e8a6117bd31dea': 682,\n",
       " '651de9bba662d76276b814d5': 647,\n",
       " '65367fe11e5cc42b1b143c6e': 1323,\n",
       " '651dcd96a662d76276b7ca37': 449,\n",
       " '6571c34d25cc9a343f03f70c': 724,\n",
       " '6555c8f94b13023f9349284a': 1284,\n",
       " '6555cc6d4b13023f934a8db5': 2211,\n",
       " '651e2381a662d76276b8a047': 402,\n",
       " '6555c7d74b13023f9348e5d2': 1958,\n",
       " '6571c029441fea11ec37f871': 689,\n",
       " '652ebbad1e5cc42b1b13999d': 812,\n",
       " '651dd8f0a662d76276b7e872': 746,\n",
       " '656476dc96c80a0efa90f8ee': 57,\n",
       " '6571c2a925cc9a343f03a442': 521,\n",
       " '6555c7e94b13023f9348ed27': 1445,\n",
       " '6560cfb4e1d8342798a46367': 292,\n",
       " '6555cc584b13023f934a7e0f': 700,\n",
       " '6555cc504b13023f934a7865': 1110,\n",
       " '65316f451e5cc42b1b13f6c2': 459,\n",
       " '657bf991857ad32209160253': 649,\n",
       " '651e2035a662d76276b89864': 429,\n",
       " '6560cf78e1d8342798a4572a': 424,\n",
       " '653168691e5cc42b1b13ab52': 766,\n",
       " '6560d241e1d8342798a467be': 506,\n",
       " '6555c4a84b13023f9348d96e': 266,\n",
       " '656557ed1fc4586a032ad7c4': 944,\n",
       " '6571c2cc25cc9a343f03b604': 429,\n",
       " '65316eb51e5cc42b1b13e64f': 510,\n",
       " '656e92629994965ac4b4d74e': 621,\n",
       " '6555b5564b13023f9348badc': 2847,\n",
       " '652fc5d11e5cc42b1b139eb5': 2363,\n",
       " '6571c2ee25cc9a343f03c75e': 319,\n",
       " '6555cb1a4b13023f9349a18b': 348,\n",
       " '6555b5ba4b13023f9348bf01': 2569,\n",
       " '6555cc5c4b13023f934a80e0': 736,\n",
       " '65703f1e53e8a6117bd305c3': 477,\n",
       " '653168a91e5cc42b1b13b3e5': 399,\n",
       " '6571c30725cc9a343f03d435': 738,\n",
       " '65769200b8b4d445277ab836': 1661,\n",
       " '6555ccb84b13023f934ac2ff': 497,\n",
       " '6571c2f225cc9a343f03c9ae': 1226,\n",
       " '651dc878a662d76276b7bc4d': 436,\n",
       " '6531691b1e5cc42b1b13d06d': 848,\n",
       " '651dfeeaa662d76276b84929': 328,\n",
       " '6571c031441fea11ec37f8fd': 1094,\n",
       " '6571c2b225cc9a343f03a88d': 995,\n",
       " '653168b71e5cc42b1b13b64b': 339,\n",
       " '6555cca74b13023f934ab5b3': 2031,\n",
       " '651e1fe0a662d76276b897a4': 443,\n",
       " '652fca1e1e5cc42b1b13a0c5': 2407,\n",
       " '6555b55b4b13023f9348bb05': 2974,\n",
       " '6555cad74b13023f934974f6': 2649,\n",
       " '655828eb4b13023f934af056': 324,\n",
       " '652fc7a71e5cc42b1b139f91': 1734,\n",
       " '6555b5d64b13023f9348c1ec': 474,\n",
       " '65813ff0683f430d81565ec8': 496,\n",
       " '652fd2b31e5cc42b1b13a4d6': 1693,\n",
       " '65853413683f430d81566619': 1425,\n",
       " '652fce421e5cc42b1b13a2e9': 2360,\n",
       " '651e01a7a662d76276b8503e': 183,\n",
       " '656dda6d9994965ac4b44e24': 822,\n",
       " '6571c26125cc9a343f03851d': 476,\n",
       " '658d473e4b25ce4814fb37c1': 1735,\n",
       " '651e2300a662d76276b89f14': 362,\n",
       " '657135be53e8a6117bd31e06': 403,\n",
       " '651e0729a662d76276b85df0': 481,\n",
       " '658d474d4b25ce4814fb38d4': 833,\n",
       " '651de9f7a662d76276b81571': 570,\n",
       " '651e1a20a662d76276b88a06': 723,\n",
       " '65316fa01e5cc42b1b140d00': 641,\n",
       " '654310d4dc4fa72a6c4037c9': 246,\n",
       " '6555cc584b13023f934a7e14': 577,\n",
       " '65316eb61e5cc42b1b13e657': 1294,\n",
       " '6571c26b25cc9a343f0388fb': 985,\n",
       " '6564770796c80a0efa90fc8e': 896,\n",
       " '651e0d7ca662d76276b86c7e': 402,\n",
       " '658d47264b25ce4814fb35ff': 1522,\n",
       " '653168ad1e5cc42b1b13b47c': 416,\n",
       " '65316f001e5cc42b1b13ebd6': 1426,\n",
       " '6555c03f4b13023f9348ca93': 328,\n",
       " '6571c2f925cc9a343f03cd10': 563,\n",
       " '6555cbde4b13023f934a257d': 701,\n",
       " '65694c4d207bb033b910ef1f': 208,\n",
       " '656dd7799994965ac4b44443': 784,\n",
       " '65767b4cb8b4d445277ab731': 871,\n",
       " '6555b48d4b13023f9348b681': 3071,\n",
       " '6571c033441fea11ec37f953': 1006,\n",
       " '658d47114b25ce4814fb3475': 619,\n",
       " '65316f061e5cc42b1b13ec8e': 246,\n",
       " '654cbbd0dc4fa72a6c403e25': 1369,\n",
       " '6571c24f25cc9a343f037e03': 625,\n",
       " '6555c4274b13023f9348d747': 695,\n",
       " '6571c2ab25cc9a343f03a599': 885,\n",
       " '6555c7fa4b13023f9348f567': 1322,\n",
       " '653168901e5cc42b1b13afd9': 1180,\n",
       " '6571c30625cc9a343f03d37d': 881,\n",
       " '65367fe91e5cc42b1b143cbf': 1399,\n",
       " '6555cc0a4b13023f934a4498': 618,\n",
       " '65367fe21e5cc42b1b143c78': 1099,\n",
       " '656dd5019994965ac4b43d67': 811,\n",
       " '65703fce53e8a6117bd3082f': 370,\n",
       " '652fc8fb1e5cc42b1b13a034': 2359,\n",
       " '6555cbeb4b13023f934a2f35': 1051,\n",
       " '65316f3d1e5cc42b1b13f550': 531,\n",
       " '6571c33025cc9a343f03e892': 1117,\n",
       " '6555ca884b13023f934943b4': 2117,\n",
       " '657d12d38f821120f67a07ac': 575,\n",
       " '657bf98d857ad3220916022f': 819,\n",
       " '65316f471e5cc42b1b13f72e': 6843,\n",
       " '657041c053e8a6117bd30d9f': 1079,\n",
       " '6567fae8207bb033b910ecda': 518,\n",
       " '6564770996c80a0efa90fcb6': 1648,\n",
       " '6571c02c441fea11ec37f89d': 951,\n",
       " '6571c031441fea11ec37f90d': 1244,\n",
       " '656dd6139994965ac4b44090': 477,\n",
       " '6555b4a34b13023f9348b6eb': 1512,\n",
       " '65686b55207bb033b910eeac': 684,\n",
       " '655c8dd5f1c0ed6a1e04227b': 466,\n",
       " '651ddaada662d76276b7ecef': 363,\n",
       " '6555cafa4b13023f93498d12': 941,\n",
       " '658d47384b25ce4814fb3753': 695,\n",
       " '65783dbc1678087a99296440': 759,\n",
       " '6571c23725cc9a343f0376fb': 589,\n",
       " '6555c0964b13023f9348cbf4': 311,\n",
       " '6571c030441fea11ec37f8ea': 914,\n",
       " '6560cfa4e1d8342798a45eae': 488,\n",
       " '651dc5f5a662d76276b7b55d': 901,\n",
       " '652fcfec1e5cc42b1b13a377': 2084,\n",
       " '652ebbb31e5cc42b1b1399c0': 717,\n",
       " '6555cc244b13023f934a5816': 1678,\n",
       " '6555b5d24b13023f9348c12e': 631,\n",
       " '6567fae6207bb033b910ec93': 968,\n",
       " '658258d7683f430d8156600b': 642,\n",
       " '6571c02d441fea11ec37f8ac': 26,\n",
       " '651e0d39a662d76276b86be4': 442,\n",
       " '6571c2d825cc9a343f03bc2b': 601,\n",
       " '65316f951e5cc42b1b1409d7': 715,\n",
       " '6555cc154b13023f934a4d0f': 666,\n",
       " '6555ca654b13023f93493740': 959,\n",
       " '652fce991e5cc42b1b13a317': 1835,\n",
       " '651e0fd8a662d76276b8720d': 638,\n",
       " '651de5caa662d76276b80a84': 251,\n",
       " '6555cc724b13023f934a914f': 935,\n",
       " '65367ff71e5cc42b1b143d6d': 906,\n",
       " '656dd5949994965ac4b43ef7': 446,\n",
       " '652fcd741e5cc42b1b13a27e': 1754,\n",
       " '651dfabaa662d76276b83ed3': 883,\n",
       " '6555cb724b13023f9349db96': 391,\n",
       " '6555cce24b13023f934ae511': 1177,\n",
       " '656557dc1fc4586a032ad64d': 1090,\n",
       " '6571c2d925cc9a343f03bc94': 326,\n",
       " '6555b5a94b13023f9348be29': 2070,\n",
       " '6566a95a39bfc8784efe5beb': 211,\n",
       " '653680301e5cc42b1b144247': 1563,\n",
       " '6571c2d625cc9a343f03bad1': 785,\n",
       " '652ebb8c1e5cc42b1b139900': 2683,\n",
       " '6571c2c525cc9a343f03b1f7': 498,\n",
       " '65316ff71e5cc42b1b142cbe': 1579,\n",
       " '658d47174b25ce4814fb34f5': 1136,\n",
       " '6571c2de25cc9a343f03bf6f': 597,\n",
       " '6555cacf4b13023f93496f36': 1634,\n",
       " '651de018a662d76276b7fb67': 285,\n",
       " '656e92649994965ac4b4d795': 541,\n",
       " '6567fae3207bb033b910ec47': 439,\n",
       " '6555cc304b13023f934a60aa': 502,\n",
       " '6555b5524b13023f9348bab9': 2348,\n",
       " '653168871e5cc42b1b13aeb7': 825,\n",
       " '657c31ca8f821120f67a0734': 741,\n",
       " '657bf98e857ad32209160231': 793,\n",
       " '6571c26725cc9a343f0387af': 818,\n",
       " '656dd5649994965ac4b43e72': 760,\n",
       " '6555b4d74b13023f9348b808': 2212,\n",
       " '658258d7683f430d8156600f': 872,\n",
       " '658ba3ed4b25ce4814fb2854': 1101,\n",
       " '652ebbcc1e5cc42b1b139aa9': 991,\n",
       " '6555cb7b4b13023f9349e19d': 1072,\n",
       " '651dea2da662d76276b81608': 752,\n",
       " '6555cafe4b13023f93498f84': 1903,\n",
       " '6555b5344b13023f9348b9e2': 2376,\n",
       " '6555c0cd4b13023f9348ccd4': 681,\n",
       " '65316fc21e5cc42b1b141886': 721,\n",
       " '65316a751e5cc42b1b13dc67': 443,\n",
       " '6555c8294b13023f9349138c': 1297,\n",
       " '6571356c53e8a6117bd31d52': 297,\n",
       " '6555c8524b13023f934925ad': 930,\n",
       " '6540c8aa2936d70acf71eda3': 390,\n",
       " '658d47564b25ce4814fb398a': 1334,\n",
       " '651dd134a662d76276b7d44d': 762,\n",
       " '6571c025441fea11ec37f84a': 3163,\n",
       " '65316f9f1e5cc42b1b140cab': 541,\n",
       " '651ddc2ca662d76276b7f0e9': 623,\n",
       " '6555b4b54b13023f9348b75a': 4221,\n",
       " '6555c3884b13023f9348d4b1': 1115,\n",
       " '6555ca5a4b13023f93493496': 1358,\n",
       " '6555c7d54b13023f9348e540': 715,\n",
       " '6555cb9a4b13023f9349f6ca': 498,\n",
       " '651dee1ea662d76276b82065': 504,\n",
       " '6571c33625cc9a343f03eba6': 930,\n",
       " '65316fab1e5cc42b1b141069': 711,\n",
       " '6555cc4a4b13023f934a73fd': 399,\n",
       " '653169391e5cc42b1b13d6d3': 446,\n",
       " '6556d7774b13023f934aedb5': 492,\n",
       " '6555bf294b13023f9348c66a': 755,\n",
       " '6555c8ac4b13023f93492717': 714,\n",
       " '651dd957a662d76276b7e97c': 645,\n",
       " '6567fae3207bb033b910ec5e': 409,\n",
       " '6577ccd4b8b4d445277ab98b': 29,\n",
       " '6560cf72e1d8342798a45691': 991,\n",
       " '6565c86239bfc8784efe5ac7': 620,\n",
       " '6555b5734b13023f9348bbf5': 933,\n",
       " '6571c34d25cc9a343f03f72a': 365,\n",
       " '6555cb7d4b13023f9349e304': 514,\n",
       " '658d47494b25ce4814fb389c': 1086,\n",
       " '6541f78fdc4fa72a6c403741': 948,\n",
       " '6555cacc4b13023f93496ced': 511,\n",
       " '656476d396c80a0efa90f85f': 1582,\n",
       " '6555cc6a4b13023f934a8b9c': 598,\n",
       " '6571a5d1441fea11ec37f7c0': 1649,\n",
       " '65316e3b1e5cc42b1b13e479': 252,\n",
       " '653170031e5cc42b1b1431e3': 1004,\n",
       " '658258d9683f430d81566027': 584,\n",
       " '6555b5c84b13023f9348bfe1': 3674,\n",
       " '6536802f1e5cc42b1b144239': 967,\n",
       " '6560cd8fe1d8342798a45282': 289,\n",
       " '6571c34225cc9a343f03f198': 305,\n",
       " '6571c31125cc9a343f03d984': 423,\n",
       " '6571c2ca25cc9a343f03b505': 325,\n",
       " '653169181e5cc42b1b13cf44': 694,\n",
       " '65741086b8b4d445277ab65a': 738,\n",
       " '651dffefa662d76276b84bbf': 505,\n",
       " '6555cb1a4b13023f9349a15b': 890,\n",
       " '6555b52e4b13023f9348b9c5': 2175,\n",
       " '652fcea01e5cc42b1b13a31a': 2907,\n",
       " '651e0a34a662d76276b864db': 428,\n",
       " '6571c031441fea11ec37f914': 979,\n",
       " '6555cadc4b13023f93497835': 1851,\n",
       " '651de9f1a662d76276b8155f': 744,\n",
       " '656d79159994965ac4b4346a': 950,\n",
       " '6571c034441fea11ec37f970': 1110,\n",
       " '655c905fddbd8042d5c2cccc': 865,\n",
       " '657bc14f857ad3220916004a': 407,\n",
       " '65810740683f430d81565c92': 1082,\n",
       " '6571c28625cc9a343f0394a2': 384,\n",
       " '6571c31425cc9a343f03dadf': 840,\n",
       " '6571c33d25cc9a343f03ef12': 1128,\n",
       " '6555cc404b13023f934a6d0f': 604,\n",
       " '652df8f25669b40a3b5ab65a': 673,\n",
       " '6555cc814b13023f934a9b07': 2912,\n",
       " '653169401e5cc42b1b13d7bd': 1339,\n",
       " '6571c34125cc9a343f03f0f2': 751,\n",
       " '6564770c96c80a0efa90fcef': 902,\n",
       " '6555c7eb4b13023f9348ede3': 352,\n",
       " '65316be61e5cc42b1b13df85': 421,\n",
       " '65316f1a1e5cc42b1b13ef81': 672,\n",
       " '6566a96539bfc8784efe5ca8': 622,\n",
       " '652fc8c81e5cc42b1b13a01c': 1872,\n",
       " '6571c26425cc9a343f03861f': 825,\n",
       " '652fccf01e5cc42b1b13a23a': 1095,\n",
       " '6571c31425cc9a343f03dabb': 631,\n",
       " '6571c34625cc9a343f03f366': 473,\n",
       " '657bc159857ad3220916009f': 1045,\n",
       " '654c4b52dc4fa72a6c403d57': 238,\n",
       " '65791ed91678087a99296614': 534,\n",
       " '6571c36925cc9a343f04052d': 1546,\n",
       " '6555c3424b13023f9348d3d5': 398,\n",
       " '65316ebc1e5cc42b1b13e688': 578,\n",
       " '6555c7e04b13023f9348e919': 1373,\n",
       " '6555c5064b13023f9348db0c': 569,\n",
       " '6555cb5a4b13023f9349cb4c': 1436,\n",
       " '65503fc04b13023f9348b334': 1303,\n",
       " '6571c28e25cc9a343f03984f': 1581,\n",
       " '6555cb174b13023f93499f6b': 1775,\n",
       " '651e0251a662d76276b851ec': 585,\n",
       " '6555cae04b13023f93497ad4': 699,\n",
       " '65864d53683f430d815666e9': 3290,\n",
       " '6555ccb14b13023f934abd65': 935,\n",
       " '6555c1764b13023f9348cfb0': 703,\n",
       " '6555cc684b13023f934a89a4': 810,\n",
       " '6555c7fb4b13023f9348f614': 198,\n",
       " '6555c8424b13023f93492393': 2688,\n",
       " '651dc99da662d76276b7bf6f': 519,\n",
       " '658177ca683f430d81565f16': 1264,\n",
       " '651dd3faa662d76276b7dc47': 366,\n",
       " '65367ffc1e5cc42b1b143dc3': 2019,\n",
       " '65769200b8b4d445277ab841': 1206,\n",
       " '658d47214b25ce4814fb35a8': 1068,\n",
       " '651df2e2a662d76276b82cf0': 268,\n",
       " '651dd4e3a662d76276b7de96': 316,\n",
       " '6555c8384b13023f93491e45': 1505,\n",
       " '651dc43aa662d76276b7b130': 454,\n",
       " '658d471f4b25ce4814fb3586': 292,\n",
       " '651dffefa662d76276b84bbd': 940,\n",
       " '6578050cb8b4d445277abb37': 691,\n",
       " '6571c2b325cc9a343f03a917': 694,\n",
       " '6555b4d94b13023f9348b818': 3093,\n",
       " '6571c23325cc9a343f0375ff': 301,\n",
       " '6555cb724b13023f9349db6f': 941,\n",
       " '655da70be1d8342798a44a82': 1046,\n",
       " '651dd564a662d76276b7dfc4': 425,\n",
       " '6571c28d25cc9a343f039772': 861,\n",
       " '6571c35225cc9a343f03f93b': 907,\n",
       " '65316e421e5cc42b1b13e489': 409,\n",
       " '653168d11e5cc42b1b13bbae': 842,\n",
       " '65316b901e5cc42b1b13def4': 396,\n",
       " '65783d4f1678087a99296403': 565,\n",
       " '6555b5864b13023f9348bcb9': 1917,\n",
       " '6555c40e4b13023f9348d6d6': 684,\n",
       " '651e0a5fa662d76276b86545': 629,\n",
       " '6571c35c25cc9a343f03fe70': 366,\n",
       " '653168bc1e5cc42b1b13b724': 783,\n",
       " '651e09a6a662d76276b86396': 681,\n",
       " '6555c32f4b13023f9348d3b4': 430,\n",
       " '651ddb9ca662d76276b7ef5b': 1268,\n",
       " '6555cbd44b13023f934a1e77': 571,\n",
       " '651e1380a662d76276b87a8b': 271,\n",
       " '6560cf99e1d8342798a45c53': 685,\n",
       " '6555ccac4b13023f934ab96b': 536,\n",
       " '6555c3b24b13023f9348d54d': 393,\n",
       " '652ebbdb1e5cc42b1b139b65': 5046,\n",
       " '65316a0c1e5cc42b1b13db1b': 911,\n",
       " '6555caee4b13023f9349847f': 740,\n",
       " '6555cc2c4b13023f934a5e47': 567,\n",
       " '6571c2e425cc9a343f03c286': 589,\n",
       " '65683375207bb033b910ee20': 534,\n",
       " '6571c25b25cc9a343f038271': 416,\n",
       " '65716db7441fea11ec37f744': 629,\n",
       " '6555b5d14b13023f9348c0f5': 1774,\n",
       " '658d47394b25ce4814fb3763': 855,\n",
       " '6555cab14b13023f93495ab2': 4074,\n",
       " '6555c81c4b13023f93490b3b': 1927,\n",
       " '6555cccb4b13023f934ad395': 1317,\n",
       " '6555ca984b13023f93494b35': 1480,\n",
       " '652fd1891e5cc42b1b13a442': 1494,\n",
       " '653169041e5cc42b1b13c95b': 921,\n",
       " '6571c2e325cc9a343f03c20d': 926,\n",
       " '6536800b1e5cc42b1b143ebf': 1065,\n",
       " '656476d496c80a0efa90f86e': 1215,\n",
       " '6571c36225cc9a343f040162': 315,\n",
       " '651e01eca662d76276b850ea': 631,\n",
       " '6555cc284b13023f934a5b04': 543,\n",
       " '65316d191e5cc42b1b13e1dc': 516,\n",
       " '6571c27325cc9a343f038cbe': 306,\n",
       " '6555cb6f4b13023f9349d952': 827,\n",
       " '6571c32825cc9a343f03e45c': 435,\n",
       " '652ebbb81e5cc42b1b1399ea': 630,\n",
       " '6555cc904b13023f934aa4da': 574,\n",
       " '6571c30b25cc9a343f03d60b': 994,\n",
       " '6571c035441fea11ec37f97d': 709,\n",
       " '6571c34925cc9a343f03f4c8': 1347,\n",
       " '65316ecb1e5cc42b1b13e739': 220,\n",
       " '651dc70fa662d76276b7b83d': 321,\n",
       " '652ebb9b1e5cc42b1b139939': 782,\n",
       " '6531692a1e5cc42b1b13d437': 579,\n",
       " '6560be25e1d8342798a44c0b': 427,\n",
       " '658ce4d14b25ce4814fb2887': 2314,\n",
       " '656557e11fc4586a032ad6aa': 509,\n",
       " '6570412553e8a6117bd30c12': 370,\n",
       " '6560c6ffe1d8342798a45005': 924,\n",
       " '6536802a1e5cc42b1b14419f': 1225,\n",
       " '6555b5c94b13023f9348bff6': 3252,\n",
       " '6555f6454b13023f934aeaeb': 1406,\n",
       " '653169291e5cc42b1b13d400': 202,\n",
       " '651dedbda662d76276b81f60': 848,\n",
       " '6555cbd34b13023f934a1d72': 578,\n",
       " '651dfbc1a662d76276b84156': 437,\n",
       " '65367fe71e5cc42b1b143caa': 1172,\n",
       " '6571c038441fea11ec37f9ef': 1493,\n",
       " '6571a605441fea11ec37f7e3': 1149,\n",
       " '652fcee31e5cc42b1b13a33c': 3197,\n",
       " '6555ca9e4b13023f93494ea3': 920,\n",
       " '6555c8384b13023f93491e9a': 1374,\n",
       " '652ebbdd1e5cc42b1b139b83': 806,\n",
       " '65791e4a1678087a99296469': 28,\n",
       " '653169251e5cc42b1b13d318': 622,\n",
       " '6564770396c80a0efa90fc34': 1658,\n",
       " '6531690c1e5cc42b1b13cbe0': 556,\n",
       " '656476e896c80a0efa90f9df': 871,\n",
       " '6571c038441fea11ec37f9d8': 966,\n",
       " '651de98fa662d76276b8145f': 1441,\n",
       " '6555caab4b13023f9349568e': 3363,\n",
       " '6555c8294b13023f934913c3': 748,\n",
       " '6540c8a62936d70acf71ec52': 1485,\n",
       " '658d47324b25ce4814fb36dc': 1230,\n",
       " '6555c8294b13023f93491405': 848,\n",
       " '6571c29725cc9a343f039bfc': 1014,\n",
       " '656dd5aa9994965ac4b43f49': 357,\n",
       " '656dd1709994965ac4b43840': 199,\n",
       " '655c20c64b13023f934af5b5': 319,\n",
       " '6571c02f441fea11ec37f8dd': 796,\n",
       " '6555c3374b13023f9348d3c3': 905,\n",
       " '6555c4f34b13023f9348dab4': 185,\n",
       " '65703f0853e8a6117bd30580': 329,\n",
       " '651ded88a662d76276b81ece': 818,\n",
       " '656dd59e9994965ac4b43f1b': 1465,\n",
       " '658d47464b25ce4814fb3853': 654,\n",
       " '6531689c1e5cc42b1b13b1ab': 588,\n",
       " '6565c86139bfc8784efe5abf': 1540,\n",
       " '6571c2fc25cc9a343f03cec1': 974,\n",
       " '6560cfabe1d8342798a460bb': 677,\n",
       " '6555b5d84b13023f9348c255': 418,\n",
       " '6531694d1e5cc42b1b13d8e9': 300,\n",
       " '6531691a1e5cc42b1b13d01a': 415,\n",
       " '6555c80f4b13023f9349023d': 879,\n",
       " '6555cc1f4b13023f934a5414': 438,\n",
       " '65316f671e5cc42b1b13fdd3': 594,\n",
       " '6567fae2207bb033b910ec43': 1277,\n",
       " '6571c31825cc9a343f03dca4': 823,\n",
       " '6571c25d25cc9a343f038334': 277,\n",
       " '656719d8207bb033b910ea89': 289,\n",
       " '6555c7d44b13023f9348e4d6': 2228,\n",
       " '656dd1369994965ac4b437eb': 99,\n",
       " '653168bb1e5cc42b1b13b711': 1468,\n",
       " '6555b4c24b13023f9348b793': 2127,\n",
       " '656e92659994965ac4b4d7a2': 812,\n",
       " '6570544f53e8a6117bd31bde': 733,\n",
       " '651e1effa662d76276b89587': 594,\n",
       " '6531693d1e5cc42b1b13d764': 745,\n",
       " '651defa9a662d76276b82464': 937,\n",
       " '65367ff71e5cc42b1b143d70': 1178,\n",
       " '655acc374b13023f934af2a1': 209,\n",
       " '6571c2d725cc9a343f03bba8': 283,\n",
       " '657286d2cbb3242a0060e6a2': 353,\n",
       " '651dcaeba662d76276b7c2f4': 666,\n",
       " '6555bfbf4b13023f9348c837': 653,\n",
       " '65316d891e5cc42b1b13e301': 592,\n",
       " '6555cac34b13023f9349666b': 1463,\n",
       " '653680111e5cc42b1b143f50': 977,\n",
       " '652ebbd91e5cc42b1b139b4c': 688,\n",
       " '6560cf9be1d8342798a45cb4': 540,\n",
       " '6555cbdc4b13023f934a2417': 485,\n",
       " '657bc159857ad322091600ab': 222,\n",
       " '651e10a5a662d76276b873ed': 222,\n",
       " '6536802c1e5cc42b1b1441e9': 1414,\n",
       " '6555cc3f4b13023f934a6c28': 979,\n",
       " '6555ca864b13023f934942b9': 1442,\n",
       " '657bf98d857ad32209160229': 926,\n",
       " '651dd543a662d76276b7df82': 778,\n",
       " '65316f1d1e5cc42b1b13efe5': 595,\n",
       " '651dfa86a662d76276b83e51': 479,\n",
       " '6531690b1e5cc42b1b13cb5a': 1217,\n",
       " '6571c02b441fea11ec37f88e': 1455,\n",
       " '656e02049994965ac4b4b37f': 626,\n",
       " '65316fee1e5cc42b1b142922': 96,\n",
       " '653169111e5cc42b1b13cd69': 540,\n",
       " '6560cface1d8342798a460de': 736,\n",
       " '6571c2a425cc9a343f03a1ee': 2146,\n",
       " '651ddfe6a662d76276b7fae2': 504,\n",
       " '6555cb2c4b13023f9349ad34': 1005,\n",
       " '65864d52683f430d815666db': 1011,\n",
       " '6571c34825cc9a343f03f46a': 766,\n",
       " '652fc7b81e5cc42b1b139f99': 2049,\n",
       " '6555cbb24b13023f934a0773': 632,\n",
       " '651ddc74a662d76276b7f1af': 535,\n",
       " '6555ca3d4b13023f9349303b': 969,\n",
       " '6571c24625cc9a343f037b37': 257,\n",
       " '65367ffd1e5cc42b1b143dd5': 1996,\n",
       " '6555b53e4b13023f9348ba1d': 1577,\n",
       " '6555c8274b13023f9349124b': 1531,\n",
       " '65367feb1e5cc42b1b143cd3': 937,\n",
       " '6571c29a25cc9a343f039d09': 310,\n",
       " '65316ae41e5cc42b1b13dd90': 565,\n",
       " '6571357053e8a6117bd31d62': 243,\n",
       " '656476de96c80a0efa90f905': 66,\n",
       " '65791e611678087a9929657e': 546,\n",
       " '65367fd11e5cc42b1b143bf1': 791,\n",
       " '6564770b96c80a0efa90fcdf': 1038,\n",
       " '656476d396c80a0efa90f865': 1835,\n",
       " '6571c27725cc9a343f038e22': 506,\n",
       " '651e1b02a662d76276b88c0e': 496,\n",
       " '65880f46683f430d815668b3': 2365,\n",
       " '6555b5324b13023f9348b9d8': 2450,\n",
       " '65791e561678087a992964e9': 609,\n",
       " '6564770a96c80a0efa90fccd': 1015,\n",
       " '653168891e5cc42b1b13aef9': 599,\n",
       " '65316efa1e5cc42b1b13eb34': 1253,\n",
       " '6564772296c80a0efa90fe99': 928,\n",
       " '6555c7e14b13023f9348e9cd': 2261,\n",
       " '656dd3c29994965ac4b43b49': 1034,\n",
       " '6555cc3a4b13023f934a6896': 763,\n",
       " '65798ed6a3d42e7319c281cc': 835,\n",
       " '6571c2a325cc9a343f03a174': 997,\n",
       " '6560c36ee1d8342798a44e7f': 905,\n",
       " '6584fbc2683f430d81566486': 682,\n",
       " '656476ed96c80a0efa90fa6d': 908,\n",
       " '6564771696c80a0efa90fda7': 1213,\n",
       " '656dcece9994965ac4b434e9': 562,\n",
       " '651dd464a662d76276b7dd5c': 610,\n",
       " '6571c33a25cc9a343f03eda6': 898,\n",
       " '658d47454b25ce4814fb3850': 411,\n",
       " '6555cc514b13023f934a7934': 479,\n",
       " '6555cb824b13023f9349e6cf': 583,\n",
       " '6555c00d4b13023f9348c98e': 829,\n",
       " '655c1eb74b13023f934af585': 642,\n",
       " '65316fd11e5cc42b1b141e13': 691,\n",
       " '6555c0bf4b13023f9348cc9f': 587,\n",
       " '652fce2a1e5cc42b1b13a2dd': 1306,\n",
       " '651de6c1a662d76276b80d28': 967,\n",
       " '6571c29425cc9a343f039a78': 247,\n",
       " '651e21cba662d76276b89c2b': 633,\n",
       " '6555cb5e4b13023f9349cdf6': 284,\n",
       " '6571c2b725cc9a343f03ab2a': 700,\n",
       " '6560cfb9e1d8342798a4655b': 850,\n",
       " '652fd05a1e5cc42b1b13a3ac': 2710,\n",
       " '6555c4674b13023f9348d869': 803,\n",
       " '651dff73a662d76276b84a79': 835,\n",
       " '651dd5baa662d76276b7e08f': 854,\n",
       " '6555ca8f4b13023f9349466b': 2473,\n",
       " '6571c2ea25cc9a343f03c5b7': 262,\n",
       " '653170031e5cc42b1b1431ce': 555,\n",
       " '654b6a49dc4fa72a6c403cff': 1152,\n",
       " '6555cc2a4b13023f934a5cc3': 488,\n",
       " '653170091e5cc42b1b143468': 643,\n",
       " '65325de51e5cc42b1b1438cf': 484,\n",
       " '653168ae1e5cc42b1b13b48e': 832,\n",
       " '6555cba44b13023f9349fe45': 295,\n",
       " '6555cbbf4b13023f934a1097': 1411,\n",
       " '6555b57e4b13023f9348bc71': 2369,\n",
       " '657529c5b8b4d445277ab682': 375,\n",
       " '6555c7d84b13023f9348e619': 1309,\n",
       " '65316f971e5cc42b1b140a68': 467,\n",
       " '657448c5b8b4d445277ab668': 640,\n",
       " '657bc256857ad322091601da': 1316,\n",
       " '6555c0d04b13023f9348cce7': 1114,\n",
       " '6555cc914b13023f934aa54a': 1433,\n",
       " '6555cc1f4b13023f934a543c': 1770,\n",
       " '65316f301e5cc42b1b13f2dc': 553,\n",
       " '6567fadb207bb033b910eba1': 4484,\n",
       " '651e0aefa662d76276b86698': 655,\n",
       " '6555b5b34b13023f9348be9f': 2549,\n",
       " '653170001e5cc42b1b1430cb': 919,\n",
       " '6571c22f25cc9a343f03751e': 833,\n",
       " '6555c81c4b13023f93490b0a': 756,\n",
       " '6560dcaae1d8342798a47346': 947,\n",
       " '6555cb104b13023f93499b24': 734,\n",
       " '6566a97339bfc8784efe5e01': 81,\n",
       " '6555b4c04b13023f9348b785': 2602,\n",
       " '651de1c5a662d76276b7ffc9': 484,\n",
       " '65316ef61e5cc42b1b13eab9': 739,\n",
       " '65316ee21e5cc42b1b13e8d4': 1402,\n",
       " '6555caef4b13023f93498596': 367,\n",
       " '6555c05c4b13023f9348cb08': 1001,\n",
       " '6536801d1e5cc42b1b144061': 119,\n",
       " '6555b5c54b13023f9348bf9c': 3397,\n",
       " '65316fd31e5cc42b1b141e74': 1077,\n",
       " '6536802c1e5cc42b1b1441d8': 1157,\n",
       " '653168851e5cc42b1b13ae76': 571,\n",
       " '65367ff31e5cc42b1b143d39': 1441,\n",
       " '6571c28225cc9a343f03932f': 389,\n",
       " '651e07e8a662d76276b85faf': 458,\n",
       " '651dc7eea662d76276b7bace': 219,\n",
       " '6555b52f4b13023f9348b9cb': 2130,\n",
       " '6555cad94b13023f934975e3': 777,\n",
       " '652ebbdb1e5cc42b1b139b69': 1985,\n",
       " '6555cb294b13023f9349ab4e': 1670,\n",
       " '6571c36d25cc9a343f040734': 307,\n",
       " '653169251e5cc42b1b13d312': 496,\n",
       " '6560c465e1d8342798a44ef6': 733,\n",
       " '651dd0a1a662d76276b7d2b2': 395,\n",
       " '653680121e5cc42b1b143f63': 530,\n",
       " '6555c2ea4b13023f9348d333': 520,\n",
       " '6555c81d4b13023f93490bdc': 1039,\n",
       " '655da70ae1d8342798a44a7e': 837,\n",
       " '6582c940683f430d81566184': 540,\n",
       " '6571c038441fea11ec37f9eb': 1064,\n",
       " '656dd7de9994965ac4b4456d': 364,\n",
       " '6555c8024b13023f9348fa49': 1817,\n",
       " '651df275a662d76276b82bd0': 535,\n",
       " '6555c7f74b13023f9348f442': 1290,\n",
       " '6571c031441fea11ec37f913': 1536,\n",
       " '651dcbb2a662d76276b7c511': 302,\n",
       " '6571c2fa25cc9a343f03cd9a': 3030,\n",
       " '6582910b683f430d8156616b': 620,\n",
       " '652fcce51e5cc42b1b13a234': 2936,\n",
       " '652ebbe31e5cc42b1b139c04': 3897,\n",
       " '65841ac3683f430d81566437': 6925,\n",
       " '6555c83a4b13023f93492002': 464,\n",
       " '6555bf124b13023f9348c626': 146,\n",
       " '657fb5d08f821120f67a094c': 1992,\n",
       " '6555bee34b13023f9348c5b6': 511,\n",
       " '658a41d3683f430d815669fb': 2005,\n",
       " '653169221e5cc42b1b13d278': 644,\n",
       " '6555ca234b13023f93492eb6': 1015,\n",
       " '653169201e5cc42b1b13d1ea': 472,\n",
       " '6577ccd0b8b4d445277ab95a': 655,\n",
       " '651dde63a662d76276b7f6ae': 462,\n",
       " '6555cb864b13023f9349e902': 2236,\n",
       " '6571c2cf25cc9a343f03b77f': 402,\n",
       " '651e1b95a662d76276b88d4d': 286,\n",
       " '651dd7e3a662d76276b7e5b8': 370,\n",
       " '6555c8e94b13023f934927fe': 592,\n",
       " '6571c34825cc9a343f03f421': 503,\n",
       " '6555b5514b13023f9348baa7': 2465,\n",
       " '6555b5d44b13023f9348c194': 439,\n",
       " '6555b4eb4b13023f9348b867': 2038,\n",
       " '657d12c78f821120f67a0771': 768,\n",
       " '6571c036441fea11ec37f991': 2515,\n",
       " '65698487207bb033b910ef91': 873,\n",
       " '6571c2fd25cc9a343f03cf39': 757,\n",
       " '6566a96139bfc8784efe5c59': 639,\n",
       " '658d3c2e4b25ce4814fb3233': 449,\n",
       " '6571c2f825cc9a343f03ccab': 390,\n",
       " '6555cbdb4b13023f934a2398': 454,\n",
       " '6571c2fd25cc9a343f03cefc': 541,\n",
       " '654856c9dc4fa72a6c403a1e': 246,\n",
       " '6555c7cb4b13023f9348e253': 1187,\n",
       " '651e0c36a662d76276b86987': 648,\n",
       " '6555c80b4b13023f9348ffea': 915,\n",
       " '65310c491e5cc42b1b13a741': 454,\n",
       " '6571c30325cc9a343f03d236': 444,\n",
       " '651df09aa662d76276b826bd': 241,\n",
       " '6555bee74b13023f9348c5be': 762,\n",
       " '653680041e5cc42b1b143e45': 2779,\n",
       " '6584fbc2683f430d81566487': 1028,\n",
       " '65316eec1e5cc42b1b13e9c4': 1069,\n",
       " '651e1b6fa662d76276b88cfb': 445,\n",
       " '6555caa24b13023f934950d3': 1199,\n",
       " '6571c25f25cc9a343f038404': 1084,\n",
       " '658d47584b25ce4814fb39a7': 1340,\n",
       " '6555c4bd4b13023f9348d9d1': 909,\n",
       " '657135c853e8a6117bd31ee8': 1259,\n",
       " '6564771496c80a0efa90fd82': 1688,\n",
       " '6555c8294b13023f93491364': 452,\n",
       " '65728735cbb3242a0060e764': 787,\n",
       " '652ebbb51e5cc42b1b1399d3': 936,\n",
       " '656476f896c80a0efa90fb58': 1235,\n",
       " '6555c15c4b13023f9348cf35': 482,\n",
       " '65316f2d1e5cc42b1b13f259': 682,\n",
       " '651dc4c5a662d76276b7b284': 220,\n",
       " '652ebba21e5cc42b1b139960': 717,\n",
       " '6531682d1e5cc42b1b13a7b9': 608,\n",
       " '6555cb784b13023f9349df7c': 5057,\n",
       " '6571c36225cc9a343f040198': 507,\n",
       " '6571c2a325cc9a343f03a170': 695,\n",
       " '653170091e5cc42b1b143481': 1473,\n",
       " '652ebbdf1e5cc42b1b139bb1': 2647,\n",
       " '6555cba44b13023f9349fdfe': 1479,\n",
       " '65367ff81e5cc42b1b143d8e': 2850,\n",
       " '653169931e5cc42b1b13d9e8': 522,\n",
       " '6571c28b25cc9a343f0396a7': 1224,\n",
       " '653680191e5cc42b1b143ff7': 2729,\n",
       " '6560cd84e1d8342798a4527a': 524,\n",
       " '6555c02f4b13023f9348ca41': 642,\n",
       " '6555cccb4b13023f934ad3be': 547,\n",
       " '651e1998a662d76276b888d8': 826,\n",
       " '6571c2c425cc9a343f03b187': 599,\n",
       " '653170031e5cc42b1b143206': 904,\n",
       " '651dc81ba662d76276b7bb45': 405,\n",
       " '651df077a662d76276b82666': 346,\n",
       " '653169251e5cc42b1b13d317': 346,\n",
       " '65367fd61e5cc42b1b143c15': 874,\n",
       " '653168461e5cc42b1b13a8b7': 1756,\n",
       " '657ed4c48f821120f67a08f3': 785,\n",
       " '6555ccc24b13023f934acb87': 1045,\n",
       " '651e08e7a662d76276b861f4': 524,\n",
       " '65316f071e5cc42b1b13ecb0': 703,\n",
       " '6560cf94e1d8342798a45b4d': 910,\n",
       " '6571c30825cc9a343f03d4b4': 1953,\n",
       " '6555bfe94b13023f9348c8fd': 685,\n",
       " '65767b4fb8b4d445277ab752': 27,\n",
       " '6571c2dc25cc9a343f03be05': 545,\n",
       " '655da70ae1d8342798a44a7a': 1138,\n",
       " '65316ec11e5cc42b1b13e6bd': 508,\n",
       " '65316f941e5cc42b1b14095f': 1494,\n",
       " '658d47644b25ce4814fb3a95': 583,\n",
       " '653170021e5cc42b1b143162': 916,\n",
       " '652fcc0d1e5cc42b1b13a1c5': 1605,\n",
       " '651e0304a662d76276b853a9': 737,\n",
       " '6571c2c725cc9a343f03b33b': 793,\n",
       " '657e644c8f821120f67a08bd': 1086,\n",
       " '6555c8434b13023f934923b9': 1686,\n",
       " '6571c29125cc9a343f039926': 2425,\n",
       " '65769200b8b4d445277ab83d': 1451,\n",
       " '65309c0a1e5cc42b1b13a6bf': 263,\n",
       " '653169d81e5cc42b1b13daad': 649,\n",
       " '6571c2c025cc9a343f03afc3': 1158,\n",
       " '652fca571e5cc42b1b13a0e3': 2119,\n",
       " '6555cb574b13023f9349c8c6': 931,\n",
       " '652fca401e5cc42b1b13a0d7': 1670,\n",
       " '6569bcc9207bb033b910efc8': 450,\n",
       " '653680271e5cc42b1b144152': 744,\n",
       " '658d474f4b25ce4814fb3900': 1376,\n",
       " '6555b51d4b13023f9348b966': 2042,\n",
       " '6555cc204b13023f934a5493': 353,\n",
       " '652fcb9f1e5cc42b1b13a18b': 1593,\n",
       " '651e1aa8a662d76276b88b3e': 496,\n",
       " '6573d853b8b4d445277ab5b9': 424,\n",
       " '656dd82e9994965ac4b44663': 737,\n",
       " '651e22e3a662d76276b89ec9': 765,\n",
       " '6536801e1e5cc42b1b144070': 917,\n",
       " '6555cba74b13023f934a0046': 1035,\n",
       " '651e03a8a662d76276b85555': 556,\n",
       " '65316a681e5cc42b1b13dc2a': 524,\n",
       " '652fd28f1e5cc42b1b13a4c4': 1346,\n",
       " '65316f8e1e5cc42b1b1407da': 1464,\n",
       " '656eca959f528f16c001a7da': 797,\n",
       " '6536801b1e5cc42b1b144028': 1128,\n",
       " '6571c31325cc9a343f03da8b': 435,\n",
       " '653680151e5cc42b1b143fa7': 881,\n",
       " '6571c33f25cc9a343f03efea': 934,\n",
       " '6555cbcb4b13023f934a181d': 569,\n",
       " '653680241e5cc42b1b144112': 770,\n",
       " '656557dc1fc4586a032ad656': 733,\n",
       " '656476f396c80a0efa90fafd': 1118,\n",
       " '6555ccc74b13023f934ad066': 664,\n",
       " '651dc62ca662d76276b7b5ea': 490,\n",
       " '6571c27a25cc9a343f038f6d': 314,\n",
       " '65316ebd1e5cc42b1b13e690': 602,\n",
       " '651e0848a662d76276b86081': 507,\n",
       " '6571c37325cc9a343f040a14': 304,\n",
       " '6571c28c25cc9a343f03970f': 792,\n",
       " '6571c2fd25cc9a343f03cf1f': 1146,\n",
       " '6571c30225cc9a343f03d157': 430,\n",
       " '6555cc5d4b13023f934a8194': 621,\n",
       " '6531689b1e5cc42b1b13b17d': 273,\n",
       " '652cdf8350af0e25a9123111': 574,\n",
       " '6555bfd94b13023f9348c8b2': 449,\n",
       " '651dc5f0a662d76276b7b552': 788,\n",
       " '653680171e5cc42b1b143fb9': 1114,\n",
       " '65683313207bb033b910edd7': 493,\n",
       " '65438149dc4fa72a6c403880': 765,\n",
       " '651dcd60a662d76276b7c99a': 934,\n",
       " '6571c2d325cc9a343f03b9ac': 1166,\n",
       " '6577cccbb8b4d445277ab938': 2104,\n",
       " '657bf98c857ad32209160211': 910,\n",
       " '6555cca24b13023f934ab231': 3473,\n",
       " '658d470f4b25ce4814fb3464': 1034,\n",
       " '6566a96639bfc8784efe5cc7': 340,\n",
       " '6564770896c80a0efa90fca6': 1954,\n",
       " '65703f0c53e8a6117bd30592': 641,\n",
       " '655b3c514b13023f934af391': 918,\n",
       " '653680091e5cc42b1b143eaa': 1833,\n",
       " '65810740683f430d81565c91': 710,\n",
       " '658d475b4b25ce4814fb39e1': 1199,\n",
       " '6555c1e54b13023f9348d0ce': 750,\n",
       " '6571c30c25cc9a343f03d6c8': 327,\n",
       " '656476fb96c80a0efa90fb8f': 2024,\n",
       " '656476e396c80a0efa90f969': 44,\n",
       " '6555ccd04b13023f934ad7d9': 516,\n",
       " '6555cacd4b13023f93496dd4': 2039,\n",
       " '6555c8084b13023f9348fe0c': 1587,\n",
       " '653168861e5cc42b1b13aea9': 574,\n",
       " '656dd9929994965ac4b44afa': 488,\n",
       " '65616350aa3101769d151036': 224,\n",
       " ...}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98debfa6-57b3-4fdc-a66f-611d926f9aa7",
   "metadata": {},
   "source": [
    "#### Finding the token limit for articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25bb00d5-b5db-455b-963f-c28a0765ae73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer_original = AutoTokenizer.from_pretrained('teknium/OpenHermes-2.5-Mistral-7B', use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80877f84-ed1b-4678-8aed-8789162ec7e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.chat_template = tokenizer_original.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec554d1f-f427-4429-8564-0aee5ab3acde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1465"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_template = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\" '|article_start|\\n'{''}'\\n|article_end|'\\n\"}]\n",
    "\n",
    "OUTPUT_TOKEN_LIMIT = 1024 # set based on the distribution of completion tokens from gpt4\n",
    "INSTRUCTION_TOKENS = len(tokenizer.apply_chat_template(message_template, add_generation_prompt=True))\n",
    "BUFFER_TOKENS = 10\n",
    "ARTICLE_TOKEN_LIMIT = 4096 - OUTPUT_TOKEN_LIMIT - INSTRUCTION_TOKENS - BUFFER_TOKENS\n",
    "ARTICLE_TOKEN_LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c4b3428-06ff-4773-9ad1-f581c2df6233",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['content', 'attributes'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_train_set['65316d5c1e5cc42b1b13e25a'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63d4c0b0-f126-4994-91a1-d2d84b4aaadd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_train_set_copy = {k: {'content': v['content'], 'attributes': json.dumps(v['attributes'])} for k, v in cleaned_train_set.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d7b8d29-b7bc-4f86-bfd6-6b822822fe0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame.from_dict(cleaned_train_set_copy).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c8bc982-31b7-4c31-8d30-e18dc922c63b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65316f071e5cc42b1b13ecb0    {\"summary\": \"**Company Profile**: The automoti...\n",
       "6555c80d4b13023f93490129    {\"summary\": \"**Yield Increase**: The 10-year T...\n",
       "6571c02b441fea11ec37f88c    {\"summary\": \"**Threshold Crossing**: America i...\n",
       "65841ac3683f430d81566437    {\"summary\": \"**Market Insights**: India's dire...\n",
       "65316f471e5cc42b1b13f72e    {\"summary\": \"**Market Roundup**: The Indian ma...\n",
       "652fcc931e5cc42b1b13a20b    {\"summary\": \"**Location Advantage**: Saugor, a...\n",
       "6536801e1e5cc42b1b144070    {\"summary\": \"**Asset type**: Long-Term Capital...\n",
       "65316d191e5cc42b1b13e1dc    {\"summary\": \"**DA Increase**: The central gove...\n",
       "6555cac04b13023f934964c2    {\"summary\": \"**Debt forgiveness**: Co-founder ...\n",
       "65892882683f430d8156693e    {\"summary\": \"**Compounding Effect**: The magic...\n",
       "Name: attributes, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['attributes'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "705ed650-a113-4414-a7e4-b39024eb4373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67c030-895d-4c7d-bbe8-6ea32104ce76",
   "metadata": {},
   "source": [
    "### Setting up prompt in ChatML Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33af3259-0675-4233-b63c-6484ea3aa555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_text_response_as_prompt(train_row):\n",
    "    truncated_content = truncate_text_to_token_limit(text=train_row['content'], encoder=tokenizer, token_limit=ARTICLE_TOKEN_LIMIT)\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{truncated_content}\\n\"}]\n",
    "    context_prompt = tokenizer.decode(tokenizer.apply_chat_template(messages, add_generation_prompt=True))\n",
    "    prompt = context_prompt + json.dumps(train_row['attributes'])\n",
    "    prompt = re.sub(r'\\n+','\\n',prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cba3d686-d495-420c-8545-ccc70cfd1256",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|> system\\nYou are an expert chief editor for a leading Indian business and financial content website. You evaluate critical attributes of articles to gatekeep content quality. The following are 18 attributes with the format of attribute (datatype): <instruction>\\n1. summary (markdown text):  <Summarize the following article with following instructions.\\na. Readability: Follow proper grammar and maintain easy readability with no more than 2-3 points and up to 80 words. 2 points for short articles and 3 points for long articles\\nb. Faithfulness: Don\\'t mention any details which are not part of the article\\nc. Accuracy: All the numbers, dates, events should have the correct attribution. Do not, at any cost mix up numbers or dates. \\nd. Recall: No critical info should be missed\\ne. structure: Each point should be only a single line. Prefix the point with a relevant label for that point. The points should overall capture the essence of the article. The labels should be human readable and don’t use any _ or programming symbols. \\nf. format: the following markdown label point format. The labels are bolded followed by : and a point. New points are separated by \\n. We’ll call this format as _summary_markdown_format_\\n\"**label1**: point1 \\n **label2**: point2 \\n …\"\\nno preamble or postamble. Make sure that you adhere to the maximum limit of 3 points. It is very important that the format is a valid _summary_markdown_format_>\\n2. summary_critique (short text): <critique the summary above by comparing with the article and the instructions. check for any important details missed or changes needed in Readability, Faithfulness, Accuracy and Recall of the expected format. Evaluate if there are too many or too few points based on article length. Assess the validity of the markdown format as well against _summary_markdown_format_>\\n3. improved_summary (markdown text): <create an improved summary by considering summary and summary_critique in the same format as a valid _summary_markdown_format_>\\n4. top_categories (5 semi colon separated words): <List 5 progressively general categories separated by semicolons (;), avoiding quotes to prevent json.loads() failures>\\n5. business_or_financial_article (True/False) : <True or False, based on the article\\'s relevance to Indian corporations, investors, and policies impacting them.>\\n6. indian_or_international (indian/international): <is the article specific for india or is an international content>\\n7. relevant_for_indians (True/False) : <True or False, considering the article\\'s relevance and applicability to Indian readers, including international and multinational contexts.>\\n8. article_validity_duration_evaluation (short text) : <analyse the factors for the relevance duration. stock fluctuations for 1 day; significant policy changes - few days; educational are timeless unless it references any regulations or acts, in which case a max of 30 days (regulations change). quarterly results valid for 3 days, yearly results for a 7>\\n9. article_validity_duration (one of 1, 3, 7, 14, 30, -1) : <calculate number of days based on previous attribute among one of 1,3,7,14,30. -1 for timeless. Don’t provide any other number apart from these>\\n10. popularity_evaluation (short text): <evaluate the likely popularity of the article based on the following criteria:\\na. reader_interest_score: how many people among casual business news readers are likely to be interested. Considering what score to give between 0 to 1\\nb. headline_effectiveness: ability of headline to engage. Considering what score to give between 0 to 1\\nc. event_novelty: how frequently the event occurs or this type of content is available. every few hours, days, weeks or months. Considering what score to give between 0 to 1. Anything which happens only every few quarters is more novel. \\nd. emotional_impact: what is the most common emotion that readers are going to go through and how many readers will likely have the emotion. Considering what score to give between 0 to 1\\nBe stingy in giving scores more than 0.4\\n>\\n11. popularity_evaluation_critique (short text): <critique the scores by relooking at the article and seeing if there is anything which is overrated or underrated>\\n12. final_reader_interest_score (0-1): <0 to 1 float>\\n13. final_headline_effectiveness_score (0-1): <0 to 1 float>\\n14. final_event_novelty_score (0-1): <0 to 1 float>\\n15. final_emotional_impact_score (0-1): <0 to 1 float>\\n16. improved_headline (short text) : <Write a headline based on the content of the article to grab attention by evoking curiosity or an emotional/intellectual response, but avoid a clickbait headline>\\n17. article_type (fact/opinion/analysis/educational/sponsored) : <Determine if the article is fact, opinion, analysis, educational, or sponsored, based on content and presentation. Predictions without sufficient data to backup is opinion, with data is analysis. >\\n18. article_sentiment (bull/bear/NA): <sentiment of the article is bullish, bearish or NA. balanced is NA>\\nyour response should be a json structure with all the 18 above keys without missing any key. It is very important that the response is directly readable with json.loads(). no preamble or postamble. respond in the exact following structure:\\n \\n{\\n  \"summary\": \"\",\\n  \"summary_critique\": \"\",\\n  \"improved_summary\": \"\",\\n  \"top_categories\": \"\",\\n  \"business_or_financial_article\": \"\",\\n  \"indian_or_international\": \"\",\\n  \"relevant_for_indians\": \"\",\\n  \"article_validity_duration_evaluation\": \"\",\\n  \"article_validity_duration\": \"\",\\n  \"popularity_evaluation\": \"\",\\n  \"popularity_evaluation_critique\": \"\",\\n  \"final_reader_interest_score\": \"\",\\n  \"final_headline_effectiveness_score\": \"\",\\n  \"final_event_novelty_score\": \"\",\\n  \"final_emotional_impact_score\": \"\",\\n  \"improved_headline\": \"\",\\n  \"article_type\": \"\",\\n  \"article_sentiment\": \"\"\\n}\\n<|im_end|> \\n<|im_start|> user\\nheadline: Mindless creation of brands has begun to get revisited  Mint  content:  NEW DELHI : Brand and business consultant Interbrand part of the global marketing and communications conglomerate Omnicon Group has worked on significant projects for Britannia Godrej Jio and Mahindra among others in the country. In an interview Ashish Mishra managing director Interbrand India talks about the post-covid world marked by new requirements from brands and consumers and the opportune time for Rebranding 3.0. Edited excerpts: Did Interbrand India lose clients owing to covid disruption in the past two years It was a contradictory set of experiences we had. On the one hand we experienced slowdown and reprioritization from a set of traditional sector clients. Simultaneously we had another set understandably from the tech sector which accelerated the pace of work. So while our implementation of the breakthrough segmented approach to realty branding and marketing for Godrej took a back seat in the wake of crisis management and the new WFH-fuelled residential demand the launch of the electric brand and shift to the future of mobility for Hero MotoCorp followed a turbo-charged course. Are brands returning as they resume business and life limps back to normalcy First up there is absolutely no questioning the palpable anxiety that is rampant across sectors and regions. Pent-up demand is creating a robust pipeline of projects for many but the ability to pay is constrained. However as confidence returns gradually there surely is a new curiosity and appreciation towards doing the right things with the brand. The erstwhile attitude of salience-driven marketing by the advertising-bred Indian marketers seems to be substantially weakened. The mindless creation of brands has begun to get revisited. Working in silos inefficiencies of engaging multiple specialists barely governed for brand coherence the fixation with the TV commercial and many such flawed ways of working are being questioned as the brands in their new avatars take centre stage. What questions are brands asking experts like you in a post-covid world One of the fundamental shifts is about thinking of a brand beyond advertising. Blinkered seeking of tearjerkers preachy progressiveness anthemic grandiosity or hilarious jokes to surrogate for all that brands can do is on the wane. For long advertising was wrongly seen as the only way of building brands. With the media consumption transforming due to the pandemic-accelerated OTT boom and the ad industry struggling to find new relevance clients are increasingly keen to know more ways of what can be done with and through their brands. Are some of them looking to overhaul or refresh brands Indeed. I am calling it The Rebranding 3.0. The first wave of Rebranding was when brands were seeking to evolve from quality assurance to a dramatized-albeit-generic category promise in Independent India. The second wave or the Rebranding 2.0 was witnessed during the 90s when post the opening up of the economy Indian brands evolved to catch up with their global counterparts who were now competing with them in their backyard. This new wave of Rebranding 3.0 is more mature and closer to global dynamics. Repositioning to find new relevance optimizing portfolios extending business categories and channels transforming to be relevant for the future connecting with new customers gender diversity opportunities progressive appeals essentially doing right doing more with less. At Interbrand we have been finding ways of demonstrating the business value-driving abilities of brands and of inspiring our partners by showing them the new possibilities in the flux. What is the biggest pressure that brands are facing from customers With customers being spoilt for choice and demand creation being critical for survival for businesses there are immense new pressures brands are facing from customers oscillating between fear and hope. Customers are interested in an If not a What. In volatility you are more likely to sell options and futures on products and services rather than products and services themselves. The demand for flexible conditionsfrom trials to returns to extensionsmeans your customers are actually paying for rights. You are trading in what could be. Even Air India much before its vaunted takeover began to provide a free change of dates for all flights cancelled due to coronavirus. Businesses will have to rebuild their customers confidence by giving them control and personalizing space and time through planned at-my time experiences. What was once the distinguishing trait of luxury showroomsappointmentsis likely to become a norm for a wide variety of stores clubs and dealerships. For customers brands now compete with cash and savings. In times of uncertainty savings and cash are brands toughest competitors. Customers expect brands to design pricing models and financing solutions that reframe value and create accessmaking financing a strategic edge not an opportunistic shortcut. Customers want what is essential and savour its emotionality. In anxiety household essentials become heroes. Whether you help keep people connected insured or clean step forward. Create an emotional bond with your brand. As fear wraps the future ostentation will be replaced by investment in things that endure and hold their value over time. Brands could do well by focusing on their products worth and meaning. Customers want you to evolve your channel strategy into their personal logistics. With direct-to-consumer a less vulnerable route to market personal supply chains offering consumers complete control of their immediate environments flourish. Customizing activities such as viewing ordering collecting assembling discussing sharing and enjoying gives rise to near-personalize logistics chains. \\n<|im_end|> \\n<|im_start|> assistant\\n\"{\\\\\"summary\\\\\": \\\\\"**Brand Evolution**: Interbrand India MD discusses post-COVID brand requirements, highlighting the pared back salience-drive marketing trend and the rise of \\'Rebranding 3.0\\' <br> **Market Changes**: Traditional brands slowed during COVID while tech accelerated; a mixed experience for Interbrand India. Brands now reconsidering marketing tactics. <br> **Consumer Expectations**: Customers increasingly need control, flexibility, and personalization, driving brands to adapt pricing, communication, and logistics strategies.\\\\\", \\\\\"summary_critique\\\\\": \\\\\"The summary encapsulates the key points of the article accurately and concisely. It effectively communicates changes in the marketing landscape, the differing experiences of traditional and tech brands, and the evolution of consumer expectations.\\\\\", \\\\\"improved_summary\\\\\": \\\\\"**Brand Evolution**: Amidst post-COVID changes, Indian brands move towards a more considerate approach, shifting from salience-driven marketing to \\'Rebranding 3.0\\', notes Interbrand India. <br> **Pandemic Impact**: COVID-19 disruption left traditional brands struggling, while tech brands gained pace; marking a pivotal turn for brand marketing strategy. <br> **Consumer Shifts**: Customers now demand control, flexibility, and personalisation, obliging brands to rethink their pricing models, engagement methods and delivery options.\\\\\", \\\\\"top_categories\\\\\": \\\\\"Indian Market; Brand Marketing; Business Consulting; Consumer Behaviour; Pandemic Impact\\\\\", \\\\\"business_or_financial_article\\\\\": true, \\\\\"indian_or_international\\\\\": \\\\\"indian\\\\\", \\\\\"relevant_for_indians\\\\\": true, \\\\\"article_validity_duration_evaluation\\\\\": \\\\\"The article detail relevant industry trends and shifts in consumer behavior. It provides a timeless educational value, particularly within the context of COVID-19.\\\\\", \\\\\"article_validity_duration\\\\\": -1, \\\\\"popularity_evaluation\\\\\": \\\\\"reader_interest_score: 0.7, as discussions on brand marketing and industry trends can capture significant interest.<br> headline_effectiveness: 0.6, \\'Mindless creation of brands\\' is a strong phrasing that grabs attention but the overall message can be more concise.<br> event_novelty: 0.4, Post-COVID changes and impacts are a common topic.<br> emotional_impact: 0.3, The article primarily provides an analysis without significant emotional appeal.\\\\\", \\\\\"popularity_evaluation_critique\\\\\": \\\\\"Appropriate scores overall, although the emotional impact could be underestimated considering the significant changes brands and consumers undergo.\\\\\", \\\\\"final_reader_interest_score\\\\\": 0.7, \\\\\"final_headline_effectiveness_score\\\\\": 0.6, \\\\\"final_event_novelty_score\\\\\": 0.4, \\\\\"final_emotional_impact_score\\\\\": 0.3, \\\\\"improved_headline\\\\\": \\\\\"Post-COVID Brands\\' Evolution: The Rise of Customer-Centric Tactics\\\\\", \\\\\"article_type\\\\\": \\\\\"analysis\\\\\", \\\\\"article_sentiment\\\\\": \\\\\"na\\\\\"}\"'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_text_response_as_prompt(train_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8976a6-b82f-4312-a525-07006a113bcc",
   "metadata": {},
   "source": [
    "### Create chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d92af3f3-4bc7-4684-bcc5-6b7161db8f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e7e2ba02-cea3-4573-9161-068fac132a74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375325163b6f40699b86e86a7ede9fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1958 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5537cb751dfa44e89ba671199b198b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1958 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking dataset into chunks of 4096 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebb4214526874e58adb60765edd0a42a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1958 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 1476\n",
      "Total number of samples: 1476\n"
     ]
    }
   ],
   "source": [
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_text_response_as_prompt(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(template_dataset)\n",
    "# tokenize dataset\n",
    "dataset = dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(dataset.features)\n",
    ")\n",
    "# chunk dataset\n",
    "lm_dataset = pack_dataset(dataset, chunk_length=4096) # We use 4096 as the maximum length for packing\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4607e40-7437-4fb3-bf5d-e3cab313dbb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('words.txt','r') as f:\n",
    "    words = f.read()\n",
    "\n",
    "words = words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea003389-99b6-4a68-b4cf-d6ecd7bb283a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_id = ''.join(np.random.choice(words, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec5ba4f2-b7b2-4df9-8f9d-73791ef647da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KaleidoscopeNarwhalIvy'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4182a20-f354-4554-a3e0-a2c97184355e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ac2a490-16c7-40ad-9f8f-fb6611e44584",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-03'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.strftime(datetime.today(),'%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9433667-f5f6-4c9a-a6a3-e19c9f50cd26",
   "metadata": {},
   "source": [
    "### Saving training data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb593874-f0fb-4773-bcd2-515390d900fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ac00c83-a9f6-4628-9ea4-d4679d830aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_dataset_config = {'finetune_id': finetune_id,\n",
    "                          'date': datetime.strftime(datetime.today(),'%Y-%m-%d'),\n",
    "                          'num_datapoints': 1488,\n",
    "                            'data_source': 'gpt4',\n",
    "                          'prompt': system_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a4a33ee-bb12-4bc5-bd8b-c8f5fc1fc517",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KaleidoscopeNarwhalIvy'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_dataset_config['finetune_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02d91b51-a693-47eb-b24d-3f3c715e7785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # save train_dataset to s3\n",
    "# training_input_path = f's3://{sess.default_bucket()}/fine_tuning_datasets/{finetune_dataset_config[\"date\"]}-{finetune_dataset_config[\"finetune_id\"]}'\n",
    "# lm_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "# print(\"uploaded data to:\")\n",
    "# print(f\"training dataset to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1dd03a33-c07e-456b-a0c9-7dae2ee9aae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_input_path = 's3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2024-01-03-ApricotTangerineScallop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d38214b-3b12-4628-a7e7-e8ae50e7e7ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lm_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a2533-b2d1-476e-bad8-1b51ecb3bdb1",
   "metadata": {},
   "source": [
    "### Hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44304c47-94f8-48db-ad95-a6a66ffb35a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'num_train_epochs': 2,                            # number of training epochs\n",
    "  'per_device_train_batch_size': 3,                 # batch size for training\n",
    "  'gradient_accumulation_steps': 3,                 # Number of updates steps to accumulate\n",
    "  'gradient_checkpointing': True,                   # save memory but slower backward pass\n",
    "  'bf16': True,                                     # use bfloat16 precision\n",
    "  'tf32': True,                                     # use tf32 precision\n",
    "  'learning_rate': 2e-4,                            # learning rate\n",
    "  'max_grad_norm': 0.3,                             # Maximum norm (for gradient clipping)\n",
    "  'warmup_ratio': 0.03,                             # warmup ratio\n",
    "  \"lr_scheduler_type\":\"cosine_with_restarts\",                   # learning rate scheduler\n",
    "  'save_strategy': \"epoch\",                         # save strategy for checkpoints\n",
    "  \"logging_steps\": 10,                              # log every x steps\n",
    "  'merge_adapters': True,                           # wether to merge LoRA into the model (needs more memory)\n",
    "  'use_flash_attn': True,                           # Whether to use Flash Attention\n",
    "  'output_dir': '/tmp/run'                         # output directory, where to save assets during training\n",
    "    \n",
    "                                                    # could be used for checkpointing. The final trained\n",
    "                                                    # model will always be saved to s3 at the end of training\n",
    "}\n",
    "\n",
    "if HfFolder.get_token() is not None:\n",
    "    hyperparameters['hf_token'] = HfFolder.get_token() # huggingface token to access gated models, e.g. llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3c504922-a491-451e-a246-b56270ab9c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mpi_options = {\n",
    "#     \"enabled\" : True,\n",
    "#     \"processes_per_host\" : 8,\n",
    "# }\n",
    "# smp_options = {\n",
    "#     \"enabled\":True,\n",
    "#     \"parameters\": {\n",
    "#         \"microbatches\": 4,\n",
    "#         \"placement_strategy\": \"spread\",\n",
    "#         \"pipeline\": \"interleaved\",\n",
    "#         \"optimize\": \"speed\",\n",
    "#         \"partitions\": 4,\n",
    "#         \"ddp\": True,\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# distribution={\n",
    "#     \"smdistributed\": {\"modelparallel\": smp_options},\n",
    "#     \"mpi\": mpi_options\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6908d813-bb59-4f10-9b5a-79c8830e3f0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f'huggingface-qlora-{hyperparameters[\"model_id\"].replace(\"/\",\"-\").replace(\".\",\"-\")}-{finetune_dataset_config[\"finetune_id\"]}'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_qlora.py',    # train script\n",
    "    source_dir           = '../utils/',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.4xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 9*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 50,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    "    disable_output_compression = True         # not compress output to save training time and cost\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe723b0-2ef5-4f09-a59a-21162e453b6a",
   "metadata": {},
   "source": [
    "### Training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16ae277e-1468-4629-af41-63d3400280a7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-TheBloke-OpenHermes-2-2024-01-03-15-34-32-417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2024-01-03 15:34:35 Starting - Starting the training job...\n",
      "2024-01-03 15:34:49 Starting - Preparing the instances for training......\n",
      "2024-01-03 15:35:54 Downloading - Downloading input data...\n",
      "2024-01-03 15:36:19 Downloading - Downloading the training image.....................\n",
      "2024-01-03 15:39:55 Training - Training image download completed. Training in progress......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-01-03 15:40:50,900 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-01-03 15:40:50,925 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-03 15:40:50,934 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-01-03 15:40:50,936 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-01-03 15:40:52,279 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.35.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 87.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.5.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 29.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting optimum==1.14.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl (398 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 398.9/398.9 kB 72.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.23.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.1/258.1 kB 53.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.41.3.post2-py3-none-any.whl (92.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.6/92.6 MB 28.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.3 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 91.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.12.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 330.1/330.1 kB 61.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 130.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting coloredlogs (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 15.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers[sentencepiece]>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (4.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (2.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting transformers[sentencepiece]>=4.26.0 (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.2/8.2 MB 116.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.1-py3-none-any.whl (8.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 136.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.2/8.2 MB 96.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (0.1.99)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 30.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (12.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (3.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.9.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: bitsandbytes, safetensors, humanfriendly, huggingface-hub, coloredlogs, tokenizers, accelerate, transformers, peft, optimum\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.14.1\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.14.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.14.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.23.0 bitsandbytes-0.41.3.post2 coloredlogs-15.0.1 huggingface-hub-0.20.1 humanfriendly-10.0 optimum-1.14.0 peft-0.5.0 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.35.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:06,795 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:06,796 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:06,841 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:06,875 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:06,909 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:06,920 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"gradient_accumulation_steps\": 3,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"learning_rate\": 0.0002,\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"cosine_with_restarts\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ\",\n",
      "        \"num_train_epochs\": 2,\n",
      "        \"output_dir\": \"/tmp/run\",\n",
      "        \"per_device_train_batch_size\": 3,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"use_flash_attn\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-TheBloke-OpenHermes-2-2024-01-03-15-34-32-417\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-TheBloke-OpenHermes-2-2024-01-03-15-34-32-417/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_qlora\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_qlora.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":3,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":0.0002,\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":3,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_qlora.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_qlora\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-TheBloke-OpenHermes-2-2024-01-03-15-34-32-417/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":3,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":0.0002,\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":3,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-TheBloke-OpenHermes-2-2024-01-03-15-34-32-417\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-TheBloke-OpenHermes-2-2024-01-03-15-34-32-417/source/sourcedir.tar.gz\",\"module_name\":\"run_qlora\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_qlora.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training\",\"--gradient_accumulation_steps\",\"3\",\"--gradient_checkpointing\",\"True\",\"--hf_token\",\"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\",\"--learning_rate\",\"0.0002\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"cosine_with_restarts\",\"--max_grad_norm\",\"0.3\",\"--merge_adapters\",\"True\",\"--model_id\",\"TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ\",\"--num_train_epochs\",\"2\",\"--output_dir\",\"/tmp/run\",\"--per_device_train_batch_size\",\"3\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--use_flash_attn\",\"True\",\"--warmup_ratio\",\"0.03\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=3\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=0.0002\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=cosine_with_restarts\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=2\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/run\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=3\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FLASH_ATTN=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 3 --gradient_checkpointing True --hf_token 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 --learning_rate 0.0002 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters True --model_id TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ --num_train_epochs 2 --output_dir /tmp/run --per_device_train_batch_size 3 --save_strategy epoch --tf32 True --use_flash_attn True --warmup_ratio 0.03\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:06,947 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flash-attn in /opt/conda/lib/python3.10/site-packages (0.2.8)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.4.2.tar.gz (2.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 55.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.4.2-cp310-cp310-linux_x86_64.whl size=113930372 sha256=2c7ddc942e0715ef4a7ab62e3404b519a7ac040b3b6eae8fedcdc08a36ced786\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/9d/cf/7f/d14555553b5b30698dae0a4159fdd058157e7021cec565ecaa\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mSuccessfully installed flash-attn-2.4.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mLogging into the Hugging Face Hub with token hf_NjVkEqg...\u001b[0m\n",
      "\u001b[34mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\u001b[0m\n",
      "\u001b[34mToken is valid (permission: write).\u001b[0m\n",
      "\u001b[34mYour token has been saved to /root/.cache/huggingface/token\u001b[0m\n",
      "\u001b[34mLogin successful\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 1.42k/1.42k [00:00<00:00, 13.5MB/s]\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/opt/ml/code/run_qlora.py\", line 202, in <module>\u001b[0m\n",
      "\u001b[34mmain()\n",
      "  File \"/opt/ml/code/run_qlora.py\", line 198, in main\u001b[0m\n",
      "\u001b[34mtraining_function(script_args, training_args)\n",
      "  File \"/opt/ml/code/run_qlora.py\", line 99, in training_function\u001b[0m\n",
      "\u001b[34mmodel = AutoModelForCausalLM.from_pretrained(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py\", line 566, in from_pretrained\u001b[0m\n",
      "\u001b[34mreturn model_class.from_pretrained(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py\", line 2786, in from_pretrained\u001b[0m\n",
      "\u001b[34mloading_attr_dict = quantization_config.get_loading_attributes()\u001b[0m\n",
      "\u001b[34mAttributeError: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:24,183 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:24,183 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 1 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:24,184 sagemaker-training-toolkit ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:24,184 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"AttributeError: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'\"\u001b[0m\n",
      "\u001b[34mCommand \"/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 3 --gradient_checkpointing True --hf_token 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 --learning_rate 0.0002 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters True --model_id TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ --num_train_epochs 2 --output_dir /tmp/run --per_device_train_batch_size 3 --save_strategy epoch --tf32 True --use_flash_attn True --warmup_ratio 0.03\"\u001b[0m\n",
      "\u001b[34m2024-01-03 15:41:24,184 sagemaker-training-toolkit ERROR    Encountered exit_code 1\u001b[0m\n",
      "\n",
      "2024-01-03 15:41:41 Uploading - Uploading generated training model\n",
      "2024-01-03 15:41:41 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job huggingface-qlora-TheBloke-OpenHermes-2-2024-01-03-15-34-32-417: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"AttributeError: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'\"\nCommand \"/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 3 --gradient_checkpointing True --hf_token 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 --learning_rate 0.0002 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters True --model_id TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ --num_train_epochs 2 --output_dir /tmp/run --per_device_train_batch_size 3 --save_strategy epoch --tf32 True --use_flash_attn True --warmup_ratio 0.03\", exit code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m: training_input_path}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# starting the train job with our uploaded datasets as input\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m huggingface_estimator\u001b[38;5;241m.\u001b[39mfit(data, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/workflow/pipeline_context.py:311\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/estimator.py:1322\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job\u001b[38;5;241m.\u001b[39mwait(logs\u001b[38;5;241m=\u001b[39mlogs)\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/estimator.py:2605\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2603\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mlogs_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, log_type\u001b[38;5;241m=\u001b[39mlogs)\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/session.py:4973\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   4952\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4953\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   4954\u001b[0m \n\u001b[1;32m   4955\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4971\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   4972\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4973\u001b[0m     _logs_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mboto_session, job_name, wait, poll, log_type, timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/session.py:6897\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(boto_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   6894\u001b[0m             last_profiler_rule_statuses \u001b[38;5;241m=\u001b[39m profiler_rule_statuses\n\u001b[1;32m   6896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 6897\u001b[0m     _check_job_status(job_name, description, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainingJobStatus\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   6899\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/session.py:6950\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   6944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   6945\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   6946\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6947\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6948\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6949\u001b[0m     )\n\u001b[0;32m-> 6950\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   6951\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   6952\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   6953\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   6954\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job huggingface-qlora-TheBloke-OpenHermes-2-2024-01-03-15-34-32-417: Failed. Reason: AlgorithmError: ExecuteUserScriptError:\nExitCode 1\nErrorMessage \"AttributeError: 'BitsAndBytesConfig' object has no attribute 'get_loading_attributes'\"\nCommand \"/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 3 --gradient_checkpointing True --hf_token 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 --learning_rate 0.0002 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters True --model_id TheBloke/OpenHermes-2.5-Mistral-7B-GPTQ --num_train_epochs 2 --output_dir /tmp/run --per_device_train_batch_size 3 --save_strategy epoch --tf32 True --use_flash_attn True --warmup_ratio 0.03\", exit code: 1"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_input_path}\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9cb916-6469-4746-b97b-6c2ba4e96922",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7a185fae-6b17-45bd-96aa-73e005c40e68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py39\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: gpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"1.1.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7b3444f4-9c5d-45c6-9cb6-a01b7fa21c97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e457d6f3-2023-43c5-81ac-6b294aef5182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0863cbb-9c81-429e-bf67-3a42eb21d49d",
   "metadata": {},
   "source": [
    "#### Download model to local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f77dc39d-8448-4486-b99f-cf004d2c3238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize a boto3 S3 client\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "337a6f95-b072-4e9a-863b-83347468e93a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "21a651b9-ed45-4081-ab50-a3ff28fba8e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_path = model_s3_path.split(bucket_name + '/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "442df457-92f1-4714-80c5-5c63a8af3a61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/added_tokens.json to ./OpenHermes_ApricotTangerineScallop/added_tokens.json\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/config.json to ./OpenHermes_ApricotTangerineScallop/config.json\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/generation_config.json to ./OpenHermes_ApricotTangerineScallop/generation_config.json\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/model-00001-of-00008.safetensors to ./OpenHermes_ApricotTangerineScallop/model-00001-of-00008.safetensors\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/model-00002-of-00008.safetensors to ./OpenHermes_ApricotTangerineScallop/model-00002-of-00008.safetensors\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/model-00003-of-00008.safetensors to ./OpenHermes_ApricotTangerineScallop/model-00003-of-00008.safetensors\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/model-00004-of-00008.safetensors to ./OpenHermes_ApricotTangerineScallop/model-00004-of-00008.safetensors\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/model-00005-of-00008.safetensors to ./OpenHermes_ApricotTangerineScallop/model-00005-of-00008.safetensors\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/model-00006-of-00008.safetensors to ./OpenHermes_ApricotTangerineScallop/model-00006-of-00008.safetensors\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/model-00007-of-00008.safetensors to ./OpenHermes_ApricotTangerineScallop/model-00007-of-00008.safetensors\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/model-00008-of-00008.safetensors to ./OpenHermes_ApricotTangerineScallop/model-00008-of-00008.safetensors\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/model.safetensors.index.json to ./OpenHermes_ApricotTangerineScallop/model.safetensors.index.json\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/special_tokens_map.json to ./OpenHermes_ApricotTangerineScallop/special_tokens_map.json\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/tokenizer.json to ./OpenHermes_ApricotTangerineScallop/tokenizer.json\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/tokenizer.model to ./OpenHermes_ApricotTangerineScallop/tokenizer.model\n",
      "Downloaded huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/tokenizer_config.json to ./OpenHermes_ApricotTangerineScallop/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize a boto3 S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# S3 bucket and folder details\n",
    "bucket_name = 'sagemaker-ap-south-1-005418323977'\n",
    "\n",
    "# Local directory to save files\n",
    "local_folder = f'./OpenHermes_{finetune_id}/'\n",
    "\n",
    "# List objects within the specified S3 folder\n",
    "objects = s3.list_objects_v2(Bucket=bucket_name, Prefix=s3_path)\n",
    "\n",
    "# Download each file in the folder\n",
    "for obj in objects.get('Contents', []):\n",
    "    s3_file_path = obj['Key']\n",
    "    local_file_path = os.path.join(local_folder, s3_file_path[len(s3_path):])\n",
    "    os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "    s3.download_file(bucket_name, s3_file_path, local_file_path)\n",
    "    print(f'Downloaded {s3_file_path} to {local_file_path}')\n",
    "# Remember to replace 'your-bucket-name', 'your-folder-name/', and 'path/to/local/folder/' with your actual bucket name, S3 folder, and local folder path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d519eb6a-4bee-4f85-b242-161763463192",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-qlora-teknium-OpenHermes-2--2024-01-03-05-28-14-355/output/model/tokenizer_config.json'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "12ec3393-ee03-4dde-ab5e-0a151c4bb255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3.download_file(bucket_name, s3_file_path, local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0987420a-1b54-4a7f-9e9c-a6d47040dc6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "dadea77f-af0e-4af4-86b1-fe89bdab5460",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "from huggingface_hub import HfFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c4404f88-4c84-44bf-9a97-3bca77d85a6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.35.2'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "88278256-a9cd-4662-84db-439006947434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3aa33-dc5d-414b-92c6-fc9dd5b9237b",
   "metadata": {},
   "source": [
    "### Upload to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ee7ff3fb-d610-4cbb-9328-ab06b8ed2c49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152e20e986184df38c20a807858b0480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained('./OpenHermes_ApricotTangerineScallop/', local_files_only = True, torch_dtype = torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b8bcbba1-e789-4e44-8d4b-e03010095a34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c554c2d025645f98b6326ac19271bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d61f5c33ef43f786067e6a5b119d9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff5de17d6fc47af94d29a70f9ddbf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d40060497f87447eb361f30a5845724b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/WintWealth/OpenHermes_ApricotTangerineScallop/commit/28f3185ca9075fe7df02c176a4a01e3d7ab9ee9f', commit_message='Upload model', commit_description='', oid='28f3185ca9075fe7df02c176a4a01e3d7ab9ee9f', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('WintWealth/OpenHermes_ApricotTangerineScallop', token = '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', private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2c74d876-e58a-465f-abcd-c3a0dd4e8695",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./OpenHermes_ApricotTangerineScallop/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ea3f675c-1b43-4d86-a490-3927109d45aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/WintWealth/OpenHermes_ApricotTangerineScallop/commit/771e867598e8e5cb3d30ce2456d8684cd24390dd', commit_message='Upload tokenizer', commit_description='', oid='771e867598e8e5cb3d30ce2456d8684cd24390dd', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub('WintWealth/OpenHermes_ApricotTangerineScallop', token = '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', private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a11fb8-3e67-4687-9583-23b9383c4fe3",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4cac6727-ce20-47d8-814a-03f6a92d48e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ed934755-bf78-48db-a105-7650556ea5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/username/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# s3 path where the model will be uploaded\n",
    "# if you try to deploy the model to a different time add the s3 path here\n",
    "# model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(3072), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(4096), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data={'S3DataSource':{'S3Uri': model_s3_path,'S3DataType': 'S3Prefix','CompressionType': 'None'}},\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "85bad177-3c5d-443c-8a96-c01483c77b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-tgi-inference-2024-01-03-15-10-48-269\n",
      "INFO:sagemaker:Creating endpoint-config with name huggingface-pytorch-tgi-inference-2024-01-03-15-10-49-022\n",
      "INFO:sagemaker:Creating endpoint with name huggingface-pytorch-tgi-inference-2024-01-03-15-10-49-022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "\n",
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b0b5c259-76aa-4b58-bcb7-092213d613b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name = llm.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bc4dd5da-517c-4f6c-b4e8-ab416b9907e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-tgi-inference-2024-01-03-15-10-49-022'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "31d280be-9338-4ca3-90e3-a681b3038830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_article_for_prompt(article_text):\n",
    "    truncated_content = truncate_text_to_token_limit(text=article_text, encoder=tokenizer, token_limit=ARTICLE_TOKEN_LIMIT)\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"{truncated_content}\\n\"}]\n",
    "    context_prompt = tokenizer.decode(tokenizer.apply_chat_template(messages, add_generation_prompt=True))\n",
    "    prompt = re.sub(r'\\n+','\\n',context_prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa2f11-5610-4328-b4e2-6a3bfd871347",
   "metadata": {},
   "source": [
    "#### Testing for a few articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a831fe67-6f4e-4401-9cf7-60675244c074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/username/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/username/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/username/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/username/anaconda3/envs/recoenv/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    }
   ],
   "source": [
    "parent_folder = '/Users/username/Desktop/ML/Recommendations/arcane/'\n",
    "from hydra import compose, initialize\n",
    "import os\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('../../../conf/application.run.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "envs_element = root.find('./configuration/envs')\n",
    "for variable in envs_element.findall('env'):\n",
    "    name = variable.get('name')\n",
    "    value = variable.get('value')\n",
    "    os.environ[name] = value\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/username/Desktop/ML/Recommendations/arcane/')\n",
    "\n",
    "from src._utils import load_bertopic_model_from_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "69d9220b-4ccf-4593-a333-58ef589b3041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.articles.ArticleService import ArticleService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "71442e8b-9f4b-4501-9f7f-8a1813c2ffe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Chelsea vs Real Madrid: Live streaming, where to watch Champions League matchChelsea will play Real Madrid in a crucial Champions League quarterfinal second-leg on April 18 at Stamford Bridge. The first-leg in Madrid saw the Blues suffer a 2-0 defeat, as Karim Benzema and Marco Asensio scored to give the defending champions a comfortable win at Santiago Bernabeu.For Chelsea, the return leg marks a pivotal moment in their season, with a Champions League exit ending their hopes of silverware. However, the team under Frank Lampard's management has struggled lately, with three consecutive defeats, making their task even more daunting.Fortunately, fans worldwide will have the chance to stream the game online. The Sporting News has provided all the necessary details on how to do so.Chelsea vs Real Madrid Live StreamChampions League streaming coverage will be offered by beIN Sports in Singapore, Hong Kong, and Malaysia, while JioTV and Sony LIV will be the streaming options available in India.These two teams have both won the Champions League in the last two seasons, and they have defeated each other on their path to becoming European champions.Benzema has played a pivotal role in their recent encounters, notably scoring a magnificent hat-trick against Chelsea at Stamford Bridge in 2022.Chelsea vs Real Madrid timing, channel Date Kickoff time StreamingIndia Wednesday, Apr. 19 00:30 IST JioTV, Sony LIVUK Tue, Apr. 18 20:00 BST BT Sport site/appUSA Tue, Apr. 18 15:00 ET Fubo, Paramount+, ViXFAQsQ1: When is the Chelsea vs Real Madrid match scheduled?A: The Chelsea vs Real Madrid match is scheduled for today, April 18, 2023.Q2: What time will the match begin?A: The match will begin at 8:00 PM GMT.\""
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art = ArticleService.get_article_json_from_s3_and_api('651e1c48a662d76276b88eee')\n",
    "\n",
    "art['title'] + art['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cf33b9a6-20e4-468e-a220-23e784d9a508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import boto3\n",
    "# from botocore.config import Config\n",
    "\n",
    "# # Configure the max_pool_connections\n",
    "# my_config = Config(\n",
    "#     region_name = 'ap-south-1',\n",
    "#     retries = {\n",
    "#         'max_attempts': 10,\n",
    "#         'mode': 'standard'\n",
    "#     },\n",
    "#     max_pool_connections = 40  # Increase the pool size\n",
    "# )\n",
    "\n",
    "# # Create a SageMaker Runtime client with the custom configuration\n",
    "# sess1 = boto3.session.Session()\n",
    "# smr1 = sess1.client(\"sagemaker-runtime\", config=my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8fe49eea-05f0-4a19-a66d-586abb6754c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smr = sess.boto_session.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ff32630e-f97c-45a7-a2b8-ace8fa765707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.8,\n",
    "    \"max_new_tokens\": 1024,\n",
    "    \"repetition_penalty\": 1.03,\n",
    "    \"stop\": [\"###\", \"</s>\", tokenizer.eos_token],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a06151fc-7aa9-4c4b-a4b3-a6133e4d9925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5718c160-92f4-44e0-9744-5a9f251f1d4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "art = ArticleService.get_article_json_from_s3_and_api('651e1c48a662d76276b88eee')\n",
    "content = art['title'] + art['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a98efc3e-a332-405a-a957-10ec95ce2a40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Chelsea vs Real Madrid: Live streaming, where to watch Champions League matchChelsea will play Real Madrid in a crucial Champions League quarterfinal second-leg on April 18 at Stamford Bridge. The first-leg in Madrid saw the Blues suffer a 2-0 defeat, as Karim Benzema and Marco Asensio scored to give the defending champions a comfortable win at Santiago Bernabeu.For Chelsea, the return leg marks a pivotal moment in their season, with a Champions League exit ending their hopes of silverware. However, the team under Frank Lampard's management has struggled lately, with three consecutive defeats, making their task even more daunting.Fortunately, fans worldwide will have the chance to stream the game online. The Sporting News has provided all the necessary details on how to do so.Chelsea vs Real Madrid Live StreamChampions League streaming coverage will be offered by beIN Sports in Singapore, Hong Kong, and Malaysia, while JioTV and Sony LIV will be the streaming options available in India.These two teams have both won the Champions League in the last two seasons, and they have defeated each other on their path to becoming European champions.Benzema has played a pivotal role in their recent encounters, notably scoring a magnificent hat-trick against Chelsea at Stamford Bridge in 2022.Chelsea vs Real Madrid timing, channel Date Kickoff time StreamingIndia Wednesday, Apr. 19 00:30 IST JioTV, Sony LIVUK Tue, Apr. 18 20:00 BST BT Sport site/appUSA Tue, Apr. 18 15:00 ET Fubo, Paramount+, ViXFAQsQ1: When is the Chelsea vs Real Madrid match scheduled?A: The Chelsea vs Real Madrid match is scheduled for today, April 18, 2023.Q2: What time will the match begin?A: The match will begin at 8:00 PM GMT.\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b21e7476-4f65-4891-b5de-88b4e58c403d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = {\"inputs\": format_article_for_prompt(content), \"parameters\": parameters, \"stream\": False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0f4bf468-a28d-4d75-afd5-d7847bb534ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp = smr.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=json.dumps(request),\n",
    "    ContentType=\"application/json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a3f6aa10-92e3-4c31-b393-29807fa29c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k = resp['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c04c172d-0cb9-48ac-9623-67fd68445a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': '**Match Preview**: Chelsea will face Real Madrid in a crucial Champions League quarterfinal second-leg on April 18 at Stamford Bridge.<br>**Previous Outcome**: The first leg in Madrid saw Real Madrid win 2-0, with Karim Benzema and Marco Asensio scoring.<br>**Streaming Availability**: Viewers can stream the match online in various regions via various platforms.',\n",
       " 'summary_critique': \"The summary is accurate, comprehensive, and follows the _summary_markdown_format_ correctly. However, the key point about Chelsea's recent performance and the significance of the match to the teams has been missed.\",\n",
       " 'improved_summary': \"**Match Preview**: The second-leg of the Champions League quarterfinal between Chelsea and Real Madrid is scheduled for April 18 at Stamford Bridge.<br>**Past Outcome**: Real Madrid won the first leg in Madrid by a comfortable margin, scoring 2-0.<br>**Team Situation**: Chelsea's recent performance, having faced three consecutive losses, adds weight to the importance of this match.\",\n",
       " 'top_categories': 'Football;Champions League;Chelsea;Real Madrid;Live Streaming',\n",
       " 'business_or_financial_article': False,\n",
       " 'indian_or_international': 'international',\n",
       " 'relevant_for_indians': True,\n",
       " 'article_validity_duration_evaluation': \"The article talks about an upcoming football match and its streaming availability. It's only relevant for those who are interested in watching the match live.\",\n",
       " 'article_validity_duration': 1,\n",
       " 'popularity_evaluation': 'reader_interest_score: 0.7, as football is a popular sport globally.\\nheadline_effectiveness: 0.6, it is clear and mentions the main event.\\nevent_novelty: 0.5, the game is an important football event.\\nemotional_impact: 0.3, football fans may feel anticipation or excitement.',\n",
       " 'popularity_evaluation_critique': 'The reader_interest_score seems appropriate given the global popularity of football. The headline is effective but could be more engaging. Event_novelty could be a bit low as football matches occur frequently. Emotional_impact could be higher for dedicated football enthusiasts.',\n",
       " 'final_reader_interest_score': 0.7,\n",
       " 'final_headline_effectiveness_score': 0.6,\n",
       " 'final_event_novelty_score': 0.4,\n",
       " 'final_emotional_impact_score': 0.4,\n",
       " 'improved_headline': 'Chelsea vs Real Madrid: A Cliffhanger Second Leg in the Champions League',\n",
       " 'article_type': 'fact',\n",
       " 'article_sentiment': 'na'}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json.loads(json.loads(k)[0]['generated_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "77780bcc-18c0-4d98-947a-fc8f8f8639a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"summary\": \"**Match Preview**: Chelsea will face Real Madrid in a crucial Champions League quarterfinal second-leg on April 18 at Stamford Bridge.<br>**Previous Outcome**: The first leg in Madrid saw Real Madrid win 2-0, with Karim Benzema and Marco Asensio scoring.<br>**Streaming Availability**: Viewers can stream the match online in various regions via various platforms.\", \"summary_critique\": \"The summary is accurate, comprehensive, and follows the _summary_markdown_format_ correctly. However, the key point about Chelsea\\'s recent performance and the significance of the match to the teams has been missed.\", \"improved_summary\": \"**Match Preview**: The second-leg of the Champions League quarterfinal between Chelsea and Real Madrid is scheduled for April 18 at Stamford Bridge.<br>**Past Outcome**: Real Madrid won the first leg in Madrid by a comfortable margin, scoring 2-0.<br>**Team Situation**: Chelsea\\'s recent performance, having faced three consecutive losses, adds weight to the importance of this match.\", \"top_categories\": \"Football;Champions League;Chelsea;Real Madrid;Live Streaming\", \"business_or_financial_article\": false, \"indian_or_international\": \"international\", \"relevant_for_indians\": true, \"article_validity_duration_evaluation\": \"The article talks about an upcoming football match and its streaming availability. It\\'s only relevant for those who are interested in watching the match live.\", \"article_validity_duration\": 1, \"popularity_evaluation\": \"reader_interest_score: 0.7, as football is a popular sport globally.\\\\nheadline_effectiveness: 0.6, it is clear and mentions the main event.\\\\nevent_novelty: 0.5, the game is an important football event.\\\\nemotional_impact: 0.3, football fans may feel anticipation or excitement.\", \"popularity_evaluation_critique\": \"The reader_interest_score seems appropriate given the global popularity of football. The headline is effective but could be more engaging. Event_novelty could be a bit low as football matches occur frequently. Emotional_impact could be higher for dedicated football enthusiasts.\", \"final_reader_interest_score\": 0.7, \"final_headline_effectiveness_score\": 0.6, \"final_event_novelty_score\": 0.4, \"final_emotional_impact_score\": 0.4, \"improved_headline\": \"Chelsea vs Real Madrid: A Cliffhanger Second Leg in the Champions League\", \"article_type\": \"fact\", \"article_sentiment\": \"na\"}'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(json.loads(k)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "1f3ef1de-e90e-4e25-aaf2-09770e0b8d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WatermelonSapphireZipline'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e6cefe54-bec3-4273-bb76-cfb902ea8b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-tgi-inference-2023-12-03-10-21-59-120'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f689c553-5c3e-42dd-9322-b7c0297cb259",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_articles = ['651de546a662d76276b80931',\n",
    " '651e2409a662d76276b8a181',\n",
    " '651dfe88a662d76276b84838',\n",
    " '651e0d14a662d76276b86b88',\n",
    " '651e2286a662d76276b89de1',\n",
    " '656719c9207bb033b910ea11',\n",
    " '651df8e1a662d76276b83a66',\n",
    " '651dca8aa662d76276b7c1f8',\n",
    " '651e0f43a662d76276b870aa',\n",
    " '6566a94f39bfc8784efe5b7c',\n",
    " '651e1c48a662d76276b88eee',\n",
    " '651dc511a662d76276b7b33e',\n",
    " '6555c17a4b13023f9348cfc5',\n",
    " '651de912a662d76276b81322',\n",
    " '6555c1f84b13023f9348d104',\n",
    " '65683309207bb033b910ed9e',\n",
    " '656557db1fc4586a032ad63e',\n",
    " '651e093aa662d76276b862ab',\n",
    " '651dd514a662d76276b7df16',\n",
    " '651e14c8a662d76276b87d8a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f274b98d-1bf5-4292-9376-4152f6545ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_endpoint_name = 'OpenHermes-Finetune-WatermelonSapphireZipline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1224f5f1-4591-4c0e-a55a-1bda6fd53c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y, z = get_attributes_from_llm('6555c17a4b13023f9348cfc5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8e97eb40-091e-4ecd-8460-e75a9a846142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_attributes_from_llm(article_id):\n",
    "    try:\n",
    "        article = ArticleService.get_article_json_from_s3_and_api(article_id)\n",
    "    except:\n",
    "        return article_id, ''\n",
    "    full_content = article['title'] + article['cleaned_text']\n",
    "    full_input = format_article_for_prompt(full_content)\n",
    "    request = {\"inputs\": full_input, \"parameters\": parameters, \"stream\": False}\n",
    "    try:\n",
    "        resp = smr1.invoke_endpoint(\n",
    "            EndpointName=new_endpoint_name,\n",
    "            Body=json.dumps(request),\n",
    "            ContentType=\"application/json\",\n",
    "            )\n",
    "        k = resp['Body'].read()\n",
    "        try:\n",
    "            attributes = json.loads(json.loads(k)[0]['generated_text'])\n",
    "            return article_id, attributes\n",
    "        except:\n",
    "            return article_id, ''\n",
    "    except:\n",
    "        print(article_id, 'some error')\n",
    "        article_id, ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e072751-bb19-4459-9aa9-93752e5adaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Binary.createFromBase64('W3siZ2VuZXJhdGVkX3RleHQiOiJ7XCJhbmFseXNpc19vZl9hcnRpY2xlX3NlbnRpbWVudFwiOiBcIlRoZSBzZW50aW1lbnQgaXMg…', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f79969ab-1e77-4ef6-b26d-36197d28f8aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "fd696e4f-184d-4cc2-a812-8d16b93546ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "111506c3-2dfd-4769-8d94-ebef59588ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 20 IDs in 93.18964195251465 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "responses = {}\n",
    "valid_attributes = {}\n",
    "invalid_response_ids = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    futures = [executor.submit(get_attributes_from_llm, art_id) for art_id in test_articles]\n",
    "    for future in as_completed(futures):\n",
    "        art_id, response = future.result()\n",
    "        responses[art_id] = response\n",
    "            # invalid_response_ids.append(art_id)\n",
    "\n",
    "print(f'Processed {len(test_articles)} IDs in {time.time() - start_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ae5d2-3078-484e-8eb8-33e029c88c4f",
   "metadata": {},
   "source": [
    "### Running the results for all the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "9cb5d2bb-6b6c-4aa5-99c6-c9781ecc32e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sql.PostgresDatabaseOperation import PostgresDatabaseOperation\n",
    "\n",
    "with PostgresDatabaseOperation() as cursor:\n",
    "    sql = 'SELECT DISTINCT article_id FROM embeddings'\n",
    "    cursor.execute(sql)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "all_article_ids = [x[0] for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "1506388d-53b2-4739-a37e-32937fb21e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118008"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_article_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4aa14d46-b3d8-4f31-b0e2-129384d46fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "eac94904-9cdc-468c-92cd-bcdd714f5e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_chunks = (len(all_article_ids)//chunk_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "cdaf58ff-9a8e-4c7f-ba86-4d242376e8c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(columns = ['article_id', 'attributes']).to_csv(f'all_article_attributes_{finetune_id}.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ce1a5d27-e3c2-4850-9f7d-5554d53cd289",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1e46f14c-a045-4848-b861-938868117c92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('OpenHermes_WatermelonSapphireZipline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "45761c4d-7abe-44bd-8581-a9797d075a45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WatermelonSapphireZipline'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "72fa6031-3ce1-455c-98d7-bc56e9f671c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "f785fa12-1fcb-4611-84c0-f6a93d168606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "7dc3da97-5b07-4eb2-88b7-49f94ad8ecec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'652fd0311e5cc42b1b13a398'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(all_article_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "79663c58-f918-4eda-993e-24c3a68b97e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('652fd0311e5cc42b1b13a398', '')"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attributes_from_llm('652fd0311e5cc42b1b13a398')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60dce05-664c-4a75-be35-5c3bfb22c753",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(30, num_chunks):\n",
    "    cur_article_ids = all_article_ids[i * chunk_size: (i+1)*chunk_size]\n",
    "    start_time = time.time()\n",
    "    completed = 0\n",
    "    with ThreadPoolExecutor(max_workers=40) as executor:\n",
    "        futures = [executor.submit(get_attributes_from_llm, art_id) for art_id in cur_article_ids]\n",
    "        for future in as_completed(futures):\n",
    "            if future.result():\n",
    "                art_id, response = future.result()\n",
    "                if response:\n",
    "                    pd.DataFrame([(art_id, json.dumps(response))]).to_csv('all_article_attributes_WatermelonSapphireZipline.csv',mode='a',index=False,header = False)\n",
    "                    completed += 1\n",
    "            # invalid_response_ids.append(art_id)\n",
    "    print(f'Processed {completed} IDs in {time.time() - start_time} seconds in chunk number {i} at {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9692f27c-ec9c-487a-b3d2-71c48293d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes_for_article_ids(article_ids, max_retries=0, retry_count=0):\n",
    "    start_time = time.time()\n",
    "    responses = {}\n",
    "    valid_attributes = {}\n",
    "    invalid_response_ids = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = [executor.submit(get_attributes_from_llm, art_id) for art_id in article_ids]\n",
    "        print(f'completed in {time.time() - start_time} seconds')\n",
    "        for future in as_completed(futures):\n",
    "            art_id, response = future.result()\n",
    "            if response is None:  # Timeout or other errors\n",
    "                invalid_response_ids.append(art_id)\n",
    "                continue\n",
    "\n",
    "            responses[art_id] = response\n",
    "            try:\n",
    "                valid_attributes[art_id] = json.loads(response['llm_attributes'])\n",
    "            except:\n",
    "                return response\n",
    "                # invalid_response_ids.append(art_id)\n",
    "\n",
    "    print(f'Attempt {retry_count + 1}: Processed {len(article_ids)} IDs in {time.time() - start_time} seconds')\n",
    "\n",
    "    if invalid_response_ids and retry_count < max_retries:\n",
    "        print(f'Retrying for {len(invalid_response_ids)} invalid IDs')\n",
    "        valid_attributes_retry = get_attributes_for_article_ids(invalid_response_ids, max_retries, retry_count + 1)\n",
    "        valid_attributes.update(valid_attributes_retry)\n",
    "\n",
    "    return valid_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6c9c5b46-d656-4174-a2e6-aaae0bf2ae89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "txt = '''\n",
    "The article highlights the challenges faced by the Indian stock market in light of global economic issues. Despite India's strong economy and positive corporate earnings growth, foreign institutional investors (FIIs) are selling their shares due to the global economic deceleration. The contraction in the global economy, led by Europe's recession and China's decelerating economy, is affecting the Indian market. The recent fall in the stock market is attributed to global factors, not intrinsic structural issues within India. The article concludes by stating that despite the challenges, the Indian stock market has maintained a high valuation, which is leading to consolidation in prices and valuations\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138da96c-85c5-4475-b1d0-dc8cb99379c4",
   "metadata": {},
   "source": [
    "### Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71437896-8e59-44ae-9d73-7b3e9b5644cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoenv",
   "language": "python",
   "name": "recoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
