{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d96b537-8f2e-46b1-a05c-8258729fdcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_folder = '/Users/ravi.tej/Desktop/ML/Recommendations/hubble/'\n",
    "from hydra import compose, initialize\n",
    "import os\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('../../conf/application.run.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "envs_element = root.find('./configuration/envs')\n",
    "for variable in envs_element.findall('env'):\n",
    "    name = variable.get('name')\n",
    "    value = variable.get('value')\n",
    "    os.environ[name] = value\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/ravi.tej/Desktop/ML/Recommendations/hubble/')\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['PATH'] = '/Users/ravi.tej/anaconda3/envs/bertopicenv/bin:/Users/ravi.tej/anaconda3/condabin:/usr/bin:/bin:/usr/sbin:/sbin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175b96dc-2e0b-43cc-9c52-7e668956e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ravi.tej/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from src.RAGTraining.FinetuneLLM import FinetuneLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce2c04ec-a153-4270-a1cf-9717aec7304e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ravi.tej/Desktop/ML/Recommendations/hubble/notebooks/RAG-Mar-5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69516a00-5c38-44bb-9cbc-02265f56ac5b",
   "metadata": {},
   "source": [
    "### Note: \n",
    "The below one is old one and was overfitting - don't use these hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b0ffda9-8b18-4b91-9c6c-7a546f3a3a28",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-teknium-OpenHermes-2--2024-03-06-13-05-16-365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-06 13:05:18 Starting - Starting the training job...\n",
      "2024-03-06 13:05:20 Pending - Training job waiting for capacity......\n",
      "2024-03-06 13:06:30 Pending - Preparing the instances for training......\n",
      "2024-03-06 13:07:51 Downloading - Downloading the training image.....................\n",
      "2024-03-06 13:11:22 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-03-06 13:11:51,290 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-03-06 13:11:51,309 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-06 13:11:51,318 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-03-06 13:11:51,319 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-03-06 13:11:52,631 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.35.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.5/123.5 kB 7.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.5.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting optimum==1.14.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl.metadata (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.23.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.3 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.11.1)\u001b[0m\n",
      "\u001b[34mCollecting datasets==2.15.0 (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting auto-gptq (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (0.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (1.24.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2023.12.25)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting coloredlogs (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (14.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (2.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0->-r requirements.txt (line 9)) (2023.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (3.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes->-r requirements.txt (line 5)) (1.11.1)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of auto-gptq to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting auto-gptq (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from auto-gptq->-r requirements.txt (line 10)) (0.1.99)\u001b[0m\n",
      "\u001b[34mCollecting rouge (from auto-gptq->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting gekko (from auto-gptq->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading gekko-1.0.7-py3-none-any.whl.metadata (3.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (23.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.14.0->-r requirements.txt (line 3)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq->-r requirements.txt (line 10)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (2.1.3)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 89.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 16.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl (398 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 398.9/398.9 kB 48.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.1/258.1 kB 40.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 521.2/521.2 kB 55.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 MB 30.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 98.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 17.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 112.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 8.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading gekko-1.0.7-py3-none-any.whl (13.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.1/13.1 MB 91.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 16.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: safetensors, rouge, humanfriendly, gekko, coloredlogs, bitsandbytes, tokenizers, accelerate, transformers, datasets, peft, optimum, auto-gptq\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: datasets\u001b[0m\n",
      "\u001b[34mFound existing installation: datasets 2.16.1\u001b[0m\n",
      "\u001b[34mUninstalling datasets-2.16.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled datasets-2.16.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.23.0 auto-gptq-0.6.0 bitsandbytes-0.42.0 coloredlogs-15.0.1 datasets-2.15.0 gekko-1.0.7 humanfriendly-10.0 optimum-1.14.0 peft-0.5.0 rouge-1.0.1 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.35.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-03-06 13:12:08,039 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-03-06 13:12:08,039 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-03-06 13:12:08,079 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-06 13:12:08,107 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-06 13:12:08,135 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-06 13:12:08,144 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"gradient_accumulation_steps\": 1,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"learning_rate\": \"1e-4\",\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"cosine_with_restarts\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"teknium/OpenHermes-2.5-Mistral-7B\",\n",
      "        \"num_train_epochs\": 2,\n",
      "        \"output_dir\": \"/tmp/run\",\n",
      "        \"per_device_train_batch_size\": 1,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"trust_remote_code\": true,\n",
      "        \"use_flash_attn\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-teknium-OpenHermes-2--2024-03-06-13-05-16-365\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-06-13-05-16-365/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_qlora\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_qlora.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":1,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":\"1e-4\",\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":1,\"save_strategy\":\"epoch\",\"tf32\":true,\"trust_remote_code\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_qlora.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_qlora\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-06-13-05-16-365/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":1,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":\"1e-4\",\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":1,\"save_strategy\":\"epoch\",\"tf32\":true,\"trust_remote_code\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-teknium-OpenHermes-2--2024-03-06-13-05-16-365\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-06-13-05-16-365/source/sourcedir.tar.gz\",\"module_name\":\"run_qlora\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_qlora.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training\",\"--gradient_accumulation_steps\",\"1\",\"--gradient_checkpointing\",\"True\",\"--hf_token\",\"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\",\"--learning_rate\",\"1e-4\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"cosine_with_restarts\",\"--max_grad_norm\",\"0.3\",\"--merge_adapters\",\"True\",\"--model_id\",\"teknium/OpenHermes-2.5-Mistral-7B\",\"--num_train_epochs\",\"2\",\"--output_dir\",\"/tmp/run\",\"--per_device_train_batch_size\",\"1\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--trust_remote_code\",\"True\",\"--use_flash_attn\",\"True\",\"--warmup_ratio\",\"0.03\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=1\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=1e-4\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=cosine_with_restarts\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=teknium/OpenHermes-2.5-Mistral-7B\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=2\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/run\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=1\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_TRUST_REMOTE_CODE=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FLASH_ATTN=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 1 --gradient_checkpointing True --hf_token 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 --learning_rate 1e-4 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters True --model_id teknium/OpenHermes-2.5-Mistral-7B --num_train_epochs 2 --output_dir /tmp/run --per_device_train_batch_size 1 --save_strategy epoch --tf32 True --trust_remote_code True --use_flash_attn True --warmup_ratio 0.03\u001b[0m\n",
      "\u001b[34m2024-03-06 13:12:08,173 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flash-attn in /opt/conda/lib/python3.10/site-packages (0.2.8)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.5.6.tar.gz (2.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 58.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.5.6-cp310-cp310-linux_x86_64.whl size=121379983 sha256=4148bf354d8fa6e8afea1bc4961830c2a189271dc74ddd4b39049374a372b1f1\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/a8/1c/88/b959d6818b98a46d61ba231683abb7523b89ac1a7ed1e0c206\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mSuccessfully installed flash-attn-2.5.6\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mLogging into the Hugging Face Hub with token hf_NjVkEqg...\u001b[0m\n",
      "\u001b[34mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\u001b[0m\n",
      "\u001b[34mToken is valid (permission: write).\u001b[0m\n",
      "\u001b[34mYour token has been saved to /root/.cache/huggingface/token\u001b[0m\n",
      "\u001b[34mLogin successful\u001b[0m\n",
      "\u001b[34mUsing `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\u001b[0m\n",
      "\u001b[34mUsing `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/624 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 624/624 [00:00<00:00, 6.58MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 166MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 52.4M/9.94G [00:00<00:20, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 115M/9.94G [00:00<00:18, 542MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 178M/9.94G [00:00<00:19, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 241M/9.94G [00:00<00:19, 504MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 304M/9.94G [00:00<00:18, 529MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▎         | 367M/9.94G [00:00<00:18, 521MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▍         | 419M/9.94G [00:00<00:18, 511MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▍         | 472M/9.94G [00:00<00:18, 508MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▌         | 524M/9.94G [00:01<00:18, 512MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 587M/9.94G [00:01<00:17, 527MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 650M/9.94G [00:01<00:17, 543MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 713M/9.94G [00:01<00:16, 545MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 776M/9.94G [00:01<00:16, 556MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 839M/9.94G [00:01<00:16, 560MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 902M/9.94G [00:01<00:15, 570MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|▉         | 965M/9.94G [00:01<00:15, 573MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|█         | 1.03G/9.94G [00:01<00:16, 556MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█         | 1.09G/9.94G [00:02<00:15, 565MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.15G/9.94G [00:02<00:16, 529MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.22G/9.94G [00:02<00:16, 522MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.28G/9.94G [00:02<00:16, 537MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.34G/9.94G [00:02<00:16, 528MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 1.41G/9.94G [00:02<00:16, 519MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▍        | 1.46G/9.94G [00:02<00:17, 493MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▌        | 1.51G/9.94G [00:02<00:16, 501MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.57G/9.94G [00:02<00:16, 496MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▋        | 1.64G/9.94G [00:03<00:16, 496MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.70G/9.94G [00:03<00:16, 514MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.75G/9.94G [00:03<00:16, 511MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.81G/9.94G [00:03<00:15, 515MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.87G/9.94G [00:03<00:16, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.93G/9.94G [00:03<00:15, 510MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|█▉        | 1.98G/9.94G [00:03<00:15, 503MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.04G/9.94G [00:03<00:15, 500MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.11G/9.94G [00:04<00:15, 514MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.17G/9.94G [00:04<00:14, 529MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.23G/9.94G [00:04<00:15, 497MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.30G/9.94G [00:04<00:14, 510MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▎       | 2.36G/9.94G [00:04<00:14, 520MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▍       | 2.42G/9.94G [00:04<00:14, 536MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▍       | 2.49G/9.94G [00:04<00:14, 525MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.55G/9.94G [00:04<00:14, 518MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▋       | 2.61G/9.94G [00:05<00:14, 516MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.67G/9.94G [00:05<00:13, 524MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.74G/9.94G [00:05<00:13, 536MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.80G/9.94G [00:05<00:14, 505MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.86G/9.94G [00:05<00:13, 524MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.93G/9.94G [00:05<00:14, 496MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|██▉       | 2.98G/9.94G [00:05<00:14, 488MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|███       | 3.03G/9.94G [00:05<00:14, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 3.08G/9.94G [00:05<00:14, 488MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.15G/9.94G [00:06<00:13, 501MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.20G/9.94G [00:06<00:13, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.26G/9.94G [00:06<00:13, 514MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.31G/9.94G [00:06<00:13, 502MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▍      | 3.38G/9.94G [00:06<00:13, 500MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▍      | 3.44G/9.94G [00:06<00:12, 520MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▌      | 3.50G/9.94G [00:06<00:12, 531MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.57G/9.94G [00:06<00:12, 499MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▋      | 3.62G/9.94G [00:07<00:13, 484MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.67G/9.94G [00:07<00:13, 480MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.73G/9.94G [00:07<00:12, 502MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.79G/9.94G [00:07<00:12, 504MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▊      | 3.85G/9.94G [00:07<00:11, 525MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.91G/9.94G [00:07<00:11, 540MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|███▉      | 3.97G/9.94G [00:07<00:11, 532MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.04G/9.94G [00:07<00:11, 516MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.09G/9.94G [00:07<00:11, 511MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.14G/9.94G [00:08<00:11, 509MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.19G/9.94G [00:08<00:11, 504MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.26G/9.94G [00:08<00:10, 524MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.32G/9.94G [00:08<00:10, 540MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▍     | 4.38G/9.94G [00:08<00:10, 514MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▍     | 4.45G/9.94G [00:08<00:10, 531MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▌     | 4.51G/9.94G [00:08<00:09, 547MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.57G/9.94G [00:08<00:09, 538MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.63G/9.94G [00:08<00:10, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.70G/9.94G [00:09<00:09, 544MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.76G/9.94G [00:09<00:09, 536MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▊     | 4.82G/9.94G [00:09<00:09, 536MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▉     | 4.89G/9.94G [00:09<00:09, 549MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|████▉     | 4.95G/9.94G [00:09<00:09, 538MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|█████     | 5.01G/9.94G [00:09<00:09, 533MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.08G/9.94G [00:09<00:09, 514MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.13G/9.94G [00:09<00:10, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.19G/9.94G [00:10<00:09, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.24G/9.94G [00:10<00:14, 330MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.31G/9.94G [00:10<00:12, 381MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▍    | 5.37G/9.94G [00:10<00:10, 426MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▍    | 5.43G/9.94G [00:10<00:09, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▌    | 5.48G/9.94G [00:10<00:09, 474MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.54G/9.94G [00:10<00:09, 476MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▋    | 5.60G/9.94G [00:10<00:08, 492MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.66G/9.94G [00:11<00:08, 516MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.73G/9.94G [00:11<00:07, 534MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.79G/9.94G [00:11<00:07, 520MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.85G/9.94G [00:11<00:07, 532MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.91G/9.94G [00:11<00:07, 524MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|██████    | 5.98G/9.94G [00:11<00:07, 536MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.04G/9.94G [00:11<00:07, 547MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████▏   | 6.10G/9.94G [00:12<00:09, 423MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.16G/9.94G [00:12<00:12, 306MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.20G/9.94G [00:12<00:15, 245MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.23G/9.94G [00:12<00:16, 222MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.26G/9.94G [00:12<00:17, 212MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.29G/9.94G [00:13<00:19, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▎   | 6.32G/9.94G [00:13<00:19, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.34G/9.94G [00:13<00:19, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.36G/9.94G [00:13<00:18, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.39G/9.94G [00:13<00:19, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.41G/9.94G [00:13<00:19, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.44G/9.94G [00:13<00:18, 193MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.47G/9.94G [00:14<00:17, 201MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.49G/9.94G [00:14<00:17, 201MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.51G/9.94G [00:14<00:17, 199MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.54G/9.94G [00:14<00:17, 200MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.57G/9.94G [00:14<00:16, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▋   | 6.60G/9.94G [00:14<00:16, 202MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.62G/9.94G [00:14<00:17, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.65G/9.94G [00:15<00:16, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.68G/9.94G [00:15<00:15, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.70G/9.94G [00:15<00:15, 210MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.72G/9.94G [00:15<00:15, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.75G/9.94G [00:15<00:15, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.77G/9.94G [00:15<00:15, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.81G/9.94G [00:15<00:15, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▊   | 6.83G/9.94G [00:15<00:15, 202MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.86G/9.94G [00:16<00:15, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.88G/9.94G [00:16<00:15, 202MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.91G/9.94G [00:16<00:14, 206MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|██████▉   | 6.93G/9.94G [00:16<00:14, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 6.96G/9.94G [00:16<00:14, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 6.98G/9.94G [00:16<00:14, 201MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 7.00G/9.94G [00:16<00:14, 202MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.04G/9.94G [00:16<00:14, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.07G/9.94G [00:17<00:13, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████▏  | 7.09G/9.94G [00:17<00:13, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.12G/9.94G [00:17<00:13, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.15G/9.94G [00:17<00:13, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.17G/9.94G [00:17<00:13, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.20G/9.94G [00:17<00:13, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.22G/9.94G [00:17<00:13, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.25G/9.94G [00:17<00:13, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.28G/9.94G [00:18<00:12, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▎  | 7.31G/9.94G [00:18<00:12, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▎  | 7.33G/9.94G [00:18<00:12, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.35G/9.94G [00:18<00:12, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.38G/9.94G [00:18<00:12, 210MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▍  | 7.41G/9.94G [00:18<00:12, 201MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▍  | 7.44G/9.94G [00:18<00:12, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▌  | 7.47G/9.94G [00:18<00:12, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▌  | 7.49G/9.94G [00:19<00:11, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.52G/9.94G [00:19<00:11, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.54G/9.94G [00:19<00:11, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.57G/9.94G [00:19<00:11, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▋  | 7.60G/9.94G [00:19<00:11, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.62G/9.94G [00:19<00:11, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.65G/9.94G [00:19<00:10, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.68G/9.94G [00:20<00:11, 199MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.70G/9.94G [00:20<00:11, 196MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.72G/9.94G [00:20<00:11, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.74G/9.94G [00:20<00:14, 148MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.79G/9.94G [00:20<00:10, 215MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▊  | 7.82G/9.94G [00:20<00:10, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.85G/9.94G [00:20<00:10, 198MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.87G/9.94G [00:21<00:10, 197MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.90G/9.94G [00:21<00:10, 200MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.92G/9.94G [00:21<00:10, 202MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.94G/9.94G [00:21<00:10, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 7.96G/9.94G [00:21<00:10, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 7.98G/9.94G [00:21<00:10, 193MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 8.00G/9.94G [00:21<00:10, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.02G/9.94G [00:21<00:10, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.04G/9.94G [00:21<00:10, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.06G/9.94G [00:22<00:09, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████▏ | 8.08G/9.94G [00:22<00:09, 192MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.11G/9.94G [00:22<00:09, 187MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.13G/9.94G [00:22<00:09, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.15G/9.94G [00:22<00:09, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.17G/9.94G [00:22<00:09, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.19G/9.94G [00:22<00:09, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.21G/9.94G [00:22<00:09, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.23G/9.94G [00:22<00:09, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.25G/9.94G [00:23<00:09, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.27G/9.94G [00:23<00:09, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.29G/9.94G [00:23<00:09, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▎ | 8.32G/9.94G [00:23<00:09, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.34G/9.94G [00:23<00:08, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.36G/9.94G [00:23<00:09, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.38G/9.94G [00:23<00:08, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.40G/9.94G [00:23<00:08, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.42G/9.94G [00:24<00:08, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.44G/9.94G [00:24<00:08, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.46G/9.94G [00:24<00:08, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.48G/9.94G [00:24<00:08, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.50G/9.94G [00:24<00:07, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.52G/9.94G [00:24<00:07, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.55G/9.94G [00:24<00:07, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.57G/9.94G [00:24<00:07, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▋ | 8.60G/9.94G [00:25<00:07, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.62G/9.94G [00:25<00:07, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.64G/9.94G [00:25<00:07, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.66G/9.94G [00:25<00:07, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.68G/9.94G [00:25<00:06, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.70G/9.94G [00:25<00:07, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.72G/9.94G [00:25<00:07, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.75G/9.94G [00:25<00:07, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.77G/9.94G [00:26<00:06, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.79G/9.94G [00:26<00:06, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▊ | 8.81G/9.94G [00:26<00:06, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.83G/9.94G [00:26<00:06, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.85G/9.94G [00:26<00:06, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.87G/9.94G [00:26<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.89G/9.94G [00:26<00:06, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.91G/9.94G [00:26<00:05, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.93G/9.94G [00:26<00:05, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 8.95G/9.94G [00:27<00:05, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 8.98G/9.94G [00:27<00:05, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 9.00G/9.94G [00:27<00:05, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.02G/9.94G [00:27<00:05, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.04G/9.94G [00:27<00:05, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.06G/9.94G [00:27<00:05, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████▏| 9.08G/9.94G [00:27<00:04, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.10G/9.94G [00:27<00:04, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.12G/9.94G [00:28<00:04, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.14G/9.94G [00:28<00:04, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.16G/9.94G [00:28<00:04, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.19G/9.94G [00:28<00:04, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.21G/9.94G [00:28<00:04, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.23G/9.94G [00:28<00:04, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.25G/9.94G [00:28<00:04, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.27G/9.94G [00:28<00:03, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.29G/9.94G [00:29<00:03, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▎| 9.31G/9.94G [00:29<00:03, 159MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.33G/9.94G [00:29<00:03, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.35G/9.94G [00:29<00:03, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.37G/9.94G [00:29<00:03, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.40G/9.94G [00:29<00:03, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.42G/9.94G [00:29<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.44G/9.94G [00:29<00:02, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.46G/9.94G [00:30<00:02, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.48G/9.94G [00:30<00:02, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.50G/9.94G [00:30<00:02, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.52G/9.94G [00:30<00:02, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.54G/9.94G [00:30<00:03, 123MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▋| 9.59G/9.94G [00:30<00:01, 198MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.63G/9.94G [00:31<00:01, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.66G/9.94G [00:31<00:01, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.68G/9.94G [00:31<00:01, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.70G/9.94G [00:31<00:01, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.72G/9.94G [00:31<00:01, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.74G/9.94G [00:31<00:01, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.76G/9.94G [00:31<00:01, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.78G/9.94G [00:31<00:00, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▊| 9.80G/9.94G [00:32<00:00, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.83G/9.94G [00:32<00:00, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.85G/9.94G [00:32<00:00, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.87G/9.94G [00:32<00:00, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.89G/9.94G [00:32<00:00, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.91G/9.94G [00:32<00:00, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.93G/9.94G [00:32<00:00, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|██████████| 9.94G/9.94G [00:32<00:00, 301MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 1/2 [00:33<00:33, 33.48s/it]\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   1%|          | 52.4M/4.54G [00:00<00:08, 503MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   2%|▏         | 105M/4.54G [00:00<00:09, 487MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   4%|▎         | 168M/4.54G [00:00<00:08, 486MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   5%|▍         | 220M/4.54G [00:00<00:12, 336MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   6%|▌         | 262M/4.54G [00:00<00:16, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   6%|▋         | 294M/4.54G [00:01<00:18, 232MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   7%|▋         | 325M/4.54G [00:01<00:20, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   8%|▊         | 357M/4.54G [00:01<00:22, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▊         | 388M/4.54G [00:01<00:21, 196MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▉         | 409M/4.54G [00:01<00:22, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▉         | 430M/4.54G [00:01<00:23, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|▉         | 451M/4.54G [00:01<00:23, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|█         | 472M/4.54G [00:02<00:24, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  11%|█         | 493M/4.54G [00:02<00:23, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  11%|█▏        | 514M/4.54G [00:02<00:23, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 535M/4.54G [00:02<00:24, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 556M/4.54G [00:02<00:23, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  13%|█▎        | 577M/4.54G [00:02<00:23, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  13%|█▎        | 598M/4.54G [00:02<00:22, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  14%|█▎        | 619M/4.54G [00:02<00:22, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  14%|█▍        | 640M/4.54G [00:03<00:22, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▍        | 661M/4.54G [00:03<00:22, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▌        | 682M/4.54G [00:03<00:22, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▌        | 703M/4.54G [00:03<00:22, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▌        | 724M/4.54G [00:03<00:22, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▋        | 744M/4.54G [00:03<00:22, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 765M/4.54G [00:03<00:21, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 786M/4.54G [00:03<00:21, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 807M/4.54G [00:04<00:21, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 828M/4.54G [00:04<00:21, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  19%|█▊        | 849M/4.54G [00:04<00:22, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  19%|█▉        | 870M/4.54G [00:04<00:21, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  20%|█▉        | 891M/4.54G [00:04<00:21, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  20%|██        | 912M/4.54G [00:04<00:21, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██        | 933M/4.54G [00:04<00:20, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██        | 954M/4.54G [00:04<00:20, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██▏       | 975M/4.54G [00:05<00:20, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  22%|██▏       | 996M/4.54G [00:05<00:20, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  22%|██▏       | 1.02G/4.54G [00:05<00:20, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  23%|██▎       | 1.04G/4.54G [00:05<00:20, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  23%|██▎       | 1.06G/4.54G [00:05<00:19, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 1.08G/4.54G [00:05<00:19, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 1.10G/4.54G [00:05<00:20, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  25%|██▍       | 1.12G/4.54G [00:05<00:20, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  25%|██▌       | 1.14G/4.54G [00:05<00:20, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  26%|██▌       | 1.16G/4.54G [00:06<00:19, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  26%|██▌       | 1.18G/4.54G [00:06<00:19, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  27%|██▋       | 1.21G/4.54G [00:06<00:19, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  27%|██▋       | 1.23G/4.54G [00:06<00:19, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  27%|██▋       | 1.25G/4.54G [00:06<00:19, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  28%|██▊       | 1.27G/4.54G [00:06<00:19, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  28%|██▊       | 1.29G/4.54G [00:06<00:18, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  29%|██▉       | 1.31G/4.54G [00:06<00:18, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  29%|██▉       | 1.33G/4.54G [00:07<00:18, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|██▉       | 1.35G/4.54G [00:07<00:18, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|███       | 1.37G/4.54G [00:07<00:25, 126MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  31%|███▏      | 1.43G/4.54G [00:07<00:16, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  32%|███▏      | 1.45G/4.54G [00:07<00:16, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  32%|███▏      | 1.47G/4.54G [00:07<00:16, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  33%|███▎      | 1.49G/4.54G [00:07<00:16, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  33%|███▎      | 1.51G/4.54G [00:08<00:17, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  34%|███▎      | 1.53G/4.54G [00:08<00:17, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  34%|███▍      | 1.55G/4.54G [00:08<00:17, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  35%|███▍      | 1.57G/4.54G [00:08<00:17, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  35%|███▌      | 1.59G/4.54G [00:08<00:16, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▌      | 1.61G/4.54G [00:08<00:16, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▌      | 1.64G/4.54G [00:08<00:16, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▋      | 1.66G/4.54G [00:08<00:16, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 1.68G/4.54G [00:09<00:16, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 1.70G/4.54G [00:09<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  38%|███▊      | 1.72G/4.54G [00:09<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  38%|███▊      | 1.74G/4.54G [00:09<00:16, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.76G/4.54G [00:09<00:16, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.78G/4.54G [00:09<00:16, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  40%|███▉      | 1.80G/4.54G [00:09<00:16, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  40%|████      | 1.82G/4.54G [00:09<00:15, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  41%|████      | 1.85G/4.54G [00:10<00:15, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  41%|████      | 1.87G/4.54G [00:10<00:15, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.89G/4.54G [00:10<00:15, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.91G/4.54G [00:10<00:15, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.93G/4.54G [00:10<00:15, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  43%|████▎     | 1.95G/4.54G [00:10<00:14, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  43%|████▎     | 1.97G/4.54G [00:10<00:14, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  44%|████▍     | 1.99G/4.54G [00:10<00:14, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  44%|████▍     | 2.01G/4.54G [00:11<00:14, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▍     | 2.03G/4.54G [00:11<00:14, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▌     | 2.06G/4.54G [00:11<00:14, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▌     | 2.08G/4.54G [00:11<00:14, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▌     | 2.10G/4.54G [00:11<00:14, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 2.12G/4.54G [00:11<00:14, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 2.14G/4.54G [00:11<00:14, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.16G/4.54G [00:11<00:13, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.18G/4.54G [00:12<00:13, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.20G/4.54G [00:12<00:13, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 2.22G/4.54G [00:12<00:13, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 2.24G/4.54G [00:12<00:13, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|████▉     | 2.26G/4.54G [00:12<00:12, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|█████     | 2.29G/4.54G [00:12<00:12, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████     | 2.31G/4.54G [00:12<00:12, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████▏    | 2.33G/4.54G [00:12<00:12, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 2.35G/4.54G [00:12<00:12, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 2.37G/4.54G [00:13<00:13, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  53%|█████▎    | 2.39G/4.54G [00:13<00:12, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  53%|█████▎    | 2.41G/4.54G [00:13<00:12, 168MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  54%|█████▎    | 2.43G/4.54G [00:13<00:12, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  54%|█████▍    | 2.45G/4.54G [00:13<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▍    | 2.47G/4.54G [00:13<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▍    | 2.50G/4.54G [00:13<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▌    | 2.52G/4.54G [00:13<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  56%|█████▌    | 2.54G/4.54G [00:14<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  56%|█████▋    | 2.56G/4.54G [00:14<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 2.58G/4.54G [00:14<00:11, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 2.60G/4.54G [00:14<00:11, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.62G/4.54G [00:14<00:10, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.64G/4.54G [00:14<00:10, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  59%|█████▊    | 2.66G/4.54G [00:14<00:11, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  59%|█████▉    | 2.68G/4.54G [00:14<00:11, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  60%|█████▉    | 2.71G/4.54G [00:15<00:10, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  60%|██████    | 2.73G/4.54G [00:15<00:10, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.75G/4.54G [00:15<00:10, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.77G/4.54G [00:15<00:10, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████▏   | 2.79G/4.54G [00:15<00:10, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.81G/4.54G [00:15<00:09, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.83G/4.54G [00:15<00:09, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.85G/4.54G [00:15<00:09, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.87G/4.54G [00:16<00:09, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▎   | 2.89G/4.54G [00:16<00:09, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▍   | 2.92G/4.54G [00:16<00:09, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▍   | 2.94G/4.54G [00:16<00:09, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▌   | 2.96G/4.54G [00:16<00:09, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  66%|██████▌   | 2.98G/4.54G [00:16<00:09, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  66%|██████▌   | 3.00G/4.54G [00:16<00:09, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.02G/4.54G [00:16<00:08, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.04G/4.54G [00:17<00:08, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.06G/4.54G [00:17<00:08, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 3.08G/4.54G [00:17<00:08, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 3.10G/4.54G [00:17<00:08, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  69%|██████▉   | 3.12G/4.54G [00:17<00:12, 116MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  70%|██████▉   | 3.18G/4.54G [00:17<00:07, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████   | 3.21G/4.54G [00:17<00:07, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████▏  | 3.24G/4.54G [00:18<00:07, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 3.26G/4.54G [00:18<00:07, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 3.28G/4.54G [00:18<00:07, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.30G/4.54G [00:18<00:07, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.32G/4.54G [00:18<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▎  | 3.34G/4.54G [00:18<00:06, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▍  | 3.37G/4.54G [00:18<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▍  | 3.39G/4.54G [00:19<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▌  | 3.41G/4.54G [00:19<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.43G/4.54G [00:19<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.45G/4.54G [00:19<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▋  | 3.47G/4.54G [00:19<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.49G/4.54G [00:19<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.51G/4.54G [00:19<00:05, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.53G/4.54G [00:19<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.55G/4.54G [00:19<00:05, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▊  | 3.58G/4.54G [00:20<00:05, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▉  | 3.60G/4.54G [00:20<00:05, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|███████▉  | 3.62G/4.54G [00:20<00:05, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|████████  | 3.64G/4.54G [00:20<00:05, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████  | 3.66G/4.54G [00:20<00:05, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████  | 3.68G/4.54G [00:20<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.70G/4.54G [00:20<00:04, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.72G/4.54G [00:20<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.74G/4.54G [00:21<00:04, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.76G/4.54G [00:21<00:04, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.79G/4.54G [00:21<00:04, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▍ | 3.81G/4.54G [00:21<00:04, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▍ | 3.84G/4.54G [00:21<00:04, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▍ | 3.86G/4.54G [00:21<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▌ | 3.88G/4.54G [00:21<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.90G/4.54G [00:21<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▋ | 3.92G/4.54G [00:22<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.94G/4.54G [00:22<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.96G/4.54G [00:22<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 3.98G/4.54G [00:22<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 4.01G/4.54G [00:22<00:03, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▊ | 4.03G/4.54G [00:22<00:03, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 4.05G/4.54G [00:22<00:02, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|████████▉ | 4.07G/4.54G [00:22<00:02, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|█████████ | 4.09G/4.54G [00:23<00:02, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.11G/4.54G [00:23<00:02, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.13G/4.54G [00:23<00:02, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████▏| 4.15G/4.54G [00:23<00:02, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.17G/4.54G [00:23<00:02, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.19G/4.54G [00:23<00:01, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.22G/4.54G [00:23<00:01, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.24G/4.54G [00:23<00:01, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.26G/4.54G [00:24<00:01, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.28G/4.54G [00:24<00:01, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▍| 4.30G/4.54G [00:24<00:01, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▌| 4.32G/4.54G [00:24<00:01, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 4.34G/4.54G [00:24<00:01, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 4.36G/4.54G [00:24<00:01, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.38G/4.54G [00:24<00:00, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.40G/4.54G [00:24<00:00, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.42G/4.54G [00:25<00:00, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.45G/4.54G [00:25<00:00, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.47G/4.54G [00:25<00:00, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▉| 4.49G/4.54G [00:25<00:00, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▉| 4.51G/4.54G [00:25<00:00, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|█████████▉| 4.53G/4.54G [00:25<00:00, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|██████████| 4.54G/4.54G [00:25<00:00, 176MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:59<00:00, 29.21s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:59<00:00, 29.85s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.46s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.22s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.46s/it]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 120/120 [00:00<00:00, 1.11MB/s]\u001b[0m\n",
      "\u001b[34mFound 7 modules to quantize: ['down_proj', 'gate_proj', 'o_proj', 'v_proj', 'up_proj', 'k_proj', 'q_proj']\u001b[0m\n",
      "\u001b[34mCUDA extension not installed.\u001b[0m\n",
      "\u001b[34mCUDA extension not installed.\u001b[0m\n",
      "\u001b[34mtrainable params: 167,772,160 || all params: 7,409,520,640 || trainable%: 2.2642781922259414\u001b[0m\n",
      "\u001b[34m0%|          | 0/1196 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34m0%|          | 1/1196 [00:12<4:14:52, 12.80s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/1196 [00:25<4:11:13, 12.62s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/1196 [00:37<4:09:52, 12.57s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 4/1196 [00:50<4:09:04, 12.54s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 5/1196 [01:02<4:08:29, 12.52s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 6/1196 [01:15<4:08:08, 12.51s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 7/1196 [01:27<4:07:48, 12.51s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 8/1196 [01:40<4:07:27, 12.50s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 9/1196 [01:52<4:07:12, 12.50s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 10/1196 [02:05<4:07:00, 12.50s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7203, 'learning_rate': 2.777777777777778e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 10/1196 [02:05<4:07:00, 12.50s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 11/1196 [02:17<4:06:48, 12.50s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 12/1196 [02:30<4:06:35, 12.50s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 13/1196 [02:42<4:06:25, 12.50s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 14/1196 [02:55<4:06:11, 12.50s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 15/1196 [03:07<4:05:58, 12.50s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 16/1196 [03:20<4:05:44, 12.50s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 17/1196 [03:32<4:05:31, 12.50s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 18/1196 [03:45<4:05:19, 12.50s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 19/1196 [03:57<4:05:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 20/1196 [04:10<4:04:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.4721, 'learning_rate': 5.555555555555556e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m2%|▏         | 20/1196 [04:10<4:04:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 21/1196 [04:22<4:04:43, 12.50s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 22/1196 [04:35<4:04:32, 12.50s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 23/1196 [04:47<4:04:18, 12.50s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 24/1196 [05:00<4:04:05, 12.50s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 25/1196 [05:12<4:03:51, 12.50s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 26/1196 [05:25<4:03:40, 12.50s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 27/1196 [05:37<4:03:35, 12.50s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 28/1196 [05:50<4:03:19, 12.50s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 29/1196 [06:02<4:03:01, 12.50s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 30/1196 [06:15<4:02:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2879, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.05}\u001b[0m\n",
      "\u001b[34m3%|▎         | 30/1196 [06:15<4:02:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 31/1196 [06:27<4:02:38, 12.50s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 32/1196 [06:40<4:02:26, 12.50s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 33/1196 [06:52<4:02:12, 12.50s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 34/1196 [07:05<4:01:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 35/1196 [07:17<4:01:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 36/1196 [07:30<4:01:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 37/1196 [07:42<4:01:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 38/1196 [07:55<4:01:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 39/1196 [08:07<4:00:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 40/1196 [08:20<4:00:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.324, 'learning_rate': 9.999706613915566e-05, 'epoch': 0.07}\u001b[0m\n",
      "\u001b[34m3%|▎         | 40/1196 [08:20<4:00:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 41/1196 [08:32<4:00:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 42/1196 [08:45<4:00:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 43/1196 [08:57<4:00:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 44/1196 [09:10<3:59:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 45/1196 [09:22<3:59:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 46/1196 [09:35<3:59:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 47/1196 [09:47<3:59:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 48/1196 [10:00<3:59:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 49/1196 [10:12<3:58:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 50/1196 [10:24<3:58:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2836, 'learning_rate': 9.996406415861763e-05, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34m4%|▍         | 50/1196 [10:25<3:58:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 51/1196 [10:37<3:58:28, 12.50s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 52/1196 [10:49<3:58:14, 12.50s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 53/1196 [11:02<3:57:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 54/1196 [11:14<3:57:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 55/1196 [11:27<3:57:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 56/1196 [11:39<3:57:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 57/1196 [11:52<3:57:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 58/1196 [12:04<3:56:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 59/1196 [12:17<3:56:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 60/1196 [12:29<3:56:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2482, 'learning_rate': 9.989441715674422e-05, 'epoch': 0.1}\u001b[0m\n",
      "\u001b[34m5%|▌         | 60/1196 [12:29<3:56:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 61/1196 [12:42<3:56:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 62/1196 [12:54<3:56:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 63/1196 [13:07<3:55:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 64/1196 [13:19<3:55:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 65/1196 [13:32<3:55:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 66/1196 [13:44<3:55:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 67/1196 [13:57<3:55:02, 12.49s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 68/1196 [14:09<3:54:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 69/1196 [14:22<3:54:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 70/1196 [14:34<3:54:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2259, 'learning_rate': 9.978817621456562e-05, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34m6%|▌         | 70/1196 [14:34<3:54:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 71/1196 [14:47<3:54:09, 12.49s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 72/1196 [14:59<3:54:04, 12.50s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 73/1196 [15:12<3:53:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 74/1196 [15:24<3:53:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 75/1196 [15:37<3:53:30, 12.50s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 76/1196 [15:49<3:53:16, 12.50s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 77/1196 [16:02<3:53:05, 12.50s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 78/1196 [16:14<3:52:50, 12.50s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 79/1196 [16:27<3:52:39, 12.50s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 80/1196 [16:39<3:52:26, 12.50s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2262, 'learning_rate': 9.964541925211612e-05, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34m7%|▋         | 80/1196 [16:39<3:52:26, 12.50s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 81/1196 [16:52<3:52:16, 12.50s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 82/1196 [17:04<3:52:00, 12.50s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 83/1196 [17:17<3:51:48, 12.50s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 84/1196 [17:29<3:51:37, 12.50s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 85/1196 [17:42<3:51:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 86/1196 [17:54<3:51:10, 12.50s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 87/1196 [18:07<3:50:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 88/1196 [18:19<3:50:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 89/1196 [18:32<3:50:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 90/1196 [18:44<3:50:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0719, 'learning_rate': 9.946625097128543e-05, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34m8%|▊         | 90/1196 [18:44<3:50:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 91/1196 [18:57<3:50:02, 12.49s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 92/1196 [19:09<3:49:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 93/1196 [19:22<3:49:42, 12.50s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 94/1196 [19:34<3:49:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 95/1196 [19:47<3:49:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 96/1196 [19:59<3:48:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 97/1196 [20:12<3:48:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 98/1196 [20:24<3:48:41, 12.50s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 99/1196 [20:37<3:48:27, 12.50s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 100/1196 [20:49<3:48:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.116, 'learning_rate': 9.925080277902743e-05, 'epoch': 0.17}\u001b[0m\n",
      "\u001b[34m8%|▊         | 100/1196 [20:49<3:48:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 101/1196 [21:02<3:47:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 102/1196 [21:14<3:47:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 103/1196 [21:27<3:47:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 104/1196 [21:39<3:47:23, 12.49s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 105/1196 [21:52<3:47:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 106/1196 [22:04<3:46:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 107/1196 [22:17<3:46:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 108/1196 [22:29<3:46:36, 12.50s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 109/1196 [22:42<3:46:23, 12.50s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 110/1196 [22:54<3:46:11, 12.50s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0837, 'learning_rate': 9.899923269098262e-05, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34m9%|▉         | 110/1196 [22:54<3:46:11, 12.50s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 111/1196 [23:07<3:45:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 112/1196 [23:19<3:45:45, 12.50s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 113/1196 [23:32<3:45:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 114/1196 [23:44<3:45:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 115/1196 [23:57<3:45:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 116/1196 [24:09<3:44:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 117/1196 [24:22<3:44:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 118/1196 [24:34<3:44:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 119/1196 [24:47<3:44:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 120/1196 [24:59<3:44:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0466, 'learning_rate': 9.871172521558523e-05, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34m10%|█         | 120/1196 [24:59<3:44:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 121/1196 [25:12<3:43:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 122/1196 [25:24<3:43:39, 12.50s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 123/1196 [25:37<3:43:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 124/1196 [25:49<3:43:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 125/1196 [26:01<3:42:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 126/1196 [26:14<3:42:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 127/1196 [26:26<3:42:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 128/1196 [26:39<3:42:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 129/1196 [26:51<3:42:09, 12.49s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 130/1196 [27:04<3:41:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0528, 'learning_rate': 9.838849121873949e-05, 'epoch': 0.22}\u001b[0m\n",
      "\u001b[34m11%|█         | 130/1196 [27:04<3:41:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 131/1196 [27:16<3:41:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 132/1196 [27:29<3:41:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 133/1196 [27:41<3:41:24, 12.50s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 134/1196 [27:54<3:41:13, 12.50s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 135/1196 [28:06<3:40:57, 12.50s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 136/1196 [28:19<3:40:46, 12.50s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 137/1196 [28:31<3:40:33, 12.50s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 138/1196 [28:44<3:40:21, 12.50s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 139/1196 [28:56<3:40:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 140/1196 [29:09<3:39:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1358, 'learning_rate': 9.802976776916494e-05, 'epoch': 0.23}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 140/1196 [29:09<3:39:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 141/1196 [29:21<3:39:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 142/1196 [29:34<3:39:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 143/1196 [29:46<3:39:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 144/1196 [29:59<3:39:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 145/1196 [30:11<3:38:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 146/1196 [30:24<3:38:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 147/1196 [30:36<3:38:27, 12.50s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 148/1196 [30:49<3:38:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 149/1196 [31:01<3:37:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 150/1196 [31:14<3:37:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1851, 'learning_rate': 9.763581796452353e-05, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 150/1196 [31:14<3:37:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 151/1196 [31:26<3:37:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 152/1196 [31:39<3:37:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 153/1196 [31:51<3:37:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 154/1196 [32:04<3:37:00, 12.50s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 155/1196 [32:16<3:36:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 156/1196 [32:29<3:36:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 157/1196 [32:41<3:36:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 158/1196 [32:54<3:36:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 159/1196 [33:06<3:35:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 160/1196 [33:19<3:35:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1123, 'learning_rate': 9.720693073845667e-05, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 160/1196 [33:19<3:35:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 161/1196 [33:31<3:35:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 162/1196 [33:44<3:35:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 163/1196 [33:56<3:35:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 164/1196 [34:09<3:34:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 165/1196 [34:21<3:34:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 166/1196 [34:34<3:34:30, 12.50s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 167/1196 [34:46<3:34:18, 12.50s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 168/1196 [34:59<3:34:06, 12.50s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 169/1196 [35:11<3:33:53, 12.50s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 170/1196 [35:24<3:33:42, 12.50s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0938, 'learning_rate': 9.674342064867326e-05, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 170/1196 [35:24<3:33:42, 12.50s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 171/1196 [35:36<3:33:29, 12.50s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 172/1196 [35:49<3:33:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 173/1196 [36:01<3:33:02, 12.50s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 174/1196 [36:14<3:32:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 175/1196 [36:26<3:32:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 176/1196 [36:39<3:32:23, 12.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 177/1196 [36:51<3:32:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 178/1196 [37:04<3:31:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 179/1196 [37:16<3:31:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 180/1196 [37:29<3:31:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0211, 'learning_rate': 9.624562764624445e-05, 'epoch': 0.3}\u001b[0m\n",
      "\u001b[34m15%|█▌        | 180/1196 [37:29<3:31:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 181/1196 [37:41<3:31:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 182/1196 [37:54<3:31:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 183/1196 [38:06<3:30:53, 12.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 184/1196 [38:19<3:30:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 185/1196 [38:31<3:30:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 186/1196 [38:44<3:30:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 187/1196 [38:56<3:30:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 188/1196 [39:09<3:29:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 189/1196 [39:21<3:29:46, 12.50s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 190/1196 [39:34<3:29:31, 12.50s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1675, 'learning_rate': 9.571391682627412e-05, 'epoch': 0.32}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 190/1196 [39:34<3:29:31, 12.50s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 191/1196 [39:46<3:29:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 192/1196 [39:59<3:29:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 193/1196 [40:11<3:28:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 194/1196 [40:24<3:28:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 195/1196 [40:36<3:28:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 196/1196 [40:49<3:28:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 197/1196 [41:01<3:27:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 198/1196 [41:13<3:27:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 199/1196 [41:26<3:27:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 200/1196 [41:38<3:27:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0554, 'learning_rate': 9.514867816012809e-05, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 200/1196 [41:38<3:27:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 201/1196 [41:51<3:27:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 202/1196 [42:03<3:26:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 203/1196 [42:16<3:26:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 204/1196 [42:28<3:26:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 205/1196 [42:41<3:26:20, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 206/1196 [42:53<3:26:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 207/1196 [43:06<3:25:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 208/1196 [43:18<3:25:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 209/1196 [43:31<3:25:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 210/1196 [43:43<3:25:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9977, 'learning_rate': 9.45503262094184e-05, 'epoch': 0.35}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 210/1196 [43:43<3:25:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 211/1196 [43:56<3:24:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 212/1196 [44:08<3:24:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 213/1196 [44:21<3:24:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 214/1196 [44:33<3:24:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 215/1196 [44:46<3:24:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 216/1196 [44:58<3:23:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 217/1196 [45:11<3:23:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 218/1196 [45:23<3:23:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 219/1196 [45:36<3:23:20, 12.49s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 220/1196 [45:48<3:23:04, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.896, 'learning_rate': 9.391929982195232e-05, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 220/1196 [45:48<3:23:04, 12.48s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 221/1196 [46:01<3:22:52, 12.48s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 222/1196 [46:13<3:22:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 223/1196 [46:26<3:22:27, 12.48s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 224/1196 [46:38<3:22:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 225/1196 [46:51<3:22:02, 12.48s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 226/1196 [47:03<3:21:53, 12.49s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 227/1196 [47:16<3:21:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 228/1196 [47:28<3:21:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 229/1196 [47:41<3:21:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 230/1196 [47:53<3:21:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0063, 'learning_rate': 9.325606180986939e-05, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 230/1196 [47:53<3:21:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 231/1196 [48:06<3:20:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 232/1196 [48:18<3:20:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 233/1196 [48:31<3:20:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 234/1196 [48:43<3:20:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 235/1196 [48:56<3:20:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 236/1196 [49:08<3:19:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 237/1196 [49:21<3:19:43, 12.50s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 238/1196 [49:33<3:19:31, 12.50s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 239/1196 [49:46<3:19:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 240/1196 [49:58<3:19:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1304, 'learning_rate': 9.256109861020213e-05, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34m20%|██        | 240/1196 [49:58<3:19:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 241/1196 [50:11<3:18:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 242/1196 [50:23<3:18:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 243/1196 [50:36<3:18:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 244/1196 [50:48<3:18:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 245/1196 [51:00<3:17:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 246/1196 [51:13<3:17:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 247/1196 [51:25<3:17:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 248/1196 [51:38<3:17:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 249/1196 [51:50<3:17:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 250/1196 [52:03<3:16:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1108, 'learning_rate': 9.183491992810979e-05, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34m21%|██        | 250/1196 [52:03<3:16:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 251/1196 [52:15<3:16:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 252/1196 [52:28<3:16:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 253/1196 [52:40<3:16:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 254/1196 [52:53<3:16:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 255/1196 [53:05<3:15:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 256/1196 [53:18<3:15:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 257/1196 [53:30<3:15:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 258/1196 [53:43<3:15:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 259/1196 [53:55<3:15:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 260/1196 [54:08<3:14:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0023, 'learning_rate': 9.107805836304658e-05, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 260/1196 [54:08<3:14:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 261/1196 [54:20<3:14:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 262/1196 [54:33<3:14:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 263/1196 [54:45<3:14:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 264/1196 [54:58<3:14:02, 12.49s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 265/1196 [55:10<3:13:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 266/1196 [55:23<3:13:40, 12.50s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 267/1196 [55:35<3:13:28, 12.50s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 268/1196 [55:48<3:13:17, 12.50s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 269/1196 [56:00<3:13:03, 12.50s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 270/1196 [56:13<3:12:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0313, 'learning_rate': 9.029106901813839e-05, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 270/1196 [56:13<3:12:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 271/1196 [56:25<3:12:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 272/1196 [56:38<3:12:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 273/1196 [56:50<3:12:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 274/1196 [57:03<3:12:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 275/1196 [57:15<3:11:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 276/1196 [57:28<3:11:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 277/1196 [57:40<3:11:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 278/1196 [57:53<3:11:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 279/1196 [58:05<3:10:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 280/1196 [58:18<3:10:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8996, 'learning_rate': 8.94745290930551e-05, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 280/1196 [58:18<3:10:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 281/1196 [58:30<3:10:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 282/1196 [58:43<3:10:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 283/1196 [58:55<3:10:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 284/1196 [59:08<3:09:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 285/1196 [59:20<3:09:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 286/1196 [59:33<3:09:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 287/1196 [59:45<3:09:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 288/1196 [59:58<3:08:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 289/1196 [1:00:10<3:08:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 290/1196 [1:00:23<3:08:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8322, 'learning_rate': 8.862903746067618e-05, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 290/1196 [1:00:23<3:08:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 291/1196 [1:00:35<3:08:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 292/1196 [1:00:48<3:08:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 293/1196 [1:01:00<3:07:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 294/1196 [1:01:12<3:07:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 295/1196 [1:01:25<3:07:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 296/1196 [1:01:37<3:07:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 297/1196 [1:01:50<3:07:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 298/1196 [1:02:02<3:06:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 299/1196 [1:02:15<3:06:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 300/1196 [1:02:27<3:06:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9503, 'learning_rate': 8.775521422786104e-05, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34m25%|██▌       | 300/1196 [1:02:27<3:06:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 301/1196 [1:02:40<3:06:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 302/1196 [1:02:52<3:06:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 303/1196 [1:03:05<3:05:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 304/1196 [1:03:17<3:05:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 305/1196 [1:03:30<3:05:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 306/1196 [1:03:42<3:05:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 307/1196 [1:03:55<3:05:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 308/1196 [1:04:07<3:04:53, 12.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 309/1196 [1:04:20<3:04:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 310/1196 [1:04:32<3:04:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.015, 'learning_rate': 8.685370028064546e-05, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 310/1196 [1:04:32<3:04:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 311/1196 [1:04:45<3:04:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 312/1196 [1:04:57<3:04:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 313/1196 [1:05:10<3:03:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 314/1196 [1:05:22<3:03:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 315/1196 [1:05:35<3:03:28, 12.50s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 316/1196 [1:05:47<3:03:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 317/1196 [1:06:00<3:03:03, 12.50s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 318/1196 [1:06:12<3:02:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 319/1196 [1:06:25<3:02:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 320/1196 [1:06:37<3:02:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9713, 'learning_rate': 8.592515681419813e-05, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 320/1196 [1:06:37<3:02:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 321/1196 [1:06:50<3:02:09, 12.49s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 322/1196 [1:07:02<3:01:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 323/1196 [1:07:15<3:01:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 324/1196 [1:07:27<3:01:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 325/1196 [1:07:40<3:01:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 326/1196 [1:07:52<3:01:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 327/1196 [1:08:05<3:00:53, 12.49s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 328/1196 [1:08:17<3:00:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 329/1196 [1:08:30<3:00:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 330/1196 [1:08:42<3:00:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.927, 'learning_rate': 8.497026484788189e-05, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 330/1196 [1:08:42<3:00:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 331/1196 [1:08:55<3:00:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 332/1196 [1:09:07<2:59:53, 12.49s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 333/1196 [1:09:20<2:59:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 334/1196 [1:09:32<2:59:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 335/1196 [1:09:45<2:59:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 336/1196 [1:09:57<2:59:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 337/1196 [1:10:10<2:58:55, 12.50s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 338/1196 [1:10:22<2:58:44, 12.50s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 339/1196 [1:10:35<2:58:31, 12.50s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 340/1196 [1:10:47<2:58:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9001, 'learning_rate': 8.39897247257754e-05, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 340/1196 [1:10:47<2:58:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 341/1196 [1:11:00<2:58:03, 12.50s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 342/1196 [1:11:12<2:57:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 343/1196 [1:11:25<2:57:36, 12.49s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 344/1196 [1:11:37<2:57:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 345/1196 [1:11:50<2:57:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 346/1196 [1:12:02<2:56:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 347/1196 [1:12:15<2:56:49, 12.50s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 348/1196 [1:12:27<2:56:36, 12.50s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 349/1196 [1:12:40<2:56:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 350/1196 [1:12:52<2:56:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.799, 'learning_rate': 8.298425560302146e-05, 'epoch': 0.59}\u001b[0m\n",
      "\u001b[34m29%|██▉       | 350/1196 [1:12:52<2:56:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 351/1196 [1:13:05<2:55:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 352/1196 [1:13:17<2:55:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 353/1196 [1:13:30<2:55:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 354/1196 [1:13:42<2:55:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 355/1196 [1:13:54<2:55:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 356/1196 [1:14:07<2:54:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 357/1196 [1:14:19<2:54:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 358/1196 [1:14:32<2:54:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 359/1196 [1:14:44<2:54:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 360/1196 [1:14:57<2:54:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.858, 'learning_rate': 8.19545949183788e-05, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34m30%|███       | 360/1196 [1:14:57<2:54:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 361/1196 [1:15:09<2:53:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 362/1196 [1:15:22<2:53:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 363/1196 [1:15:34<2:53:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 364/1196 [1:15:47<2:53:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 365/1196 [1:15:59<2:53:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 366/1196 [1:16:12<2:52:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 367/1196 [1:16:24<2:52:38, 12.50s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 368/1196 [1:16:37<2:52:23, 12.49s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 369/1196 [1:16:49<2:52:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 370/1196 [1:17:02<2:51:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8675, 'learning_rate': 8.090149785336425e-05, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34m31%|███       | 370/1196 [1:17:02<2:51:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 371/1196 [1:17:14<2:51:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 372/1196 [1:17:27<2:51:36, 12.50s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 373/1196 [1:17:39<2:51:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 374/1196 [1:17:52<2:51:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 375/1196 [1:18:04<2:50:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 376/1196 [1:18:17<2:50:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 377/1196 [1:18:29<2:50:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 378/1196 [1:18:42<2:50:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 379/1196 [1:18:54<2:50:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 380/1196 [1:19:07<2:49:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9097, 'learning_rate': 7.982573677838172e-05, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 380/1196 [1:19:07<2:49:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 381/1196 [1:19:19<2:49:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 382/1196 [1:19:32<2:49:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 383/1196 [1:19:44<2:49:18, 12.50s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 384/1196 [1:19:57<2:49:05, 12.50s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 385/1196 [1:20:09<2:48:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 386/1196 [1:20:22<2:48:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 387/1196 [1:20:34<2:48:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 388/1196 [1:20:47<2:48:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 389/1196 [1:20:59<2:47:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 390/1196 [1:21:12<2:47:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7829, 'learning_rate': 7.872810068624451e-05, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 390/1196 [1:21:12<2:47:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 391/1196 [1:21:24<2:47:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 392/1196 [1:21:37<2:47:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 393/1196 [1:21:49<2:47:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 394/1196 [1:22:02<2:46:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 395/1196 [1:22:14<2:46:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 396/1196 [1:22:27<2:46:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 397/1196 [1:22:39<2:46:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 398/1196 [1:22:52<2:46:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 399/1196 [1:23:04<2:45:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 400/1196 [1:23:17<2:45:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.774, 'learning_rate': 7.760939461350623e-05, 'epoch': 0.67}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 400/1196 [1:23:17<2:45:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 401/1196 [1:23:29<2:45:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 402/1196 [1:23:42<2:45:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 403/1196 [1:23:54<2:45:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 404/1196 [1:24:07<2:44:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 405/1196 [1:24:19<2:44:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 406/1196 [1:24:32<2:44:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 407/1196 [1:24:44<2:44:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 408/1196 [1:24:57<2:44:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 409/1196 [1:25:09<2:43:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 410/1196 [1:25:22<2:43:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8858, 'learning_rate': 7.647043905002484e-05, 'epoch': 0.69}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 410/1196 [1:25:22<2:43:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 411/1196 [1:25:34<2:43:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 412/1196 [1:25:46<2:43:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 413/1196 [1:25:59<2:42:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 414/1196 [1:26:11<2:42:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 415/1196 [1:26:24<2:42:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 416/1196 [1:26:36<2:42:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 417/1196 [1:26:49<2:42:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 418/1196 [1:27:01<2:41:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 419/1196 [1:27:14<2:41:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 420/1196 [1:27:26<2:41:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8585, 'learning_rate': 7.53120693371927e-05, 'epoch': 0.7}\u001b[0m\n",
      "\u001b[34m35%|███▌      | 420/1196 [1:27:26<2:41:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 421/1196 [1:27:39<2:41:20, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 422/1196 [1:27:51<2:41:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 423/1196 [1:28:04<2:40:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 424/1196 [1:28:16<2:40:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 425/1196 [1:28:29<2:40:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 426/1196 [1:28:41<2:40:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 427/1196 [1:28:54<2:40:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 428/1196 [1:29:06<2:39:56, 12.50s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 429/1196 [1:29:19<2:39:44, 12.50s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 430/1196 [1:29:31<2:39:33, 12.50s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8138, 'learning_rate': 7.413513505527429e-05, 'epoch': 0.72}\u001b[0m\n",
      "\u001b[34m36%|███▌      | 430/1196 [1:29:31<2:39:33, 12.50s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 431/1196 [1:29:44<2:39:20, 12.50s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 432/1196 [1:29:56<2:39:07, 12.50s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 433/1196 [1:30:09<2:38:53, 12.49s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 434/1196 [1:30:21<2:38:42, 12.50s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 435/1196 [1:30:34<2:38:29, 12.50s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 436/1196 [1:30:46<2:38:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 437/1196 [1:30:59<2:38:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 438/1196 [1:31:11<2:37:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 439/1196 [1:31:24<2:37:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 440/1196 [1:31:36<2:37:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7145, 'learning_rate': 7.294049940030055e-05, 'epoch': 0.74}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 440/1196 [1:31:36<2:37:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 441/1196 [1:31:49<2:37:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 442/1196 [1:32:01<2:36:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 443/1196 [1:32:14<2:36:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 444/1196 [1:32:26<2:36:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 445/1196 [1:32:39<2:36:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 446/1196 [1:32:51<2:36:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 447/1196 [1:33:04<2:35:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 448/1196 [1:33:16<2:35:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 449/1196 [1:33:29<2:35:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 450/1196 [1:33:41<2:35:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.781, 'learning_rate': 7.172903855097711e-05, 'epoch': 0.75}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 450/1196 [1:33:41<2:35:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 451/1196 [1:33:54<2:35:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 452/1196 [1:34:06<2:34:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 453/1196 [1:34:19<2:34:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 454/1196 [1:34:31<2:34:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 455/1196 [1:34:44<2:34:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 456/1196 [1:34:56<2:34:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 457/1196 [1:35:09<2:33:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 458/1196 [1:35:21<2:33:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 459/1196 [1:35:34<2:33:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 460/1196 [1:35:46<2:33:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7705, 'learning_rate': 7.05016410260708e-05, 'epoch': 0.77}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 460/1196 [1:35:46<2:33:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 461/1196 [1:35:59<2:33:23, 12.52s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 462/1196 [1:36:11<2:33:05, 12.51s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 463/1196 [1:36:24<2:32:49, 12.51s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 464/1196 [1:36:36<2:32:34, 12.51s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 465/1196 [1:36:49<2:32:18, 12.50s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 466/1196 [1:37:01<2:32:03, 12.50s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 467/1196 [1:37:14<2:31:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 468/1196 [1:37:26<2:31:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 469/1196 [1:37:39<2:31:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 470/1196 [1:37:51<2:31:09, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7332, 'learning_rate': 6.925920703274541e-05, 'epoch': 0.79}\u001b[0m\n",
      "\u001b[34m39%|███▉      | 470/1196 [1:37:51<2:31:09, 12.49s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 471/1196 [1:38:04<2:30:59, 12.50s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 472/1196 [1:38:16<2:30:48, 12.50s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 473/1196 [1:38:29<2:30:34, 12.50s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 474/1196 [1:38:41<2:30:23, 12.50s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 475/1196 [1:38:54<2:30:09, 12.50s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 476/1196 [1:39:06<2:29:53, 12.49s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 477/1196 [1:39:19<2:29:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 478/1196 [1:39:31<2:29:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 479/1196 [1:39:44<2:29:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 480/1196 [1:39:56<2:29:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 480/1196 [1:39:56<2:29:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8256, 'learning_rate': 6.800264780632494e-05, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m40%|████      | 481/1196 [1:40:09<2:28:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 482/1196 [1:40:21<2:28:36, 12.49s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 483/1196 [1:40:34<2:28:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 484/1196 [1:40:46<2:28:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 485/1196 [1:40:58<2:27:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 486/1196 [1:41:11<2:27:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 487/1196 [1:41:23<2:27:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 488/1196 [1:41:36<2:27:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 489/1196 [1:41:48<2:27:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 490/1196 [1:42:01<2:27:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8112, 'learning_rate': 6.673288494196858e-05, 'epoch': 0.82}\u001b[0m\n",
      "\u001b[34m41%|████      | 490/1196 [1:42:01<2:27:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 491/1196 [1:42:13<2:26:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 492/1196 [1:42:26<2:26:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 493/1196 [1:42:38<2:26:23, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 494/1196 [1:42:51<2:26:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 495/1196 [1:43:03<2:25:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 496/1196 [1:43:16<2:25:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 497/1196 [1:43:28<2:25:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 498/1196 [1:43:41<2:25:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 499/1196 [1:43:53<2:25:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 500/1196 [1:44:06<2:24:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7659, 'learning_rate': 6.545084971874738e-05, 'epoch': 0.84}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 500/1196 [1:44:06<2:24:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 501/1196 [1:44:18<2:24:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 502/1196 [1:44:31<2:24:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 503/1196 [1:44:43<2:24:19, 12.50s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 504/1196 [1:44:56<2:24:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 505/1196 [1:45:08<2:23:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 506/1196 [1:45:21<2:23:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 507/1196 [1:45:33<2:23:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 508/1196 [1:45:46<2:23:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 509/1196 [1:45:58<2:23:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 510/1196 [1:46:11<2:22:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7071, 'learning_rate': 6.415748241661851e-05, 'epoch': 0.85}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 510/1196 [1:46:11<2:22:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 511/1196 [1:46:23<2:22:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 512/1196 [1:46:36<2:22:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 513/1196 [1:46:48<2:22:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 514/1196 [1:47:01<2:21:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 515/1196 [1:47:13<2:21:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 516/1196 [1:47:26<2:21:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 517/1196 [1:47:38<2:21:25, 12.50s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 518/1196 [1:47:51<2:21:09, 12.49s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 519/1196 [1:48:03<2:20:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 520/1196 [1:48:16<2:20:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7024, 'learning_rate': 6.285373162679803e-05, 'epoch': 0.87}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 520/1196 [1:48:16<2:20:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 521/1196 [1:48:28<2:20:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 522/1196 [1:48:41<2:20:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 523/1196 [1:48:53<2:20:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 524/1196 [1:49:06<2:19:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 525/1196 [1:49:18<2:19:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 526/1196 [1:49:31<2:19:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 527/1196 [1:49:43<2:19:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 528/1196 [1:49:56<2:19:07, 12.50s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 529/1196 [1:50:08<2:18:55, 12.50s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 530/1196 [1:50:21<2:18:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7096, 'learning_rate': 6.154055355603807e-05, 'epoch': 0.89}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 530/1196 [1:50:21<2:18:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 531/1196 [1:50:33<2:18:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 532/1196 [1:50:46<2:18:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 533/1196 [1:50:58<2:18:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 534/1196 [1:51:11<2:17:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 535/1196 [1:51:23<2:17:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 536/1196 [1:51:36<2:17:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 537/1196 [1:51:48<2:17:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 538/1196 [1:52:01<2:17:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 539/1196 [1:52:13<2:16:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 540/1196 [1:52:26<2:16:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.641, 'learning_rate': 6.021891132531825e-05, 'epoch': 0.9}\u001b[0m\n",
      "\u001b[34m45%|████▌     | 540/1196 [1:52:26<2:16:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 541/1196 [1:52:38<2:16:20, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 542/1196 [1:52:51<2:16:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 543/1196 [1:53:03<2:15:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 544/1196 [1:53:16<2:15:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 545/1196 [1:53:28<2:15:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 546/1196 [1:53:41<2:15:22, 12.50s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 547/1196 [1:53:53<2:15:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 548/1196 [1:54:06<2:14:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 549/1196 [1:54:18<2:14:44, 12.50s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 550/1196 [1:54:31<2:14:32, 12.50s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7559, 'learning_rate': 5.8889774263466355e-05, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[34m46%|████▌     | 550/1196 [1:54:31<2:14:32, 12.50s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 551/1196 [1:54:43<2:14:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 552/1196 [1:54:56<2:14:07, 12.50s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 553/1196 [1:55:08<2:13:55, 12.50s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 554/1196 [1:55:21<2:13:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 555/1196 [1:55:33<2:13:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 556/1196 [1:55:45<2:13:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 557/1196 [1:55:58<2:13:04, 12.50s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 558/1196 [1:56:10<2:12:53, 12.50s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 559/1196 [1:56:23<2:12:40, 12.50s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 560/1196 [1:56:35<2:12:28, 12.50s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6981, 'learning_rate': 5.7554117196225846e-05, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[34m47%|████▋     | 560/1196 [1:56:35<2:12:28, 12.50s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 561/1196 [1:56:48<2:12:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 562/1196 [1:57:00<2:12:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 563/1196 [1:57:13<2:11:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 564/1196 [1:57:25<2:11:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 565/1196 [1:57:38<2:11:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 566/1196 [1:57:50<2:11:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 567/1196 [1:58:03<2:10:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 568/1196 [1:58:15<2:10:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 569/1196 [1:58:28<2:10:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 570/1196 [1:58:40<2:10:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7944, 'learning_rate': 5.621291973129177e-05, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 570/1196 [1:58:40<2:10:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 571/1196 [1:58:53<2:10:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 572/1196 [1:59:05<2:09:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 573/1196 [1:59:18<2:09:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 574/1196 [1:59:30<2:09:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 575/1196 [1:59:43<2:09:20, 12.50s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 576/1196 [1:59:55<2:09:08, 12.50s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 577/1196 [2:00:08<2:08:55, 12.50s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 578/1196 [2:00:20<2:08:42, 12.50s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 579/1196 [2:00:33<2:08:31, 12.50s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 580/1196 [2:00:45<2:08:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.7032, 'learning_rate': 5.486716553983951e-05, 'epoch': 0.97}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 580/1196 [2:00:45<2:08:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 581/1196 [2:00:58<2:08:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 582/1196 [2:01:10<2:07:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 583/1196 [2:01:23<2:07:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 584/1196 [2:01:35<2:07:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 585/1196 [2:01:48<2:07:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 586/1196 [2:02:00<2:06:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 587/1196 [2:02:13<2:06:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 588/1196 [2:02:25<2:06:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 589/1196 [2:02:38<2:06:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 590/1196 [2:02:50<2:06:05, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6965, 'learning_rate': 5.351784163507319e-05, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 590/1196 [2:02:50<2:06:05, 12.48s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 591/1196 [2:03:03<2:05:52, 12.48s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 592/1196 [2:03:15<2:05:40, 12.48s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 593/1196 [2:03:28<2:05:26, 12.48s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 594/1196 [2:03:40<2:05:15, 12.48s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 595/1196 [2:03:53<2:05:01, 12.48s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 596/1196 [2:04:05<2:04:49, 12.48s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 597/1196 [2:04:18<2:04:38, 12.48s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 598/1196 [2:04:30<2:04:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 599/1196 [2:04:44<2:07:11, 12.78s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 600/1196 [2:04:56<2:06:06, 12.69s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5028, 'learning_rate': 5.216593764832311e-05, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m50%|█████     | 600/1196 [2:04:56<2:06:06, 12.69s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 601/1196 [2:05:09<2:05:15, 12.63s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 602/1196 [2:05:21<2:04:36, 12.59s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 603/1196 [2:05:33<2:04:06, 12.56s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 604/1196 [2:05:46<2:03:39, 12.53s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 605/1196 [2:05:58<2:03:19, 12.52s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 606/1196 [2:06:11<2:03:01, 12.51s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 607/1196 [2:06:23<2:02:44, 12.50s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 608/1196 [2:06:36<2:02:27, 12.50s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 609/1196 [2:06:48<2:02:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 610/1196 [2:07:01<2:02:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4504, 'learning_rate': 5.081244510322274e-05, 'epoch': 1.02}\u001b[0m\n",
      "\u001b[34m51%|█████     | 610/1196 [2:07:01<2:02:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 611/1196 [2:07:13<2:01:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 612/1196 [2:07:26<2:01:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 613/1196 [2:07:38<2:01:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 614/1196 [2:07:51<2:01:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 615/1196 [2:08:03<2:00:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 616/1196 [2:08:16<2:00:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 617/1196 [2:08:28<2:00:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 618/1196 [2:08:41<2:00:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 619/1196 [2:08:53<2:00:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 620/1196 [2:09:06<1:59:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4438, 'learning_rate': 4.945835668849801e-05, 'epoch': 1.04}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 620/1196 [2:09:06<1:59:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 621/1196 [2:09:18<1:59:38, 12.48s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 622/1196 [2:09:31<1:59:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 623/1196 [2:09:43<1:59:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 624/1196 [2:09:56<1:59:02, 12.49s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 625/1196 [2:10:08<1:58:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 626/1196 [2:10:21<1:58:36, 12.49s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 627/1196 [2:10:33<1:58:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 628/1196 [2:10:46<1:58:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 629/1196 [2:10:58<1:58:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 630/1196 [2:11:11<1:57:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3491, 'learning_rate': 4.8104665529902075e-05, 'epoch': 1.05}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 630/1196 [2:11:11<1:57:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 631/1196 [2:11:23<1:57:36, 12.49s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 632/1196 [2:11:36<1:57:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 633/1196 [2:11:48<1:57:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 634/1196 [2:12:01<1:57:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 635/1196 [2:12:13<1:56:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 636/1196 [2:12:26<1:56:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 637/1196 [2:12:38<1:56:20, 12.49s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 638/1196 [2:12:51<1:56:06, 12.48s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 639/1196 [2:13:03<1:55:53, 12.48s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 640/1196 [2:13:15<1:55:40, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4624, 'learning_rate': 4.675236446182946e-05, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 640/1196 [2:13:16<1:55:40, 12.48s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 641/1196 [2:13:28<1:55:27, 12.48s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 642/1196 [2:13:40<1:55:15, 12.48s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 643/1196 [2:13:53<1:55:03, 12.48s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 644/1196 [2:14:05<1:54:51, 12.48s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 645/1196 [2:14:18<1:54:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 646/1196 [2:14:30<1:54:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 647/1196 [2:14:43<1:54:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 648/1196 [2:14:55<1:54:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 649/1196 [2:15:08<1:53:49, 12.48s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 650/1196 [2:15:20<1:53:35, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3962, 'learning_rate': 4.540244529914406e-05, 'epoch': 1.09}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 650/1196 [2:15:20<1:53:35, 12.48s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 651/1196 [2:15:33<1:53:22, 12.48s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 652/1196 [2:15:45<1:53:10, 12.48s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 653/1196 [2:15:58<1:52:58, 12.48s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 654/1196 [2:16:10<1:52:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 655/1196 [2:16:23<1:52:34, 12.48s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 656/1196 [2:16:35<1:52:23, 12.49s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 657/1196 [2:16:48<1:52:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 658/1196 [2:17:00<1:51:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 659/1196 [2:17:13<1:51:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 660/1196 [2:17:25<1:51:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4356, 'learning_rate': 4.405589810975468e-05, 'epoch': 1.1}\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 660/1196 [2:17:25<1:51:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 661/1196 [2:17:38<1:51:18, 12.48s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 662/1196 [2:17:50<1:51:05, 12.48s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 663/1196 [2:18:03<1:50:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 664/1196 [2:18:15<1:50:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 665/1196 [2:18:28<1:50:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 666/1196 [2:18:40<1:50:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 667/1196 [2:18:53<1:50:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 668/1196 [2:19:05<1:49:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 669/1196 [2:19:18<1:49:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 670/1196 [2:19:30<1:49:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.519, 'learning_rate': 4.2713710488472006e-05, 'epoch': 1.12}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 670/1196 [2:19:30<1:49:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 671/1196 [2:19:43<1:49:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 672/1196 [2:19:55<1:49:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 673/1196 [2:20:08<1:48:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 674/1196 [2:20:20<1:48:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 675/1196 [2:20:33<1:48:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 676/1196 [2:20:45<1:48:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 677/1196 [2:20:57<1:48:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 678/1196 [2:21:10<1:47:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 679/1196 [2:21:22<1:47:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 680/1196 [2:21:35<1:47:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4644, 'learning_rate': 4.1376866832679385e-05, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 680/1196 [2:21:35<1:47:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 681/1196 [2:21:47<1:47:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 682/1196 [2:22:00<1:46:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 683/1196 [2:22:12<1:46:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 684/1196 [2:22:25<1:46:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 685/1196 [2:22:37<1:46:20, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 686/1196 [2:22:50<1:46:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 687/1196 [2:23:02<1:45:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 688/1196 [2:23:15<1:45:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 689/1196 [2:23:27<1:45:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 690/1196 [2:23:40<1:45:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4365, 'learning_rate': 4.0046347620348586e-05, 'epoch': 1.15}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 690/1196 [2:23:40<1:45:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 691/1196 [2:23:52<1:45:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 692/1196 [2:24:05<1:44:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 693/1196 [2:24:17<1:44:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 694/1196 [2:24:30<1:44:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 695/1196 [2:24:42<1:44:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 696/1196 [2:24:55<1:44:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 697/1196 [2:25:07<1:43:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 698/1196 [2:25:20<1:43:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 699/1196 [2:25:32<1:43:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 700/1196 [2:25:45<1:43:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.64, 'learning_rate': 3.8723128690930296e-05, 'epoch': 1.17}\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 700/1196 [2:25:45<1:43:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 701/1196 [2:25:57<1:42:59, 12.48s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 702/1196 [2:26:10<1:42:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 703/1196 [2:26:22<1:42:36, 12.49s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 704/1196 [2:26:35<1:42:23, 12.49s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 705/1196 [2:26:47<1:42:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 706/1196 [2:27:00<1:41:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 707/1196 [2:27:12<1:41:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 708/1196 [2:27:25<1:41:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 709/1196 [2:27:37<1:41:23, 12.49s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 710/1196 [2:27:50<1:41:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4656, 'learning_rate': 3.7408180529646596e-05, 'epoch': 1.19}\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 710/1196 [2:27:50<1:41:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 711/1196 [2:28:02<1:40:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 712/1196 [2:28:15<1:40:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 713/1196 [2:28:27<1:40:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 714/1196 [2:28:40<1:40:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 715/1196 [2:28:52<1:40:09, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 716/1196 [2:29:05<1:39:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 717/1196 [2:29:17<1:39:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 718/1196 [2:29:30<1:39:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 719/1196 [2:29:42<1:39:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 720/1196 [2:29:55<1:39:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4511, 'learning_rate': 3.6102467555710295e-05, 'epoch': 1.2}\u001b[0m\n",
      "\u001b[34m60%|██████    | 720/1196 [2:29:55<1:39:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 721/1196 [2:30:07<1:38:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 722/1196 [2:30:19<1:38:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 723/1196 [2:30:32<1:38:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 724/1196 [2:30:44<1:38:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 725/1196 [2:30:57<1:38:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 726/1196 [2:31:09<1:37:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 727/1196 [2:31:22<1:37:36, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 728/1196 [2:31:34<1:37:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 729/1196 [2:31:47<1:37:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 730/1196 [2:31:59<1:37:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3672, 'learning_rate': 3.480694741499334e-05, 'epoch': 1.22}\u001b[0m\n",
      "\u001b[34m61%|██████    | 730/1196 [2:31:59<1:37:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 731/1196 [2:32:12<1:36:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 732/1196 [2:32:24<1:36:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 733/1196 [2:32:37<1:36:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 734/1196 [2:32:49<1:36:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 735/1196 [2:33:02<1:35:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 736/1196 [2:33:14<1:35:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 737/1196 [2:33:27<1:35:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 738/1196 [2:33:39<1:35:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 739/1196 [2:33:52<1:35:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 740/1196 [2:34:04<1:34:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3436, 'learning_rate': 3.3522570277662985e-05, 'epoch': 1.24}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 740/1196 [2:34:04<1:34:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 741/1196 [2:34:17<1:34:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 742/1196 [2:34:29<1:34:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 743/1196 [2:34:42<1:34:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 744/1196 [2:34:54<1:34:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 745/1196 [2:35:07<1:33:50, 12.48s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 746/1196 [2:35:19<1:33:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 747/1196 [2:35:32<1:33:25, 12.48s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 748/1196 [2:35:44<1:33:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 749/1196 [2:35:57<1:33:00, 12.48s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 750/1196 [2:36:09<1:32:48, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4513, 'learning_rate': 3.225027814130074e-05, 'epoch': 1.25}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 750/1196 [2:36:09<1:32:48, 12.48s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 751/1196 [2:36:22<1:32:35, 12.48s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 752/1196 [2:36:34<1:32:23, 12.49s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 753/1196 [2:36:47<1:32:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 754/1196 [2:36:59<1:31:58, 12.48s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 755/1196 [2:37:12<1:31:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 756/1196 [2:37:24<1:31:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 757/1196 [2:37:37<1:31:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 758/1196 [2:37:49<1:31:09, 12.49s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 759/1196 [2:38:02<1:30:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 760/1196 [2:38:14<1:30:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3221, 'learning_rate': 3.09910041400154e-05, 'epoch': 1.27}\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 760/1196 [2:38:14<1:30:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 761/1196 [2:38:26<1:30:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 762/1196 [2:38:39<1:30:20, 12.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 763/1196 [2:38:51<1:30:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 764/1196 [2:39:04<1:29:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 765/1196 [2:39:16<1:29:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 766/1196 [2:39:29<1:29:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 767/1196 [2:39:41<1:29:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 768/1196 [2:39:54<1:29:03, 12.48s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 769/1196 [2:40:06<1:28:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 770/1196 [2:40:19<1:28:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3562, 'learning_rate': 2.9745671860056868e-05, 'epoch': 1.29}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 770/1196 [2:40:19<1:28:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 771/1196 [2:40:31<1:28:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 772/1196 [2:40:44<1:28:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 773/1196 [2:40:56<1:28:01, 12.48s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 774/1196 [2:41:09<1:27:47, 12.48s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 775/1196 [2:41:21<1:27:34, 12.48s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 776/1196 [2:41:34<1:27:22, 12.48s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 777/1196 [2:41:46<1:27:10, 12.48s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 778/1196 [2:41:59<1:26:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 779/1196 [2:42:11<1:26:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 780/1196 [2:42:24<1:26:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.42, 'learning_rate': 2.851519466243242e-05, 'epoch': 1.3}\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 780/1196 [2:42:24<1:26:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 781/1196 [2:42:36<1:26:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 782/1196 [2:42:49<1:26:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 783/1196 [2:43:01<1:25:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 784/1196 [2:43:14<1:25:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 785/1196 [2:43:26<1:25:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 786/1196 [2:43:39<1:25:20, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 787/1196 [2:43:51<1:25:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 788/1196 [2:44:04<1:24:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 789/1196 [2:44:16<1:24:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 790/1196 [2:44:29<1:24:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.426, 'learning_rate': 2.7300475013022663e-05, 'epoch': 1.32}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 790/1196 [2:44:29<1:24:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 791/1196 [2:44:41<1:24:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 792/1196 [2:44:54<1:24:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 793/1196 [2:45:06<1:23:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 794/1196 [2:45:19<1:23:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 795/1196 [2:45:31<1:23:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 796/1196 [2:45:44<1:23:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 797/1196 [2:45:56<1:23:02, 12.49s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 798/1196 [2:46:09<1:22:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 799/1196 [2:46:21<1:22:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 800/1196 [2:46:34<1:22:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3617, 'learning_rate': 2.6102403820688177e-05, 'epoch': 1.34}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 800/1196 [2:46:34<1:22:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 801/1196 [2:46:46<1:22:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 802/1196 [2:46:58<1:21:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 803/1196 [2:47:11<1:21:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 804/1196 [2:47:23<1:21:33, 12.48s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 805/1196 [2:47:36<1:21:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 806/1196 [2:47:48<1:21:09, 12.48s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 807/1196 [2:48:01<1:20:56, 12.48s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 808/1196 [2:48:13<1:20:44, 12.48s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 809/1196 [2:48:26<1:20:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 810/1196 [2:48:38<1:20:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3315, 'learning_rate': 2.4921859783852408e-05, 'epoch': 1.35}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 810/1196 [2:48:38<1:20:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 811/1196 [2:48:51<1:20:06, 12.48s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 812/1196 [2:49:03<1:19:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 813/1196 [2:49:16<1:19:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 814/1196 [2:49:28<1:19:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 815/1196 [2:49:41<1:19:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 816/1196 [2:49:53<1:19:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 817/1196 [2:50:06<1:18:51, 12.48s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 818/1196 [2:50:18<1:18:38, 12.48s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 819/1196 [2:50:31<1:18:25, 12.48s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 820/1196 [2:50:43<1:18:13, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.319, 'learning_rate': 2.3759708746039976e-05, 'epoch': 1.37}\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 820/1196 [2:50:43<1:18:13, 12.48s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 821/1196 [2:50:56<1:18:02, 12.49s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 822/1196 [2:51:08<1:17:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 823/1196 [2:51:21<1:17:36, 12.48s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 824/1196 [2:51:33<1:17:23, 12.48s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 825/1196 [2:51:46<1:17:10, 12.48s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 826/1196 [2:51:58<1:16:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 827/1196 [2:52:11<1:16:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 828/1196 [2:52:23<1:16:34, 12.48s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 829/1196 [2:52:36<1:16:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 830/1196 [2:52:48<1:16:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3931, 'learning_rate': 2.2616803060843283e-05, 'epoch': 1.39}\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 830/1196 [2:52:48<1:16:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 831/1196 [2:53:01<1:15:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 832/1196 [2:53:13<1:15:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 833/1196 [2:53:26<1:15:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 834/1196 [2:53:38<1:15:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 835/1196 [2:53:51<1:15:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 836/1196 [2:54:03<1:14:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 837/1196 [2:54:16<1:14:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 838/1196 [2:54:28<1:14:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 839/1196 [2:54:40<1:14:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 840/1196 [2:54:53<1:14:04, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3233, 'learning_rate': 2.149398096678283e-05, 'epoch': 1.4}\u001b[0m\n",
      "\u001b[34m70%|███████   | 840/1196 [2:54:53<1:14:04, 12.48s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 841/1196 [2:55:05<1:13:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 842/1196 [2:55:18<1:13:39, 12.48s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 843/1196 [2:55:30<1:13:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 844/1196 [2:55:43<1:13:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 845/1196 [2:55:55<1:13:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 846/1196 [2:56:08<1:12:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 847/1196 [2:56:20<1:12:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 848/1196 [2:56:33<1:12:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 849/1196 [2:56:45<1:12:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 850/1196 [2:56:58<1:11:59, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3657, 'learning_rate': 2.039206597252001e-05, 'epoch': 1.42}\u001b[0m\n",
      "\u001b[34m71%|███████   | 850/1196 [2:56:58<1:11:59, 12.48s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 851/1196 [2:57:10<1:11:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 852/1196 [2:57:23<1:11:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 853/1196 [2:57:35<1:11:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 854/1196 [2:57:48<1:11:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 855/1196 [2:58:00<1:10:56, 12.48s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 856/1196 [2:58:13<1:10:44, 12.48s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 857/1196 [2:58:25<1:10:31, 12.48s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 858/1196 [2:58:38<1:10:19, 12.48s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 859/1196 [2:58:50<1:10:05, 12.48s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 860/1196 [2:59:03<1:09:53, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3307, 'learning_rate': 1.931186625287313e-05, 'epoch': 1.44}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 860/1196 [2:59:03<1:09:53, 12.48s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 861/1196 [2:59:15<1:09:40, 12.48s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 862/1196 [2:59:28<1:09:29, 12.48s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 863/1196 [2:59:40<1:09:17, 12.48s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 864/1196 [2:59:53<1:09:04, 12.48s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 865/1196 [3:00:05<1:08:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 866/1196 [3:00:18<1:08:39, 12.48s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 867/1196 [3:00:30<1:08:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 868/1196 [3:00:43<1:08:14, 12.48s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 869/1196 [3:00:55<1:08:01, 12.48s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 870/1196 [3:01:07<1:07:49, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5292, 'learning_rate': 1.82541740560798e-05, 'epoch': 1.45}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 870/1196 [3:01:07<1:07:49, 12.48s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 871/1196 [3:01:20<1:07:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 872/1196 [3:01:32<1:07:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 873/1196 [3:01:45<1:07:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 874/1196 [3:01:57<1:07:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 875/1196 [3:02:10<1:06:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 876/1196 [3:02:22<1:06:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 877/1196 [3:02:35<1:06:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 878/1196 [3:02:47<1:06:09, 12.48s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 879/1196 [3:03:00<1:05:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 880/1196 [3:03:12<1:05:44, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4025, 'learning_rate': 1.72197651227402e-05, 'epoch': 1.47}\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 880/1196 [3:03:12<1:05:44, 12.48s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 881/1196 [3:03:25<1:05:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 882/1196 [3:03:37<1:05:20, 12.48s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 883/1196 [3:03:50<1:05:07, 12.48s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 884/1196 [3:04:02<1:04:55, 12.48s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 885/1196 [3:04:15<1:04:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 886/1196 [3:04:27<1:04:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 887/1196 [3:04:40<1:04:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 888/1196 [3:04:52<1:04:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 889/1196 [3:05:05<1:03:52, 12.48s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 890/1196 [3:05:17<1:03:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4313, 'learning_rate': 1.6209398116867574e-05, 'epoch': 1.49}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 890/1196 [3:05:17<1:03:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 891/1196 [3:05:30<1:03:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 892/1196 [3:05:42<1:03:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 893/1196 [3:05:55<1:03:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 894/1196 [3:06:07<1:02:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 895/1196 [3:06:20<1:02:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 896/1196 [3:06:32<1:02:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 897/1196 [3:06:45<1:02:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 898/1196 [3:06:57<1:02:03, 12.50s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 899/1196 [3:07:10<1:01:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 900/1196 [3:07:22<1:01:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2731, 'learning_rate': 1.5223814069463078e-05, 'epoch': 1.51}\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 900/1196 [3:07:22<1:01:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 901/1196 [3:07:35<1:01:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 902/1196 [3:07:47<1:01:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 903/1196 [3:08:00<1:00:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 904/1196 [3:08:12<1:00:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 905/1196 [3:08:25<1:00:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 906/1196 [3:08:37<1:00:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 907/1196 [3:08:50<1:00:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 908/1196 [3:09:02<59:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 909/1196 [3:09:15<59:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 910/1196 [3:09:27<59:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3545, 'learning_rate': 1.4263735835023317e-05, 'epoch': 1.52}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 910/1196 [3:09:27<59:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 911/1196 [3:09:39<59:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 912/1196 [3:09:52<59:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 913/1196 [3:10:04<58:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 914/1196 [3:10:17<58:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 915/1196 [3:10:29<58:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 916/1196 [3:10:42<58:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 917/1196 [3:10:54<58:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 918/1196 [3:11:07<57:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 919/1196 [3:11:19<57:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 920/1196 [3:11:32<57:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2943, 'learning_rate': 1.332986756137889e-05, 'epoch': 1.54}\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 920/1196 [3:11:32<57:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 921/1196 [3:11:44<57:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 922/1196 [3:11:57<57:02, 12.49s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 923/1196 [3:12:09<56:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 924/1196 [3:12:22<56:45, 12.52s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 925/1196 [3:12:34<56:30, 12.51s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 926/1196 [3:12:47<56:14, 12.50s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 927/1196 [3:12:59<56:01, 12.50s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 928/1196 [3:13:12<55:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 929/1196 [3:13:24<55:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 930/1196 [3:13:37<55:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3686, 'learning_rate': 1.2422894173252935e-05, 'epoch': 1.56}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 930/1196 [3:13:37<55:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 931/1196 [3:13:49<55:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 932/1196 [3:14:02<54:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 933/1196 [3:14:14<54:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 934/1196 [3:14:27<54:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 935/1196 [3:14:39<54:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 936/1196 [3:14:52<54:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 937/1196 [3:15:04<53:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 938/1196 [3:15:17<53:41, 12.48s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 939/1196 [3:15:29<53:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 940/1196 [3:15:42<53:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5085, 'learning_rate': 1.1543480869918555e-05, 'epoch': 1.57}\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 940/1196 [3:15:42<53:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 941/1196 [3:15:54<53:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 942/1196 [3:16:07<52:51, 12.48s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 943/1196 [3:16:19<52:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 944/1196 [3:16:32<52:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 945/1196 [3:16:44<52:13, 12.48s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 946/1196 [3:16:57<52:01, 12.48s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 947/1196 [3:17:09<51:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 948/1196 [3:17:22<51:36, 12.48s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 949/1196 [3:17:34<51:23, 12.48s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 950/1196 [3:17:47<51:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3062, 'learning_rate': 1.0692272637323281e-05, 'epoch': 1.59}\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 950/1196 [3:17:47<51:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 951/1196 [3:17:59<50:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 952/1196 [3:18:12<50:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 953/1196 [3:18:24<50:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 954/1196 [3:18:37<50:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 955/1196 [3:18:49<50:09, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 956/1196 [3:19:02<49:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 957/1196 [3:19:14<49:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 958/1196 [3:19:26<49:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 959/1196 [3:19:39<49:20, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 960/1196 [3:19:51<49:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3723, 'learning_rate': 9.869893775038558e-06, 'epoch': 1.61}\u001b[0m\n",
      "\u001b[34m80%|████████  | 960/1196 [3:19:51<49:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 961/1196 [3:20:04<48:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 962/1196 [3:20:16<48:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 963/1196 [3:20:29<48:30, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 964/1196 [3:20:41<48:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 965/1196 [3:20:54<48:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 966/1196 [3:21:06<47:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 967/1196 [3:21:19<47:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 968/1196 [3:21:31<47:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 969/1196 [3:21:44<47:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 970/1196 [3:21:56<47:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.319, 'learning_rate': 9.076947438381412e-06, 'epoch': 1.62}\u001b[0m\n",
      "\u001b[34m81%|████████  | 970/1196 [3:21:56<47:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 971/1196 [3:22:09<46:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 972/1196 [3:22:21<46:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 973/1196 [3:22:34<46:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 974/1196 [3:22:46<46:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 975/1196 [3:22:59<46:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 976/1196 [3:23:11<45:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 977/1196 [3:23:24<45:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 978/1196 [3:23:36<45:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 979/1196 [3:23:49<45:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 980/1196 [3:24:01<44:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.405, 'learning_rate': 8.3140151960435e-06, 'epoch': 1.64}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 980/1196 [3:24:01<44:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 981/1196 [3:24:14<44:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 982/1196 [3:24:26<44:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 983/1196 [3:24:39<44:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 984/1196 [3:24:51<44:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 985/1196 [3:25:04<43:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 986/1196 [3:25:16<43:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 987/1196 [3:25:29<43:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 988/1196 [3:25:41<43:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 989/1196 [3:25:54<43:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 990/1196 [3:26:06<42:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4261, 'learning_rate': 7.581656603552745e-06, 'epoch': 1.66}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 990/1196 [3:26:06<42:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 991/1196 [3:26:19<42:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 992/1196 [3:26:31<42:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 993/1196 [3:26:44<42:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 994/1196 [3:26:56<42:02, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 995/1196 [3:27:09<41:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 996/1196 [3:27:21<41:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 997/1196 [3:27:34<41:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 998/1196 [3:27:46<41:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 999/1196 [3:27:59<41:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1000/1196 [3:28:11<40:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3842, 'learning_rate': 6.880408792879905e-06, 'epoch': 1.67}\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1000/1196 [3:28:11<40:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 1001/1196 [3:28:24<40:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1002/1196 [3:28:36<40:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1003/1196 [3:28:48<40:09, 12.49s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1004/1196 [3:29:01<39:56, 12.48s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1005/1196 [3:29:13<39:44, 12.48s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1006/1196 [3:29:26<39:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1007/1196 [3:29:38<39:20, 12.49s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1008/1196 [3:29:51<39:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1009/1196 [3:30:03<38:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1010/1196 [3:30:16<38:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2797, 'learning_rate': 6.210786078491087e-06, 'epoch': 1.69}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 1010/1196 [3:30:16<38:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1011/1196 [3:30:28<38:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1012/1196 [3:30:41<38:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1013/1196 [3:30:53<38:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1014/1196 [3:31:06<37:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1015/1196 [3:31:18<37:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 1016/1196 [3:31:31<37:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1017/1196 [3:31:43<37:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1018/1196 [3:31:56<37:02, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1019/1196 [3:32:08<36:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1020/1196 [3:32:21<36:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3854, 'learning_rate': 5.573279580135438e-06, 'epoch': 1.71}\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1020/1196 [3:32:21<36:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1021/1196 [3:32:33<36:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 1022/1196 [3:32:46<36:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1023/1196 [3:32:58<36:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1024/1196 [3:33:11<35:47, 12.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1025/1196 [3:33:23<35:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1026/1196 [3:33:36<35:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1027/1196 [3:33:48<35:09, 12.48s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1028/1196 [3:34:01<34:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1029/1196 [3:34:13<34:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1030/1196 [3:34:26<34:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.315, 'learning_rate': 4.9683568626443525e-06, 'epoch': 1.72}\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1030/1196 [3:34:26<34:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 1031/1196 [3:34:38<34:20, 12.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1032/1196 [3:34:51<34:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1033/1196 [3:35:03<33:55, 12.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 1034/1196 [3:35:16<33:42, 12.48s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1035/1196 [3:35:28<33:29, 12.48s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1036/1196 [3:35:41<33:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1037/1196 [3:35:53<33:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1038/1196 [3:36:06<32:53, 12.49s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1039/1196 [3:36:18<32:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1040/1196 [3:36:31<32:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4395, 'learning_rate': 4.396461593006512e-06, 'epoch': 1.74}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1040/1196 [3:36:31<32:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1041/1196 [3:36:43<32:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1042/1196 [3:36:55<32:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1043/1196 [3:37:08<31:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1044/1196 [3:37:20<31:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1045/1196 [3:37:33<31:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 1046/1196 [3:37:45<31:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1047/1196 [3:37:58<31:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1048/1196 [3:38:10<30:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1049/1196 [3:38:23<30:35, 12.49s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1050/1196 [3:38:35<30:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3647, 'learning_rate': 3.858013214970363e-06, 'epoch': 1.76}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1050/1196 [3:38:35<30:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1051/1196 [3:38:48<30:10, 12.48s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1052/1196 [3:39:00<29:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1053/1196 [3:39:13<29:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1054/1196 [3:39:25<29:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1055/1196 [3:39:38<29:20, 12.48s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1056/1196 [3:39:50<29:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1057/1196 [3:40:03<28:55, 12.48s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 1058/1196 [3:40:15<28:42, 12.48s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1059/1196 [3:40:28<28:30, 12.48s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1060/1196 [3:40:40<28:17, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1896, 'learning_rate': 3.35340664141246e-06, 'epoch': 1.77}\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1060/1196 [3:40:40<28:17, 12.48s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 1061/1196 [3:40:53<28:05, 12.49s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1062/1196 [3:41:05<27:53, 12.49s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1063/1196 [3:41:18<27:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1064/1196 [3:41:30<27:28, 12.49s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1065/1196 [3:41:43<27:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1066/1196 [3:41:55<27:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1067/1196 [3:42:08<26:50, 12.49s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1068/1196 [3:42:20<26:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1069/1196 [3:42:33<26:25, 12.49s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1070/1196 [3:42:45<26:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3206, 'learning_rate': 2.8830119646974795e-06, 'epoch': 1.79}\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 1070/1196 [3:42:45<26:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1071/1196 [3:42:58<26:00, 12.48s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1072/1196 [3:43:10<25:47, 12.48s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1073/1196 [3:43:23<25:35, 12.48s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1074/1196 [3:43:35<25:23, 12.49s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1075/1196 [3:43:48<25:10, 12.49s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 1076/1196 [3:44:00<24:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1077/1196 [3:44:13<24:45, 12.49s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1078/1196 [3:44:25<24:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1079/1196 [3:44:37<24:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1080/1196 [3:44:50<24:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.344, 'learning_rate': 2.4471741852423237e-06, 'epoch': 1.81}\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1080/1196 [3:44:50<24:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1081/1196 [3:45:02<23:55, 12.48s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 1082/1196 [3:45:15<23:43, 12.49s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1083/1196 [3:45:27<23:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1084/1196 [3:45:40<23:18, 12.49s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1085/1196 [3:45:52<23:05, 12.48s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1086/1196 [3:46:05<22:53, 12.49s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1087/1196 [3:46:17<22:40, 12.49s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1088/1196 [3:46:30<22:28, 12.48s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1089/1196 [3:46:42<22:15, 12.49s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1090/1196 [3:46:55<22:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2935, 'learning_rate': 2.046212958483268e-06, 'epoch': 1.82}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1090/1196 [3:46:55<22:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 1091/1196 [3:47:07<21:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1092/1196 [3:47:20<21:38, 12.49s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1093/1196 [3:47:32<21:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 1094/1196 [3:47:45<21:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1095/1196 [3:47:57<21:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1096/1196 [3:48:10<20:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1097/1196 [3:48:22<20:36, 12.49s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1098/1196 [3:48:35<20:23, 12.49s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1099/1196 [3:48:47<20:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1100/1196 [3:49:00<19:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3103, 'learning_rate': 1.6804223604318825e-06, 'epoch': 1.84}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1100/1196 [3:49:00<19:58, 12.49s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1101/1196 [3:49:12<19:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1102/1196 [3:49:25<19:33, 12.48s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1103/1196 [3:49:37<19:21, 12.49s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1104/1196 [3:49:50<19:08, 12.49s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1105/1196 [3:50:02<18:56, 12.49s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 1106/1196 [3:50:15<18:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1107/1196 [3:50:27<18:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1108/1196 [3:50:40<18:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1109/1196 [3:50:52<18:06, 12.49s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1110/1196 [3:51:05<17:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3015, 'learning_rate': 1.350070671991549e-06, 'epoch': 1.86}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1110/1196 [3:51:05<17:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1111/1196 [3:51:17<17:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1112/1196 [3:51:30<17:28, 12.48s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1113/1196 [3:51:42<17:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1114/1196 [3:51:55<17:03, 12.49s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1115/1196 [3:52:07<16:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1116/1196 [3:52:20<16:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1117/1196 [3:52:32<16:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 1118/1196 [3:52:44<16:13, 12.49s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1119/1196 [3:52:57<16:01, 12.49s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1120/1196 [3:53:09<15:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.4286, 'learning_rate': 1.055400182192906e-06, 'epoch': 1.87}\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1120/1196 [3:53:09<15:48, 12.49s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 1121/1196 [3:53:22<15:36, 12.49s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1122/1196 [3:53:34<15:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1123/1196 [3:53:47<15:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1124/1196 [3:53:59<14:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1125/1196 [3:54:12<14:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1126/1196 [3:54:24<14:33, 12.49s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1127/1196 [3:54:37<14:21, 12.48s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1128/1196 [3:54:49<14:08, 12.48s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1129/1196 [3:55:02<13:56, 12.48s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1130/1196 [3:55:14<13:43, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2817, 'learning_rate': 7.966270104923457e-07, 'epoch': 1.89}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 1130/1196 [3:55:14<13:43, 12.48s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1131/1196 [3:55:27<13:31, 12.49s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1132/1196 [3:55:39<13:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1133/1196 [3:55:52<13:06, 12.48s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1134/1196 [3:56:04<12:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1135/1196 [3:56:17<12:41, 12.49s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 1136/1196 [3:56:29<12:29, 12.48s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1137/1196 [3:56:42<12:16, 12.49s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1138/1196 [3:56:54<12:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1139/1196 [3:57:07<11:51, 12.49s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1140/1196 [3:57:19<11:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3936, 'learning_rate': 5.739409482640956e-07, 'epoch': 1.91}\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1140/1196 [3:57:19<11:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1141/1196 [3:57:32<11:26, 12.49s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 1142/1196 [3:57:44<11:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1143/1196 [3:57:57<11:02, 12.49s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1144/1196 [3:58:09<10:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1145/1196 [3:58:22<10:36, 12.49s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1146/1196 [3:58:34<10:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1147/1196 [3:58:47<10:11, 12.49s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1148/1196 [3:58:59<09:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1149/1196 [3:59:12<09:46, 12.49s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1150/1196 [3:59:24<09:34, 12.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3182, 'learning_rate': 3.8750531960194404e-07, 'epoch': 1.92}\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1150/1196 [3:59:24<09:34, 12.48s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 1151/1196 [3:59:37<09:21, 12.48s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1152/1196 [3:59:49<09:09, 12.48s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1153/1196 [4:00:01<08:56, 12.48s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 1154/1196 [4:00:14<08:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1155/1196 [4:00:26<08:31, 12.48s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1156/1196 [4:00:39<08:19, 12.48s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1157/1196 [4:00:51<08:06, 12.48s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1158/1196 [4:01:04<07:54, 12.49s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1159/1196 [4:01:16<07:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1160/1196 [4:01:29<07:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2902, 'learning_rate': 2.3745686153290313e-07, 'epoch': 1.94}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1160/1196 [4:01:29<07:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1161/1196 [4:01:41<07:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1162/1196 [4:01:54<07:04, 12.49s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1163/1196 [4:02:06<06:52, 12.49s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1164/1196 [4:02:19<06:39, 12.49s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1165/1196 [4:02:31<06:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 1166/1196 [4:02:44<06:14, 12.48s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1167/1196 [4:02:56<06:02, 12.48s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1168/1196 [4:03:09<05:49, 12.48s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1169/1196 [4:03:21<05:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1170/1196 [4:03:34<05:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2837, 'learning_rate': 1.2390562373046367e-07, 'epoch': 1.96}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1170/1196 [4:03:34<05:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1171/1196 [4:03:46<05:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1172/1196 [4:03:59<04:59, 12.49s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1173/1196 [4:04:11<04:47, 12.48s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1174/1196 [4:04:24<04:34, 12.49s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1175/1196 [4:04:36<04:22, 12.49s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1176/1196 [4:04:49<04:09, 12.49s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1177/1196 [4:05:01<03:57, 12.49s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 1178/1196 [4:05:14<03:44, 12.49s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1179/1196 [4:05:26<03:32, 12.49s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1180/1196 [4:05:39<03:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3194, 'learning_rate': 4.6934887801164396e-08, 'epoch': 1.97}\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1180/1196 [4:05:39<03:19, 12.49s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 1181/1196 [4:05:51<03:07, 12.49s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1182/1196 [4:06:04<02:54, 12.48s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1183/1196 [4:06:16<02:42, 12.49s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1184/1196 [4:06:29<02:29, 12.49s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1185/1196 [4:06:41<02:17, 12.49s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1186/1196 [4:06:54<02:04, 12.48s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1187/1196 [4:07:06<01:52, 12.48s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1188/1196 [4:07:18<01:39, 12.48s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1189/1196 [4:07:31<01:27, 12.49s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1190/1196 [4:07:43<01:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.3146, 'learning_rate': 6.601106203535379e-09, 'epoch': 1.99}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 1190/1196 [4:07:43<01:14, 12.49s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1191/1196 [4:07:56<01:02, 12.49s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1192/1196 [4:08:08<00:49, 12.49s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1193/1196 [4:08:21<00:37, 12.49s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1194/1196 [4:08:33<00:24, 12.49s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 1195/1196 [4:08:46<00:12, 12.49s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1196/1196 [4:08:58<00:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 14939.8787, 'train_samples_per_second': 0.08, 'train_steps_per_second': 0.08, 'train_loss': 0.6672635923659921, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 1196/1196 [4:08:59<00:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1196/1196 [4:08:59<00:00, 12.49s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.57s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.70s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.68s/it]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 1.60k/1.60k [00:00<00:00, 15.5MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 22.0MB/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json: 100%|██████████| 51.0/51.0 [00:00<00:00, 526kB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 101/101 [00:00<00:00, 1.04MB/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m2024-03-06 17:28:07,391 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-03-06 17:28:07,392 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-03-06 17:28:07,392 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-03-06 17:28:11 Uploading - Uploading generated training model\n",
      "2024-03-06 17:28:57 Completed - Training job completed\n",
      "Training seconds: 15692\n",
      "Billable seconds: 15692\n"
     ]
    }
   ],
   "source": [
    "finetune = FinetuneLLM(model_id='teknium/OpenHermes-2.5-Mistral-7B', \n",
    "                       finetune_id = 'ArmadilloZiplineQuiche',\n",
    "                       batch_size=1,\n",
    "                       merge_adapters=True,\n",
    "                       learning_rate='1e-4',\n",
    "                       training_input_path='s3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2024-Mar-06-teknium/OpenHermes-2.5-Mistral-7B-search-ArmadilloZiplineQuiche')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8201ed9-f91d-4af5-a93b-4cc550b9eae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-06-13-05-16-365/output/model/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune.model_s3_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8adccd3-9f2f-4e89-9f0f-7240360b6280",
   "metadata": {},
   "source": [
    "### These params worked better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db21b239-bf99-493c-819a-f9c26600e3d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-teknium-OpenHermes-2--2024-03-07-06-46-58-396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-07 06:46:59 Starting - Starting the training job...\n",
      "2024-03-07 06:47:25 Pending - Preparing the instances for training......\n",
      "2024-03-07 06:48:24 Downloading - Downloading input data...\n",
      "2024-03-07 06:48:59 Downloading - Downloading the training image.....................\n",
      "2024-03-07 06:52:15 Training - Training image download completed. Training in progress...\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:41,181 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:41,199 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:41,208 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:41,210 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:42,500 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.35.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.5/123.5 kB 7.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.5.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting optimum==1.14.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl.metadata (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.23.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.3 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.11.1)\u001b[0m\n",
      "\u001b[34mCollecting datasets==2.15.0 (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting auto-gptq (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (0.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (1.24.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2023.12.25)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting coloredlogs (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (14.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (2.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0->-r requirements.txt (line 9)) (2023.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (3.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes->-r requirements.txt (line 5)) (1.11.1)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of auto-gptq to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting auto-gptq (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from auto-gptq->-r requirements.txt (line 10)) (0.1.99)\u001b[0m\n",
      "\u001b[34mCollecting rouge (from auto-gptq->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting gekko (from auto-gptq->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading gekko-1.0.7-py3-none-any.whl.metadata (3.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (23.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.14.0->-r requirements.txt (line 3)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq->-r requirements.txt (line 10)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (2.1.3)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 78.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 12.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl (398 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 398.9/398.9 kB 55.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.1/258.1 kB 30.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 521.2/521.2 kB 50.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 MB 23.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 94.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 54.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 113.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 6.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading gekko-1.0.7-py3-none-any.whl (13.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.1/13.1 MB 72.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 13.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: safetensors, rouge, humanfriendly, gekko, coloredlogs, bitsandbytes, tokenizers, accelerate, transformers, datasets, peft, optimum, auto-gptq\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: datasets\u001b[0m\n",
      "\u001b[34mFound existing installation: datasets 2.16.1\u001b[0m\n",
      "\u001b[34mUninstalling datasets-2.16.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled datasets-2.16.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.23.0 auto-gptq-0.6.0 bitsandbytes-0.42.0 coloredlogs-15.0.1 datasets-2.15.0 gekko-1.0.7 humanfriendly-10.0 optimum-1.14.0 peft-0.5.0 rouge-1.0.1 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.35.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:57,256 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:57,256 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:57,296 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:57,325 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:57,353 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:57,362 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"gradient_accumulation_steps\": 3,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"learning_rate\": \"8e-5\",\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"cosine_with_restarts\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"teknium/OpenHermes-2.5-Mistral-7B\",\n",
      "        \"num_train_epochs\": 2,\n",
      "        \"output_dir\": \"/tmp/run\",\n",
      "        \"per_device_train_batch_size\": 2,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"trust_remote_code\": true,\n",
      "        \"use_flash_attn\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-teknium-OpenHermes-2--2024-03-07-06-46-58-396\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-07-06-46-58-396/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_qlora\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_qlora.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":3,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":\"8e-5\",\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":2,\"save_strategy\":\"epoch\",\"tf32\":true,\"trust_remote_code\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_qlora.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_qlora\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-07-06-46-58-396/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":3,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":\"8e-5\",\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":2,\"save_strategy\":\"epoch\",\"tf32\":true,\"trust_remote_code\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-teknium-OpenHermes-2--2024-03-07-06-46-58-396\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-07-06-46-58-396/source/sourcedir.tar.gz\",\"module_name\":\"run_qlora\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_qlora.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training\",\"--gradient_accumulation_steps\",\"3\",\"--gradient_checkpointing\",\"True\",\"--hf_token\",\"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\",\"--learning_rate\",\"8e-5\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"cosine_with_restarts\",\"--max_grad_norm\",\"0.3\",\"--merge_adapters\",\"True\",\"--model_id\",\"teknium/OpenHermes-2.5-Mistral-7B\",\"--num_train_epochs\",\"2\",\"--output_dir\",\"/tmp/run\",\"--per_device_train_batch_size\",\"2\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--trust_remote_code\",\"True\",\"--use_flash_attn\",\"True\",\"--warmup_ratio\",\"0.03\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=3\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=8e-5\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=cosine_with_restarts\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=teknium/OpenHermes-2.5-Mistral-7B\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=2\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/run\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_TRUST_REMOTE_CODE=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FLASH_ATTN=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 3 --gradient_checkpointing True --hf_token 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 --learning_rate 8e-5 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters True --model_id teknium/OpenHermes-2.5-Mistral-7B --num_train_epochs 2 --output_dir /tmp/run --per_device_train_batch_size 2 --save_strategy epoch --tf32 True --trust_remote_code True --use_flash_attn True --warmup_ratio 0.03\u001b[0m\n",
      "\u001b[34m2024-03-07 06:52:57,391 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flash-attn in /opt/conda/lib/python3.10/site-packages (0.2.8)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.5.6.tar.gz (2.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 78.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.5.6-cp310-cp310-linux_x86_64.whl size=121379983 sha256=4148bf354d8fa6e8afea1bc4961830c2a189271dc74ddd4b39049374a372b1f1\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/a8/1c/88/b959d6818b98a46d61ba231683abb7523b89ac1a7ed1e0c206\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mSuccessfully installed flash-attn-2.5.6\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mLogging into the Hugging Face Hub with token hf_NjVkEqg...\u001b[0m\n",
      "\u001b[34mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\u001b[0m\n",
      "\u001b[34mToken is valid (permission: write).\u001b[0m\n",
      "\u001b[34mYour token has been saved to /root/.cache/huggingface/token\u001b[0m\n",
      "\u001b[34mLogin successful\u001b[0m\n",
      "\u001b[34mUsing `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\u001b[0m\n",
      "\u001b[34mUsing `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/624 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 624/624 [00:00<00:00, 6.46MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 171MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 21.0M/9.94G [00:00<00:50, 197MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 41.9M/9.94G [00:00<00:53, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 73.4M/9.94G [00:00<00:49, 198MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 105M/9.94G [00:00<00:51, 192MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|▏         | 136M/9.94G [00:00<00:46, 210MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 168M/9.94G [00:00<00:46, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 199M/9.94G [00:00<00:43, 223MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 231M/9.94G [00:01<00:44, 219MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 262M/9.94G [00:01<00:41, 234MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 294M/9.94G [00:01<00:41, 235MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 325M/9.94G [00:01<00:40, 240MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▎         | 357M/9.94G [00:01<00:39, 240MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▍         | 388M/9.94G [00:01<00:41, 228MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▍         | 419M/9.94G [00:01<00:42, 225MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▍         | 451M/9.94G [00:02<00:39, 242MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▍         | 482M/9.94G [00:02<00:37, 251MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▌         | 514M/9.94G [00:02<00:41, 230MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▌         | 545M/9.94G [00:02<00:43, 217MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 577M/9.94G [00:02<00:41, 228MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 608M/9.94G [00:02<00:38, 239MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▋         | 640M/9.94G [00:02<00:39, 238MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 671M/9.94G [00:02<00:41, 221MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 703M/9.94G [00:03<00:44, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 734M/9.94G [00:03<00:42, 216MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 776M/9.94G [00:03<00:36, 249MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 818M/9.94G [00:03<00:33, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▊         | 860M/9.94G [00:03<00:30, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 902M/9.94G [00:03<00:30, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 933M/9.94G [00:03<00:31, 288MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|▉         | 965M/9.94G [00:04<00:30, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|█         | 996M/9.94G [00:04<00:30, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|█         | 1.04G/9.94G [00:04<00:28, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█         | 1.08G/9.94G [00:04<00:27, 326MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█▏        | 1.12G/9.94G [00:04<00:25, 341MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.16G/9.94G [00:04<00:24, 355MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.21G/9.94G [00:04<00:27, 313MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.25G/9.94G [00:04<00:29, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.28G/9.94G [00:05<00:33, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.31G/9.94G [00:05<00:36, 237MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.34G/9.94G [00:05<00:34, 249MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 1.37G/9.94G [00:05<00:33, 253MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 1.42G/9.94G [00:05<00:29, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▍        | 1.45G/9.94G [00:05<00:31, 269MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▍        | 1.48G/9.94G [00:05<00:33, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▌        | 1.51G/9.94G [00:05<00:33, 252MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.54G/9.94G [00:06<00:32, 258MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.57G/9.94G [00:06<00:32, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.60G/9.94G [00:06<00:36, 226MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▋        | 1.64G/9.94G [00:06<00:37, 224MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.67G/9.94G [00:06<00:41, 199MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.70G/9.94G [00:06<00:38, 215MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.73G/9.94G [00:06<00:35, 230MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.76G/9.94G [00:07<00:33, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.79G/9.94G [00:07<00:33, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.82G/9.94G [00:07<00:39, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▊        | 1.86G/9.94G [00:07<00:36, 220MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.89G/9.94G [00:07<00:35, 225MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.92G/9.94G [00:07<00:34, 235MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|█▉        | 1.95G/9.94G [00:07<00:31, 253MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|█▉        | 1.98G/9.94G [00:08<00:30, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|██        | 2.01G/9.94G [00:08<00:31, 250MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.04G/9.94G [00:08<00:29, 267MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.08G/9.94G [00:08<00:29, 267MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.11G/9.94G [00:08<00:30, 254MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.14G/9.94G [00:08<00:34, 228MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.18G/9.94G [00:08<00:29, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.22G/9.94G [00:08<00:26, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.25G/9.94G [00:09<00:26, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.30G/9.94G [00:09<00:27, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.33G/9.94G [00:09<00:29, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▎       | 2.36G/9.94G [00:09<00:30, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▍       | 2.39G/9.94G [00:09<00:30, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▍       | 2.42G/9.94G [00:09<00:30, 247MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▍       | 2.45G/9.94G [00:09<00:31, 236MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▌       | 2.50G/9.94G [00:09<00:27, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▌       | 2.53G/9.94G [00:10<00:34, 216MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.56G/9.94G [00:10<00:47, 156MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.58G/9.94G [00:10<00:51, 142MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.60G/9.94G [00:11<01:01, 120MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▋       | 2.63G/9.94G [00:11<00:49, 148MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.66G/9.94G [00:11<00:41, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.69G/9.94G [00:11<00:36, 197MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.73G/9.94G [00:11<00:34, 212MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.77G/9.94G [00:11<00:29, 241MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.80G/9.94G [00:11<00:32, 217MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.83G/9.94G [00:11<00:34, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.86G/9.94G [00:12<00:37, 187MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.88G/9.94G [00:12<00:38, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.90G/9.94G [00:12<00:42, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.93G/9.94G [00:12<00:48, 146MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|██▉       | 2.95G/9.94G [00:12<00:50, 138MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|██▉       | 2.97G/9.94G [00:12<00:51, 134MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|███       | 2.99G/9.94G [00:13<00:54, 127MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|███       | 3.01G/9.94G [00:13<00:57, 121MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|███       | 3.03G/9.94G [00:13<01:00, 113MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 3.05G/9.94G [00:13<01:02, 110MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 3.09G/9.94G [00:13<00:42, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███▏      | 3.12G/9.94G [00:14<00:37, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.16G/9.94G [00:14<00:34, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.19G/9.94G [00:14<00:32, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.22G/9.94G [00:14<00:30, 217MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.25G/9.94G [00:14<00:30, 220MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.29G/9.94G [00:14<00:26, 253MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.32G/9.94G [00:14<00:25, 258MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▎      | 3.36G/9.94G [00:14<00:24, 267MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▍      | 3.39G/9.94G [00:15<00:24, 267MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▍      | 3.42G/9.94G [00:15<00:23, 274MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▍      | 3.46G/9.94G [00:15<00:22, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▌      | 3.49G/9.94G [00:15<00:23, 280MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▌      | 3.52G/9.94G [00:15<00:22, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.55G/9.94G [00:15<00:22, 283MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.59G/9.94G [00:15<00:23, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▋      | 3.62G/9.94G [00:15<00:22, 276MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.65G/9.94G [00:15<00:23, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.68G/9.94G [00:16<00:23, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.71G/9.94G [00:16<00:24, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.74G/9.94G [00:16<00:22, 272MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.77G/9.94G [00:16<00:22, 276MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.81G/9.94G [00:16<00:22, 272MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▊      | 3.84G/9.94G [00:16<00:25, 243MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.87G/9.94G [00:16<00:23, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.90G/9.94G [00:16<00:22, 265MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|███▉      | 3.93G/9.94G [00:17<00:21, 277MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|███▉      | 3.97G/9.94G [00:17<00:21, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|████      | 4.02G/9.94G [00:17<00:20, 288MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.05G/9.94G [00:17<00:20, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.09G/9.94G [00:17<00:18, 321MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.13G/9.94G [00:17<00:19, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.16G/9.94G [00:17<00:22, 262MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.19G/9.94G [00:17<00:21, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.23G/9.94G [00:18<00:22, 257MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.26G/9.94G [00:18<00:22, 258MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.30G/9.94G [00:18<00:20, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▎     | 4.33G/9.94G [00:18<00:20, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▍     | 4.37G/9.94G [00:18<00:19, 288MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▍     | 4.40G/9.94G [00:18<00:19, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▍     | 4.44G/9.94G [00:18<00:21, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▍     | 4.47G/9.94G [00:18<00:21, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▌     | 4.50G/9.94G [00:19<00:20, 267MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.53G/9.94G [00:19<00:19, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.56G/9.94G [00:19<00:19, 272MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.59G/9.94G [00:19<00:20, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.63G/9.94G [00:19<00:19, 268MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.67G/9.94G [00:19<00:20, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.70G/9.94G [00:19<00:24, 215MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.73G/9.94G [00:20<00:27, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.77G/9.94G [00:20<00:22, 230MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.81G/9.94G [00:20<00:20, 251MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▊     | 4.84G/9.94G [00:20<00:19, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▉     | 4.89G/9.94G [00:20<00:18, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▉     | 4.92G/9.94G [00:20<00:17, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|████▉     | 4.95G/9.94G [00:20<00:17, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|█████     | 4.99G/9.94G [00:20<00:16, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.03G/9.94G [00:21<00:15, 311MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.06G/9.94G [00:21<00:16, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████▏    | 5.11G/9.94G [00:21<00:14, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.15G/9.94G [00:21<00:15, 318MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.19G/9.94G [00:21<00:14, 330MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.23G/9.94G [00:21<00:13, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.27G/9.94G [00:21<00:12, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.32G/9.94G [00:21<00:12, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▍    | 5.36G/9.94G [00:22<00:12, 354MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▍    | 5.40G/9.94G [00:22<00:13, 344MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▍    | 5.44G/9.94G [00:22<00:13, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▌    | 5.48G/9.94G [00:22<00:14, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.53G/9.94G [00:22<00:15, 287MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.56G/9.94G [00:22<00:15, 283MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▋    | 5.60G/9.94G [00:22<00:14, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.64G/9.94G [00:22<00:13, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.68G/9.94G [00:23<00:12, 345MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.73G/9.94G [00:23<00:12, 346MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.77G/9.94G [00:23<00:12, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.81G/9.94G [00:23<00:12, 339MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.85G/9.94G [00:23<00:12, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.89G/9.94G [00:23<00:14, 283MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|█████▉    | 5.92G/9.94G [00:23<00:16, 238MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|█████▉    | 5.96G/9.94G [00:24<00:18, 218MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|██████    | 5.99G/9.94G [00:24<00:24, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|██████    | 6.01G/9.94G [00:24<00:25, 152MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.03G/9.94G [00:24<00:28, 137MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.05G/9.94G [00:25<00:31, 125MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.07G/9.94G [00:25<00:32, 120MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████▏   | 6.09G/9.94G [00:25<00:31, 122MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.12G/9.94G [00:25<00:27, 138MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.14G/9.94G [00:25<00:29, 128MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.17G/9.94G [00:25<00:30, 124MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.21G/9.94G [00:26<00:21, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.23G/9.94G [00:26<00:24, 150MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.25G/9.94G [00:26<00:26, 137MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.27G/9.94G [00:26<00:29, 125MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.29G/9.94G [00:26<00:30, 120MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.31G/9.94G [00:27<00:31, 116MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▎   | 6.33G/9.94G [00:27<00:32, 110MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.35G/9.94G [00:27<00:33, 108MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.38G/9.94G [00:27<00:33, 108MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.40G/9.94G [00:27<00:33, 106MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.43G/9.94G [00:28<00:24, 141MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.46G/9.94G [00:28<00:19, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.50G/9.94G [00:28<00:15, 222MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.55G/9.94G [00:28<00:12, 277MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▋   | 6.60G/9.94G [00:28<00:11, 298MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.64G/9.94G [00:28<00:10, 311MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.68G/9.94G [00:28<00:10, 312MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.72G/9.94G [00:28<00:10, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.76G/9.94G [00:28<00:09, 334MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▊   | 6.82G/9.94G [00:29<00:08, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.86G/9.94G [00:29<00:09, 319MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.90G/9.94G [00:29<00:10, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|██████▉   | 6.94G/9.94G [00:29<00:09, 310MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 6.98G/9.94G [00:29<00:09, 308MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.03G/9.94G [00:29<00:09, 323MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.07G/9.94G [00:29<00:08, 325MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.11G/9.94G [00:30<00:09, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.14G/9.94G [00:30<00:10, 280MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.17G/9.94G [00:30<00:11, 248MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.20G/9.94G [00:30<00:10, 256MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.25G/9.94G [00:30<00:09, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.28G/9.94G [00:30<00:09, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▎  | 7.31G/9.94G [00:30<00:09, 283MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.34G/9.94G [00:30<00:09, 275MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.37G/9.94G [00:31<00:09, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.40G/9.94G [00:31<00:09, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▍  | 7.44G/9.94G [00:31<00:08, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▌  | 7.48G/9.94G [00:31<00:08, 287MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.52G/9.94G [00:31<00:08, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.55G/9.94G [00:31<00:09, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.58G/9.94G [00:31<00:08, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.61G/9.94G [00:32<00:10, 222MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.65G/9.94G [00:32<00:09, 251MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.70G/9.94G [00:32<00:07, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.74G/9.94G [00:32<00:07, 291MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.78G/9.94G [00:32<00:07, 304MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▊  | 7.81G/9.94G [00:32<00:07, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.84G/9.94G [00:32<00:07, 280MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.87G/9.94G [00:32<00:07, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.91G/9.94G [00:33<00:07, 283MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.94G/9.94G [00:33<00:06, 287MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 7.97G/9.94G [00:33<00:06, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.01G/9.94G [00:33<00:06, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.04G/9.94G [00:33<00:06, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.07G/9.94G [00:33<00:09, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.12G/9.94G [00:33<00:07, 230MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.15G/9.94G [00:34<00:07, 238MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.18G/9.94G [00:34<00:07, 239MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.21G/9.94G [00:34<00:06, 256MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.24G/9.94G [00:34<00:06, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.27G/9.94G [00:34<00:07, 226MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▎ | 8.30G/9.94G [00:34<00:07, 233MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.35G/9.94G [00:34<00:06, 259MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.38G/9.94G [00:34<00:05, 268MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.42G/9.94G [00:35<00:05, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.45G/9.94G [00:35<00:05, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.49G/9.94G [00:35<00:05, 279MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.52G/9.94G [00:35<00:05, 279MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.56G/9.94G [00:35<00:04, 282MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▋ | 8.60G/9.94G [00:35<00:04, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.64G/9.94G [00:35<00:04, 303MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.67G/9.94G [00:35<00:04, 271MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.70G/9.94G [00:36<00:05, 239MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.73G/9.94G [00:36<00:04, 243MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.77G/9.94G [00:36<00:04, 252MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.80G/9.94G [00:36<00:04, 250MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.83G/9.94G [00:36<00:04, 238MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.86G/9.94G [00:36<00:04, 230MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.90G/9.94G [00:36<00:03, 265MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.94G/9.94G [00:37<00:03, 280MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 8.99G/9.94G [00:37<00:03, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.03G/9.94G [00:37<00:02, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.06G/9.94G [00:37<00:03, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████▏| 9.09G/9.94G [00:37<00:02, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.12G/9.94G [00:37<00:02, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.16G/9.94G [00:37<00:02, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.20G/9.94G [00:37<00:02, 301MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.24G/9.94G [00:38<00:02, 295MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.27G/9.94G [00:38<00:03, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▎| 9.30G/9.94G [00:38<00:03, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.32G/9.94G [00:38<00:04, 141MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.34G/9.94G [00:39<00:04, 123MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.36G/9.94G [00:39<00:04, 120MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.38G/9.94G [00:39<00:05, 110MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.41G/9.94G [00:39<00:05, 105MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.43G/9.94G [00:39<00:04, 104MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.45G/9.94G [00:40<00:04, 106MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.47G/9.94G [00:40<00:04, 99.2MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.49G/9.94G [00:40<00:04, 104MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.51G/9.94G [00:40<00:04, 102MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.53G/9.94G [00:40<00:04, 98.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.55G/9.94G [00:41<00:03, 106MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▋| 9.57G/9.94G [00:41<00:03, 104MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▋| 9.59G/9.94G [00:41<00:03, 108MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.62G/9.94G [00:41<00:03, 106MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.64G/9.94G [00:41<00:02, 113MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.66G/9.94G [00:42<00:02, 127MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.69G/9.94G [00:42<00:01, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.72G/9.94G [00:42<00:01, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.75G/9.94G [00:42<00:00, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.79G/9.94G [00:42<00:00, 242MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.83G/9.94G [00:42<00:00, 248MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.86G/9.94G [00:42<00:00, 254MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.89G/9.94G [00:42<00:00, 250MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.92G/9.94G [00:42<00:00, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|██████████| 9.94G/9.94G [00:43<00:00, 231MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 1/2 [00:43<00:43, 43.63s/it]\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   0%|          | 21.0M/4.54G [00:00<00:25, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   1%|          | 41.9M/4.54G [00:00<00:28, 156MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   2%|▏         | 73.4M/4.54G [00:00<00:21, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   2%|▏         | 105M/4.54G [00:00<00:20, 212MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   3%|▎         | 136M/4.54G [00:00<00:18, 234MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   4%|▎         | 168M/4.54G [00:00<00:18, 241MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   4%|▍         | 199M/4.54G [00:00<00:17, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   5%|▌         | 231M/4.54G [00:00<00:16, 263MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   6%|▌         | 273M/4.54G [00:01<00:14, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   7%|▋         | 304M/4.54G [00:01<00:15, 276MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   7%|▋         | 336M/4.54G [00:01<00:15, 279MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   8%|▊         | 367M/4.54G [00:01<00:14, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▉         | 409M/4.54G [00:01<00:13, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|▉         | 440M/4.54G [00:01<00:13, 307MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|█         | 472M/4.54G [00:01<00:14, 281MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  11%|█         | 503M/4.54G [00:01<00:16, 251MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 535M/4.54G [00:02<00:15, 256MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 566M/4.54G [00:02<00:15, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  13%|█▎        | 598M/4.54G [00:02<00:14, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  14%|█▍        | 640M/4.54G [00:02<00:14, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▍        | 671M/4.54G [00:02<00:14, 261MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▌        | 703M/4.54G [00:02<00:15, 251MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▌        | 734M/4.54G [00:02<00:16, 233MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 765M/4.54G [00:03<00:15, 238MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 797M/4.54G [00:03<00:15, 239MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 828M/4.54G [00:03<00:16, 229MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  19%|█▉        | 860M/4.54G [00:03<00:15, 232MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  20%|█▉        | 902M/4.54G [00:03<00:14, 244MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██        | 933M/4.54G [00:03<00:14, 255MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██        | 965M/4.54G [00:03<00:14, 242MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  22%|██▏       | 996M/4.54G [00:03<00:14, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  23%|██▎       | 1.04G/4.54G [00:04<00:13, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▎       | 1.07G/4.54G [00:04<00:13, 264MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 1.10G/4.54G [00:04<00:14, 237MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  25%|██▍       | 1.13G/4.54G [00:04<00:17, 198MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  26%|██▌       | 1.16G/4.54G [00:04<00:16, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  26%|██▋       | 1.20G/4.54G [00:04<00:15, 221MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  27%|██▋       | 1.23G/4.54G [00:04<00:14, 227MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  28%|██▊       | 1.26G/4.54G [00:05<00:14, 224MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  28%|██▊       | 1.29G/4.54G [00:05<00:13, 236MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  29%|██▉       | 1.33G/4.54G [00:05<00:12, 267MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|███       | 1.36G/4.54G [00:05<00:11, 269MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  31%|███       | 1.39G/4.54G [00:05<00:11, 278MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  31%|███▏      | 1.43G/4.54G [00:05<00:11, 270MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  32%|███▏      | 1.46G/4.54G [00:05<00:11, 268MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  33%|███▎      | 1.50G/4.54G [00:05<00:10, 283MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  34%|███▎      | 1.53G/4.54G [00:06<00:10, 279MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  34%|███▍      | 1.56G/4.54G [00:06<00:10, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  35%|███▌      | 1.59G/4.54G [00:06<00:10, 277MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▌      | 1.63G/4.54G [00:06<00:10, 273MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▋      | 1.66G/4.54G [00:06<00:11, 254MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 1.70G/4.54G [00:06<00:10, 275MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  38%|███▊      | 1.73G/4.54G [00:06<00:10, 274MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.76G/4.54G [00:06<00:10, 266MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.79G/4.54G [00:07<00:10, 258MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  40%|████      | 1.82G/4.54G [00:07<00:11, 230MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  41%|████      | 1.86G/4.54G [00:07<00:11, 236MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.90G/4.54G [00:07<00:10, 260MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.93G/4.54G [00:07<00:11, 231MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  43%|████▎     | 1.96G/4.54G [00:07<00:11, 227MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  44%|████▍     | 1.99G/4.54G [00:07<00:11, 230MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▍     | 2.02G/4.54G [00:08<00:10, 233MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▌     | 2.06G/4.54G [00:08<00:10, 247MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▌     | 2.09G/4.54G [00:08<00:10, 224MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 2.12G/4.54G [00:08<00:10, 221MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 2.15G/4.54G [00:08<00:10, 225MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.18G/4.54G [00:08<00:12, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.20G/4.54G [00:09<00:12, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 2.22G/4.54G [00:09<00:13, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|████▉     | 2.25G/4.54G [00:09<00:12, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|█████     | 2.29G/4.54G [00:09<00:11, 192MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████     | 2.32G/4.54G [00:09<00:10, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 2.35G/4.54G [00:09<00:09, 220MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 2.38G/4.54G [00:09<00:09, 217MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  53%|█████▎    | 2.41G/4.54G [00:09<00:09, 215MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  54%|█████▍    | 2.44G/4.54G [00:10<00:09, 215MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▍    | 2.47G/4.54G [00:10<00:09, 223MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▌    | 2.51G/4.54G [00:10<00:08, 233MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  56%|█████▌    | 2.54G/4.54G [00:10<00:08, 240MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 2.57G/4.54G [00:10<00:07, 256MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 2.60G/4.54G [00:10<00:07, 245MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.63G/4.54G [00:10<00:08, 236MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  59%|█████▊    | 2.66G/4.54G [00:11<00:08, 226MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  59%|█████▉    | 2.69G/4.54G [00:11<00:08, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  60%|██████    | 2.73G/4.54G [00:11<00:09, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.75G/4.54G [00:11<00:09, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.77G/4.54G [00:11<00:09, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████▏   | 2.79G/4.54G [00:11<00:09, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.81G/4.54G [00:11<00:09, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.83G/4.54G [00:12<00:09, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.85G/4.54G [00:12<00:09, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.87G/4.54G [00:12<00:09, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▎   | 2.89G/4.54G [00:12<00:09, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▍   | 2.92G/4.54G [00:12<00:09, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▍   | 2.94G/4.54G [00:12<00:09, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▌   | 2.97G/4.54G [00:13<00:12, 127MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  66%|██████▋   | 3.01G/4.54G [00:13<00:09, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.05G/4.54G [00:13<00:07, 195MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 3.08G/4.54G [00:13<00:07, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 3.10G/4.54G [00:13<00:07, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  69%|██████▉   | 3.12G/4.54G [00:13<00:07, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  69%|██████▉   | 3.15G/4.54G [00:13<00:07, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  70%|██████▉   | 3.17G/4.54G [00:13<00:07, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  70%|███████   | 3.19G/4.54G [00:14<00:07, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████   | 3.21G/4.54G [00:14<00:07, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████   | 3.23G/4.54G [00:14<00:07, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 3.25G/4.54G [00:14<00:07, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 3.27G/4.54G [00:14<00:07, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.29G/4.54G [00:14<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.31G/4.54G [00:14<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.33G/4.54G [00:14<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▍  | 3.36G/4.54G [00:15<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▍  | 3.38G/4.54G [00:15<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▍  | 3.40G/4.54G [00:15<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▌  | 3.42G/4.54G [00:15<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.44G/4.54G [00:15<00:06, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.46G/4.54G [00:15<00:06, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.48G/4.54G [00:15<00:06, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.50G/4.54G [00:15<00:05, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.52G/4.54G [00:16<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.54G/4.54G [00:16<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▊  | 3.57G/4.54G [00:16<00:05, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▉  | 3.59G/4.54G [00:16<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▉  | 3.61G/4.54G [00:16<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|███████▉  | 3.63G/4.54G [00:16<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|████████  | 3.65G/4.54G [00:16<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████  | 3.67G/4.54G [00:16<00:04, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████▏ | 3.69G/4.54G [00:16<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.71G/4.54G [00:17<00:04, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.73G/4.54G [00:17<00:04, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.75G/4.54G [00:17<00:04, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.77G/4.54G [00:17<00:04, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▎ | 3.80G/4.54G [00:17<00:04, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▍ | 3.82G/4.54G [00:17<00:04, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▍ | 3.85G/4.54G [00:17<00:03, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▌ | 3.87G/4.54G [00:17<00:03, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.89G/4.54G [00:18<00:03, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.91G/4.54G [00:18<00:03, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.93G/4.54G [00:18<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.95G/4.54G [00:18<00:03, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 3.97G/4.54G [00:18<00:03, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 4.00G/4.54G [00:18<00:03, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 4.02G/4.54G [00:18<00:03, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 4.04G/4.54G [00:18<00:02, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 4.06G/4.54G [00:19<00:02, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|████████▉ | 4.08G/4.54G [00:19<00:02, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|█████████ | 4.10G/4.54G [00:19<00:02, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.12G/4.54G [00:19<00:02, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.14G/4.54G [00:19<00:02, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.16G/4.54G [00:19<00:02, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.18G/4.54G [00:19<00:02, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.20G/4.54G [00:19<00:01, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.23G/4.54G [00:20<00:01, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▎| 4.25G/4.54G [00:20<00:01, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.27G/4.54G [00:20<00:01, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.29G/4.54G [00:20<00:01, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▍| 4.31G/4.54G [00:20<00:01, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▌| 4.33G/4.54G [00:20<00:01, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 4.35G/4.54G [00:20<00:01, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▋| 4.37G/4.54G [00:20<00:00, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.39G/4.54G [00:21<00:00, 150MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.41G/4.54G [00:21<00:00, 134MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.44G/4.54G [00:21<00:00, 128MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.46G/4.54G [00:21<00:00, 120MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▉| 4.49G/4.54G [00:21<00:00, 149MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|█████████▉| 4.52G/4.54G [00:21<00:00, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|██████████| 4.54G/4.54G [00:22<00:00, 206MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [01:05<00:00, 31.05s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [01:05<00:00, 32.94s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:15<00:15, 15.48s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.23s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.47s/it]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 120/120 [00:00<00:00, 1.34MB/s]\u001b[0m\n",
      "\u001b[34mFound 7 modules to quantize: ['k_proj', 'o_proj', 'up_proj', 'q_proj', 'gate_proj', 'down_proj', 'v_proj']\u001b[0m\n",
      "\u001b[34mCUDA extension not installed.\u001b[0m\n",
      "\u001b[34mCUDA extension not installed.\u001b[0m\n",
      "\u001b[34mtrainable params: 167,772,160 || all params: 7,409,520,640 || trainable%: 2.2642781922259414\u001b[0m\n",
      "\u001b[34m0%|          | 0/244 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34m0%|          | 1/244 [00:55<3:44:06, 55.34s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 2/244 [01:50<3:41:52, 55.01s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 3/244 [02:44<3:40:32, 54.91s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 4/244 [03:39<3:39:25, 54.86s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 5/244 [04:34<3:38:24, 54.83s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 6/244 [05:29<3:37:25, 54.81s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 7/244 [06:24<3:36:28, 54.80s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 8/244 [07:18<3:35:32, 54.80s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 9/244 [08:13<3:34:36, 54.79s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 10/244 [09:08<3:33:41, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.599, 'learning_rate': 7.998582444493811e-05, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34m4%|▍         | 10/244 [09:08<3:33:41, 54.79s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 11/244 [10:03<3:32:45, 54.79s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 12/244 [10:57<3:31:50, 54.79s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 13/244 [11:52<3:30:55, 54.79s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 14/244 [12:47<3:30:00, 54.79s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 15/244 [13:42<3:29:05, 54.79s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 16/244 [14:37<3:28:10, 54.78s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 17/244 [15:31<3:27:16, 54.79s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 18/244 [16:26<3:26:21, 54.79s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 19/244 [17:21<3:25:26, 54.78s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 20/244 [18:16<3:24:31, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2959, 'learning_rate': 7.949073418885378e-05, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34m8%|▊         | 20/244 [18:16<3:24:31, 54.79s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 21/244 [19:11<3:23:37, 54.78s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 22/244 [20:05<3:22:42, 54.78s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 23/244 [21:00<3:21:47, 54.79s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 24/244 [21:55<3:20:52, 54.78s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 25/244 [22:50<3:19:57, 54.78s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 26/244 [23:44<3:19:02, 54.78s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 27/244 [24:39<3:18:08, 54.78s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 28/244 [25:34<3:17:13, 54.78s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 29/244 [26:29<3:16:18, 54.78s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 30/244 [27:24<3:15:23, 54.78s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2297, 'learning_rate': 7.829688153448022e-05, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 30/244 [27:24<3:15:23, 54.78s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 31/244 [28:18<3:14:28, 54.78s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 32/244 [29:13<3:13:34, 54.78s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 33/244 [30:08<3:12:40, 54.79s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 34/244 [31:03<3:11:45, 54.79s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 35/244 [31:58<3:10:50, 54.79s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 36/244 [32:52<3:09:55, 54.79s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 37/244 [33:47<3:09:00, 54.79s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 38/244 [34:42<3:08:05, 54.78s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 39/244 [35:37<3:07:10, 54.78s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 40/244 [36:31<3:06:16, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2326, 'learning_rate': 7.642539091419654e-05, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34m16%|█▋        | 40/244 [36:31<3:06:16, 54.79s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 41/244 [37:26<3:05:21, 54.79s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 42/244 [38:21<3:04:26, 54.79s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 43/244 [39:16<3:03:31, 54.79s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 44/244 [40:11<3:02:37, 54.79s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 45/244 [41:05<3:01:42, 54.79s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 46/244 [42:00<3:00:47, 54.79s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 47/244 [42:55<2:59:52, 54.79s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 48/244 [43:50<2:58:58, 54.79s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 49/244 [44:45<2:58:03, 54.79s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 50/244 [45:39<2:57:08, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2238, 'learning_rate': 7.390937711558683e-05, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34m20%|██        | 50/244 [45:39<2:57:08, 54.79s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 51/244 [46:34<2:56:13, 54.79s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 52/244 [47:29<2:55:18, 54.78s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 53/244 [48:24<2:54:23, 54.78s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 54/244 [49:18<2:53:29, 54.78s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 55/244 [50:13<2:52:34, 54.78s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 56/244 [51:08<2:51:39, 54.78s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 57/244 [52:03<2:50:44, 54.78s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 58/244 [52:58<2:49:49, 54.78s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 59/244 [53:52<2:48:55, 54.78s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 60/244 [54:47<2:48:00, 54.78s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1487, 'learning_rate': 7.079335933719625e-05, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34m25%|██▍       | 60/244 [54:47<2:48:00, 54.78s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 61/244 [55:42<2:47:05, 54.78s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 62/244 [56:37<2:46:10, 54.78s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 63/244 [57:31<2:45:15, 54.78s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 64/244 [58:26<2:44:21, 54.78s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 65/244 [59:21<2:43:26, 54.78s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 66/244 [1:00:16<2:42:31, 54.78s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 67/244 [1:01:11<2:41:36, 54.78s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 68/244 [1:02:05<2:40:42, 54.79s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 69/244 [1:03:00<2:39:47, 54.78s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 70/244 [1:03:55<2:38:52, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.139, 'learning_rate': 6.713247345078465e-05, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m29%|██▊       | 70/244 [1:03:55<2:38:52, 54.79s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 71/244 [1:04:50<2:37:57, 54.79s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 72/244 [1:05:45<2:37:03, 54.79s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 73/244 [1:06:39<2:36:08, 54.79s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 74/244 [1:07:34<2:35:13, 54.79s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 75/244 [1:08:29<2:34:18, 54.79s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 76/244 [1:09:24<2:33:23, 54.79s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 77/244 [1:10:18<2:32:29, 54.79s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 78/244 [1:11:13<2:31:34, 54.79s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 79/244 [1:12:08<2:30:39, 54.79s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 80/244 [1:13:03<2:29:44, 54.78s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1139, 'learning_rate': 6.29914964085763e-05, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 80/244 [1:13:03<2:29:44, 54.78s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 81/244 [1:13:58<2:28:50, 54.79s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 82/244 [1:14:52<2:27:55, 54.79s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 83/244 [1:15:47<2:27:00, 54.79s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 84/244 [1:16:42<2:26:05, 54.79s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 85/244 [1:17:37<2:25:10, 54.79s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 86/244 [1:18:32<2:24:16, 54.79s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 87/244 [1:19:26<2:23:21, 54.79s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 88/244 [1:20:21<2:22:26, 54.79s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 89/244 [1:21:16<2:21:31, 54.79s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 90/244 [1:22:11<2:20:37, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1766, 'learning_rate': 5.844370005797304e-05, 'epoch': 0.74}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 90/244 [1:22:11<2:20:37, 54.79s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 91/244 [1:23:05<2:19:42, 54.79s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 92/244 [1:24:00<2:18:47, 54.79s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 93/244 [1:24:55<2:17:52, 54.79s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 94/244 [1:25:50<2:16:57, 54.79s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 95/244 [1:26:45<2:16:03, 54.79s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 96/244 [1:27:39<2:15:08, 54.79s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 97/244 [1:28:34<2:14:13, 54.79s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 98/244 [1:29:29<2:13:18, 54.79s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 99/244 [1:30:24<2:12:23, 54.79s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 100/244 [1:31:19<2:11:29, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1018, 'learning_rate': 5.356955464472121e-05, 'epoch': 0.82}\u001b[0m\n",
      "\u001b[34m41%|████      | 100/244 [1:31:19<2:11:29, 54.79s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 101/244 [1:32:13<2:10:34, 54.79s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 102/244 [1:33:08<2:09:39, 54.79s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 103/244 [1:34:03<2:08:44, 54.79s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 104/244 [1:34:58<2:07:50, 54.79s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 105/244 [1:35:53<2:06:55, 54.79s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 106/244 [1:36:47<2:06:00, 54.79s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 107/244 [1:37:42<2:05:05, 54.79s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 108/244 [1:38:37<2:04:11, 54.79s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 109/244 [1:39:32<2:03:16, 54.79s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 110/244 [1:40:26<2:02:21, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0664, 'learning_rate': 4.845530494518498e-05, 'epoch': 0.9}\u001b[0m\n",
      "\u001b[34m45%|████▌     | 110/244 [1:40:26<2:02:21, 54.79s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 111/244 [1:41:21<2:01:26, 54.79s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 112/244 [1:42:16<2:00:31, 54.79s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 113/244 [1:43:11<1:59:37, 54.79s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 114/244 [1:44:06<1:58:42, 54.79s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 115/244 [1:45:00<1:57:47, 54.79s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 116/244 [1:45:55<1:56:52, 54.79s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 117/244 [1:46:50<1:55:57, 54.78s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 118/244 [1:47:45<1:55:02, 54.78s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 119/244 [1:48:40<1:54:08, 54.79s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 120/244 [1:49:34<1:53:13, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0938, 'learning_rate': 4.3191444222123326e-05, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 120/244 [1:49:34<1:53:13, 54.79s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 121/244 [1:50:29<1:52:18, 54.79s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 122/244 [1:51:24<1:51:23, 54.79s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 123/244 [1:52:20<1:51:04, 55.08s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 124/244 [1:53:14<1:49:58, 54.99s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 125/244 [1:54:09<1:48:56, 54.93s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 126/244 [1:55:04<1:47:56, 54.89s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 127/244 [1:55:59<1:46:58, 54.86s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 128/244 [1:56:54<1:46:00, 54.84s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 129/244 [1:57:48<1:45:04, 54.82s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 130/244 [1:58:43<1:44:08, 54.81s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0769, 'learning_rate': 3.787111300631287e-05, 'epoch': 1.06}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 130/244 [1:58:43<1:44:08, 54.81s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 131/244 [1:59:38<1:43:12, 54.80s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 132/244 [2:00:33<1:42:17, 54.80s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 133/244 [2:01:27<1:41:22, 54.79s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 134/244 [2:02:22<1:40:27, 54.79s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 135/244 [2:03:17<1:39:32, 54.79s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 136/244 [2:04:12<1:38:37, 54.79s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 137/244 [2:05:07<1:37:42, 54.79s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 138/244 [2:06:01<1:36:47, 54.78s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 139/244 [2:06:56<1:35:52, 54.78s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 140/244 [2:07:51<1:34:57, 54.78s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9658, 'learning_rate': 3.2588451036515435e-05, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 140/244 [2:07:51<1:34:57, 54.78s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 141/244 [2:08:46<1:34:02, 54.79s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 142/244 [2:09:41<1:33:08, 54.79s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 143/244 [2:10:35<1:32:13, 54.79s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 144/244 [2:11:30<1:31:18, 54.79s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 145/244 [2:12:25<1:30:23, 54.79s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 146/244 [2:13:20<1:29:29, 54.79s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 147/244 [2:14:14<1:28:34, 54.79s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 148/244 [2:15:09<1:27:39, 54.79s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 149/244 [2:16:04<1:26:44, 54.79s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 150/244 [2:16:59<1:25:49, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9851, 'learning_rate': 2.743693151912206e-05, 'epoch': 1.23}\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 150/244 [2:16:59<1:25:49, 54.79s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 151/244 [2:17:54<1:24:55, 54.79s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 152/244 [2:18:48<1:24:00, 54.79s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 153/244 [2:19:43<1:23:05, 54.79s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 154/244 [2:20:38<1:22:10, 54.79s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 155/244 [2:21:33<1:21:16, 54.79s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 156/244 [2:22:28<1:20:21, 54.79s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 157/244 [2:23:22<1:19:26, 54.79s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 158/244 [2:24:17<1:18:31, 54.79s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 159/244 [2:25:12<1:17:36, 54.79s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 160/244 [2:26:07<1:16:42, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9287, 'learning_rate': 2.250770718164579e-05, 'epoch': 1.31}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 160/244 [2:26:07<1:16:42, 54.79s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 161/244 [2:27:01<1:15:47, 54.79s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 162/244 [2:27:56<1:14:52, 54.79s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 163/244 [2:28:51<1:13:57, 54.79s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 164/244 [2:29:46<1:13:02, 54.79s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 165/244 [2:30:41<1:12:08, 54.79s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 166/244 [2:31:35<1:11:13, 54.79s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 167/244 [2:32:30<1:10:18, 54.79s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 168/244 [2:33:25<1:09:23, 54.79s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 169/244 [2:34:20<1:08:28, 54.79s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 170/244 [2:35:15<1:07:34, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9045, 'learning_rate': 1.7887997385552278e-05, 'epoch': 1.39}\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 170/244 [2:35:15<1:07:34, 54.79s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 171/244 [2:36:09<1:06:39, 54.79s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 172/244 [2:37:04<1:05:44, 54.79s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 173/244 [2:37:59<1:04:49, 54.79s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 174/244 [2:38:54<1:03:55, 54.79s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 175/244 [2:39:48<1:03:00, 54.79s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 176/244 [2:40:43<1:02:05, 54.79s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 177/244 [2:41:38<1:01:10, 54.79s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 178/244 [2:42:33<1:00:15, 54.79s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 179/244 [2:43:28<59:21, 54.79s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 180/244 [2:44:22<58:26, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9796, 'learning_rate': 1.365954483739846e-05, 'epoch': 1.47}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 180/244 [2:44:22<58:26, 54.79s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 181/244 [2:45:17<57:31, 54.79s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 182/244 [2:46:12<56:36, 54.79s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 183/244 [2:47:07<55:42, 54.79s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 184/244 [2:48:02<54:47, 54.79s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 185/244 [2:48:56<53:52, 54.79s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 186/244 [2:49:51<52:57, 54.79s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 187/244 [2:50:46<52:02, 54.79s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 188/244 [2:51:41<51:07, 54.79s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 189/244 [2:52:35<50:13, 54.79s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 190/244 [2:53:30<49:18, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9295, 'learning_rate': 9.897169205754461e-06, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 190/244 [2:53:30<49:18, 54.79s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 191/244 [2:54:25<48:23, 54.79s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 192/244 [2:55:20<47:28, 54.79s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 193/244 [2:56:15<46:34, 54.79s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 194/244 [2:57:09<45:39, 54.79s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 195/244 [2:58:04<44:44, 54.79s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 196/244 [2:58:59<43:49, 54.79s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 197/244 [2:59:54<42:54, 54.79s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 198/244 [3:00:49<42:00, 54.79s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 199/244 [3:01:43<41:05, 54.79s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 200/244 [3:02:38<40:10, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8895, 'learning_rate': 6.667443236699398e-06, 'epoch': 1.63}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 200/244 [3:02:38<40:10, 54.79s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 201/244 [3:03:33<39:15, 54.79s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 202/244 [3:04:28<38:20, 54.79s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 203/244 [3:05:22<37:26, 54.78s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 204/244 [3:06:17<36:31, 54.78s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 205/244 [3:07:12<35:36, 54.78s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 206/244 [3:08:07<34:41, 54.78s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 207/244 [3:09:02<33:46, 54.78s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 208/244 [3:09:56<32:52, 54.78s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 209/244 [3:10:51<31:57, 54.78s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 210/244 [3:11:46<31:02, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9277, 'learning_rate': 4.027514793151235e-06, 'epoch': 1.72}\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 210/244 [3:11:46<31:02, 54.79s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 211/244 [3:12:41<30:07, 54.79s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 212/244 [3:13:36<29:13, 54.79s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 213/244 [3:14:30<28:18, 54.78s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 214/244 [3:15:25<27:23, 54.78s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 215/244 [3:16:20<26:28, 54.78s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 216/244 [3:17:15<25:33, 54.78s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 217/244 [3:18:09<24:39, 54.78s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 218/244 [3:19:04<23:44, 54.78s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 219/244 [3:19:59<22:49, 54.79s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 220/244 [3:20:54<21:54, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9342, 'learning_rate': 2.0240956612647487e-06, 'epoch': 1.8}\u001b[0m\n",
      "\u001b[34m90%|█████████ | 220/244 [3:20:54<21:54, 54.79s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 221/244 [3:21:49<21:00, 54.79s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 222/244 [3:22:43<20:05, 54.79s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 223/244 [3:23:38<19:10, 54.79s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 224/244 [3:24:33<18:15, 54.79s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 225/244 [3:25:28<17:20, 54.79s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 226/244 [3:26:23<16:26, 54.79s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 227/244 [3:27:17<15:31, 54.78s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 228/244 [3:28:12<14:36, 54.79s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 229/244 [3:29:07<13:41, 54.78s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 230/244 [3:30:02<12:46, 54.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9882, 'learning_rate': 6.926350162991613e-07, 'epoch': 1.88}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 230/244 [3:30:02<12:46, 54.79s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 231/244 [3:30:56<11:52, 54.79s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 232/244 [3:31:51<10:57, 54.79s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 233/244 [3:32:46<10:02, 54.79s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 234/244 [3:33:41<09:07, 54.78s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 235/244 [3:34:36<08:13, 54.78s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 236/244 [3:35:30<07:18, 54.78s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 237/244 [3:36:25<06:23, 54.78s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 238/244 [3:37:20<05:28, 54.78s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 239/244 [3:38:15<04:33, 54.78s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 240/244 [3:39:10<03:39, 54.78s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9261, 'learning_rate': 5.669217292952223e-08, 'epoch': 1.96}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 240/244 [3:39:10<03:39, 54.78s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 241/244 [3:40:04<02:44, 54.78s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 242/244 [3:40:59<01:49, 54.78s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 243/244 [3:41:54<00:54, 54.78s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 244/244 [3:42:49<00:00, 54.78s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 13370.1617, 'train_samples_per_second': 0.11, 'train_steps_per_second': 0.018, 'train_loss': 1.075101327700693, 'epoch': 1.99}\u001b[0m\n",
      "\u001b[34m100%|██████████| 244/244 [3:42:50<00:00, 54.78s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 244/244 [3:42:50<00:00, 54.80s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.36s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.63s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.59s/it]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 1.60k/1.60k [00:00<00:00, 12.6MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 107MB/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json: 100%|██████████| 51.0/51.0 [00:00<00:00, 548kB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 101/101 [00:00<00:00, 868kB/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m2024-03-07 10:42:54,581 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-03-07 10:42:54,581 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-03-07 10:42:54,582 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-03-07 10:43:00 Uploading - Uploading generated training model\n",
      "2024-03-07 10:43:46 Completed - Training job completed\n",
      "Training seconds: 14122\n",
      "Billable seconds: 14122\n"
     ]
    }
   ],
   "source": [
    "finetune = FinetuneLLM(model_id='teknium/OpenHermes-2.5-Mistral-7B', \n",
    "                       finetune_id = 'SeashellNarwhalXanadu',\n",
    "                       batch_size=2,\n",
    "                       merge_adapters=True,\n",
    "                       learning_rate='8e-5',\n",
    "                       training_input_path='s3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2024-Mar-07-teknium/OpenHermes-2.5-Mistral-7B-search-SeashellNarwhalXanadu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b5f499-9b52-47a2-8016-4e38a07e21d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-07-06-46-58-396/output/model/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune.model_s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8be5d-d996-472e-a460-370c453d02ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoenv",
   "language": "python",
   "name": "recoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
