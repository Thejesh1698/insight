{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d96b537-8f2e-46b1-a05c-8258729fdcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_folder = '/Users/ravi.tej/Desktop/ML/Recommendations/hubble/'\n",
    "from hydra import compose, initialize\n",
    "import os\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "tree = ET.parse('../../conf/application.run.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "envs_element = root.find('./configuration/envs')\n",
    "for variable in envs_element.findall('env'):\n",
    "    name = variable.get('name')\n",
    "    value = variable.get('value')\n",
    "    os.environ[name] = value\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/ravi.tej/Desktop/ML/Recommendations/hubble/')\n",
    "import pandas as pd\n",
    "\n",
    "os.environ['PATH'] = '/Users/ravi.tej/anaconda3/envs/bertopicenv/bin:/Users/ravi.tej/anaconda3/condabin:/usr/bin:/bin:/usr/sbin:/sbin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "175b96dc-2e0b-43cc-9c52-7e668956e5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ravi.tej/Library/Application Support/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from src.RAGTraining.FinetuneLLM import FinetuneLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce2c04ec-a153-4270-a1cf-9717aec7304e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ravi.tej/Desktop/ML/Recommendations/hubble/notebooks/RAG-Mar-5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db21b239-bf99-493c-819a-f9c26600e3d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-teknium-OpenHermes-2--2024-03-07-15-02-28-599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-07 15:02:30 Starting - Starting the training job...\n",
      "2024-03-07 15:02:57 Pending - Preparing the instances for training......\n",
      "2024-03-07 15:03:56 Downloading - Downloading input data...\n",
      "2024-03-07 15:04:22 Downloading - Downloading the training image.....................\n",
      "2024-03-07 15:07:47 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:12,132 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:12,151 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:12,160 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:12,161 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:13,475 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.35.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.5/123.5 kB 10.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.5.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting optimum==1.14.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl.metadata (17 kB)\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.23.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.3 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.11.1)\u001b[0m\n",
      "\u001b[34mCollecting datasets==2.15.0 (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting auto-gptq (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (0.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (1.24.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2023.12.25)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting coloredlogs (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (14.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (2.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (3.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0->-r requirements.txt (line 9)) (2023.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (3.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes->-r requirements.txt (line 5)) (1.11.1)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of auto-gptq to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting auto-gptq (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from auto-gptq->-r requirements.txt (line 10)) (0.1.99)\u001b[0m\n",
      "\u001b[34mCollecting rouge (from auto-gptq->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\u001b[0m\n",
      "\u001b[34mCollecting gekko (from auto-gptq->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading gekko-1.0.7-py3-none-any.whl.metadata (3.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (23.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (6.0.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.9.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (2024.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.14.0->-r requirements.txt (line 3)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq->-r requirements.txt (line 10)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (2.1.3)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 133.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 16.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl (398 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 398.9/398.9 kB 58.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.1/258.1 kB 37.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 521.2/521.2 kB 61.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 MB 34.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 99.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 122.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 109.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 8.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading gekko-1.0.7-py3-none-any.whl (13.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.1/13.1 MB 114.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 18.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: safetensors, rouge, humanfriendly, gekko, coloredlogs, bitsandbytes, tokenizers, accelerate, transformers, datasets, peft, optimum, auto-gptq\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: datasets\u001b[0m\n",
      "\u001b[34mFound existing installation: datasets 2.16.1\u001b[0m\n",
      "\u001b[34mUninstalling datasets-2.16.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled datasets-2.16.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.23.0 auto-gptq-0.6.0 bitsandbytes-0.42.0 coloredlogs-15.0.1 datasets-2.15.0 gekko-1.0.7 humanfriendly-10.0 optimum-1.14.0 peft-0.5.0 rouge-1.0.1 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.35.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:27,922 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:27,922 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:27,961 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:27,989 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:28,017 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:28,027 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"gradient_accumulation_steps\": 1,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"learning_rate\": \"3e-5\",\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"cosine_with_restarts\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"teknium/OpenHermes-2.5-Mistral-7B\",\n",
      "        \"num_train_epochs\": 2,\n",
      "        \"output_dir\": \"/tmp/run\",\n",
      "        \"per_device_train_batch_size\": 2,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"trust_remote_code\": true,\n",
      "        \"use_flash_attn\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-teknium-OpenHermes-2--2024-03-07-15-02-28-599\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-07-15-02-28-599/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_qlora\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_qlora.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":1,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":\"3e-5\",\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":2,\"save_strategy\":\"epoch\",\"tf32\":true,\"trust_remote_code\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_qlora.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_qlora\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-07-15-02-28-599/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":1,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":\"3e-5\",\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":2,\"save_strategy\":\"epoch\",\"tf32\":true,\"trust_remote_code\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-teknium-OpenHermes-2--2024-03-07-15-02-28-599\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-07-15-02-28-599/source/sourcedir.tar.gz\",\"module_name\":\"run_qlora\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_qlora.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training\",\"--gradient_accumulation_steps\",\"1\",\"--gradient_checkpointing\",\"True\",\"--hf_token\",\"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\",\"--learning_rate\",\"3e-5\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"cosine_with_restarts\",\"--max_grad_norm\",\"0.3\",\"--merge_adapters\",\"True\",\"--model_id\",\"teknium/OpenHermes-2.5-Mistral-7B\",\"--num_train_epochs\",\"2\",\"--output_dir\",\"/tmp/run\",\"--per_device_train_batch_size\",\"2\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--trust_remote_code\",\"True\",\"--use_flash_attn\",\"True\",\"--warmup_ratio\",\"0.03\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=1\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=3e-5\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=cosine_with_restarts\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=teknium/OpenHermes-2.5-Mistral-7B\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=2\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/run\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_TRUST_REMOTE_CODE=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FLASH_ATTN=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 1 --gradient_checkpointing True --hf_token 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 --learning_rate 3e-5 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters True --model_id teknium/OpenHermes-2.5-Mistral-7B --num_train_epochs 2 --output_dir /tmp/run --per_device_train_batch_size 2 --save_strategy epoch --tf32 True --trust_remote_code True --use_flash_attn True --warmup_ratio 0.03\u001b[0m\n",
      "\u001b[34m2024-03-07 15:08:28,056 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flash-attn in /opt/conda/lib/python3.10/site-packages (0.2.8)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.5.6.tar.gz (2.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 44.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.5.6-cp310-cp310-linux_x86_64.whl size=121379983 sha256=4148bf354d8fa6e8afea1bc4961830c2a189271dc74ddd4b39049374a372b1f1\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/a8/1c/88/b959d6818b98a46d61ba231683abb7523b89ac1a7ed1e0c206\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mSuccessfully installed flash-attn-2.5.6\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.2 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mLogging into the Hugging Face Hub with token hf_NjVkEqg...\u001b[0m\n",
      "\u001b[34mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\u001b[0m\n",
      "\u001b[34mToken is valid (permission: write).\u001b[0m\n",
      "\u001b[34mYour token has been saved to /root/.cache/huggingface/token\u001b[0m\n",
      "\u001b[34mLogin successful\u001b[0m\n",
      "\u001b[34mUsing `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\u001b[0m\n",
      "\u001b[34mUsing `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/624 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 624/624 [00:00<00:00, 5.68MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 114MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 52.4M/9.94G [00:00<00:19, 510MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 105M/9.94G [00:00<00:19, 514MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 168M/9.94G [00:00<00:18, 527MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 231M/9.94G [00:00<00:18, 529MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 294M/9.94G [00:00<00:18, 535MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▎         | 357M/9.94G [00:00<00:18, 527MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▍         | 419M/9.94G [00:00<00:18, 512MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▍         | 482M/9.94G [00:00<00:18, 517MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▌         | 535M/9.94G [00:01<00:18, 504MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 587M/9.94G [00:01<00:18, 505MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▋         | 640M/9.94G [00:01<00:18, 508MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 703M/9.94G [00:01<00:17, 522MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 765M/9.94G [00:01<00:17, 526MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 828M/9.94G [00:01<00:17, 524MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 891M/9.94G [00:01<00:17, 526MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|▉         | 954M/9.94G [00:01<00:16, 533MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|█         | 1.02G/9.94G [00:01<00:16, 537MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█         | 1.08G/9.94G [00:02<00:16, 526MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█▏        | 1.14G/9.94G [00:02<00:16, 521MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.20G/9.94G [00:02<00:16, 521MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.25G/9.94G [00:02<00:16, 520MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.30G/9.94G [00:02<00:16, 521MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▎        | 1.36G/9.94G [00:02<00:16, 521MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 1.42G/9.94G [00:02<00:16, 520MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▍        | 1.47G/9.94G [00:02<00:16, 514MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▌        | 1.52G/9.94G [00:02<00:16, 513MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.58G/9.94G [00:03<00:15, 523MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.65G/9.94G [00:03<00:15, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.71G/9.94G [00:03<00:15, 533MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.77G/9.94G [00:03<00:15, 538MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.84G/9.94G [00:03<00:15, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.90G/9.94G [00:03<00:15, 526MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|█▉        | 1.96G/9.94G [00:03<00:14, 536MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|██        | 2.02G/9.94G [00:03<00:15, 527MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.09G/9.94G [00:03<00:14, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.15G/9.94G [00:04<00:14, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.21G/9.94G [00:04<00:14, 528MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.28G/9.94G [00:04<00:14, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▎       | 2.34G/9.94G [00:04<00:14, 527MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▍       | 2.40G/9.94G [00:04<00:14, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▍       | 2.46G/9.94G [00:04<00:14, 531MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▌       | 2.53G/9.94G [00:04<00:13, 533MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.59G/9.94G [00:04<00:13, 536MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.65G/9.94G [00:05<00:13, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.72G/9.94G [00:05<00:13, 533MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.78G/9.94G [00:05<00:13, 543MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▊       | 2.84G/9.94G [00:05<00:12, 550MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.90G/9.94G [00:05<00:12, 543MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|██▉       | 2.97G/9.94G [00:05<00:13, 535MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|███       | 3.03G/9.94G [00:05<00:12, 538MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 3.09G/9.94G [00:05<00:12, 543MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.16G/9.94G [00:05<00:12, 537MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.22G/9.94G [00:06<00:12, 542MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.28G/9.94G [00:06<00:12, 544MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▎      | 3.34G/9.94G [00:06<00:12, 536MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▍      | 3.41G/9.94G [00:06<00:12, 523MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▍      | 3.47G/9.94G [00:06<00:12, 526MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.53G/9.94G [00:06<00:12, 527MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.60G/9.94G [00:06<00:11, 538MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.66G/9.94G [00:06<00:11, 539MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.72G/9.94G [00:07<00:11, 539MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.79G/9.94G [00:07<00:11, 539MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▊      | 3.85G/9.94G [00:07<00:11, 535MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.91G/9.94G [00:07<00:11, 531MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|███▉      | 3.97G/9.94G [00:07<00:11, 526MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.04G/9.94G [00:07<00:11, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.10G/9.94G [00:07<00:11, 522MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.16G/9.94G [00:07<00:10, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.23G/9.94G [00:07<00:10, 531MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.29G/9.94G [00:08<00:11, 490MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▎     | 4.34G/9.94G [00:08<00:11, 498MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▍     | 4.40G/9.94G [00:08<00:10, 507MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▍     | 4.46G/9.94G [00:08<00:10, 509MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▌     | 4.51G/9.94G [00:08<00:10, 498MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.56G/9.94G [00:08<00:10, 491MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.62G/9.94G [00:08<00:10, 506MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.68G/9.94G [00:08<00:10, 494MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.73G/9.94G [00:09<00:10, 500MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.78G/9.94G [00:09<00:10, 500MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▊     | 4.84G/9.94G [00:09<00:09, 511MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▉     | 4.91G/9.94G [00:09<00:09, 525MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|████▉     | 4.97G/9.94G [00:09<00:09, 534MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.03G/9.94G [00:09<00:09, 520MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.09G/9.94G [00:09<00:09, 506MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.14G/9.94G [00:09<00:09, 509MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.20G/9.94G [00:09<00:09, 520MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.26G/9.94G [00:10<00:08, 532MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▎    | 5.33G/9.94G [00:10<00:08, 523MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▍    | 5.39G/9.94G [00:10<00:08, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▍    | 5.45G/9.94G [00:10<00:08, 544MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▌    | 5.52G/9.94G [00:10<00:08, 530MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.58G/9.94G [00:10<00:11, 386MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.64G/9.94G [00:10<00:10, 428MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.69G/9.94G [00:11<00:11, 367MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.74G/9.94G [00:11<00:14, 289MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.80G/9.94G [00:11<00:12, 340MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.85G/9.94G [00:11<00:11, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.89G/9.94G [00:11<00:15, 269MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|█████▉    | 5.93G/9.94G [00:11<00:13, 293MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|██████    | 5.99G/9.94G [00:12<00:11, 335MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.04G/9.94G [00:12<00:10, 377MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████▏   | 6.09G/9.94G [00:12<00:13, 292MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.13G/9.94G [00:12<00:15, 244MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.17G/9.94G [00:12<00:17, 222MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.20G/9.94G [00:13<00:19, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.23G/9.94G [00:13<00:19, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.26G/9.94G [00:13<00:19, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.28G/9.94G [00:13<00:20, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.31G/9.94G [00:13<00:21, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.34G/9.94G [00:13<00:20, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.36G/9.94G [00:14<00:20, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.39G/9.94G [00:14<00:21, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.41G/9.94G [00:14<00:21, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.43G/9.94G [00:14<00:22, 160MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.45G/9.94G [00:14<00:21, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.47G/9.94G [00:14<00:21, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.49G/9.94G [00:14<00:20, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.51G/9.94G [00:15<00:21, 162MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.54G/9.94G [00:15<00:19, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.56G/9.94G [00:15<00:19, 172MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.59G/9.94G [00:15<00:20, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▋   | 6.61G/9.94G [00:15<00:21, 156MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.63G/9.94G [00:15<00:21, 157MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.65G/9.94G [00:15<00:22, 146MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.68G/9.94G [00:16<00:20, 161MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.71G/9.94G [00:16<00:18, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.73G/9.94G [00:16<00:17, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.76G/9.94G [00:16<00:16, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.78G/9.94G [00:16<00:16, 190MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▊   | 6.82G/9.94G [00:16<00:15, 201MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.85G/9.94G [00:16<00:15, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.87G/9.94G [00:16<00:15, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.90G/9.94G [00:17<00:14, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|██████▉   | 6.92G/9.94G [00:17<00:14, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|██████▉   | 6.94G/9.94G [00:17<00:14, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 6.97G/9.94G [00:17<00:14, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 7.00G/9.94G [00:17<00:14, 205MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.04G/9.94G [00:17<00:13, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.07G/9.94G [00:17<00:13, 213MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████▏  | 7.10G/9.94G [00:18<00:13, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.13G/9.94G [00:18<00:13, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.16G/9.94G [00:18<00:13, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.19G/9.94G [00:18<00:13, 210MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.22G/9.94G [00:18<00:13, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.26G/9.94G [00:18<00:12, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.29G/9.94G [00:18<00:12, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▎  | 7.32G/9.94G [00:19<00:12, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.35G/9.94G [00:19<00:12, 206MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.38G/9.94G [00:19<00:12, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.40G/9.94G [00:19<00:16, 151MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▌  | 7.47G/9.94G [00:19<00:10, 227MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▌  | 7.50G/9.94G [00:19<00:10, 225MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.53G/9.94G [00:20<00:11, 217MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.56G/9.94G [00:20<00:11, 215MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▋  | 7.59G/9.94G [00:20<00:10, 217MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.62G/9.94G [00:20<00:10, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.65G/9.94G [00:20<00:10, 213MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.69G/9.94G [00:20<00:10, 213MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.72G/9.94G [00:21<00:10, 215MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.75G/9.94G [00:21<00:10, 211MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.78G/9.94G [00:21<00:10, 208MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.80G/9.94G [00:21<00:10, 199MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.83G/9.94G [00:21<00:10, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.85G/9.94G [00:21<00:10, 199MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.87G/9.94G [00:21<00:10, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.90G/9.94G [00:21<00:10, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.93G/9.94G [00:22<00:10, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.95G/9.94G [00:22<00:10, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 7.97G/9.94G [00:22<00:10, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 7.99G/9.94G [00:22<00:10, 185MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.01G/9.94G [00:22<00:10, 188MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.03G/9.94G [00:22<00:09, 191MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.05G/9.94G [00:22<00:10, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████▏ | 8.08G/9.94G [00:22<00:09, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.12G/9.94G [00:23<00:09, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.15G/9.94G [00:23<00:09, 198MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.17G/9.94G [00:23<00:09, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.20G/9.94G [00:23<00:09, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.22G/9.94G [00:23<00:08, 194MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.24G/9.94G [00:23<00:08, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.27G/9.94G [00:23<00:08, 193MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.29G/9.94G [00:24<00:08, 196MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▎ | 8.32G/9.94G [00:24<00:08, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.34G/9.94G [00:24<00:08, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.37G/9.94G [00:24<00:08, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.39G/9.94G [00:24<00:08, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.41G/9.94G [00:24<00:08, 187MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.43G/9.94G [00:24<00:08, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.45G/9.94G [00:24<00:08, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.47G/9.94G [00:25<00:07, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.49G/9.94G [00:25<00:07, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.51G/9.94G [00:25<00:07, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.54G/9.94G [00:25<00:08, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.56G/9.94G [00:25<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▋ | 8.58G/9.94G [00:25<00:07, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▋ | 8.60G/9.94G [00:25<00:07, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.62G/9.94G [00:25<00:07, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.64G/9.94G [00:25<00:07, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.66G/9.94G [00:26<00:07, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.68G/9.94G [00:26<00:06, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.70G/9.94G [00:26<00:06, 184MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.72G/9.94G [00:26<00:06, 183MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.75G/9.94G [00:26<00:06, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.77G/9.94G [00:26<00:06, 189MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.79G/9.94G [00:26<00:06, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▊ | 8.81G/9.94G [00:26<00:06, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.83G/9.94G [00:26<00:06, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.85G/9.94G [00:27<00:06, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.87G/9.94G [00:27<00:06, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.89G/9.94G [00:27<00:06, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.91G/9.94G [00:27<00:05, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.93G/9.94G [00:27<00:05, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 8.95G/9.94G [00:27<00:05, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 8.98G/9.94G [00:27<00:05, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 9.00G/9.94G [00:27<00:05, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.02G/9.94G [00:28<00:05, 163MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.05G/9.94G [00:28<00:04, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.07G/9.94G [00:28<00:04, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████▏| 9.09G/9.94G [00:28<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.11G/9.94G [00:28<00:04, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.13G/9.94G [00:28<00:04, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.15G/9.94G [00:28<00:04, 173MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.18G/9.94G [00:28<00:04, 181MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.20G/9.94G [00:29<00:04, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.22G/9.94G [00:29<00:04, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.24G/9.94G [00:29<00:04, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.26G/9.94G [00:29<00:03, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.28G/9.94G [00:29<00:03, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▎| 9.30G/9.94G [00:29<00:03, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.32G/9.94G [00:29<00:03, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.34G/9.94G [00:29<00:03, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.36G/9.94G [00:30<00:03, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.38G/9.94G [00:30<00:03, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.41G/9.94G [00:30<00:03, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.43G/9.94G [00:30<00:03, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.45G/9.94G [00:30<00:02, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.47G/9.94G [00:30<00:02, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.49G/9.94G [00:30<00:02, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.51G/9.94G [00:30<00:02, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.53G/9.94G [00:31<00:02, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.55G/9.94G [00:31<00:02, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▋| 9.57G/9.94G [00:31<00:02, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▋| 9.59G/9.94G [00:31<00:02, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.62G/9.94G [00:31<00:01, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.64G/9.94G [00:31<00:01, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.66G/9.94G [00:31<00:01, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.68G/9.94G [00:31<00:01, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.70G/9.94G [00:32<00:01, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.72G/9.94G [00:32<00:01, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.74G/9.94G [00:32<00:01, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.76G/9.94G [00:32<00:01, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.78G/9.94G [00:32<00:00, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▊| 9.80G/9.94G [00:32<00:00, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.83G/9.94G [00:32<00:00, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.85G/9.94G [00:32<00:00, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.87G/9.94G [00:33<00:00, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.89G/9.94G [00:33<00:00, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.91G/9.94G [00:33<00:00, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.93G/9.94G [00:33<00:00, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|██████████| 9.94G/9.94G [00:33<00:00, 296MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 1/2 [00:34<00:34, 34.08s/it]\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   1%|          | 52.4M/4.54G [00:00<00:09, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   2%|▏         | 105M/4.54G [00:00<00:09, 460MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   3%|▎         | 157M/4.54G [00:00<00:09, 482MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   5%|▍         | 210M/4.54G [00:00<00:08, 483MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   6%|▌         | 262M/4.54G [00:00<00:14, 294MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   7%|▋         | 304M/4.54G [00:00<00:17, 246MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   7%|▋         | 336M/4.54G [00:01<00:19, 216MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   8%|▊         | 367M/4.54G [00:01<00:20, 203MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▉         | 398M/4.54G [00:01<00:21, 193MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▉         | 430M/4.54G [00:01<00:22, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|▉         | 451M/4.54G [00:01<00:23, 177MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|█         | 472M/4.54G [00:01<00:23, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  11%|█         | 493M/4.54G [00:02<00:23, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  11%|█▏        | 514M/4.54G [00:02<00:22, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 535M/4.54G [00:02<00:22, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 556M/4.54G [00:02<00:23, 167MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  13%|█▎        | 577M/4.54G [00:02<00:23, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  13%|█▎        | 598M/4.54G [00:02<00:23, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  14%|█▎        | 619M/4.54G [00:02<00:22, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  14%|█▍        | 640M/4.54G [00:02<00:22, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▍        | 661M/4.54G [00:03<00:23, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▌        | 682M/4.54G [00:03<00:23, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▌        | 703M/4.54G [00:03<00:22, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▌        | 724M/4.54G [00:03<00:22, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▋        | 744M/4.54G [00:03<00:22, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 765M/4.54G [00:03<00:21, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 786M/4.54G [00:03<00:21, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 807M/4.54G [00:03<00:21, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 828M/4.54G [00:04<00:22, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  19%|█▊        | 849M/4.54G [00:04<00:21, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  19%|█▉        | 870M/4.54G [00:04<00:21, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  20%|█▉        | 891M/4.54G [00:04<00:21, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  20%|██        | 912M/4.54G [00:04<00:20, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██        | 933M/4.54G [00:04<00:20, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██        | 954M/4.54G [00:04<00:20, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██▏       | 975M/4.54G [00:04<00:21, 165MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  22%|██▏       | 996M/4.54G [00:05<00:21, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  22%|██▏       | 1.02G/4.54G [00:05<00:20, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  23%|██▎       | 1.04G/4.54G [00:05<00:20, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  23%|██▎       | 1.06G/4.54G [00:05<00:20, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 1.08G/4.54G [00:05<00:20, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 1.10G/4.54G [00:05<00:19, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  25%|██▍       | 1.12G/4.54G [00:05<00:19, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  25%|██▌       | 1.14G/4.54G [00:05<00:19, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  26%|██▌       | 1.16G/4.54G [00:06<00:19, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  26%|██▌       | 1.18G/4.54G [00:06<00:28, 116MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  27%|██▋       | 1.24G/4.54G [00:06<00:17, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  28%|██▊       | 1.27G/4.54G [00:06<00:17, 186MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  29%|██▊       | 1.30G/4.54G [00:06<00:17, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  29%|██▉       | 1.32G/4.54G [00:06<00:17, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|██▉       | 1.34G/4.54G [00:07<00:17, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|███       | 1.36G/4.54G [00:07<00:17, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|███       | 1.38G/4.54G [00:07<00:17, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  31%|███       | 1.41G/4.54G [00:07<00:17, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  31%|███▏      | 1.43G/4.54G [00:07<00:17, 176MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  32%|███▏      | 1.45G/4.54G [00:07<00:17, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  32%|███▏      | 1.47G/4.54G [00:07<00:17, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  33%|███▎      | 1.49G/4.54G [00:07<00:17, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  33%|███▎      | 1.51G/4.54G [00:08<00:17, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  34%|███▎      | 1.53G/4.54G [00:08<00:17, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  34%|███▍      | 1.55G/4.54G [00:08<00:17, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  35%|███▍      | 1.57G/4.54G [00:08<00:16, 175MB/s]\u001b[0m\n",
      "\u001b[34m#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  35%|███▌      | 1.59G/4.54G [00:08<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▌      | 1.61G/4.54G [00:08<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▌      | 1.64G/4.54G [00:08<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▋      | 1.66G/4.54G [00:08<00:16, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 1.68G/4.54G [00:08<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 1.70G/4.54G [00:09<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  38%|███▊      | 1.72G/4.54G [00:09<00:16, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  38%|███▊      | 1.74G/4.54G [00:09<00:17, 164MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.76G/4.54G [00:09<00:16, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.78G/4.54G [00:09<00:16, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  40%|███▉      | 1.80G/4.54G [00:09<00:15, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  40%|████      | 1.82G/4.54G [00:09<00:15, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  41%|████      | 1.85G/4.54G [00:09<00:15, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  41%|████      | 1.87G/4.54G [00:10<00:15, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.89G/4.54G [00:10<00:15, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.91G/4.54G [00:10<00:15, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.93G/4.54G [00:10<00:14, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  43%|████▎     | 1.95G/4.54G [00:10<00:14, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  43%|████▎     | 1.97G/4.54G [00:10<00:14, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  44%|████▍     | 1.99G/4.54G [00:10<00:14, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  44%|████▍     | 2.01G/4.54G [00:10<00:14, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▍     | 2.03G/4.54G [00:11<00:14, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▌     | 2.06G/4.54G [00:11<00:14, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▌     | 2.08G/4.54G [00:11<00:14, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▌     | 2.10G/4.54G [00:11<00:13, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 2.12G/4.54G [00:11<00:13, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 2.14G/4.54G [00:11<00:13, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.16G/4.54G [00:11<00:13, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.18G/4.54G [00:11<00:13, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.20G/4.54G [00:12<00:13, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 2.22G/4.54G [00:12<00:13, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 2.24G/4.54G [00:12<00:13, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|████▉     | 2.26G/4.54G [00:12<00:13, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|█████     | 2.29G/4.54G [00:12<00:13, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████     | 2.31G/4.54G [00:12<00:13, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████▏    | 2.33G/4.54G [00:12<00:12, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 2.35G/4.54G [00:12<00:12, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 2.37G/4.54G [00:12<00:12, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  53%|█████▎    | 2.39G/4.54G [00:13<00:12, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  53%|█████▎    | 2.41G/4.54G [00:13<00:12, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  54%|█████▎    | 2.43G/4.54G [00:13<00:12, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  54%|█████▍    | 2.45G/4.54G [00:13<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▍    | 2.47G/4.54G [00:13<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▍    | 2.50G/4.54G [00:13<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▌    | 2.52G/4.54G [00:13<00:11, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  56%|█████▌    | 2.54G/4.54G [00:13<00:11, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  56%|█████▋    | 2.56G/4.54G [00:14<00:11, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 2.58G/4.54G [00:14<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 2.60G/4.54G [00:14<00:11, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.62G/4.54G [00:14<00:11, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.64G/4.54G [00:14<00:10, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  59%|█████▊    | 2.66G/4.54G [00:14<00:10, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  59%|█████▉    | 2.68G/4.54G [00:14<00:10, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  60%|█████▉    | 2.71G/4.54G [00:14<00:10, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  60%|██████    | 2.73G/4.54G [00:15<00:10, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.75G/4.54G [00:15<00:10, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.77G/4.54G [00:15<00:10, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████▏   | 2.79G/4.54G [00:15<00:10, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.81G/4.54G [00:15<00:10, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.83G/4.54G [00:15<00:10, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.85G/4.54G [00:15<00:09, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.87G/4.54G [00:15<00:09, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▎   | 2.89G/4.54G [00:16<00:09, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▍   | 2.92G/4.54G [00:16<00:09, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▍   | 2.94G/4.54G [00:16<00:09, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▌   | 2.96G/4.54G [00:16<00:09, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  66%|██████▌   | 2.98G/4.54G [00:16<00:08, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  66%|██████▌   | 3.00G/4.54G [00:16<00:08, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.02G/4.54G [00:16<00:08, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.04G/4.54G [00:16<00:08, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.06G/4.54G [00:16<00:08, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 3.08G/4.54G [00:17<00:08, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 3.10G/4.54G [00:17<00:08, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  69%|██████▉   | 3.12G/4.54G [00:17<00:08, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  69%|██████▉   | 3.15G/4.54G [00:17<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  70%|██████▉   | 3.17G/4.54G [00:17<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  70%|███████   | 3.19G/4.54G [00:17<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████   | 3.21G/4.54G [00:17<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████   | 3.23G/4.54G [00:17<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 3.25G/4.54G [00:18<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 3.27G/4.54G [00:18<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.29G/4.54G [00:18<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.31G/4.54G [00:18<00:07, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.33G/4.54G [00:18<00:07, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▍  | 3.36G/4.54G [00:18<00:07, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▍  | 3.38G/4.54G [00:18<00:06, 170MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▍  | 3.40G/4.54G [00:18<00:06, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▌  | 3.42G/4.54G [00:19<00:07, 159MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.45G/4.54G [00:19<00:06, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▋  | 3.47G/4.54G [00:19<00:05, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.49G/4.54G [00:19<00:05, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.51G/4.54G [00:19<00:05, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.53G/4.54G [00:19<00:05, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.55G/4.54G [00:19<00:05, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▊  | 3.58G/4.54G [00:19<00:05, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▉  | 3.60G/4.54G [00:20<00:05, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|███████▉  | 3.62G/4.54G [00:20<00:05, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|████████  | 3.64G/4.54G [00:20<00:05, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████  | 3.66G/4.54G [00:20<00:05, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████  | 3.68G/4.54G [00:20<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.70G/4.54G [00:20<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.72G/4.54G [00:20<00:04, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.74G/4.54G [00:20<00:04, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.76G/4.54G [00:21<00:04, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.79G/4.54G [00:21<00:04, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▍ | 3.81G/4.54G [00:21<00:05, 124MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▍ | 3.86G/4.54G [00:21<00:03, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.89G/4.54G [00:21<00:03, 185MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.91G/4.54G [00:21<00:03, 182MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.93G/4.54G [00:22<00:03, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.95G/4.54G [00:22<00:03, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 3.97G/4.54G [00:22<00:03, 179MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 4.00G/4.54G [00:22<00:03, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 4.02G/4.54G [00:22<00:02, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 4.04G/4.54G [00:22<00:02, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 4.06G/4.54G [00:22<00:02, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|████████▉ | 4.08G/4.54G [00:22<00:02, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|█████████ | 4.10G/4.54G [00:22<00:02, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.12G/4.54G [00:23<00:02, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.14G/4.54G [00:23<00:02, 169MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.16G/4.54G [00:23<00:02, 171MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.18G/4.54G [00:23<00:02, 172MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.20G/4.54G [00:23<00:01, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.23G/4.54G [00:23<00:01, 173MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▎| 4.25G/4.54G [00:23<00:01, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.27G/4.54G [00:23<00:01, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.29G/4.54G [00:24<00:01, 155MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▌| 4.32G/4.54G [00:24<00:01, 180MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 4.34G/4.54G [00:24<00:01, 178MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 4.36G/4.54G [00:24<00:01, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.38G/4.54G [00:24<00:00, 177MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.40G/4.54G [00:24<00:00, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.42G/4.54G [00:24<00:00, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.45G/4.54G [00:24<00:00, 176MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.47G/4.54G [00:25<00:00, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▉| 4.49G/4.54G [00:25<00:00, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▉| 4.51G/4.54G [00:25<00:00, 174MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|█████████▉| 4.53G/4.54G [00:25<00:00, 175MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|██████████| 4.54G/4.54G [00:25<00:00, 178MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [01:00<00:00, 29.36s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [01:00<00:00, 30.07s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.86s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  7.00s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.18s/it]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 120/120 [00:00<00:00, 1.26MB/s]\u001b[0m\n",
      "\u001b[34mFound 7 modules to quantize: ['o_proj', 'down_proj', 'gate_proj', 'k_proj', 'v_proj', 'up_proj', 'q_proj']\u001b[0m\n",
      "\u001b[34mCUDA extension not installed.\u001b[0m\n",
      "\u001b[34mCUDA extension not installed.\u001b[0m\n",
      "\u001b[34mtrainable params: 167,772,160 || all params: 7,409,520,640 || trainable%: 2.2642781922259414\u001b[0m\n",
      "\u001b[34m0%|          | 0/658 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34m0%|          | 1/658 [00:18<3:23:39, 18.60s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 2/658 [00:36<3:21:13, 18.40s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/658 [00:55<3:20:15, 18.34s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 4/658 [01:13<3:19:39, 18.32s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 5/658 [01:31<3:19:11, 18.30s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 6/658 [01:49<3:18:46, 18.29s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 7/658 [02:08<3:18:24, 18.29s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 8/658 [02:26<3:18:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 9/658 [02:44<3:17:44, 18.28s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 10/658 [03:03<3:17:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6927, 'learning_rate': 1.5e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m2%|▏         | 10/658 [03:03<3:17:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 11/658 [03:21<3:17:07, 18.28s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 12/658 [03:39<3:16:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 13/658 [03:57<3:16:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 14/658 [04:16<3:16:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 15/658 [04:34<3:15:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 16/658 [04:52<3:15:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 17/658 [05:11<3:15:16, 18.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 18/658 [05:29<3:14:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 19/658 [05:47<3:14:39, 18.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 20/658 [06:05<3:14:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.5476, 'learning_rate': 3e-05, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34m3%|▎         | 20/658 [06:05<3:14:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 21/658 [06:24<3:14:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 22/658 [06:42<3:13:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 23/658 [07:00<3:13:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 24/658 [07:18<3:13:09, 18.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 25/658 [07:37<3:12:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 26/658 [07:55<3:12:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 27/658 [08:13<3:12:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 28/658 [08:32<3:11:56, 18.28s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 29/658 [08:50<3:11:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 30/658 [09:08<3:11:19, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2731, 'learning_rate': 2.9981818408468026e-05, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34m5%|▍         | 30/658 [09:08<3:11:19, 18.28s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 31/658 [09:26<3:11:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 32/658 [09:45<3:10:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 33/658 [10:03<3:10:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 34/658 [10:21<3:10:07, 18.28s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 35/658 [10:40<3:09:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 36/658 [10:58<3:09:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 37/658 [11:16<3:09:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 38/658 [11:34<3:08:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 39/658 [11:53<3:08:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 40/658 [12:11<3:08:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1895, 'learning_rate': 2.992731770990817e-05, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34m6%|▌         | 40/658 [12:11<3:08:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 41/658 [12:29<3:07:59, 18.28s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 42/658 [12:48<3:07:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 43/658 [13:06<3:07:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 44/658 [13:24<3:07:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 45/658 [13:42<3:06:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 46/658 [14:01<3:06:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 47/658 [14:19<3:06:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 48/658 [14:37<3:05:50, 18.28s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 49/658 [14:55<3:05:32, 18.28s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 50/658 [15:14<3:05:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.292, 'learning_rate': 2.9836630025579043e-05, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34m8%|▊         | 50/658 [15:14<3:05:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 51/658 [15:32<3:04:56, 18.28s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 52/658 [15:50<3:04:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 53/658 [16:09<3:04:19, 18.28s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 54/658 [16:27<3:04:00, 18.28s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 55/658 [16:45<3:03:42, 18.28s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 56/658 [17:03<3:03:24, 18.28s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 57/658 [17:22<3:03:05, 18.28s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 58/658 [17:40<3:02:47, 18.28s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 59/658 [17:58<3:02:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 60/658 [18:17<3:02:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1243, 'learning_rate': 2.9709975201671755e-05, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34m9%|▉         | 60/658 [18:17<3:02:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 61/658 [18:35<3:01:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 62/658 [18:53<3:01:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 63/658 [19:11<3:01:16, 18.28s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 64/658 [19:30<3:00:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 65/658 [19:48<3:00:39, 18.28s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 66/658 [20:06<3:00:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 67/658 [20:25<3:00:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 68/658 [20:43<2:59:44, 18.28s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 69/658 [21:01<2:59:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 70/658 [21:19<2:59:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2075, 'learning_rate': 2.954766027635616e-05, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34m11%|█         | 70/658 [21:19<2:59:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 71/658 [21:38<2:58:50, 18.28s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 72/658 [21:56<2:58:31, 18.28s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 73/658 [22:14<2:58:12, 18.28s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 74/658 [22:32<2:57:54, 18.28s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 75/658 [22:51<2:57:36, 18.28s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 76/658 [23:09<2:57:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 77/658 [23:27<2:56:59, 18.28s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 78/658 [23:46<2:56:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 79/658 [24:04<2:56:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 80/658 [24:22<2:56:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0696, 'learning_rate': 2.9350078735455142e-05, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 80/658 [24:22<2:56:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 81/658 [24:40<2:55:46, 18.28s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 82/658 [24:59<2:55:28, 18.28s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 83/658 [25:17<2:55:10, 18.28s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 84/658 [25:35<2:54:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 85/658 [25:54<2:54:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 86/658 [26:12<2:54:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 87/658 [26:30<2:53:56, 18.28s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 88/658 [26:48<2:53:38, 18.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 89/658 [27:07<2:53:20, 18.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 90/658 [27:25<2:53:02, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2391, 'learning_rate': 2.9117709558551485e-05, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34m14%|█▎        | 90/658 [27:25<2:53:02, 18.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 91/658 [27:43<2:52:44, 18.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 92/658 [28:01<2:52:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 93/658 [28:20<2:52:07, 18.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 94/658 [28:38<2:51:49, 18.28s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 95/658 [28:56<2:51:31, 18.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 96/658 [29:15<2:51:13, 18.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 97/658 [29:33<2:50:55, 18.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 98/658 [29:51<2:50:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 99/658 [30:09<2:50:18, 18.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 100/658 [30:28<2:50:00, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1709, 'learning_rate': 2.8851116057839732e-05, 'epoch': 0.3}\u001b[0m\n",
      "\u001b[34m15%|█▌        | 100/658 [30:28<2:50:00, 18.28s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 101/658 [30:46<2:49:42, 18.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 102/658 [31:04<2:49:24, 18.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 103/658 [31:23<2:49:05, 18.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 104/658 [31:41<2:48:47, 18.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 105/658 [31:59<2:48:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 106/658 [32:17<2:48:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 107/658 [32:36<2:47:52, 18.28s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 108/658 [32:54<2:47:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 109/658 [33:12<2:47:15, 18.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 110/658 [33:31<2:46:57, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1473, 'learning_rate': 2.8550944512537897e-05, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 110/658 [33:31<2:46:57, 18.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 111/658 [33:49<2:46:39, 18.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 112/658 [34:07<2:46:20, 18.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 113/658 [34:25<2:46:02, 18.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 114/658 [34:44<2:45:44, 18.28s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 115/658 [35:02<2:45:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 116/658 [35:20<2:45:07, 18.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 117/658 [35:38<2:44:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 118/658 [35:57<2:44:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 119/658 [36:15<2:44:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 120/658 [36:33<2:43:52, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2227, 'learning_rate': 2.8217922602169464e-05, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 120/658 [36:33<2:43:52, 18.28s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 121/658 [36:52<2:43:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 122/658 [37:10<2:43:15, 18.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 123/658 [37:28<2:42:57, 18.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 124/658 [37:46<2:42:39, 18.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 125/658 [38:05<2:42:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 126/658 [38:23<2:42:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 127/658 [38:41<2:41:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 128/658 [39:00<2:41:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 129/658 [39:18<2:41:09, 18.28s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 130/658 [39:36<2:40:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1191, 'learning_rate': 2.7852857642513838e-05, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34m20%|█▉        | 130/658 [39:36<2:40:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 131/658 [39:54<2:40:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 132/658 [40:13<2:40:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 133/658 [40:31<2:39:55, 18.28s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 134/658 [40:49<2:39:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 135/658 [41:07<2:39:18, 18.28s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 136/658 [41:26<2:38:59, 18.28s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 137/658 [41:44<2:38:41, 18.28s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 138/658 [42:02<2:38:23, 18.28s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 139/658 [42:21<2:38:05, 18.28s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 140/658 [42:39<2:37:47, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1322, 'learning_rate': 2.7456634628501568e-05, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34m21%|██▏       | 140/658 [42:39<2:37:47, 18.28s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 141/658 [42:57<2:37:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 142/658 [43:15<2:37:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 143/658 [43:34<2:36:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 144/658 [43:52<2:36:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 145/658 [44:10<2:36:16, 18.28s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 146/658 [44:29<2:35:59, 18.28s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 147/658 [44:47<2:35:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 148/658 [45:05<2:35:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 149/658 [45:23<2:35:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 150/658 [45:42<2:34:44, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0745, 'learning_rate': 2.703021408879883e-05, 'epoch': 0.46}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 150/658 [45:42<2:34:44, 18.28s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 151/658 [46:00<2:34:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 152/658 [46:18<2:34:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 153/658 [46:36<2:33:50, 18.28s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 154/658 [46:55<2:33:32, 18.28s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 155/658 [47:13<2:33:13, 18.28s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 156/658 [47:31<2:32:55, 18.28s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 157/658 [47:50<2:32:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 158/658 [48:08<2:32:18, 18.28s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 159/658 [48:26<2:32:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 160/658 [48:44<2:31:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1283, 'learning_rate': 2.6574629757282116e-05, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 160/658 [48:44<2:31:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 161/658 [49:03<2:31:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 162/658 [49:21<2:31:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 163/658 [49:39<2:30:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 164/658 [49:58<2:30:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 165/658 [50:16<2:30:12, 18.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 166/658 [50:34<2:29:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 167/658 [50:52<2:29:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 168/658 [51:11<2:29:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 169/658 [51:29<2:28:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 170/658 [51:47<2:28:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1428, 'learning_rate': 2.6090986067047967e-05, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 170/658 [51:47<2:28:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 171/658 [52:05<2:28:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 172/658 [52:24<2:28:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 173/658 [52:42<2:27:46, 18.28s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 174/658 [53:00<2:27:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 175/658 [53:19<2:27:09, 18.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 176/658 [53:37<2:26:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 177/658 [53:55<2:26:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 178/658 [54:13<2:26:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 179/658 [54:32<2:25:56, 18.28s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 180/658 [54:50<2:25:38, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1234, 'learning_rate': 2.5580455473032763e-05, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 180/658 [54:50<2:25:38, 18.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 181/658 [55:08<2:25:20, 18.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 182/658 [55:27<2:25:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 183/658 [55:45<2:24:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 184/658 [56:03<2:24:24, 18.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 185/658 [56:21<2:24:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 186/658 [56:40<2:23:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 187/658 [56:58<2:23:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 188/658 [57:16<2:23:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 189/658 [57:35<2:22:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 190/658 [57:53<2:22:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1559, 'learning_rate': 2.5044275609733162e-05, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34m29%|██▉       | 190/658 [57:53<2:22:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 191/658 [58:11<2:22:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 192/658 [58:29<2:21:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 193/658 [58:48<2:21:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 194/658 [59:06<2:21:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 195/658 [59:24<2:21:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 196/658 [59:43<2:20:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 197/658 [1:00:01<2:20:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 198/658 [1:00:19<2:20:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 199/658 [1:00:37<2:19:50, 18.28s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 200/658 [1:00:56<2:19:32, 18.28s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 200/658 [1:00:56<2:19:32, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1271, 'learning_rate': 2.448374629091746e-05, 'epoch': 0.61}\u001b[0m\n",
      "\u001b[34m31%|███       | 201/658 [1:01:14<2:19:13, 18.28s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 202/658 [1:01:32<2:18:55, 18.28s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 203/658 [1:01:50<2:18:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 204/658 [1:02:09<2:18:19, 18.28s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 205/658 [1:02:27<2:18:02, 18.28s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 206/658 [1:02:45<2:17:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 207/658 [1:03:04<2:17:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 208/658 [1:03:22<2:17:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 209/658 [1:03:40<2:16:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 210/658 [1:03:58<2:16:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.088, 'learning_rate': 2.390022635860117e-05, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 210/658 [1:03:58<2:16:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 211/658 [1:04:17<2:16:10, 18.28s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 212/658 [1:04:35<2:15:52, 18.28s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 213/658 [1:04:53<2:15:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 214/658 [1:05:12<2:15:15, 18.28s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 215/658 [1:05:30<2:14:56, 18.28s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 216/658 [1:05:48<2:14:38, 18.28s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 217/658 [1:06:06<2:14:20, 18.28s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 218/658 [1:06:25<2:14:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 219/658 [1:06:43<2:13:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 220/658 [1:07:01<2:13:24, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0956, 'learning_rate': 2.329513038892565e-05, 'epoch': 0.67}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 220/658 [1:07:01<2:13:24, 18.28s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 221/658 [1:07:19<2:13:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 222/658 [1:07:38<2:12:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 223/658 [1:07:56<2:12:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 224/658 [1:08:14<2:12:12, 18.28s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 225/658 [1:08:33<2:11:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 226/658 [1:08:51<2:11:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 227/658 [1:09:09<2:11:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 228/658 [1:09:27<2:10:59, 18.28s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 229/658 [1:09:46<2:10:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 230/658 [1:10:04<2:10:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1044, 'learning_rate': 2.266992526292534e-05, 'epoch': 0.7}\u001b[0m\n",
      "\u001b[34m35%|███▍      | 230/658 [1:10:04<2:10:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 231/658 [1:10:22<2:10:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 232/658 [1:10:41<2:09:46, 18.28s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 233/658 [1:10:59<2:09:28, 18.28s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 234/658 [1:11:17<2:09:10, 18.28s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 235/658 [1:11:35<2:08:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 236/658 [1:11:54<2:08:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 237/658 [1:12:12<2:08:15, 18.28s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 238/658 [1:12:30<2:07:57, 18.28s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 239/658 [1:12:48<2:07:39, 18.28s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 240/658 [1:13:07<2:07:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1102, 'learning_rate': 2.2026126610496852e-05, 'epoch': 0.73}\u001b[0m\n",
      "\u001b[34m36%|███▋      | 240/658 [1:13:07<2:07:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 241/658 [1:13:25<2:07:02, 18.28s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 242/658 [1:13:43<2:06:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 243/658 [1:14:02<2:06:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 244/658 [1:14:20<2:06:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 245/658 [1:14:38<2:05:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 246/658 [1:14:56<2:05:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 247/658 [1:15:15<2:05:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 248/658 [1:15:33<2:04:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 249/658 [1:15:51<2:04:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 250/658 [1:16:10<2:04:16, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0968, 'learning_rate': 2.13652951361905e-05, 'epoch': 0.76}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 250/658 [1:16:10<2:04:16, 18.28s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 251/658 [1:16:28<2:03:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 252/658 [1:16:46<2:03:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 253/658 [1:17:04<2:03:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 254/658 [1:17:23<2:03:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 255/658 [1:17:41<2:02:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 256/658 [1:17:59<2:02:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 257/658 [1:18:17<2:02:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 258/658 [1:18:36<2:01:50, 18.28s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 259/658 [1:18:54<2:01:32, 18.28s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 260/658 [1:19:12<2:01:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0086, 'learning_rate': 2.0689032835731246e-05, 'epoch': 0.79}\u001b[0m\n",
      "\u001b[34m40%|███▉      | 260/658 [1:19:12<2:01:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 261/658 [1:19:31<2:00:55, 18.28s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 262/658 [1:19:49<2:00:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 263/658 [1:20:07<2:00:19, 18.28s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 264/658 [1:20:25<2:00:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 265/658 [1:20:44<1:59:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 266/658 [1:21:02<1:59:24, 18.28s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 267/658 [1:21:20<1:59:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 268/658 [1:21:39<1:58:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 269/658 [1:21:57<1:58:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 270/658 [1:22:15<1:58:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1264, 'learning_rate': 1.9998979112441166e-05, 'epoch': 0.82}\u001b[0m\n",
      "\u001b[34m41%|████      | 270/658 [1:22:15<1:58:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 271/658 [1:22:33<1:57:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 272/658 [1:22:52<1:57:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 273/658 [1:23:10<1:57:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 274/658 [1:23:28<1:56:59, 18.28s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 275/658 [1:23:46<1:56:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 276/658 [1:24:05<1:56:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 277/658 [1:24:23<1:56:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 278/658 [1:24:41<1:55:46, 18.28s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 279/658 [1:25:00<1:55:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 280/658 [1:25:18<1:55:09, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1082, 'learning_rate': 1.929680680297784e-05, 'epoch': 0.85}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 280/658 [1:25:18<1:55:09, 18.28s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 281/658 [1:25:36<1:54:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 282/658 [1:25:54<1:54:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 283/658 [1:26:13<1:54:15, 18.28s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 284/658 [1:26:31<1:53:56, 18.28s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 285/658 [1:26:49<1:53:38, 18.28s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 286/658 [1:27:08<1:53:20, 18.28s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 287/658 [1:27:26<1:53:02, 18.28s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 288/658 [1:27:44<1:52:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 289/658 [1:28:02<1:52:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 290/658 [1:28:21<1:52:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9945, 'learning_rate': 1.8584218122023377e-05, 'epoch': 0.88}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 290/658 [1:28:21<1:52:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 291/658 [1:28:39<1:51:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 292/658 [1:28:57<1:51:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 293/658 [1:29:16<1:51:12, 18.28s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 294/658 [1:29:34<1:50:54, 18.28s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 295/658 [1:29:52<1:50:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 296/658 [1:30:10<1:50:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 297/658 [1:30:29<1:49:59, 18.28s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 298/658 [1:30:47<1:49:41, 18.28s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 299/658 [1:31:05<1:49:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 300/658 [1:31:23<1:49:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0909, 'learning_rate': 1.7862940535754754e-05, 'epoch': 0.91}\u001b[0m\n",
      "\u001b[34m46%|████▌     | 300/658 [1:31:23<1:49:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 301/658 [1:31:42<1:48:46, 18.28s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 302/658 [1:32:00<1:48:28, 18.28s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 303/658 [1:32:18<1:48:09, 18.28s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 304/658 [1:32:37<1:47:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 305/658 [1:32:55<1:47:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 306/658 [1:33:13<1:47:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 307/658 [1:33:31<1:46:56, 18.28s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 308/658 [1:33:50<1:46:38, 18.28s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 309/658 [1:34:08<1:46:19, 18.28s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 310/658 [1:34:26<1:46:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0531, 'learning_rate': 1.713472257409928e-05, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[34m47%|████▋     | 310/658 [1:34:26<1:46:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 311/658 [1:34:45<1:45:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 312/658 [1:35:03<1:45:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 313/658 [1:35:21<1:45:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 314/658 [1:35:39<1:44:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 315/658 [1:35:58<1:44:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 316/658 [1:36:16<1:44:12, 18.28s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 317/658 [1:36:34<1:43:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 318/658 [1:36:53<1:43:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 319/658 [1:37:11<1:43:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 320/658 [1:37:29<1:42:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0517, 'learning_rate': 1.640132959192695e-05, 'epoch': 0.97}\u001b[0m\n",
      "\u001b[34m49%|████▊     | 320/658 [1:37:29<1:42:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 321/658 [1:37:47<1:42:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 322/658 [1:38:06<1:42:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 323/658 [1:38:24<1:42:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 324/658 [1:38:42<1:41:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 325/658 [1:39:01<1:41:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 326/658 [1:39:19<1:41:09, 18.28s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 327/658 [1:39:37<1:40:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 328/658 [1:39:55<1:40:31, 18.28s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 329/658 [1:40:05<1:25:44, 15.64s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 330/658 [1:40:24<1:31:25, 16.72s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9459, 'learning_rate': 1.5664539489455684e-05, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m50%|█████     | 330/658 [1:40:24<1:31:25, 16.72s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 331/658 [1:40:42<1:33:41, 17.19s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 332/658 [1:41:01<1:35:10, 17.52s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 333/658 [1:41:19<1:36:07, 17.75s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 334/658 [1:41:37<1:36:41, 17.91s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 335/658 [1:41:55<1:37:00, 18.02s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 336/658 [1:42:14<1:37:07, 18.10s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 337/658 [1:42:32<1:37:06, 18.15s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 338/658 [1:42:50<1:37:01, 18.19s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 339/658 [1:43:09<1:36:51, 18.22s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 340/658 [1:43:27<1:36:39, 18.24s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9677, 'learning_rate': 1.4926138402243861e-05, 'epoch': 1.03}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 340/658 [1:43:27<1:36:39, 18.24s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 341/658 [1:43:45<1:36:25, 18.25s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 342/658 [1:44:03<1:36:09, 18.26s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 343/658 [1:44:22<1:35:53, 18.27s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 344/658 [1:44:40<1:35:37, 18.27s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 345/658 [1:44:58<1:35:19, 18.27s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 346/658 [1:45:17<1:35:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 347/658 [1:45:35<1:34:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 348/658 [1:45:53<1:34:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 349/658 [1:46:11<1:34:07, 18.28s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 350/658 [1:46:30<1:33:49, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9966, 'learning_rate': 1.4187916371218739e-05, 'epoch': 1.06}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 350/658 [1:46:30<1:33:49, 18.28s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 351/658 [1:46:48<1:33:32, 18.28s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 352/658 [1:47:06<1:33:13, 18.28s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 353/658 [1:47:25<1:32:55, 18.28s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 354/658 [1:47:43<1:32:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 355/658 [1:48:01<1:32:18, 18.28s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 356/658 [1:48:19<1:32:00, 18.28s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 357/658 [1:48:38<1:31:42, 18.28s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 358/658 [1:48:56<1:31:24, 18.28s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 359/658 [1:49:14<1:31:05, 18.28s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 360/658 [1:49:32<1:30:47, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.922, 'learning_rate': 1.3451663003237395e-05, 'epoch': 1.09}\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 360/658 [1:49:32<1:30:47, 18.28s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 361/658 [1:49:51<1:30:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 362/658 [1:50:09<1:30:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 363/658 [1:50:27<1:29:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 364/658 [1:50:46<1:29:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 365/658 [1:51:04<1:29:16, 18.28s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 366/658 [1:51:22<1:28:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 367/658 [1:51:40<1:28:39, 18.28s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 368/658 [1:51:59<1:28:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 369/658 [1:52:17<1:28:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 370/658 [1:52:35<1:27:44, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8764, 'learning_rate': 1.2719163132699918e-05, 'epoch': 1.12}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 370/658 [1:52:35<1:27:44, 18.28s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 371/658 [1:52:54<1:27:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 372/658 [1:53:12<1:27:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 373/658 [1:53:30<1:26:50, 18.28s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 374/658 [1:53:48<1:26:31, 18.28s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 375/658 [1:54:07<1:26:13, 18.28s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 376/658 [1:54:25<1:25:55, 18.28s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 377/658 [1:54:43<1:25:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 378/658 [1:55:02<1:25:18, 18.28s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 379/658 [1:55:20<1:25:00, 18.28s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 380/658 [1:55:38<1:24:42, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9008, 'learning_rate': 1.1992192494732083e-05, 'epoch': 1.16}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 380/658 [1:55:38<1:24:42, 18.28s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 381/658 [1:55:56<1:24:23, 18.28s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 382/658 [1:56:15<1:24:05, 18.28s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 383/658 [1:56:33<1:23:47, 18.28s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 384/658 [1:56:51<1:23:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 385/658 [1:57:10<1:23:10, 18.28s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 386/658 [1:57:28<1:22:52, 18.28s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 387/658 [1:57:46<1:22:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 388/658 [1:58:04<1:22:15, 18.28s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 389/658 [1:58:23<1:21:57, 18.28s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 390/658 [1:58:41<1:21:39, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8804, 'learning_rate': 1.1272513420426589e-05, 'epoch': 1.19}\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 390/658 [1:58:41<1:21:39, 18.28s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 391/658 [1:58:59<1:21:20, 18.28s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 392/658 [1:59:17<1:21:02, 18.28s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 393/658 [1:59:36<1:20:44, 18.28s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 394/658 [1:59:54<1:20:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 395/658 [2:00:12<1:20:07, 18.28s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 396/658 [2:00:31<1:19:49, 18.28s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 397/658 [2:00:49<1:19:31, 18.28s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 398/658 [2:01:07<1:19:12, 18.28s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 399/658 [2:01:25<1:18:54, 18.28s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 400/658 [2:01:44<1:18:36, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9602, 'learning_rate': 1.0561870564578535e-05, 'epoch': 1.22}\u001b[0m\n",
      "\u001b[34m61%|██████    | 400/658 [2:01:44<1:18:36, 18.28s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 401/658 [2:02:02<1:18:18, 18.28s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 402/658 [2:02:20<1:17:59, 18.28s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 403/658 [2:02:39<1:17:41, 18.28s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 404/658 [2:02:57<1:17:23, 18.28s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 405/658 [2:03:15<1:17:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 406/658 [2:03:33<1:16:46, 18.28s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 407/658 [2:03:52<1:16:28, 18.28s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 408/658 [2:04:10<1:16:10, 18.28s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 409/658 [2:04:28<1:15:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 410/658 [2:04:47<1:15:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9116, 'learning_rate': 9.86198667627193e-06, 'epoch': 1.25}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 410/658 [2:04:47<1:15:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 411/658 [2:05:05<1:15:15, 18.28s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 412/658 [2:05:23<1:14:57, 18.28s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 413/658 [2:05:41<1:14:38, 18.28s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 414/658 [2:06:00<1:14:20, 18.28s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 415/658 [2:06:18<1:14:02, 18.28s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 416/658 [2:06:36<1:13:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 417/658 [2:06:55<1:13:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 418/658 [2:07:13<1:13:07, 18.28s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 419/658 [2:07:31<1:12:49, 18.28s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 420/658 [2:07:49<1:12:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9159, 'learning_rate': 9.174558422570372e-06, 'epoch': 1.28}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 420/658 [2:07:49<1:12:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 421/658 [2:08:08<1:12:12, 18.28s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 422/658 [2:08:26<1:11:54, 18.28s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 423/658 [2:08:44<1:11:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 424/658 [2:09:02<1:11:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 425/658 [2:09:21<1:10:59, 18.28s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 426/658 [2:09:39<1:10:41, 18.28s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 427/658 [2:09:57<1:10:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 428/658 [2:10:16<1:10:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 429/658 [2:10:34<1:09:46, 18.28s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 430/658 [2:10:52<1:09:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8554, 'learning_rate': 8.501252275436047e-06, 'epoch': 1.31}\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 430/658 [2:10:52<1:09:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 431/658 [2:11:10<1:09:09, 18.28s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 432/658 [2:11:29<1:08:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 433/658 [2:11:47<1:08:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 434/658 [2:12:05<1:08:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 435/658 [2:12:24<1:07:56, 18.28s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 436/658 [2:12:42<1:07:38, 18.28s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 437/658 [2:13:00<1:07:20, 18.28s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 438/658 [2:13:18<1:07:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 439/658 [2:13:37<1:06:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 440/658 [2:13:55<1:06:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8942, 'learning_rate': 7.843700471848044e-06, 'epoch': 1.34}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 440/658 [2:13:55<1:06:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 441/658 [2:14:13<1:06:07, 18.28s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 442/658 [2:14:32<1:05:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 443/658 [2:14:50<1:05:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 444/658 [2:15:08<1:05:12, 18.28s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 445/658 [2:15:26<1:04:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 446/658 [2:15:45<1:04:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 447/658 [2:16:03<1:04:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 448/658 [2:16:21<1:03:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 449/658 [2:16:39<1:03:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 450/658 [2:16:58<1:03:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8379, 'learning_rate': 7.203497056913553e-06, 'epoch': 1.37}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 450/658 [2:16:58<1:03:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 451/658 [2:17:16<1:03:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 452/658 [2:17:34<1:02:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 453/658 [2:17:53<1:02:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 454/658 [2:18:11<1:02:09, 18.28s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 455/658 [2:18:29<1:01:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 456/658 [2:18:47<1:01:32, 18.28s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 457/658 [2:19:06<1:01:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 458/658 [2:19:24<1:00:56, 18.28s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 459/658 [2:19:42<1:00:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 460/658 [2:20:01<1:00:19, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8381, 'learning_rate': 6.582194019564266e-06, 'epoch': 1.4}\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 460/658 [2:20:01<1:00:19, 18.28s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 461/658 [2:20:19<1:00:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 462/658 [2:20:37<59:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 463/658 [2:20:55<59:24, 18.28s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 464/658 [2:21:14<59:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 465/658 [2:21:32<58:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 466/658 [2:21:50<58:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 467/658 [2:22:09<58:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 468/658 [2:22:27<57:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 469/658 [2:22:45<57:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 470/658 [2:23:03<57:16, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.915, 'learning_rate': 5.981297530205881e-06, 'epoch': 1.43}\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 470/658 [2:23:03<57:16, 18.28s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 471/658 [2:23:22<56:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 472/658 [2:23:40<56:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 473/658 [2:23:58<56:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 474/658 [2:24:17<56:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 475/658 [2:24:35<55:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 476/658 [2:24:53<55:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 477/658 [2:25:11<55:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 478/658 [2:25:30<54:50, 18.28s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 479/658 [2:25:48<54:32, 18.28s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 480/658 [2:26:06<54:13, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8995, 'learning_rate': 5.402264289441387e-06, 'epoch': 1.46}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 480/658 [2:26:06<54:13, 18.28s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 481/658 [2:26:24<53:55, 18.28s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 482/658 [2:26:43<53:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 483/658 [2:27:01<53:19, 18.28s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 484/658 [2:27:19<53:00, 18.28s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 485/658 [2:27:38<52:42, 18.28s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 486/658 [2:27:56<52:24, 18.28s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 487/658 [2:28:14<52:05, 18.28s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 488/658 [2:28:32<51:47, 18.28s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 489/658 [2:28:51<51:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 490/658 [2:29:09<51:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8374, 'learning_rate': 4.846497996719734e-06, 'epoch': 1.49}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 490/658 [2:29:09<51:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 491/658 [2:29:27<50:52, 18.28s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 492/658 [2:29:46<50:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 493/658 [2:30:04<50:16, 18.28s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 494/658 [2:30:22<49:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 495/658 [2:30:40<49:39, 18.28s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 496/658 [2:30:59<49:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 497/658 [2:31:17<49:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 498/658 [2:31:35<48:44, 18.28s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 499/658 [2:31:54<48:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 500/658 [2:32:12<48:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8219, 'learning_rate': 4.3153459474704446e-06, 'epoch': 1.52}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 500/658 [2:32:12<48:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 501/658 [2:32:30<47:50, 18.28s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 502/658 [2:32:48<47:31, 18.28s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 503/658 [2:33:07<47:13, 18.28s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 504/658 [2:33:25<46:55, 18.28s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 505/658 [2:33:43<46:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 506/658 [2:34:01<46:18, 18.28s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 507/658 [2:34:20<46:00, 18.28s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 508/658 [2:34:38<45:42, 18.28s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 509/658 [2:34:56<45:23, 18.28s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 510/658 [2:35:15<45:05, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8567, 'learning_rate': 3.810095766973638e-06, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 510/658 [2:35:15<45:05, 18.28s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 511/658 [2:35:33<44:47, 18.28s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 512/658 [2:35:51<44:28, 18.28s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 513/658 [2:36:09<44:10, 18.28s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 514/658 [2:36:28<43:52, 18.28s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 515/658 [2:36:46<43:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 516/658 [2:37:04<43:20, 18.31s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 517/658 [2:37:23<43:00, 18.30s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 518/658 [2:37:41<42:41, 18.30s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 519/658 [2:37:59<42:22, 18.29s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 520/658 [2:38:18<42:03, 18.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.894, 'learning_rate': 3.3319722888830766e-06, 'epoch': 1.58}\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 520/658 [2:38:18<42:03, 18.29s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 521/658 [2:38:36<41:45, 18.29s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 522/658 [2:38:54<41:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 523/658 [2:39:12<41:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 524/658 [2:39:31<40:49, 18.28s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 525/658 [2:39:49<40:31, 18.28s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 526/658 [2:40:07<40:13, 18.28s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 527/658 [2:40:25<39:54, 18.28s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 528/658 [2:40:44<39:36, 18.28s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 529/658 [2:41:02<39:18, 18.28s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 530/658 [2:41:20<39:00, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8324, 'learning_rate': 2.8821345859694914e-06, 'epoch': 1.61}\u001b[0m\n",
      "\u001b[34m81%|████████  | 530/658 [2:41:20<39:00, 18.28s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 531/658 [2:41:39<38:41, 18.28s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 532/658 [2:41:57<38:23, 18.28s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 533/658 [2:42:15<38:05, 18.28s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 534/658 [2:42:33<37:46, 18.28s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 535/658 [2:42:52<37:28, 18.28s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 536/658 [2:43:10<37:10, 18.28s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 537/658 [2:43:28<36:52, 18.28s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 538/658 [2:43:47<36:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 539/658 [2:44:05<36:15, 18.28s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 540/658 [2:44:23<35:57, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9177, 'learning_rate': 2.4616731602822218e-06, 'epoch': 1.64}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 540/658 [2:44:23<35:57, 18.28s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 541/658 [2:44:41<35:38, 18.28s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 542/658 [2:45:00<35:20, 18.28s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 543/658 [2:45:18<35:02, 18.28s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 544/658 [2:45:36<34:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 545/658 [2:45:55<34:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 546/658 [2:46:13<34:07, 18.28s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 547/658 [2:46:31<33:49, 18.28s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 548/658 [2:46:49<33:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 549/658 [2:47:08<33:12, 18.28s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 550/658 [2:47:26<32:54, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9714, 'learning_rate': 2.0716072995408425e-06, 'epoch': 1.67}\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 550/658 [2:47:26<32:54, 18.28s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 551/658 [2:47:44<32:36, 18.28s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 552/658 [2:48:03<32:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 553/658 [2:48:21<31:59, 18.28s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 554/658 [2:48:39<31:41, 18.28s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 555/658 [2:48:57<31:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 556/658 [2:49:16<31:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 557/658 [2:49:34<30:46, 18.28s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 558/658 [2:49:52<30:28, 18.28s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 559/658 [2:50:10<30:09, 18.28s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 560/658 [2:50:29<29:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.852, 'learning_rate': 1.7128826061654346e-06, 'epoch': 1.7}\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 560/658 [2:50:29<29:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 561/658 [2:50:47<29:33, 18.28s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 562/658 [2:51:05<29:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 563/658 [2:51:24<28:56, 18.28s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 564/658 [2:51:42<28:38, 18.28s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 565/658 [2:52:00<28:20, 18.28s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 566/658 [2:52:18<28:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 567/658 [2:52:37<27:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 568/658 [2:52:55<27:25, 18.28s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 569/658 [2:53:13<27:07, 18.28s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 570/658 [2:53:32<26:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8625, 'learning_rate': 1.3863687049356465e-06, 'epoch': 1.73}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 570/658 [2:53:32<26:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 571/658 [2:53:50<26:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 572/658 [2:54:08<26:12, 18.28s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 573/658 [2:54:26<25:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 574/658 [2:54:45<25:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 575/658 [2:55:03<25:17, 18.28s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 576/658 [2:55:21<24:59, 18.28s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 577/658 [2:55:40<24:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 578/658 [2:55:58<24:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 579/658 [2:56:16<24:04, 18.28s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 580/658 [2:56:34<23:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9685, 'learning_rate': 1.092857134835696e-06, 'epoch': 1.76}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 580/658 [2:56:34<23:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 581/658 [2:56:53<23:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 582/658 [2:57:11<23:09, 18.28s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 583/658 [2:57:29<22:51, 18.28s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 584/658 [2:57:48<22:32, 18.28s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 585/658 [2:58:06<22:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 586/658 [2:58:24<21:56, 18.28s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 587/658 [2:58:42<21:38, 18.28s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 588/658 [2:59:01<21:19, 18.28s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 589/658 [2:59:19<21:01, 18.28s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 590/658 [2:59:37<20:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9208, 'learning_rate': 8.330594301959194e-07, 'epoch': 1.79}\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 590/658 [2:59:37<20:43, 18.28s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 591/658 [2:59:55<20:24, 18.28s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 592/658 [3:00:14<20:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 593/658 [3:00:32<19:48, 18.28s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 594/658 [3:00:50<19:30, 18.28s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 595/658 [3:01:09<19:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 596/658 [3:01:27<18:53, 18.28s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 597/658 [3:01:45<18:35, 18.28s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 598/658 [3:02:03<18:16, 18.28s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 599/658 [3:02:22<17:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 600/658 [3:02:40<17:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8366, 'learning_rate': 6.076053957825411e-07, 'epoch': 1.82}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 600/658 [3:02:40<17:40, 18.28s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 601/658 [3:02:58<17:22, 18.28s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 602/658 [3:03:17<17:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 603/658 [3:03:35<16:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 604/658 [3:03:53<16:27, 18.28s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 605/658 [3:04:11<16:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 606/658 [3:04:30<15:50, 18.28s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 607/658 [3:04:48<15:32, 18.28s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 608/658 [3:05:06<15:14, 18.28s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 609/658 [3:05:25<14:55, 18.28s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 610/658 [3:05:43<14:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.798, 'learning_rate': 4.1704158001728333e-07, 'epoch': 1.85}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 610/658 [3:05:43<14:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 611/658 [3:06:01<14:19, 18.28s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 612/658 [3:06:19<14:00, 18.28s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 613/658 [3:06:38<13:42, 18.28s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 614/658 [3:06:56<13:24, 18.28s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 615/658 [3:07:14<13:06, 18.28s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 616/658 [3:07:33<12:47, 18.28s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 617/658 [3:07:51<12:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 618/658 [3:08:09<12:11, 18.28s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 619/658 [3:08:27<11:52, 18.28s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 620/658 [3:08:46<11:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8909, 'learning_rate': 2.618299500280208e-07, 'epoch': 1.88}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 620/658 [3:08:46<11:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 621/658 [3:09:04<11:16, 18.28s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 622/658 [3:09:22<10:58, 18.28s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 623/658 [3:09:40<10:39, 18.28s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 624/658 [3:09:59<10:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 625/658 [3:10:17<10:03, 18.28s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 626/658 [3:10:35<09:45, 18.28s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 627/658 [3:10:54<09:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 628/658 [3:11:12<09:08, 18.28s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 629/658 [3:11:30<08:50, 18.28s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 630/658 [3:11:48<08:31, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8446, 'learning_rate': 1.4234677174241372e-07, 'epoch': 1.91}\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 630/658 [3:11:48<08:31, 18.28s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 631/658 [3:12:07<08:13, 18.28s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 632/658 [3:12:25<07:55, 18.28s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 633/658 [3:12:43<07:37, 18.28s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 634/658 [3:13:02<07:18, 18.28s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 635/658 [3:13:20<07:00, 18.28s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 636/658 [3:13:38<06:42, 18.28s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 637/658 [3:13:56<06:23, 18.28s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 638/658 [3:14:15<06:05, 18.28s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 639/658 [3:14:33<05:47, 18.28s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 640/658 [3:14:51<05:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9487, 'learning_rate': 5.888169773946905e-08, 'epoch': 1.95}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 640/658 [3:14:51<05:29, 18.28s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 641/658 [3:15:10<05:10, 18.28s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 642/658 [3:15:28<04:52, 18.28s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 643/658 [3:15:46<04:34, 18.28s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 644/658 [3:16:04<04:15, 18.28s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 645/658 [3:16:23<03:57, 18.28s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 646/658 [3:16:41<03:39, 18.28s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 647/658 [3:16:59<03:21, 18.28s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 648/658 [3:17:18<03:02, 18.28s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 649/658 [3:17:36<02:44, 18.28s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 650/658 [3:17:54<02:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8697, 'learning_rate': 1.1637065070210784e-08, 'epoch': 1.98}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 650/658 [3:17:54<02:26, 18.28s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 651/658 [3:18:12<02:07, 18.28s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 652/658 [3:18:31<01:49, 18.28s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 653/658 [3:18:49<01:31, 18.28s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 654/658 [3:19:07<01:13, 18.28s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 655/658 [3:19:25<00:54, 18.28s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 656/658 [3:19:44<00:36, 18.28s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 657/658 [3:20:02<00:18, 18.28s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 658/658 [3:20:12<00:00, 15.64s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 12013.0355, 'train_samples_per_second': 0.109, 'train_steps_per_second': 0.055, 'train_loss': 1.0193874205499434, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 658/658 [3:20:13<00:00, 15.64s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 658/658 [3:20:13<00:00, 18.26s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:14<00:14, 14.07s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.92s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.94s/it]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 1.60k/1.60k [00:00<00:00, 13.4MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 110MB/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json: 100%|██████████| 51.0/51.0 [00:00<00:00, 543kB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 101/101 [00:00<00:00, 1.03MB/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m2024-03-07 18:35:42,292 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-03-07 18:35:42,292 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-03-07 18:35:42,292 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-03-07 18:35:48 Uploading - Uploading generated training model\n",
      "2024-03-07 18:36:34 Completed - Training job completed\n",
      "Training seconds: 12758\n",
      "Billable seconds: 12758\n"
     ]
    }
   ],
   "source": [
    "finetune = FinetuneLLM(model_id='teknium/OpenHermes-2.5-Mistral-7B', \n",
    "                       finetune_id = 'UkuleleZebraWillow',\n",
    "                       batch_size=2,\n",
    "                       instance='ml.g5.2xlarge',\n",
    "                       merge_adapters=True,\n",
    "                       learning_rate='3e-5',\n",
    "                       training_input_path='s3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2024-Mar-07-teknium/OpenHermes-2.5-Mistral-7B-search-UkuleleZebraWillow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53b5f499-9b52-47a2-8016-4e38a07e21d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-03-07-06-46-58-396/output/model/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune.model_s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8be5d-d996-472e-a460-370c453d02ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoenv",
   "language": "python",
   "name": "recoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
