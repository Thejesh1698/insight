{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "def01f54-cc88-410d-b9ba-93e3c83f8258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AmazonSageMaker-ExecutionRole-20231030T210397'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "iam = boto3.client('iam')\n",
    "response = iam.list_roles()\n",
    "sagemaker_roles = [role for role in response['Roles'] if 'SageMaker' in role['RoleName']]\n",
    "sagemaker_roles[0]['RoleName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f82005cf-1ebd-41e1-9e0e-2d2e8090187a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import GPTQConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd4ae9-5a82-4e25-a9ee-6d6717cdfc54",
   "metadata": {},
   "source": [
    "### Creating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65a1f9ad-e7d5-4f9d-babb-ccb741deb30a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "model_id = 'teknium/OpenHermes-2.5-Mistral-7B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id,trust_remote_code=True,use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27a7de7f-a9c7-4fc5-8c97-0e03c6dd3c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "You're an AI expert in financial and business topics designed by Insight, answering queries using relevant materials and following strict rules:\n",
    "* Valid Queries: Questions about finance, business, or financially relevant entities (e.g., India, RBI, Reliance, Fed).\n",
    "* Invalid Queries: Avoid questions unrelated to finance or business (e.g., Bollywood, sports, unless financially relevant), non-financial instructional queries (e.g., jokes, coding), and inappropriate content.\n",
    "\n",
    "Response Instructions:\n",
    "* If the query is valid and answerable only using references, summarize the information clearly and concisely.\n",
    "* If the query is an entity like India, Supreme Court, Modi, RBI - and if the articles contain news about these entities - then you can mention that the latest news about ‘query’ by giving brief details. When the published date is old - mention the dates.\n",
    "* Prioritize Indian entities in responses involving both Indian and international contexts. Clearly specify the country when referencing international entities.\n",
    "* If it's a valid query but the exact answer isn't in the references, state your inability to find the exact answer and provide a brief summary of related information.\n",
    "* If it's a valid query but there's no relevant information, apologize, say you can't find the answer, and note that the Insight team is working to expand knowledge.\n",
    "* For invalid queries, politely decline, noting your focus on finance. You are provided with a timeless financial articles for you to share as a trivia to illustrate the kind of information you possess. If the reference is not timeless in these cases, then don't share any trivia.\n",
    "\n",
    "General Response Guidelines:\n",
    "* Maintain professionalism and respect in responses.\n",
    "* Ensure grammatical accuracy and readability.\n",
    "* Don't use the word 'references' in the response. You simply have knowledge or don't have the knowledge. \n",
    "* Keep responses concise (50-200 words, 3-4 sentences, max 6).\n",
    "* Only provide answers found in references.\n",
    "* Politely decline irrelevant queries, emphasizing financial expertise.\n",
    "* Calculate dates using today's date provided in format %Y-%m-%d.\n",
    "* When users ask for explicit stock recommendations or predictions, explicitly mention that \n",
    "You are provided with the following query_json: {'original_query': , 'guess_of_is_valid_query': ,'augmented_query_if_valid':}\n",
    "prioritize original_query and use augmented_query_if_valid and guess_of_is_valid_query as suggestions. Don't communicate the augmented_query_if_valid at any cost to the user\n",
    "|query_json|\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c258fd66-f2ac-405d-a61f-7d8a840a416c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "677960ef-36e9-4331-ab04-0bb384aa020b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_articles(a_lst):\n",
    "    if len(a_lst) == 1:\n",
    "        a = a_lst[0]\n",
    "        return [a[i*24:(i+1)*24] for i in range(int(len(a)/24))]\n",
    "    else:\n",
    "        return a_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "217ea309-1ff9-4b79-b552-f5862d9d3ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_responses = pd.read_csv('gpt-4-search-responses-30-jan.csv',on_bad_lines='skip',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c56eb5b-0cee-40c6-a98a-b90969f245ad",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\nYou're an AI expert in financial and business topics designed by Insight, answering queries using relevant materials and following strict rules:\\n* Valid Queries: Questions about finance, business, or financially relevant entities (e.g., India, RBI, Reliance, Fed).\\n* Invalid Queries: Avoid questions unrelated to finance or business (e.g., Bollywood, sports, unless financially relevant), non-financial instructional queries (e.g., jokes, coding), and inappropriate content.\\n\\nResponse Instructions:\\n* If the query is valid and answerable only using references, summarize the information clearly and concisely.\\n* If the query is an entity like India, Supreme Court, Modi, RBI - and if the articles contain news about these entities - then you can mention that the latest news about ‘query’ by giving brief details. When the published date is old - mention the dates.\\n* Prioritize Indian entities in responses involving both Indian and international contexts. Clearly specify the country when referencing international entities.\\n* If it's a valid query but the exact answer isn't in the references, state your inability to find the exact answer and provide a brief summary of related information.\\n* If it's a valid query but there's no relevant information, apologize, say you can't find the answer, and note that the Insight team is working to expand knowledge.\\n* For invalid queries, politely decline, noting your focus on finance. You are provided with a timeless financial articles for you to share as a trivia to illustrate the kind of information you possess. If the reference is not timeless in these cases, then don't share any trivia.\\n\\nGeneral Response Guidelines:\\n* Maintain professionalism and respect in responses.\\n* Ensure grammatical accuracy and readability.\\n* Don't use the word 'references' in the response. You simply have knowledge or don't have the knowledge. \\n* Keep responses concise (50-200 words, 3-4 sentences, max 6).\\n* Only provide answers found in references.\\n* Politely decline irrelevant queries, emphasizing financial expertise.\\n* Calculate dates using today's date provided in format %Y-%m-%d.\\n* When users ask for explicit stock recommendations or predictions, explicitly mention that \\nYou are provided with the following query_json: {'original_query': , 'guess_of_is_valid_query': ,'reformulated_query_if_valid':}\\nprioritize original_query and use reformulated_query_if_valid and guess_of_is_valid_query as suggestions. Don't communicate the reformulated_query_if_valid at any cost to the user\\n\",\n",
       " '\\n{\"original_query\": \"moon phases this month\", \"guess_of_is_valid_query\": true, \"augmented_query_if_valid\": \"Moon phases calendar January 2024\"}today\\'s date: 2023-12-08 reference 0: title: Race to Moon: India soft lands at moon; where are the rest?. published_time: 2023-08-20T18:50:00+05:30. content: India became the first nation to successfully land a craft on the Moon\\'s south pole on Wednesday, the latest milestone in a renewed push for lunar exploration that has drawn in both the world\\'s top space powers and new players.New Delhi\\'s attempt came days after the crash-landing on the Moon of Russia\\'s Luna-25 probe.Here is the latest on various missions to the celestial body:India\\'s Chandrayaan-3Chandrayaan-3, which means  Mooncraft  in Sanskrit, follows India\\'s successful launch of a probe into lunar orbit in 2008 and a failed lunar landing in 2019.The mission launched in mid-July and orbited Earth several times to build up the necessary speed for its journey.Following Wednesday\\'s successful landing, a solar-powered rover will explore the surface of the relatively unmapped lunar south pole and transmit data to Earth over its two-week lifespan.The mission is the latest milestone in an ambitious but relatively cheap space programme that saw India become the first Asian nation to put a craft into orbit around Mars in 2014.The Indian Space Research Organisation is also slated to launch a three-day crewed mission into Earth\\'s orbit by next year.Russia\\'s LunaThe launch of Luna-25 on August 11 was the first such Russian mission in almost 50 years and marked the beginning of Moscow\\'s new lunar project.On August 16, the lander was successfully placed in the Moon\\'s orbit but three days later, it  ceased to exist following a collision with the Moon\\'s surface , space agency Roscomos said.It had been set to land on the Moon\\'s surface and remain there for one year to collect samples and analyse soil.Russian President Vladimir Putin has been working to strengthen space cooperation with China after ties with the West broke down following the start of Moscow\\'s invasion of Ukraine in 2022.Moscow had hoped to build on the legacy of the Soviet-era Luna programme, marking a return to independent lunar exploration in the face of financial troubles and corruption scandals at its space programme.China\\'s great leapChina is pursuing plans to send a crewed mission to the Moon by 2030 and build a base there.The world\\'s second-largest economy has invested billions of dollars in its military-run space programme in a push to catch up with the United States and Russia.China was the third country to place humans in orbit in 2003 and its Tiangong rocket is the crown jewel of its space programme, which has also landed rovers on Mars and the Moon.The unmanned Chang\\'e-4 rocket landed on the far side of the Moon in 2019. Another robot mission to the near side raised the Chinese flag there in 2020.That Moon landing brought rock and soil samples back to Earth, the first time that has been done in more than four decades.NASA\\'s ArtemisNASA\\'s Artemis 3 mission is set to return humans to the Moon in 2025.Under the Artemis program, NASA is planning a series of missions of increasing complexity to return to the Moon and build up a sustained presence so it can develop and test technologies for an eventual journey to Mars.Artemis 1 flew an uncrewed spacecraft around the Moon in 2022.Artemis 2, planned for November 2024, will do the same with crew on board.NASA sees the Moon as a pitstop for missions to Mars and has done a deal with Finnish mobile firm Nokia to set up a 4G network there.However it has said the Artemis 3 mission may not land humans on the Moon. That will depend on whether certain key elements are finished in time.Elon Musk\\'s firm SpaceX won the contract for a landing system based on a version of its prototype Starship rocket, which remains far from ready.An orbital test flight of the uncrewed Starship ended in a dramatic explosion in April.New players Recent technological progress has reduced the cost of space missions and opened the way for new players in the public and private sectors to get involved.But getting to the Moon is not an easy task. Israeli non-profit organisation SpaceIL launched its Beresheet lunar lander in 2019 but it crashed.And in April this year, Japan\\'s ispace was the latest company to try, and fail, at the historic bid to put a private lunar lander on the Moon.Two US companies, Astrobotic and Intuitive Machines, are set to try later in the year. \\n\\nreference 1: title: ITR refunds for previous years will be paid by January 2024, assures Income Tax Department. published_time: 2023-12-06T17:25:13+05:30. content: Taxpayers awaiting income tax refunds for financial year 2017-18, 2018-19 and 2019-20 can expect payment by January 31, 2024. A recent order by the Income Tax department addressed glitches and other issues hindering income tax return (ITR) processing for these years. The department assured that refunds will be issued soon if the calculation in the ITR aligns with their assessment. Live TV Loading... Even belated ITRs for the mentioned financial years are eligible for refunds, the order said. The department mentioned that before refund is credited to the bank account, an intimation notice will be dispatched to the registered email ID. It added that ITRs that are under scrutiny or are pending due to reasons attributable to the assessees will not be part of this refund cycle. Additionally, ITRs where a demand is displayed as payable or likely to arise post-processing will not be refunded. The income tax rules stipulate certain time limits for processing filed ITRs. Earlier, the department had a year from the end of the financial year for complete the processing. This was revised, mandating a nine-month period from the financial year\\'s expiry, effective from April 1, 2021. For instance, an ITR filed for FY 2021-22 (AY 2022-23) should ideally be processed by December 31, 2023, adhering to the new rule. However, nothing could be done if this time limit is exceeded and the ITR is still not processed. Meanwhile, taxpayers should remember that December 31 is the deadline for filing of belated/revised ITR for the assessment year 2023-24 for all assessees (provided the assessment has not been completed before December 31, 2023). A fee of ₹5,000 is levied under Section 234F of the Income Tax Act, 1961, for filing belated returns. For taxpayers whose total income is not more than ₹5 lakh in a financial year, the maximum penalty for the delay is ₹1,000. Also, if there is tax to be paid, taxpayers are charged interest at 1% per month after the end of the due date till they file ITR. (Edited by : Shoma Bhattacharjee ) \\n\\nreference 2: title: Victor J. Glover will make history as the first Black astronaut to go to the moon. Of over 350 NASA astronauts who have traveled to space, only 13 have been Black.. published_time: 2023-04-10T15:23:08+0000. content: Last week, NASA announced a crew for its next lunar expedition. Set to take off in 2024, the Artemis II mission will be the first manned moon mission in more than five decades since the Apollo missions. The crew has made NASA history , with the first woman, Christina Hammock Koch, and first Black astronaut, Victor J. Glover, assigned to lunar orbit. Glover has been appointed the pilot of the mission. While they won\\'t land on the moon, NASA has announced the following mission, Artemis III, will have two astronauts walk on the lunar surface for the first time since 1972. A Pomona, California, native, Glover earned a Bachelor of Science degree in general engineering from California Polytechnic State University in 1999. As a part of the U.S. Air Force Test Pilot School program, he obtained a Master of Science degree in flight test engineering from the Air University at Edwards Air Force Base in 2007. Two years later, he earned a Master of Science degree in systems engineering from the Naval Postgraduate School. By 2010, he received a Master of Military Operational Art and Science from the Air University in Montgomery, Alabama. Glover became a NASA astronaut in 2013, while working as a Legislative Fellow in the United States Senate. He went on to serve as the pilot and second-in-command on the Crew-1 SpaceX Crew Dragon and as a Flight Engineer on the International Space Station as a part of Expedition 64. \\n\\n']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_responses[12].iloc[2].split('|query_json|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "225f038a-e526-4b50-8f74-176d6d354f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93a4796a-0fa5-41ab-ba7a-04d60c172e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"../utils\")\n",
    "from pack_dataset import pack_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ad85cfac-e267-49b3-8933-43a5a7c611aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_id = 'PurpleCherryPanda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87dc481d-4657-41cb-b7db-744ebff49ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = all_responses[[12,13]]\n",
    "dataset = Dataset.from_pandas(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c6dab42-f5e4-41c4-b9c9-a0b45a8d55a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_as_prompt_response(response_row):\n",
    "    response = response_row['13']\n",
    "    input_prompt = response_row['12']\n",
    "    sys_prompt, user_content = input_prompt.split('|query_json|')\n",
    "    messages = [{\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_content}]\n",
    "    context_prompt = tokenizer.decode(tokenizer.apply_chat_template(messages, add_generation_prompt=True))\n",
    "    prompt = context_prompt + response\n",
    "    prompt = re.sub(r'\\n+','\\n',prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e84d11d-9398-4d37-a24a-fbe6430c7404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9bfea5daa840948fa5753064751c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/671 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71cfb20c0cd47e4b50caf7a1f276354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/671 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking dataset into chunks of 4096 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6457e40b233a4187b8f66a75db4df051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/671 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 592\n",
      "Total number of samples: 592\n"
     ]
    }
   ],
   "source": [
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_as_prompt_response(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(template_dataset)\n",
    "# tokenize dataset\n",
    "dataset = dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(dataset.features)\n",
    ")\n",
    "# chunk dataset\n",
    "lm_dataset = pack_dataset(dataset, chunk_length=4096) # We use 4096 as the maximum length for packing\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd6fdb02-cc08-4b4c-8a58-525cf38b584c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Couldn't call 'get_role' to get Role ARN from role name ravi_tej to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20231030T210397')['Role']['Arn']\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f8250a0-0c80-4a80-b516-a43363caa88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_dataset_config = {'finetune_id': 'OpenHermes_Search_' + finetune_id,\n",
    "                          'date': datetime.strftime(datetime.today(),'%Y-%m-%d'),\n",
    "                          'num_datapoints': len(train_df),\n",
    "                            'data_source': 'gpt4',\n",
    "                          'prompt': system_prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0cc4e26-5c58-4899-89dd-b3c8bab84a90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aiobotocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c3a3b48f6a4df4a092a0d487010ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/592 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n",
      "training dataset to: s3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2024-02-01-OpenHermes_Search_PurpleCherryPanda\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/fine_tuning_datasets/{finetune_dataset_config[\"date\"]}-{finetune_dataset_config[\"finetune_id\"]}'\n",
    "lm_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "print(f\"training dataset to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6464458-827b-49f8-866f-1d816f7ae6fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "from random import randint\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from pack_dataset import pack_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1de2cba9-09ca-4a6e-8dec-abd73b4915d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'num_train_epochs': 2,                            # number of training epochs\n",
    "  'per_device_train_batch_size': 2,                 # batch size for training\n",
    "  'gradient_accumulation_steps': 4,                 # Number of updates steps to accumulate\n",
    "  'gradient_checkpointing': True,                   # save memory but slower backward pass\n",
    "  'bf16': True,                                     # use bfloat16 precision\n",
    "  'tf32': True,                                     # use tf32 precision\n",
    "  'learning_rate': 5e-5,                            # learning rate\n",
    "  'max_grad_norm': 0.3,                             # Maximum norm (for gradient clipping)\n",
    "  'warmup_ratio': 0.03,                             # warmup ratio\n",
    "  \"lr_scheduler_type\":\"cosine_with_restarts\",                   # learning rate scheduler\n",
    "  'save_strategy': \"epoch\",                         # save strategy for checkpoints\n",
    "  \"logging_steps\": 10,                              # log every x steps\n",
    "  'merge_adapters': True,                           # wether to merge LoRA into the model (needs more memory)\n",
    "  'use_flash_attn': True,                           # Whether to use Flash Attention\n",
    "  'output_dir': '/tmp/run'                         # output directory, where to save assets during training\n",
    "    \n",
    "                                                    # could be used for checkpointing. The final trained\n",
    "                                                    # model will always be saved to s3 at the end of training\n",
    "}\n",
    "\n",
    "if HfFolder.get_token() is not None:\n",
    "    hyperparameters['hf_token'] = HfFolder.get_token() # huggingface token to access gated models, e.g. llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c5fd6b5-fd27-4c47-b032-46c078ed457d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f'huggingface-qlora-{hyperparameters[\"model_id\"].replace(\"/\",\"-\").replace(\".\",\"-\")}-{finetune_dataset_config[\"finetune_id\"]}'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_qlora-original.py',    # train script\n",
    "    source_dir           = '../utils/',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.4xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 6*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 50,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    "    disable_output_compression = True         # not compress output to save training time and cost\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d73c5365-f6e2-4738-a3a8-ef8d313fe143",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-teknium-OpenHermes-2--2024-02-01-07-05-56-586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-01 07:05:58 Starting - Starting the training job...\n",
      "2024-02-01 07:06:14 Starting - Preparing the instances for training......\n",
      "2024-02-01 07:07:11 Downloading - Downloading input data...\n",
      "2024-02-01 07:07:36 Downloading - Downloading the training image.....................\n",
      "2024-02-01 07:11:17 Training - Training image download completed. Training in progress......\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:13,389 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:13,407 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:13,416 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:13,418 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:14,815 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.35.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 99.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.5.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 27.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting optimum==1.14.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl (398 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 398.9/398.9 kB 56.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.23.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.1/258.1 kB 52.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 MB 21.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.3 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 98.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.11.1)\u001b[0m\n",
      "\u001b[34mCollecting datasets==2.15.0 (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 521.2/521.2 kB 72.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting auto-gptq (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 73.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.12.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 330.1/330.1 kB 66.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 126.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting coloredlogs (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 15.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers[sentencepiece]>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (4.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (12.0.0)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow-hotfix (from datasets==2.15.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (3.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes->-r requirements.txt (line 5)) (1.10.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from auto-gptq->-r requirements.txt (line 10)) (0.1.99)\u001b[0m\n",
      "\u001b[34mCollecting rouge (from auto-gptq->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting gekko (from auto-gptq->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading gekko-1.0.6-py3-none-any.whl (12.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 94.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.9.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting transformers[sentencepiece]>=4.26.0 (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 110.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.37.1-py3-none-any.whl (8.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 99.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.37.0-py3-none-any.whl (8.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 103.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.2/8.2 MB 88.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.1-py3-none-any.whl (8.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 84.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.2/8.2 MB 57.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 25.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq->-r requirements.txt (line 10)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (2.1.2)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: safetensors, rouge, pyarrow-hotfix, humanfriendly, gekko, huggingface-hub, coloredlogs, bitsandbytes, tokenizers, accelerate, transformers, datasets, peft, optimum, auto-gptq\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.14.1\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.14.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.14.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: datasets\u001b[0m\n",
      "\u001b[34mFound existing installation: datasets 2.12.0\u001b[0m\n",
      "\u001b[34mUninstalling datasets-2.12.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled datasets-2.12.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.23.0 auto-gptq-0.6.0 bitsandbytes-0.42.0 coloredlogs-15.0.1 datasets-2.15.0 gekko-1.0.6 huggingface-hub-0.20.3 humanfriendly-10.0 optimum-1.14.0 peft-0.5.0 pyarrow-hotfix-0.6 rouge-1.0.1 safetensors-0.4.2 tokenizers-0.15.1 transformers-4.35.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:32,675 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:32,676 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:32,712 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:32,740 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:32,767 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:32,778 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"gradient_accumulation_steps\": 4,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"learning_rate\": 5e-05,\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"cosine_with_restarts\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"teknium/OpenHermes-2.5-Mistral-7B\",\n",
      "        \"num_train_epochs\": 2,\n",
      "        \"output_dir\": \"/tmp/run\",\n",
      "        \"per_device_train_batch_size\": 2,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"use_flash_attn\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-teknium-OpenHermes-2--2024-02-01-07-05-56-586\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-02-01-07-05-56-586/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_qlora-original\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_qlora-original.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":4,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":5e-05,\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":2,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_qlora-original.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_qlora-original\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-02-01-07-05-56-586/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":4,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":5e-05,\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":2,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":2,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-teknium-OpenHermes-2--2024-02-01-07-05-56-586\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-02-01-07-05-56-586/source/sourcedir.tar.gz\",\"module_name\":\"run_qlora-original\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_qlora-original.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training\",\"--gradient_accumulation_steps\",\"4\",\"--gradient_checkpointing\",\"True\",\"--hf_token\",\"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\",\"--learning_rate\",\"5e-05\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"cosine_with_restarts\",\"--max_grad_norm\",\"0.3\",\"--merge_adapters\",\"True\",\"--model_id\",\"teknium/OpenHermes-2.5-Mistral-7B\",\"--num_train_epochs\",\"2\",\"--output_dir\",\"/tmp/run\",\"--per_device_train_batch_size\",\"2\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--use_flash_attn\",\"True\",\"--warmup_ratio\",\"0.03\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=4\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=5e-05\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=cosine_with_restarts\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=teknium/OpenHermes-2.5-Mistral-7B\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=2\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/run\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FLASH_ATTN=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_qlora-original.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 4 --gradient_checkpointing True --hf_token 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 --learning_rate 5e-05 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters True --model_id teknium/OpenHermes-2.5-Mistral-7B --num_train_epochs 2 --output_dir /tmp/run --per_device_train_batch_size 2 --save_strategy epoch --tf32 True --use_flash_attn True --warmup_ratio 0.03\u001b[0m\n",
      "\u001b[34m2024-02-01 07:12:32,805 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mCollecting flash-attn==2.4.2\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.4.2.tar.gz (2.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 67.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.4.2) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.4.2) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn==2.4.2) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn==2.4.2) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.4.2-cp310-cp310-linux_x86_64.whl size=113930372 sha256=2c7ddc942e0715ef4a7ab62e3404b519a7ac040b3b6eae8fedcdc08a36ced786\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/9d/cf/7f/d14555553b5b30698dae0a4159fdd058157e7021cec565ecaa\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mSuccessfully installed flash-attn-2.4.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mLogging into the Hugging Face Hub with token hf_NjVkEqg...\u001b[0m\n",
      "\u001b[34mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\u001b[0m\n",
      "\u001b[34mToken is valid (permission: write).\u001b[0m\n",
      "\u001b[34mYour token has been saved to /root/.cache/huggingface/token\u001b[0m\n",
      "\u001b[34mLogin successful\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/624 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 624/624 [00:00<00:00, 6.73MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 168MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 41.9M/9.94G [00:00<00:23, 413MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 83.9M/9.94G [00:00<00:23, 416MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|▏         | 136M/9.94G [00:00<00:23, 420MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 189M/9.94G [00:00<00:22, 428MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 241M/9.94G [00:00<00:22, 434MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 294M/9.94G [00:00<00:21, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 346M/9.94G [00:00<00:21, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▍         | 398M/9.94G [00:00<00:21, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▍         | 451M/9.94G [00:01<00:21, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▌         | 503M/9.94G [00:01<00:21, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 556M/9.94G [00:01<00:21, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 608M/9.94G [00:01<00:21, 434MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 661M/9.94G [00:01<00:21, 431MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 713M/9.94G [00:01<00:21, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 765M/9.94G [00:01<00:20, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 818M/9.94G [00:01<00:20, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 870M/9.94G [00:01<00:20, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 923M/9.94G [00:02<00:20, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|▉         | 975M/9.94G [00:02<00:19, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|█         | 1.03G/9.94G [00:02<00:19, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█         | 1.08G/9.94G [00:02<00:19, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█▏        | 1.13G/9.94G [00:02<00:19, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.18G/9.94G [00:02<00:19, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.24G/9.94G [00:02<00:19, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.29G/9.94G [00:02<00:19, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.34G/9.94G [00:03<00:19, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 1.39G/9.94G [00:03<00:19, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▍        | 1.45G/9.94G [00:03<00:19, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▌        | 1.50G/9.94G [00:03<00:19, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.55G/9.94G [00:03<00:18, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.60G/9.94G [00:03<00:18, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.66G/9.94G [00:03<00:18, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.71G/9.94G [00:03<00:18, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.76G/9.94G [00:03<00:18, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.81G/9.94G [00:04<00:18, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.87G/9.94G [00:04<00:18, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.92G/9.94G [00:04<00:18, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|█▉        | 1.97G/9.94G [00:04<00:17, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|██        | 2.02G/9.94G [00:04<00:18, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.08G/9.94G [00:04<00:17, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██▏       | 2.13G/9.94G [00:04<00:17, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.18G/9.94G [00:04<00:17, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.23G/9.94G [00:05<00:17, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.29G/9.94G [00:05<00:17, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▎       | 2.34G/9.94G [00:05<00:17, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▍       | 2.39G/9.94G [00:05<00:16, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▍       | 2.44G/9.94G [00:05<00:16, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▌       | 2.50G/9.94G [00:05<00:16, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.55G/9.94G [00:05<00:16, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.60G/9.94G [00:05<00:16, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.65G/9.94G [00:05<00:16, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.71G/9.94G [00:06<00:16, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.76G/9.94G [00:06<00:16, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.81G/9.94G [00:06<00:16, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.86G/9.94G [00:06<00:16, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.92G/9.94G [00:06<00:16, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|██▉       | 2.97G/9.94G [00:06<00:15, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|███       | 3.02G/9.94G [00:06<00:15, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 3.07G/9.94G [00:06<00:15, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███▏      | 3.12G/9.94G [00:07<00:15, 433MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.18G/9.94G [00:07<00:15, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.23G/9.94G [00:07<00:15, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.28G/9.94G [00:07<00:15, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▎      | 3.33G/9.94G [00:07<00:14, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▍      | 3.39G/9.94G [00:07<00:14, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▍      | 3.44G/9.94G [00:07<00:14, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▌      | 3.49G/9.94G [00:07<00:14, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.54G/9.94G [00:08<00:14, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.60G/9.94G [00:08<00:14, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.65G/9.94G [00:08<00:14, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.70G/9.94G [00:08<00:14, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.75G/9.94G [00:08<00:13, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.81G/9.94G [00:08<00:13, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.86G/9.94G [00:08<00:13, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.91G/9.94G [00:08<00:13, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|███▉      | 3.96G/9.94G [00:08<00:13, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|████      | 4.02G/9.94G [00:09<00:13, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.07G/9.94G [00:09<00:13, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████▏     | 4.12G/9.94G [00:09<00:13, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.17G/9.94G [00:09<00:13, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.23G/9.94G [00:09<00:12, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.28G/9.94G [00:09<00:12, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▎     | 4.33G/9.94G [00:09<00:12, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▍     | 4.38G/9.94G [00:09<00:12, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▍     | 4.44G/9.94G [00:10<00:18, 290MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▌     | 4.48G/9.94G [00:10<00:17, 314MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.53G/9.94G [00:10<00:15, 342MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.58G/9.94G [00:10<00:14, 364MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.63G/9.94G [00:10<00:13, 386MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.69G/9.94G [00:10<00:13, 401MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.74G/9.94G [00:10<00:12, 413MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.79G/9.94G [00:11<00:12, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▊     | 4.84G/9.94G [00:11<00:11, 426MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▉     | 4.90G/9.94G [00:11<00:11, 429MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|████▉     | 4.95G/9.94G [00:11<00:11, 433MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|█████     | 5.00G/9.94G [00:11<00:11, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.05G/9.94G [00:11<00:11, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████▏    | 5.11G/9.94G [00:11<00:11, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.16G/9.94G [00:11<00:10, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.21G/9.94G [00:12<00:10, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.26G/9.94G [00:12<00:10, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.32G/9.94G [00:12<00:10, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▍    | 5.37G/9.94G [00:12<00:10, 424MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▍    | 5.42G/9.94G [00:12<00:11, 383MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▌    | 5.47G/9.94G [00:12<00:11, 398MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.53G/9.94G [00:12<00:10, 410MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.58G/9.94G [00:12<00:10, 420MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.63G/9.94G [00:13<00:10, 425MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.68G/9.94G [00:13<00:09, 432MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.74G/9.94G [00:13<00:09, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.79G/9.94G [00:13<00:09, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▊    | 5.84G/9.94G [00:13<00:09, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.89G/9.94G [00:13<00:09, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|█████▉    | 5.95G/9.94G [00:13<00:09, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|██████    | 6.00G/9.94G [00:13<00:08, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.05G/9.94G [00:13<00:08, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████▏   | 6.10G/9.94G [00:14<00:08, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.16G/9.94G [00:14<00:08, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.21G/9.94G [00:14<00:08, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.26G/9.94G [00:14<00:08, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.31G/9.94G [00:14<00:08, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.36G/9.94G [00:14<00:08, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.42G/9.94G [00:14<00:08, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.47G/9.94G [00:14<00:07, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.52G/9.94G [00:15<00:07, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.57G/9.94G [00:15<00:07, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.63G/9.94G [00:15<00:07, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.68G/9.94G [00:15<00:07, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.73G/9.94G [00:15<00:07, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.78G/9.94G [00:15<00:07, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.84G/9.94G [00:15<00:07, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.89G/9.94G [00:15<00:06, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|██████▉   | 6.94G/9.94G [00:16<00:06, 434MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 6.99G/9.94G [00:16<00:06, 432MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.05G/9.94G [00:16<00:06, 430MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████▏  | 7.10G/9.94G [00:16<00:06, 433MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.15G/9.94G [00:16<00:06, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.20G/9.94G [00:16<00:06, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.26G/9.94G [00:16<00:06, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▎  | 7.31G/9.94G [00:16<00:05, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.36G/9.94G [00:16<00:05, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▍  | 7.41G/9.94G [00:17<00:05, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▌  | 7.47G/9.94G [00:17<00:05, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.52G/9.94G [00:17<00:05, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.57G/9.94G [00:17<00:05, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.62G/9.94G [00:17<00:05, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.68G/9.94G [00:17<00:05, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.73G/9.94G [00:17<00:04, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.78G/9.94G [00:17<00:04, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.83G/9.94G [00:18<00:04, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.89G/9.94G [00:18<00:04, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.94G/9.94G [00:18<00:04, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 7.99G/9.94G [00:18<00:04, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.04G/9.94G [00:18<00:04, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████▏ | 8.10G/9.94G [00:18<00:04, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.15G/9.94G [00:18<00:04, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.20G/9.94G [00:18<00:03, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.25G/9.94G [00:18<00:03, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▎ | 8.30G/9.94G [00:19<00:03, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.36G/9.94G [00:19<00:03, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.41G/9.94G [00:19<00:03, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.46G/9.94G [00:19<00:03, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.51G/9.94G [00:19<00:03, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.57G/9.94G [00:19<00:03, 426MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.62G/9.94G [00:19<00:03, 427MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.67G/9.94G [00:19<00:02, 428MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.72G/9.94G [00:20<00:02, 430MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.78G/9.94G [00:20<00:02, 433MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.83G/9.94G [00:20<00:03, 285MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.88G/9.94G [00:20<00:03, 320MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.93G/9.94G [00:20<00:02, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 8.99G/9.94G [00:20<00:02, 370MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.04G/9.94G [00:21<00:02, 387MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████▏| 9.09G/9.94G [00:21<00:02, 401MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.14G/9.94G [00:21<00:01, 411MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.20G/9.94G [00:21<00:01, 421MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.25G/9.94G [00:21<00:01, 423MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▎| 9.30G/9.94G [00:21<00:01, 428MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.35G/9.94G [00:21<00:01, 432MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.41G/9.94G [00:21<00:01, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.46G/9.94G [00:21<00:01, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.51G/9.94G [00:22<00:00, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.56G/9.94G [00:22<00:00, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.62G/9.94G [00:22<00:00, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.67G/9.94G [00:22<00:00, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.72G/9.94G [00:22<00:00, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.77G/9.94G [00:22<00:00, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.83G/9.94G [00:22<00:00, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.88G/9.94G [00:22<00:00, 413MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.92G/9.94G [00:23<00:00, 410MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|██████████| 9.94G/9.94G [00:23<00:00, 431MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 1/2 [00:23<00:23, 23.33s/it]\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   1%|          | 52.4M/4.54G [00:00<00:10, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   2%|▏         | 105M/4.54G [00:00<00:09, 451MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   3%|▎         | 157M/4.54G [00:00<00:09, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   5%|▍         | 210M/4.54G [00:00<00:09, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   6%|▌         | 262M/4.54G [00:00<00:09, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   7%|▋         | 315M/4.54G [00:00<00:09, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   8%|▊         | 367M/4.54G [00:00<00:09, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▉         | 419M/4.54G [00:00<00:09, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|█         | 472M/4.54G [00:01<00:09, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 524M/4.54G [00:01<00:09, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  13%|█▎        | 577M/4.54G [00:01<00:08, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  14%|█▍        | 629M/4.54G [00:01<00:08, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▌        | 682M/4.54G [00:01<00:08, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▌        | 734M/4.54G [00:01<00:08, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 786M/4.54G [00:01<00:08, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 839M/4.54G [00:01<00:08, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  20%|█▉        | 891M/4.54G [00:01<00:08, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██        | 944M/4.54G [00:02<00:08, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  22%|██▏       | 996M/4.54G [00:02<00:07, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  23%|██▎       | 1.05G/4.54G [00:02<00:07, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 1.10G/4.54G [00:02<00:07, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  25%|██▌       | 1.15G/4.54G [00:02<00:07, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  27%|██▋       | 1.21G/4.54G [00:02<00:07, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  28%|██▊       | 1.26G/4.54G [00:02<00:07, 443MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  29%|██▉       | 1.31G/4.54G [00:02<00:07, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|███       | 1.36G/4.54G [00:03<00:07, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  31%|███       | 1.42G/4.54G [00:03<00:06, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  32%|███▏      | 1.47G/4.54G [00:03<00:06, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  33%|███▎      | 1.52G/4.54G [00:03<00:06, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  35%|███▍      | 1.57G/4.54G [00:03<00:06, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▌      | 1.63G/4.54G [00:03<00:06, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  37%|███▋      | 1.68G/4.54G [00:03<00:06, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  38%|███▊      | 1.73G/4.54G [00:03<00:06, 430MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.78G/4.54G [00:04<00:06, 429MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  40%|████      | 1.84G/4.54G [00:04<00:06, 418MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.89G/4.54G [00:04<00:06, 429MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  43%|████▎     | 1.94G/4.54G [00:04<00:06, 414MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  44%|████▍     | 1.99G/4.54G [00:04<00:06, 423MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▌     | 2.04G/4.54G [00:04<00:06, 404MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▌     | 2.10G/4.54G [00:04<00:05, 412MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 2.14G/4.54G [00:04<00:05, 405MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.18G/4.54G [00:04<00:05, 404MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 2.23G/4.54G [00:05<00:05, 412MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|█████     | 2.28G/4.54G [00:05<00:05, 405MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████▏    | 2.33G/4.54G [00:05<00:05, 417MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  52%|█████▏    | 2.37G/4.54G [00:05<00:05, 403MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  53%|█████▎    | 2.42G/4.54G [00:05<00:05, 417MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▍    | 2.47G/4.54G [00:05<00:04, 424MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  56%|█████▌    | 2.53G/4.54G [00:05<00:04, 429MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 2.58G/4.54G [00:05<00:04, 433MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.63G/4.54G [00:06<00:04, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  59%|█████▉    | 2.68G/4.54G [00:06<00:04, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  60%|██████    | 2.74G/4.54G [00:06<00:04, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████▏   | 2.79G/4.54G [00:06<00:03, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.84G/4.54G [00:06<00:03, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▎   | 2.89G/4.54G [00:06<00:03, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▍   | 2.95G/4.54G [00:06<00:03, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  66%|██████▌   | 3.00G/4.54G [00:06<00:03, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.05G/4.54G [00:06<00:03, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 3.10G/4.54G [00:07<00:03, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  70%|██████▉   | 3.16G/4.54G [00:07<00:04, 286MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████   | 3.21G/4.54G [00:07<00:04, 321MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 3.26G/4.54G [00:07<00:03, 350MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.31G/4.54G [00:07<00:03, 375MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  74%|███████▍  | 3.37G/4.54G [00:07<00:02, 394MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▌  | 3.42G/4.54G [00:08<00:02, 407MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▋  | 3.47G/4.54G [00:08<00:02, 417MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.52G/4.54G [00:08<00:02, 424MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▊  | 3.58G/4.54G [00:08<00:02, 431MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|███████▉  | 3.63G/4.54G [00:08<00:02, 435MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  81%|████████  | 3.68G/4.54G [00:08<00:01, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.73G/4.54G [00:08<00:01, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.79G/4.54G [00:08<00:01, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▍ | 3.84G/4.54G [00:08<00:01, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.89G/4.54G [00:09<00:01, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.94G/4.54G [00:09<00:01, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 4.00G/4.54G [00:09<00:01, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  89%|████████▉ | 4.05G/4.54G [00:09<00:01, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|█████████ | 4.10G/4.54G [00:09<00:00, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████▏| 4.15G/4.54G [00:09<00:00, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.20G/4.54G [00:09<00:00, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.26G/4.54G [00:09<00:00, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▍| 4.31G/4.54G [00:10<00:00, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▌| 4.36G/4.54G [00:10<00:00, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.41G/4.54G [00:10<00:00, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  98%|█████████▊| 4.47G/4.54G [00:10<00:00, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|█████████▉| 4.52G/4.54G [00:10<00:00, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|██████████| 4.54G/4.54G [00:10<00:00, 430MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:34<00:00, 15.94s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:34<00:00, 17.05s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.47s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 120/120 [00:00<00:00, 1.38MB/s]\u001b[0m\n",
      "\u001b[34mFound 7 modules to quantize: ['q_proj', 'up_proj', 'down_proj', 'gate_proj', 'v_proj', 'k_proj', 'o_proj']\u001b[0m\n",
      "\u001b[34mCUDA extension not installed.\u001b[0m\n",
      "\u001b[34mCUDA extension not installed.\u001b[0m\n",
      "\u001b[34mtrainable params: 83,886,080 || all params: 7,325,634,560 || trainable%: 1.1451032577852205\u001b[0m\n",
      "\u001b[34m0%|          | 0/148 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34m1%|          | 1/148 [00:48<1:59:15, 48.67s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 2/148 [01:37<1:58:12, 48.58s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 3/148 [02:25<1:57:22, 48.57s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 4/148 [03:14<1:56:34, 48.57s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 5/148 [04:02<1:55:45, 48.57s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 6/148 [04:51<1:54:57, 48.57s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 7/148 [05:40<1:54:09, 48.58s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 8/148 [06:28<1:53:21, 48.58s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 9/148 [07:17<1:52:31, 48.58s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 10/148 [08:05<1:51:43, 48.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7762, 'learning_rate': 4.9849325083059e-05, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34m7%|▋         | 10/148 [08:05<1:51:43, 48.58s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 11/148 [08:54<1:50:54, 48.58s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 12/148 [09:42<1:50:06, 48.58s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 13/148 [10:31<1:49:18, 48.58s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 14/148 [11:20<1:48:30, 48.58s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 15/148 [12:08<1:47:40, 48.58s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 16/148 [12:57<1:46:51, 48.57s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 17/148 [13:45<1:46:03, 48.58s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 18/148 [14:34<1:45:15, 48.58s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 19/148 [15:22<1:44:26, 48.58s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 20/148 [16:11<1:43:38, 48.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.4182, 'learning_rate': 4.865480126133872e-05, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34m14%|█▎        | 20/148 [16:11<1:43:38, 48.58s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 21/148 [17:00<1:42:50, 48.59s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 22/148 [17:48<1:42:02, 48.59s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 23/148 [18:37<1:41:13, 48.59s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 24/148 [19:25<1:40:25, 48.59s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 25/148 [20:14<1:39:35, 48.58s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 26/148 [21:03<1:38:47, 48.59s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 27/148 [21:51<1:37:59, 48.59s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 28/148 [22:40<1:37:10, 48.59s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 29/148 [23:28<1:36:21, 48.58s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 30/148 [24:17<1:35:33, 48.59s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2827, 'learning_rate': 4.6323175183912024e-05, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34m20%|██        | 30/148 [24:17<1:35:33, 48.59s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 31/148 [25:06<1:34:45, 48.59s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 32/148 [25:54<1:33:57, 48.60s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 33/148 [26:43<1:33:07, 48.59s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 34/148 [27:31<1:32:18, 48.59s/it]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 35/148 [28:20<1:31:29, 48.58s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 36/148 [29:08<1:30:41, 48.58s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 37/148 [29:57<1:29:52, 48.58s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 38/148 [30:46<1:29:03, 48.58s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 39/148 [31:34<1:28:15, 48.58s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 40/148 [32:23<1:27:26, 48.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2817, 'learning_rate': 4.296652968938807e-05, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 40/148 [32:23<1:27:26, 48.58s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 41/148 [33:11<1:26:38, 48.58s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 42/148 [34:00<1:25:49, 48.58s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 43/148 [34:49<1:25:01, 48.58s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 44/148 [35:37<1:24:12, 48.58s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 45/148 [36:26<1:23:24, 48.58s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 46/148 [37:14<1:22:35, 48.58s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 47/148 [38:03<1:21:46, 48.58s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 48/148 [38:51<1:20:58, 48.58s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 49/148 [39:40<1:20:10, 48.59s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 50/148 [40:29<1:19:21, 48.59s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2685, 'learning_rate': 3.874622099130087e-05, 'epoch': 0.68}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 50/148 [40:29<1:19:21, 48.59s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 51/148 [41:17<1:18:32, 48.58s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 52/148 [42:06<1:17:43, 48.58s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 53/148 [42:54<1:16:55, 48.58s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 54/148 [43:43<1:16:06, 48.58s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 55/148 [44:32<1:15:18, 48.58s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 56/148 [45:20<1:14:29, 48.59s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 57/148 [46:09<1:13:40, 48.58s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 58/148 [46:57<1:12:52, 48.58s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 59/148 [47:46<1:12:03, 48.58s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 60/148 [48:34<1:11:15, 48.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2615, 'learning_rate': 3.386512217606339e-05, 'epoch': 0.81}\u001b[0m\n",
      "\u001b[34m41%|████      | 60/148 [48:34<1:11:15, 48.58s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 61/148 [49:23<1:10:26, 48.58s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 62/148 [50:12<1:09:37, 48.58s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 63/148 [51:00<1:08:49, 48.58s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 64/148 [51:49<1:08:00, 48.58s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 65/148 [52:37<1:07:11, 48.58s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 66/148 [53:26<1:06:23, 48.58s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 67/148 [54:15<1:05:34, 48.58s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 68/148 [55:03<1:04:46, 48.58s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 69/148 [55:52<1:03:57, 48.58s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 70/148 [56:40<1:03:08, 48.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2902, 'learning_rate': 2.8557870956832132e-05, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[34m47%|████▋     | 70/148 [56:40<1:03:08, 48.58s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 71/148 [57:29<1:02:20, 48.57s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 72/148 [58:17<1:01:31, 48.57s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 73/148 [59:06<1:00:42, 48.57s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 74/148 [59:55<59:54, 48.57s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 75/148 [1:00:44<59:18, 48.74s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 76/148 [1:01:32<58:26, 48.69s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 77/148 [1:02:21<57:34, 48.66s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 78/148 [1:03:09<56:44, 48.64s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 79/148 [1:03:58<55:55, 48.62s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 80/148 [1:04:47<55:05, 48.61s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2434, 'learning_rate': 2.307959048033383e-05, 'epoch': 1.08}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 80/148 [1:04:47<55:05, 48.61s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 81/148 [1:05:35<54:16, 48.61s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 82/148 [1:06:24<53:27, 48.60s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 83/148 [1:07:12<52:38, 48.59s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 84/148 [1:08:01<51:49, 48.59s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 85/148 [1:08:49<51:00, 48.58s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 86/148 [1:09:38<50:12, 48.58s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 87/148 [1:10:27<49:23, 48.58s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 88/148 [1:11:15<48:34, 48.58s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 89/148 [1:12:04<47:46, 48.58s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 90/148 [1:12:52<46:57, 48.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2301, 'learning_rate': 1.7693625385079577e-05, 'epoch': 1.22}\u001b[0m\n",
      "\u001b[34m61%|██████    | 90/148 [1:12:52<46:57, 48.58s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 91/148 [1:13:41<46:08, 48.58s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 92/148 [1:14:30<45:20, 48.58s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 93/148 [1:15:18<44:32, 48.58s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 94/148 [1:16:07<43:43, 48.58s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 95/148 [1:16:55<42:54, 48.58s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 96/148 [1:17:44<42:06, 48.58s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 97/148 [1:18:32<41:17, 48.58s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 98/148 [1:19:21<40:28, 48.58s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 99/148 [1:20:10<39:40, 48.58s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 100/148 [1:20:58<38:51, 48.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2101, 'learning_rate': 1.2658882646922034e-05, 'epoch': 1.35}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 100/148 [1:20:58<38:51, 48.58s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 101/148 [1:21:47<38:03, 48.58s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 102/148 [1:22:35<37:14, 48.58s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 103/148 [1:23:24<36:26, 48.59s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 104/148 [1:24:13<35:37, 48.58s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 105/148 [1:25:01<34:49, 48.58s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 106/148 [1:25:50<34:00, 48.59s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 107/148 [1:26:38<33:11, 48.58s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 108/148 [1:27:27<32:23, 48.59s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 109/148 [1:28:15<31:34, 48.59s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 110/148 [1:29:04<30:46, 48.59s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.207, 'learning_rate': 8.217385746050742e-06, 'epoch': 1.49}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 110/148 [1:29:04<30:46, 48.59s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 111/148 [1:29:53<29:57, 48.58s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 112/148 [1:30:41<29:09, 48.59s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 113/148 [1:31:30<28:20, 48.58s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 114/148 [1:32:18<27:31, 48.58s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 115/148 [1:33:07<26:43, 48.58s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 116/148 [1:33:56<25:54, 48.58s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 117/148 [1:34:44<25:06, 48.59s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 118/148 [1:35:33<24:17, 48.58s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 119/148 [1:36:21<23:28, 48.59s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 120/148 [1:37:10<22:40, 48.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2007, 'learning_rate': 4.58264043501446e-06, 'epoch': 1.62}\u001b[0m\n",
      "\u001b[34m81%|████████  | 120/148 [1:37:10<22:40, 48.58s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 121/148 [1:37:58<21:51, 48.59s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 122/148 [1:38:47<21:03, 48.59s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 123/148 [1:39:36<20:14, 48.59s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 124/148 [1:40:24<19:26, 48.59s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 125/148 [1:41:13<18:37, 48.59s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 126/148 [1:42:01<17:48, 48.59s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 127/148 [1:42:50<17:00, 48.59s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 128/148 [1:43:39<16:11, 48.59s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 129/148 [1:44:27<15:23, 48.59s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 130/148 [1:45:16<14:34, 48.59s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.2267, 'learning_rate': 1.9293713731512673e-06, 'epoch': 1.76}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 130/148 [1:45:16<14:34, 48.59s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 131/148 [1:46:04<13:45, 48.58s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 132/148 [1:46:53<12:57, 48.58s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 133/148 [1:47:41<12:08, 48.58s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 134/148 [1:48:30<11:20, 48.59s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 135/148 [1:49:19<10:31, 48.58s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 136/148 [1:50:07<09:43, 48.59s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 137/148 [1:50:56<08:54, 48.59s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 138/148 [1:51:44<08:05, 48.59s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 139/148 [1:52:33<07:17, 48.59s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 140/148 [1:53:22<06:28, 48.58s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.188, 'learning_rate': 3.851229943335394e-07, 'epoch': 1.89}\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 140/148 [1:53:22<06:28, 48.58s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 141/148 [1:54:10<05:40, 48.58s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 142/148 [1:54:59<04:51, 48.58s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 143/148 [1:55:47<04:02, 48.58s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 144/148 [1:56:36<03:14, 48.58s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 145/148 [1:57:25<02:25, 48.59s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 146/148 [1:58:13<01:37, 48.59s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 147/148 [1:59:02<00:48, 48.59s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 148/148 [1:59:50<00:00, 48.59s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 7191.3469, 'train_samples_per_second': 0.165, 'train_steps_per_second': 0.021, 'train_loss': 1.2846708813229122, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m100%|██████████| 148/148 [1:59:51<00:00, 48.59s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 148/148 [1:59:51<00:00, 48.59s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.40s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 1.60k/1.60k [00:00<00:00, 18.5MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 96.1MB/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json: 100%|██████████| 51.0/51.0 [00:00<00:00, 438kB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 101/101 [00:00<00:00, 1.04MB/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m2024-02-01 09:17:17,336 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-02-01 09:17:17,336 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-02-01 09:17:17,336 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-02-01 09:17:40 Uploading - Uploading generated training model\n",
      "2024-02-01 09:18:11 Completed - Training job completed\n",
      "Training seconds: 7859\n",
      "Billable seconds: 7859\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_input_path}\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62642ba5-453f-4c80-9428-773b12de264e",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bbc0484c-77c2-4a06-a5aa-e7775efd1698",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py39\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: gpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"1.1.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1372c205-c464-4688-b303-9ab9dac48453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize a boto3 S3 client\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82f87e53-4f67-4969-8680-12d083e20641",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb05636a-fbb8-4b93-a83e-16e2ea665834",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-02-01-07-05-56-586/output/model/'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f66c4951-41bc-4fa0-8fff-833df281d01b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(3584), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(4096), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data={'S3DataSource':{'S3Uri': model_s3_path,'S3DataType': 'S3Prefix','CompressionType': 'None'}},\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a79a2eb1-1c3f-4241-820e-73b0eeb91908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PurpleCherryPanda'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9764731-c0c1-4781-ae65-656e6bf0479f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-tgi-inference-2024-02-01-09-21-18-500\n",
      "INFO:sagemaker:Creating endpoint-config with name OpenHermes-Search-PurpleCherryPanda\n",
      "INFO:sagemaker:Creating endpoint with name OpenHermes-Search-PurpleCherryPanda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "    endpoint_name = f\"OpenHermes-Search-{finetune_id.replace('_','-')}\",\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e52712f2-ed9a-4164-ba60-2cc973fba069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smr = sess.boto_session.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fc51d308-38f1-48ef-ab61-26551ffe6fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"repetition_penalty\": 1.03,\n",
    "    \"stop\": [\"###\", \"</s>\", tokenizer.eos_token],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "25b2f24d-510c-49d8-81e5-b4add05bb378",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "You're an AI expert in financial and business topics designed by Insight, answering queries using relevant materials and following strict rules:\n",
    "* Valid Queries: Questions about finance, business, or financially relevant entities (e.g., India, RBI, Reliance, Fed).\n",
    "* Invalid Queries: Avoid questions unrelated to finance or business (e.g., Bollywood, sports, unless financially relevant), non-financial instructional queries (e.g., jokes, coding), and inappropriate content.\n",
    "\n",
    "Response Instructions:\n",
    "* If the query is valid and answerable only using references, summarize the information clearly and concisely.\n",
    "* If the query is an entity like India, Supreme Court, Modi, RBI - and if the articles contain news about these entities - then you can mention that the latest news about ‘query’ by giving brief details. When the published date is old - mention the dates.\n",
    "* Prioritize Indian entities in responses involving both Indian and international contexts. Clearly specify the country when referencing international entities.\n",
    "* If it's a valid query but the exact answer isn't in the references, state your inability to find the exact answer and provide a brief summary of related information.\n",
    "* If it's a valid query but there's no relevant information, apologize, say you can't find the answer, and note that the Insight team is working to expand knowledge.\n",
    "* For invalid queries, politely decline, noting your focus on finance. You are provided with a timeless financial articles for you to share as a trivia to illustrate the kind of information you possess. If the reference is not timeless in these cases, then don't share any trivia.\n",
    "\n",
    "General Response Guidelines:\n",
    "* Maintain professionalism and respect in responses.\n",
    "* Ensure grammatical accuracy and readability.\n",
    "* Don't use the word 'references' in the response. You simply have knowledge or don't have the knowledge. \n",
    "* Keep responses concise (50-200 words, 3-4 sentences, max 6).\n",
    "* Only provide answers found in references.\n",
    "* Politely decline irrelevant queries, emphasizing financial expertise.\n",
    "* Calculate dates using today's date provided in format %Y-%m-%d.\n",
    "* When users ask for explicit stock recommendations or predictions, explicitly mention that \n",
    "You are provided with the following query_json: {'original_query': , 'guess_of_is_valid_query': ,'augmented_query_if_valid':}\n",
    "prioritize original_query and use augmented_query_if_valid and guess_of_is_valid_query as suggestions. Don't communicate the augmented_query_if_valid at any cost to the user\n",
    "|query_json|\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "81e26b0b-9fcc-42c8-a811-93111db2c24a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a,b,c,d = 'False,,,'.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "5a362a9c-e1b8-41b5-bb7c-982c724a7c11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'False'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e1daab11-2da3-4358-ba6b-36e3f6cfb7e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = 2; c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "75cedba4-f147-4c34-b9a7-05839d764920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = {'1': b, '2': c}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cca4d5a1-f894-4db0-98d6-732d4c333c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 2, '2': 3}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "941bcefa-383c-40ce-8e46-85b2f388ee0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f60f2c7e-78ca-4de2-a8f7-800085b42607",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 2, '2': 3}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "11d4954c-7a39-4e18-80d0-87b755430251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a62f8397-2b9e-4a18-9a68-2cbf5449c55e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFalse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(fp\u001b[38;5;241m.\u001b[39mread(),\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "json.load('False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "59157846-4aab-4f7e-a303-6dc7a1a7ddae",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>0</td>\n",
       "      <td>444</td>\n",
       "      <td>what is sensex</td>\n",
       "      <td>2023-11-02</td>\n",
       "      <td>True,Low,False,What is Sensex</td>\n",
       "      <td>True</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>What is Sensex</td>\n",
       "      <td>True</td>\n",
       "      <td>['652fca6d1e5cc42b1b13a0ee', '6555b5084b13023f...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>The Sensex, or the S&amp;P BSE Sensex, is India's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>240</td>\n",
       "      <td>terrie</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>False,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['656476fe96c80a0efa90fbcb']</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>I'm sorry, but \"terrie\" is not a valid query r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>ipo</td>\n",
       "      <td>2024-02-12</td>\n",
       "      <td>True,High,False,Upcoming IPOs in India</td>\n",
       "      <td>True</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Upcoming IPOs in India</td>\n",
       "      <td>True</td>\n",
       "      <td>['65acc1006391ac19baa87097', '65813f89683f430d...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>The IPO (Initial Public Offering) market in In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>michael scott</td>\n",
       "      <td>2024-02-07</td>\n",
       "      <td>False,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['6564772b96c80a0efa90ff7f']</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>The query 'Michael Scott' is not related to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0</td>\n",
       "      <td>171</td>\n",
       "      <td>collapsed real estate firm unitech</td>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>True,Medium,True,Unitech real estate financial...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>True</td>\n",
       "      <td>Unitech real estate financial news</td>\n",
       "      <td>True</td>\n",
       "      <td>['65922acb4b25ce4814fb420a', '65a920496391ac19...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Unitech Advisors (India) mentioned in the cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0</td>\n",
       "      <td>518</td>\n",
       "      <td>tata motors stock outlook</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>True,Medium,False,Tata Motors stock analysis J...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Tata Motors stock analysis January 2024</td>\n",
       "      <td>True</td>\n",
       "      <td>['65adda586391ac19baa871e6', '65a9e5d16391ac19...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Tata Motors' stock has seen fluctuations over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0</td>\n",
       "      <td>459</td>\n",
       "      <td>credit cards</td>\n",
       "      <td>2023-12-21</td>\n",
       "      <td>True,Medium,False,Credit card industry trends ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Credit card industry trends in India</td>\n",
       "      <td>True</td>\n",
       "      <td>['657bc159857ad3220916009f', '6571c36725cc9a34...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Credit cards in India have shown substantial g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0</td>\n",
       "      <td>225</td>\n",
       "      <td>coal india limited's stock</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>True,Medium,False,Coal India Limited's stock p...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Coal India Limited's stock performance</td>\n",
       "      <td>True</td>\n",
       "      <td>['65316fe21e5cc42b1b142486', '65316f8d1e5cc42b...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Coal India's stock performance has seen slight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>stocks rising with green energy transition</td>\n",
       "      <td>2023-12-19</td>\n",
       "      <td>True,Medium,False,Stocks rising with green ene...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Stocks rising with green energy transition in ...</td>\n",
       "      <td>True</td>\n",
       "      <td>['658258d8683f430d81566015', '6570445153e8a611...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>The transition to green energy appears to be p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>383</td>\n",
       "      <td>ulip as a strategic investment</td>\n",
       "      <td>2024-01-22</td>\n",
       "      <td>True,Low,False,ULIP as a strategic investment ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>ULIP as a strategic investment option</td>\n",
       "      <td>True</td>\n",
       "      <td>['65683309207bb033b910eda3', '653680181e5cc42b...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Unit-Linked Insurance Plans (ULIP) combine ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>sample</td>\n",
       "      <td>2023-11-30</td>\n",
       "      <td>False,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['656476fe96c80a0efa90fbc8']</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>I'm sorry, but your query seems incomplete or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "      <td>loan services</td>\n",
       "      <td>2023-11-27</td>\n",
       "      <td>True,Medium,False,Loan services in India</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Loan services in India</td>\n",
       "      <td>True</td>\n",
       "      <td>['6571c2e625cc9a343f03c39f', '653680281e5cc42b...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>In India, numerous banks offer loan services, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0</td>\n",
       "      <td>468</td>\n",
       "      <td>real estate market forecast india</td>\n",
       "      <td>2024-02-06</td>\n",
       "      <td>True,Medium,False,Real estate market forecast ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Real estate market forecast in India 2024</td>\n",
       "      <td>True</td>\n",
       "      <td>['65b23f501b79671c6b70cc2e', '65ab6f826391ac19...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>The forecast for India's real estate market co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0</td>\n",
       "      <td>440</td>\n",
       "      <td>is eating out healthy</td>\n",
       "      <td>2023-11-11</td>\n",
       "      <td>False,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['656476f496c80a0efa90fb08']</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>I'm afraid your query about the healthiness of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>how to prepare for retirement effectively</td>\n",
       "      <td>2023-11-24</td>\n",
       "      <td>True,Low,False,How to effectively prepare for ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>How to effectively prepare for retirement</td>\n",
       "      <td>True</td>\n",
       "      <td>['6555c8264b13023f93491168', '653680111e5cc42b...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Planning for retirement effectively entails se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0</td>\n",
       "      <td>504</td>\n",
       "      <td>impact of ai on indian banking</td>\n",
       "      <td>2024-01-18</td>\n",
       "      <td>True,Medium,False,Impact of AI on Indian banki...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Impact of AI on Indian banking sector</td>\n",
       "      <td>True</td>\n",
       "      <td>['659fca4be362d630b6472683', '65a896721c9bc64b...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>The impact of AI on Indian banking has elicite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0</td>\n",
       "      <td>357</td>\n",
       "      <td>insights from media outlets</td>\n",
       "      <td>2023-11-05</td>\n",
       "      <td>True,Medium,True,Insights from Indian media ou...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>True</td>\n",
       "      <td>Insights from Indian media outlets</td>\n",
       "      <td>True</td>\n",
       "      <td>['6555cbec4b13023f934a2fe1', '6571c24225cc9a34...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>In recent media reports, there's been substant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>optimistic</td>\n",
       "      <td>2024-01-19</td>\n",
       "      <td>False,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['656476ec96c80a0efa90fa52']</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>I'm sorry, but your query \"optimistic\" doesn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0</td>\n",
       "      <td>392</td>\n",
       "      <td>upcoming ipo india</td>\n",
       "      <td>2024-01-17</td>\n",
       "      <td>True,High,False,Upcoming IPOs in India 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Upcoming IPOs in India 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>['659e085b4b25ce4814fb552a', '65a896841c9bc64b...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>The upcoming IPO scenario in India for 2024 se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>bond investment principles</td>\n",
       "      <td>2023-12-10</td>\n",
       "      <td>True,Low,False,Bond investment principles in I...</td>\n",
       "      <td>True</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Bond investment principles in India</td>\n",
       "      <td>True</td>\n",
       "      <td>['6555b5784b13023f9348bc2c', '652fc5db1e5cc42b...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Investing in bonds can be a strategic move if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>why hdfc bank shares are falling</td>\n",
       "      <td>2024-01-08</td>\n",
       "      <td>True,Medium,False,Why is HDFC Bank share price...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Why is HDFC Bank share price falling</td>\n",
       "      <td>True</td>\n",
       "      <td>['65316ef41e5cc42b1b13ea79', '65316f901e5cc42b...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>The fall in HDFC Bank's share prices can be at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>321</td>\n",
       "      <td>best users</td>\n",
       "      <td>2024-01-18</td>\n",
       "      <td>False,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['6564772896c80a0efa90ff25']</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>I'm sorry, but I'm unable to assist with the q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0</td>\n",
       "      <td>450</td>\n",
       "      <td>investors lose 3 lakh crore in a day</td>\n",
       "      <td>2023-12-12</td>\n",
       "      <td>True,High,False,Indian investors lose 3 lakh c...</td>\n",
       "      <td>True</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Indian investors lose 3 lakh crore in a day</td>\n",
       "      <td>True</td>\n",
       "      <td>['652fbad41e5cc42b1b139e30', '65325dce1e5cc42b...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Based on the financial data, there are two ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0</td>\n",
       "      <td>222</td>\n",
       "      <td>travel restrictions update</td>\n",
       "      <td>2024-01-19</td>\n",
       "      <td>True,Medium,True,Latest travel restrictions up...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>True</td>\n",
       "      <td>Latest travel restrictions update in India</td>\n",
       "      <td>True</td>\n",
       "      <td>['651dc55fa662d76276b7b3f4', '651dfd78a662d762...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>As an AI financial expert, my scope doesn't al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "      <td>world happiest countries</td>\n",
       "      <td>2023-12-02</td>\n",
       "      <td>False,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>['656476fe96c80a0efa90fbc8']</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>I'm sorry, but your query about \"world happies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>solar energy home setup</td>\n",
       "      <td>2023-11-17</td>\n",
       "      <td>True,Medium,False,Solar energy home setup guid...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Solar energy home setup guide in India</td>\n",
       "      <td>True</td>\n",
       "      <td>['6564772896c80a0efa90ff1b', '652fcbde1e5cc42b...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Solar energy home setups are attracting increa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>cashless transactions in india</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>True,Medium,False,Cashless transactions trends...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Cashless transactions trends in India</td>\n",
       "      <td>True</td>\n",
       "      <td>['658ff8af4b25ce4814fb413a', '658e36a64b25ce48...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Despite governmental efforts towards a cashles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>best digital payment apps in india</td>\n",
       "      <td>2023-11-09</td>\n",
       "      <td>True,Medium,False,Best digital payment apps in...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Best digital payment apps in India 2023</td>\n",
       "      <td>True</td>\n",
       "      <td>['653169161e5cc42b1b13cecb', '6555cccc4b13023f...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Based on the latest reports, the following are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>livemint</td>\n",
       "      <td>2024-01-28</td>\n",
       "      <td>True,Medium,True,Livemint financial and busine...</td>\n",
       "      <td>True</td>\n",
       "      <td>Medium</td>\n",
       "      <td>True</td>\n",
       "      <td>Livemint financial and business news</td>\n",
       "      <td>True</td>\n",
       "      <td>['65b4aa031b79671c6b70d124', '65b207126391ac19...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Livemint is an Indian financial daily, providi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>0</td>\n",
       "      <td>179</td>\n",
       "      <td>how do i decide if a ulip is the right decisio...</td>\n",
       "      <td>2024-01-23</td>\n",
       "      <td>True,Low,False,How to decide if a ULIP is righ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>How to decide if a ULIP is right for me</td>\n",
       "      <td>True</td>\n",
       "      <td>['65683309207bb033b910eda3', '6555be0e4b13023f...</td>\n",
       "      <td>relevant</td>\n",
       "      <td>\\nYou're an AI expert in financial and busines...</td>\n",
       "      <td>Deciding whether a Unit Linked Insurance Plan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1                                                  2           3   \\\n",
       "592   0  444                                     what is sensex  2023-11-02   \n",
       "63    0  240                                             terrie  2023-12-02   \n",
       "397   0  232                                                ipo  2024-02-12   \n",
       "179   0  272                                      michael scott  2024-02-07   \n",
       "548   0  171                 collapsed real estate firm unitech  2024-01-07   \n",
       "95    0  518                          tata motors stock outlook  2024-01-22   \n",
       "445   0  459                                       credit cards  2023-12-21   \n",
       "273   0  225                         coal india limited's stock  2024-01-17   \n",
       "371   0  263         stocks rising with green energy transition  2023-12-19   \n",
       "303   0  383                     ulip as a strategic investment  2024-01-22   \n",
       "209   0  340                                             sample  2023-11-30   \n",
       "457   0  333                                      loan services  2023-11-27   \n",
       "431   0  468                  real estate market forecast india  2024-02-06   \n",
       "247   0  440                              is eating out healthy  2023-11-11   \n",
       "659   0  501          how to prepare for retirement effectively  2023-11-24   \n",
       "340   0  504                     impact of ai on indian banking  2024-01-18   \n",
       "607   0  357                        insights from media outlets  2023-11-05   \n",
       "53    0  490                                         optimistic  2024-01-19   \n",
       "96    0  392                                 upcoming ipo india  2024-01-17   \n",
       "543   0  192                         bond investment principles  2023-12-10   \n",
       "194   0  166                   why hdfc bank shares are falling  2024-01-08   \n",
       "191   0  321                                         best users  2024-01-18   \n",
       "487   0  450               investors lose 3 lakh crore in a day  2023-12-12   \n",
       "79    0  222                         travel restrictions update  2024-01-19   \n",
       "117   0  295                           world happiest countries  2023-12-02   \n",
       "486   0  142                            solar energy home setup  2023-11-17   \n",
       "470   0  164                     cashless transactions in india  2024-01-01   \n",
       "517   0  245                 best digital payment apps in india  2023-11-09   \n",
       "402   0  155                                           livemint  2024-01-28   \n",
       "631   0  179  how do i decide if a ulip is the right decisio...  2024-01-23   \n",
       "\n",
       "                                                    4      5       6      7   \\\n",
       "592                      True,Low,False,What is Sensex   True     Low  False   \n",
       "63                                            False,,,  False     NaN    NaN   \n",
       "397             True,High,False,Upcoming IPOs in India   True    High  False   \n",
       "179                                           False,,,  False     NaN    NaN   \n",
       "548  True,Medium,True,Unitech real estate financial...   True  Medium   True   \n",
       "95   True,Medium,False,Tata Motors stock analysis J...   True  Medium  False   \n",
       "445  True,Medium,False,Credit card industry trends ...   True  Medium  False   \n",
       "273  True,Medium,False,Coal India Limited's stock p...   True  Medium  False   \n",
       "371  True,Medium,False,Stocks rising with green ene...   True  Medium  False   \n",
       "303  True,Low,False,ULIP as a strategic investment ...   True     Low  False   \n",
       "209                                           False,,,  False     NaN    NaN   \n",
       "457           True,Medium,False,Loan services in India   True  Medium  False   \n",
       "431  True,Medium,False,Real estate market forecast ...   True  Medium  False   \n",
       "247                                           False,,,  False     NaN    NaN   \n",
       "659  True,Low,False,How to effectively prepare for ...   True     Low  False   \n",
       "340  True,Medium,False,Impact of AI on Indian banki...   True  Medium  False   \n",
       "607  True,Medium,True,Insights from Indian media ou...   True  Medium   True   \n",
       "53                                            False,,,  False     NaN    NaN   \n",
       "96         True,High,False,Upcoming IPOs in India 2023   True    High  False   \n",
       "543  True,Low,False,Bond investment principles in I...   True     Low  False   \n",
       "194  True,Medium,False,Why is HDFC Bank share price...   True  Medium  False   \n",
       "191                                           False,,,  False     NaN    NaN   \n",
       "487  True,High,False,Indian investors lose 3 lakh c...   True    High  False   \n",
       "79   True,Medium,True,Latest travel restrictions up...   True  Medium   True   \n",
       "117                                           False,,,  False     NaN    NaN   \n",
       "486  True,Medium,False,Solar energy home setup guid...   True  Medium  False   \n",
       "470  True,Medium,False,Cashless transactions trends...   True  Medium  False   \n",
       "517  True,Medium,False,Best digital payment apps in...   True  Medium  False   \n",
       "402  True,Medium,True,Livemint financial and busine...   True  Medium   True   \n",
       "631  True,Low,False,How to decide if a ULIP is righ...   True     Low  False   \n",
       "\n",
       "                                                    8      9   \\\n",
       "592                                     What is Sensex   True   \n",
       "63                                                 NaN  False   \n",
       "397                             Upcoming IPOs in India   True   \n",
       "179                                                NaN  False   \n",
       "548                 Unitech real estate financial news   True   \n",
       "95             Tata Motors stock analysis January 2024   True   \n",
       "445               Credit card industry trends in India   True   \n",
       "273             Coal India Limited's stock performance   True   \n",
       "371  Stocks rising with green energy transition in ...   True   \n",
       "303              ULIP as a strategic investment option   True   \n",
       "209                                                NaN  False   \n",
       "457                             Loan services in India   True   \n",
       "431          Real estate market forecast in India 2024   True   \n",
       "247                                                NaN  False   \n",
       "659          How to effectively prepare for retirement   True   \n",
       "340              Impact of AI on Indian banking sector   True   \n",
       "607                 Insights from Indian media outlets   True   \n",
       "53                                                 NaN  False   \n",
       "96                         Upcoming IPOs in India 2023   True   \n",
       "543                Bond investment principles in India   True   \n",
       "194               Why is HDFC Bank share price falling   True   \n",
       "191                                                NaN  False   \n",
       "487        Indian investors lose 3 lakh crore in a day   True   \n",
       "79          Latest travel restrictions update in India   True   \n",
       "117                                                NaN  False   \n",
       "486             Solar energy home setup guide in India   True   \n",
       "470              Cashless transactions trends in India   True   \n",
       "517            Best digital payment apps in India 2023   True   \n",
       "402               Livemint financial and business news   True   \n",
       "631            How to decide if a ULIP is right for me   True   \n",
       "\n",
       "                                                    10        11  \\\n",
       "592  ['652fca6d1e5cc42b1b13a0ee', '6555b5084b13023f...  relevant   \n",
       "63                        ['656476fe96c80a0efa90fbcb']  relevant   \n",
       "397  ['65acc1006391ac19baa87097', '65813f89683f430d...  relevant   \n",
       "179                       ['6564772b96c80a0efa90ff7f']  relevant   \n",
       "548  ['65922acb4b25ce4814fb420a', '65a920496391ac19...  relevant   \n",
       "95   ['65adda586391ac19baa871e6', '65a9e5d16391ac19...  relevant   \n",
       "445  ['657bc159857ad3220916009f', '6571c36725cc9a34...  relevant   \n",
       "273  ['65316fe21e5cc42b1b142486', '65316f8d1e5cc42b...  relevant   \n",
       "371  ['658258d8683f430d81566015', '6570445153e8a611...  relevant   \n",
       "303  ['65683309207bb033b910eda3', '653680181e5cc42b...  relevant   \n",
       "209                       ['656476fe96c80a0efa90fbc8']  relevant   \n",
       "457  ['6571c2e625cc9a343f03c39f', '653680281e5cc42b...  relevant   \n",
       "431  ['65b23f501b79671c6b70cc2e', '65ab6f826391ac19...  relevant   \n",
       "247                       ['656476f496c80a0efa90fb08']  relevant   \n",
       "659  ['6555c8264b13023f93491168', '653680111e5cc42b...  relevant   \n",
       "340  ['659fca4be362d630b6472683', '65a896721c9bc64b...  relevant   \n",
       "607  ['6555cbec4b13023f934a2fe1', '6571c24225cc9a34...  relevant   \n",
       "53                        ['656476ec96c80a0efa90fa52']  relevant   \n",
       "96   ['659e085b4b25ce4814fb552a', '65a896841c9bc64b...  relevant   \n",
       "543  ['6555b5784b13023f9348bc2c', '652fc5db1e5cc42b...  relevant   \n",
       "194  ['65316ef41e5cc42b1b13ea79', '65316f901e5cc42b...  relevant   \n",
       "191                       ['6564772896c80a0efa90ff25']  relevant   \n",
       "487  ['652fbad41e5cc42b1b139e30', '65325dce1e5cc42b...  relevant   \n",
       "79   ['651dc55fa662d76276b7b3f4', '651dfd78a662d762...  relevant   \n",
       "117                       ['656476fe96c80a0efa90fbc8']  relevant   \n",
       "486  ['6564772896c80a0efa90ff1b', '652fcbde1e5cc42b...  relevant   \n",
       "470  ['658ff8af4b25ce4814fb413a', '658e36a64b25ce48...  relevant   \n",
       "517  ['653169161e5cc42b1b13cecb', '6555cccc4b13023f...  relevant   \n",
       "402  ['65b4aa031b79671c6b70d124', '65b207126391ac19...  relevant   \n",
       "631  ['65683309207bb033b910eda3', '6555be0e4b13023f...  relevant   \n",
       "\n",
       "                                                    12  \\\n",
       "592  \\nYou're an AI expert in financial and busines...   \n",
       "63   \\nYou're an AI expert in financial and busines...   \n",
       "397  \\nYou're an AI expert in financial and busines...   \n",
       "179  \\nYou're an AI expert in financial and busines...   \n",
       "548  \\nYou're an AI expert in financial and busines...   \n",
       "95   \\nYou're an AI expert in financial and busines...   \n",
       "445  \\nYou're an AI expert in financial and busines...   \n",
       "273  \\nYou're an AI expert in financial and busines...   \n",
       "371  \\nYou're an AI expert in financial and busines...   \n",
       "303  \\nYou're an AI expert in financial and busines...   \n",
       "209  \\nYou're an AI expert in financial and busines...   \n",
       "457  \\nYou're an AI expert in financial and busines...   \n",
       "431  \\nYou're an AI expert in financial and busines...   \n",
       "247  \\nYou're an AI expert in financial and busines...   \n",
       "659  \\nYou're an AI expert in financial and busines...   \n",
       "340  \\nYou're an AI expert in financial and busines...   \n",
       "607  \\nYou're an AI expert in financial and busines...   \n",
       "53   \\nYou're an AI expert in financial and busines...   \n",
       "96   \\nYou're an AI expert in financial and busines...   \n",
       "543  \\nYou're an AI expert in financial and busines...   \n",
       "194  \\nYou're an AI expert in financial and busines...   \n",
       "191  \\nYou're an AI expert in financial and busines...   \n",
       "487  \\nYou're an AI expert in financial and busines...   \n",
       "79   \\nYou're an AI expert in financial and busines...   \n",
       "117  \\nYou're an AI expert in financial and busines...   \n",
       "486  \\nYou're an AI expert in financial and busines...   \n",
       "470  \\nYou're an AI expert in financial and busines...   \n",
       "517  \\nYou're an AI expert in financial and busines...   \n",
       "402  \\nYou're an AI expert in financial and busines...   \n",
       "631  \\nYou're an AI expert in financial and busines...   \n",
       "\n",
       "                                                    13  \n",
       "592  The Sensex, or the S&P BSE Sensex, is India's ...  \n",
       "63   I'm sorry, but \"terrie\" is not a valid query r...  \n",
       "397  The IPO (Initial Public Offering) market in In...  \n",
       "179  The query 'Michael Scott' is not related to th...  \n",
       "548  Unitech Advisors (India) mentioned in the cont...  \n",
       "95   Tata Motors' stock has seen fluctuations over ...  \n",
       "445  Credit cards in India have shown substantial g...  \n",
       "273  Coal India's stock performance has seen slight...  \n",
       "371  The transition to green energy appears to be p...  \n",
       "303  Unit-Linked Insurance Plans (ULIP) combine ins...  \n",
       "209  I'm sorry, but your query seems incomplete or ...  \n",
       "457  In India, numerous banks offer loan services, ...  \n",
       "431  The forecast for India's real estate market co...  \n",
       "247  I'm afraid your query about the healthiness of...  \n",
       "659  Planning for retirement effectively entails se...  \n",
       "340  The impact of AI on Indian banking has elicite...  \n",
       "607  In recent media reports, there's been substant...  \n",
       "53   I'm sorry, but your query \"optimistic\" doesn't...  \n",
       "96   The upcoming IPO scenario in India for 2024 se...  \n",
       "543  Investing in bonds can be a strategic move if ...  \n",
       "194  The fall in HDFC Bank's share prices can be at...  \n",
       "191  I'm sorry, but I'm unable to assist with the q...  \n",
       "487  Based on the financial data, there are two ins...  \n",
       "79   As an AI financial expert, my scope doesn't al...  \n",
       "117  I'm sorry, but your query about \"world happies...  \n",
       "486  Solar energy home setups are attracting increa...  \n",
       "470  Despite governmental efforts towards a cashles...  \n",
       "517  Based on the latest reports, the following are...  \n",
       "402  Livemint is an Indian financial daily, providi...  \n",
       "631  Deciding whether a Unit Linked Insurance Plan ...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_responses[(all_responses[11]=='relevant')].sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "35983103-8539-4e96-820a-e3e1000aeac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inp = all_responses[all_responses[11]=='relevant'].loc[444][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f59d0432-0032-4c25-96ed-a9a91c826abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys_prompt, user_content = inp.split('|query_json|')\n",
    "messages = [{\"role\": \"system\", \"content\": sys_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_content}]\n",
    "context_prompt = tokenizer.decode(tokenizer.apply_chat_template(messages, add_generation_prompt=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e6548234-fdfd-47cc-b7a9-f86aaf386775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6721"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(context_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6a95ba38-4e51-4b9b-8e9b-8468bdeb2066",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(' '.join(context_prompt.split(' ')[:2048]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7a2ea73f-c475-4a2c-870a-eb1f6086124b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context_prompt = ' '.join(context_prompt.split(' ')[:1800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "81c35e49-9f59-494a-bd63-5172de5c77de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3239"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(context_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bad59e34-1375-4ef6-b986-7f1e1f1ab4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = {\"inputs\": context_prompt, \"parameters\": parameters, \"stream\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ec701914-fbd8-4d16-8357-cac750d5e613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.35460495948791504 seconds\n",
      "0 AUM: ₹6929.06 Crore Expense Ratio: 1.93% Risk: High Risk Min Investment: SIP: Rs. 500 Lump Sum: Rs.5000 3-Year Return: 24.76% 5-Year Return: 17.21% 3. Nippon India Multi-Cap Fund This fund has been created to give investors the opportunity to invest in a diversified portfolio of stocks across market capitalisation classes. The fund aims to offer high returns for investors with a long-term investment horizon. It invests at least 65% of its assets in equity and equity-related instruments. It also allows investors to choose between the direct and regular plans. NAV: ₹162.90 AUM: ₹14091.596 Crore Expense Ratio: 1.88% Risk: High Risk Min Investment: SIP: Rs. 500 Lump Sum: Rs.5000 3-Year Return: 12.49% 5-Year Return: 14.71% 4. Quant Active Fund Quant Active Fund has been designed to provide investors with the opportunity to invest in a diversified portfolio of stocks across market capitalisation classes. The fund invests at least 65% of its assets in equity and equity-related instruments. It also allows investors to choose between the direct and regular plans. This fund has been designed for investors with a long-term investment horizon. NAV: ₹412.96 AUM: ₹3531.839 Crore Expense Ratio: 2.63% Risk: High Risk Min Investment: SIP: Rs. 500 Lump Sum: Rs.5000 3-Year Return: N/A 5-Year Return: N/A 5. Edelweiss Recently Listed IPO Fund – Direct Plan – Growth Edelweiss recently listed IPO Fund is a mutual fund that has been designed to help investors invest in newly listed stocks. This fund has been created to allow investors to invest in a diversified portfolio of stocks that have recently listed on the stock exchange. This fund has been designed for investors with a long-term investment horizon."
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "resp = smr.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=f\"OpenHermes-Search-PurpleCherryPanda\",\n",
    "    Body=json.dumps(request),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "print(f'done in {time.time() - t} seconds')\n",
    "# k = resp['Body'].read()\n",
    "for token in TokenIterator(resp[\"Body\"]):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2ba63f47-a00d-4db3-be13-90f5282560f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "\n",
    "class TokenIterator:\n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "            if line and line[-1] == ord(\"\\n\"):\n",
    "                self.read_pos += len(line) + 1\n",
    "                full_line = line[:-1].decode(\"utf-8\")\n",
    "                line_data = json.loads(full_line.lstrip(\"data:\").rstrip(\"/n\"))\n",
    "                return line_data[\"token\"][\"text\"]\n",
    "            chunk = next(self.byte_iterator)\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk[\"PayloadPart\"][\"Bytes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "63f467e3-d192-4aa0-8f93-7122029e5a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b73c431f-4844-4493-b8fc-dfab861c9a78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EventStream' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m resp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EventStream' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "resp['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab8093-acca-41d7-8c51-e63ecf03bc38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoenv",
   "language": "python",
   "name": "recoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
