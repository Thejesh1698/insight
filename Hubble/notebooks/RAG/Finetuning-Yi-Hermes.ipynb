{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def01f54-cc88-410d-b9ba-93e3c83f8258",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AmazonSageMaker-ExecutionRole-20231030T210397'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "iam = boto3.client('iam')\n",
    "response = iam.list_roles()\n",
    "sagemaker_roles = [role for role in response['Roles'] if 'SageMaker' in role['RoleName']]\n",
    "sagemaker_roles[0]['RoleName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6fdb02-cc08-4b4c-8a58-525cf38b584c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ravi.tej/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name ravi_tej to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20231030T210397')['Role']['Arn']\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6464458-827b-49f8-866f-1d816f7ae6fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "from random import randint\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from pack_dataset import pack_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb402e2-4b71-4b25-b464-0189218ad3fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravi.tej/anaconda3/envs/recoenv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_id = \"TheBloke/Nous-Hermes-2-Yi-34B-GPTQ\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea7f6974-035b-4665-824f-1ed4590d179a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_s3_path = 's3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2024-01-30-Search_PurpleCherryPanda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04365590-a3cd-4f0a-90a7-134f8559d567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25d1bce4-e1f4-48b2-8d6f-6503c14a21a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_dataset_config = {'finetune_id': 'Search_' + 'PurpleCherryPanda',\n",
    "                          'date': datetime.strftime(datetime.today(),'%Y-%m-%d'),\n",
    "                          'num_datapoints': 671,\n",
    "                            'data_source': 'gpt4'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1de2cba9-09ca-4a6e-8dec-abd73b4915d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'num_train_epochs': 1,                            # number of training epochs\n",
    "  'per_device_train_batch_size': 2,                 # batch size for training\n",
    "  'gradient_accumulation_steps': 4,                 # Number of updates steps to accumulate\n",
    "  'gradient_checkpointing': True,                   # save memory but slower backward pass\n",
    "  'bf16': True,                                     # use bfloat16 precision\n",
    "  'tf32': True,                                     # use tf32 precision\n",
    "  'learning_rate': 2e-5,                            # learning rate\n",
    "  'max_grad_norm': 0.3,                             # Maximum norm (for gradient clipping)\n",
    "  'warmup_ratio': 0.03,                             # warmup ratio\n",
    "    'weight_decay': 0.02,\n",
    "  \"lr_scheduler_type\":\"cosine_with_restarts\",                   # learning rate scheduler\n",
    "  'save_strategy': \"epoch\",                         # save strategy for checkpoints\n",
    "  \"logging_steps\": 10,                              # log every x steps\n",
    "  'merge_adapters': False,                           # wether to merge LoRA into the model (needs more memory)\n",
    "  'use_flash_attn': True,                           # Whether to use Flash Attention\n",
    "  'output_dir': '/tmp/run'                         # output directory, where to save assets during training\n",
    "    \n",
    "                                                    # could be used for checkpointing. The final trained\n",
    "                                                    # model will always be saved to s3 at the end of training\n",
    "}\n",
    "\n",
    "if HfFolder.get_token() is not None:\n",
    "    hyperparameters['hf_token'] = HfFolder.get_token() # huggingface token to access gated models, e.g. llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c5fd6b5-fd27-4c47-b032-46c078ed457d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f'huggingface-qlora-{hyperparameters[\"model_id\"].replace(\"/\",\"-\").replace(\".\",\"-\")}-{finetune_dataset_config[\"finetune_id\"]}'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_qlora-gptq.py',    # train script\n",
    "    source_dir           = '../utils/',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.12xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 4*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 50,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    "    disable_output_compression = True         # not compress output to save training time and cost\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d73c5365-f6e2-4738-a3a8-ef8d313fe143",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-TheBloke-Nous-Hermes--2024-02-01-07-11-34-007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-01 07:11:35 Starting - Starting the training job......\n",
      "2024-02-01 07:12:09 Starting - Preparing the instances for training......\n",
      "2024-02-01 07:13:36 Downloading - Downloading the training image........................\n",
      "2024-02-01 07:17:27 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:16,792 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:16,846 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:16,855 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:16,856 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:18,203 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.35.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 89.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.5.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 25.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting optimum==1.14.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl (398 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 398.9/398.9 kB 66.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.23.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.1/258.1 kB 48.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 MB 22.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.3 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 96.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.11.1)\u001b[0m\n",
      "\u001b[34mCollecting datasets==2.15.0 (from -r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 521.2/521.2 kB 71.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting auto-gptq (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 99.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.12.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 330.1/330.1 kB 65.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.6/3.6 MB 129.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting coloredlogs (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 13.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers[sentencepiece]>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (4.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (12.0.0)\u001b[0m\n",
      "\u001b[34mCollecting pyarrow-hotfix (from datasets==2.15.0->-r requirements.txt (line 9))\u001b[0m\n",
      "\u001b[34mDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0->-r requirements.txt (line 9)) (3.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes->-r requirements.txt (line 5)) (1.10.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from auto-gptq->-r requirements.txt (line 10)) (0.1.99)\u001b[0m\n",
      "\u001b[34mCollecting rouge (from auto-gptq->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting gekko (from auto-gptq->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading gekko-1.0.6-py3-none-any.whl (12.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 89.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.9.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0->-r requirements.txt (line 9)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting transformers[sentencepiece]>=4.26.0 (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.37.2-py3-none-any.whl (8.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 127.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.37.1-py3-none-any.whl (8.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 112.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.37.0-py3-none-any.whl (8.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.4/8.4 MB 58.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.2/8.2 MB 126.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.1-py3-none-any.whl (8.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 145.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.2/8.2 MB 120.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 25.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0->-r requirements.txt (line 9)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->auto-gptq->-r requirements.txt (line 10)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (2.1.2)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: safetensors, rouge, pyarrow-hotfix, humanfriendly, gekko, huggingface-hub, coloredlogs, bitsandbytes, tokenizers, accelerate, transformers, datasets, peft, optimum, auto-gptq\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.14.1\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.14.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.14.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: datasets\u001b[0m\n",
      "\u001b[34mFound existing installation: datasets 2.12.0\u001b[0m\n",
      "\u001b[34mUninstalling datasets-2.12.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled datasets-2.12.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.23.0 auto-gptq-0.6.0 bitsandbytes-0.42.0 coloredlogs-15.0.1 datasets-2.15.0 gekko-1.0.6 huggingface-hub-0.20.3 humanfriendly-10.0 optimum-1.14.0 peft-0.5.0 pyarrow-hotfix-0.6 rouge-1.0.1 safetensors-0.4.2 tokenizers-0.15.1 transformers-4.35.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:35,552 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:35,552 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:35,628 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:35,692 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:35,755 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:35,766 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"gradient_accumulation_steps\": 4,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"learning_rate\": 2e-05,\n",
      "        \"logging_steps\": 10,\n",
      "        \"lr_scheduler_type\": \"cosine_with_restarts\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"merge_adapters\": false,\n",
      "        \"model_id\": \"TheBloke/Nous-Hermes-2-Yi-34B-GPTQ\",\n",
      "        \"num_train_epochs\": 1,\n",
      "        \"output_dir\": \"/tmp/run\",\n",
      "        \"per_device_train_batch_size\": 2,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"use_flash_attn\": true,\n",
      "        \"warmup_ratio\": 0.03,\n",
      "        \"weight_decay\": 0.02\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-TheBloke-Nous-Hermes--2024-02-01-07-11-34-007\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-TheBloke-Nous-Hermes--2024-02-01-07-11-34-007/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_qlora-gptq\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_qlora-gptq.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":4,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":2e-05,\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":false,\"model_id\":\"TheBloke/Nous-Hermes-2-Yi-34B-GPTQ\",\"num_train_epochs\":1,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":2,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03,\"weight_decay\":0.02}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_qlora-gptq.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.12xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_qlora-gptq\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-TheBloke-Nous-Hermes--2024-02-01-07-11-34-007/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.12xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":4,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":2e-05,\"logging_steps\":10,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":false,\"model_id\":\"TheBloke/Nous-Hermes-2-Yi-34B-GPTQ\",\"num_train_epochs\":1,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":2,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03,\"weight_decay\":0.02},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-TheBloke-Nous-Hermes--2024-02-01-07-11-34-007\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-TheBloke-Nous-Hermes--2024-02-01-07-11-34-007/source/sourcedir.tar.gz\",\"module_name\":\"run_qlora-gptq\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_qlora-gptq.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training\",\"--gradient_accumulation_steps\",\"4\",\"--gradient_checkpointing\",\"True\",\"--hf_token\",\"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\",\"--learning_rate\",\"2e-05\",\"--logging_steps\",\"10\",\"--lr_scheduler_type\",\"cosine_with_restarts\",\"--max_grad_norm\",\"0.3\",\"--merge_adapters\",\"False\",\"--model_id\",\"TheBloke/Nous-Hermes-2-Yi-34B-GPTQ\",\"--num_train_epochs\",\"1\",\"--output_dir\",\"/tmp/run\",\"--per_device_train_batch_size\",\"2\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--use_flash_attn\",\"True\",\"--warmup_ratio\",\"0.03\",\"--weight_decay\",\"0.02\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=4\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=2e-05\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=cosine_with_restarts\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=false\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=TheBloke/Nous-Hermes-2-Yi-34B-GPTQ\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/run\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=2\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FLASH_ATTN=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=0.02\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_qlora-gptq.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 4 --gradient_checkpointing True --hf_token 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 --learning_rate 2e-05 --logging_steps 10 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters False --model_id TheBloke/Nous-Hermes-2-Yi-34B-GPTQ --num_train_epochs 1 --output_dir /tmp/run --per_device_train_batch_size 2 --save_strategy epoch --tf32 True --use_flash_attn True --warmup_ratio 0.03 --weight_decay 0.02\u001b[0m\n",
      "\u001b[34m2024-02-01 07:18:35,793 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flash-attn in /opt/conda/lib/python3.10/site-packages (0.2.8)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.5.2.tar.gz (2.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.5/2.5 MB 79.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.5.2-cp310-cp310-linux_x86_64.whl size=121774310 sha256=14853cd74b4ff4ab92da28ad6cc6d3bf4968e823af42d61711667439dfba1929\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/ff/8e/8b/5fb0f8eb882c58b2bcfb4302860884d1b45d8513f8b3daac9c\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mSuccessfully installed flash-attn-2.5.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mLogging into the Hugging Face Hub with token hf_NjVkEqg...\u001b[0m\n",
      "\u001b[34mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\u001b[0m\n",
      "\u001b[34mToken is valid (permission: write).\u001b[0m\n",
      "\u001b[34mYour token has been saved to /root/.cache/huggingface/token\u001b[0m\n",
      "\u001b[34mLogin successful\u001b[0m\n",
      "\u001b[34mUsing `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\u001b[0m\n",
      "\u001b[34mUsing `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 1.53k/1.53k [00:00<00:00, 14.5MB/s]\u001b[0m\n",
      "\u001b[34mYou passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. use_exllama, exllama_config, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\u001b[0m\n",
      "\u001b[34mYou passed `quantization_config` to `from_pretrained` but the model you're loading already has a `quantization_config` attribute and has already quantized weights. However, loading attributes (e.g. use_exllama, exllama_config, use_cuda_fp16, max_input_length) will be overwritten with the one you passed to `from_pretrained`. The rest will be ignored.\u001b[0m\n",
      "\u001b[34mCUDA extension not installed.\u001b[0m\n",
      "\u001b[34mCUDA extension not installed.\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   0%|          | 0.00/18.6G [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   0%|          | 52.4M/18.6G [00:00<00:41, 446MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   1%|          | 115M/18.6G [00:00<00:35, 523MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   1%|          | 178M/18.6G [00:00<00:33, 545MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   1%|▏         | 241M/18.6G [00:00<00:32, 558MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   2%|▏         | 304M/18.6G [00:00<00:32, 568MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   2%|▏         | 367M/18.6G [00:00<00:32, 565MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   2%|▏         | 430M/18.6G [00:00<00:32, 567MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   3%|▎         | 493M/18.6G [00:00<00:33, 548MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   3%|▎         | 556M/18.6G [00:01<00:32, 556MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   3%|▎         | 619M/18.6G [00:01<00:32, 559MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   4%|▎         | 682M/18.6G [00:01<00:31, 562MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   4%|▍         | 744M/18.6G [00:01<00:31, 567MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   4%|▍         | 807M/18.6G [00:01<00:31, 567MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   5%|▍         | 870M/18.6G [00:01<00:33, 532MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   5%|▌         | 933M/18.6G [00:01<00:32, 542MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   5%|▌         | 996M/18.6G [00:01<00:33, 531MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   6%|▌         | 1.06G/18.6G [00:01<00:32, 536MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   6%|▌         | 1.12G/18.6G [00:02<00:32, 544MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   6%|▋         | 1.18G/18.6G [00:02<00:31, 546MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   7%|▋         | 1.25G/18.6G [00:02<00:31, 549MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   7%|▋         | 1.31G/18.6G [00:02<00:31, 553MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   7%|▋         | 1.37G/18.6G [00:02<00:30, 556MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   8%|▊         | 1.44G/18.6G [00:02<00:30, 558MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   8%|▊         | 1.50G/18.6G [00:02<00:30, 567MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   8%|▊         | 1.56G/18.6G [00:02<00:30, 568MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   9%|▊         | 1.63G/18.6G [00:02<00:29, 566MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   9%|▉         | 1.69G/18.6G [00:03<00:29, 566MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:   9%|▉         | 1.75G/18.6G [00:03<00:29, 566MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  10%|▉         | 1.81G/18.6G [00:03<00:29, 561MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  10%|█         | 1.88G/18.6G [00:03<00:29, 564MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  10%|█         | 1.94G/18.6G [00:03<00:29, 571MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  11%|█         | 2.00G/18.6G [00:03<00:29, 563MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  11%|█         | 2.07G/18.6G [00:03<00:29, 564MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  11%|█▏        | 2.13G/18.6G [00:03<00:31, 531MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  12%|█▏        | 2.19G/18.6G [00:03<00:32, 503MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  12%|█▏        | 2.24G/18.6G [00:04<00:33, 488MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  12%|█▏        | 2.30G/18.6G [00:04<00:34, 471MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  13%|█▎        | 2.35G/18.6G [00:04<00:35, 456MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  13%|█▎        | 2.40G/18.6G [00:04<00:35, 453MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  13%|█▎        | 2.45G/18.6G [00:04<00:35, 450MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  13%|█▎        | 2.51G/18.6G [00:04<00:36, 445MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  14%|█▍        | 2.56G/18.6G [00:04<00:35, 447MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  14%|█▍        | 2.61G/18.6G [00:04<00:35, 448MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  14%|█▍        | 2.66G/18.6G [00:05<00:35, 447MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  15%|█▍        | 2.72G/18.6G [00:05<00:35, 442MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  15%|█▍        | 2.77G/18.6G [00:05<00:35, 442MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  15%|█▌        | 2.82G/18.6G [00:05<00:35, 442MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  15%|█▌        | 2.87G/18.6G [00:05<00:36, 427MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  16%|█▌        | 2.93G/18.6G [00:05<00:36, 425MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  16%|█▌        | 2.98G/18.6G [00:05<00:36, 428MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  16%|█▋        | 3.03G/18.6G [00:05<00:35, 433MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  17%|█▋        | 3.08G/18.6G [00:06<00:35, 441MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  17%|█▋        | 3.14G/18.6G [00:06<00:35, 432MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  17%|█▋        | 3.20G/18.6G [00:06<00:33, 460MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  17%|█▋        | 3.25G/18.6G [00:06<00:32, 465MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  18%|█▊        | 3.31G/18.6G [00:06<00:31, 493MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  18%|█▊        | 3.38G/18.6G [00:06<00:29, 521MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  18%|█▊        | 3.44G/18.6G [00:06<00:28, 528MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  19%|█▉        | 3.50G/18.6G [00:06<00:27, 540MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  19%|█▉        | 3.57G/18.6G [00:06<00:27, 544MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  20%|█▉        | 3.63G/18.6G [00:07<00:26, 558MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  20%|█▉        | 3.69G/18.6G [00:07<00:26, 562MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  20%|██        | 3.75G/18.6G [00:07<00:26, 569MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  21%|██        | 3.82G/18.6G [00:07<00:25, 570MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  21%|██        | 3.88G/18.6G [00:07<00:25, 570MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  21%|██        | 3.94G/18.6G [00:07<00:25, 572MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  22%|██▏       | 4.01G/18.6G [00:07<00:25, 576MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  22%|██▏       | 4.07G/18.6G [00:07<00:25, 578MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  22%|██▏       | 4.13G/18.6G [00:07<00:24, 579MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  23%|██▎       | 4.19G/18.6G [00:08<00:25, 555MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  23%|██▎       | 4.26G/18.6G [00:08<00:25, 562MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  23%|██▎       | 4.32G/18.6G [00:08<00:25, 564MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  24%|██▎       | 4.38G/18.6G [00:08<00:24, 569MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  24%|██▍       | 4.45G/18.6G [00:08<00:24, 574MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  24%|██▍       | 4.51G/18.6G [00:08<00:24, 575MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  25%|██▍       | 4.57G/18.6G [00:08<00:24, 580MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  25%|██▍       | 4.63G/18.6G [00:08<00:31, 445MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  25%|██▌       | 4.69G/18.6G [00:09<00:31, 443MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  25%|██▌       | 4.74G/18.6G [00:09<00:31, 442MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  26%|██▌       | 4.79G/18.6G [00:09<00:31, 443MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  26%|██▌       | 4.85G/18.6G [00:09<00:29, 470MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  26%|██▋       | 4.91G/18.6G [00:09<00:29, 468MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  27%|██▋       | 4.97G/18.6G [00:09<00:27, 496MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  27%|██▋       | 5.03G/18.6G [00:09<00:26, 516MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  27%|██▋       | 5.10G/18.6G [00:09<00:25, 524MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  28%|██▊       | 5.16G/18.6G [00:09<00:25, 520MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  28%|██▊       | 5.22G/18.6G [00:10<00:25, 534MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  28%|██▊       | 5.28G/18.6G [00:10<00:25, 515MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  29%|██▊       | 5.35G/18.6G [00:10<00:25, 528MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  29%|██▉       | 5.41G/18.6G [00:10<00:24, 535MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  29%|██▉       | 5.47G/18.6G [00:10<00:26, 491MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  30%|██▉       | 5.53G/18.6G [00:10<00:29, 440MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  30%|███       | 5.59G/18.6G [00:10<00:27, 475MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  30%|███       | 5.64G/18.6G [00:10<00:27, 475MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  31%|███       | 5.70G/18.6G [00:11<00:26, 492MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  31%|███       | 5.77G/18.6G [00:11<00:25, 509MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  31%|███▏      | 5.83G/18.6G [00:11<00:24, 522MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  32%|███▏      | 5.89G/18.6G [00:11<00:24, 524MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  32%|███▏      | 5.96G/18.6G [00:11<00:23, 530MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  32%|███▏      | 6.02G/18.6G [00:11<00:23, 541MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  33%|███▎      | 6.08G/18.6G [00:11<00:23, 542MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  33%|███▎      | 6.14G/18.6G [00:11<00:22, 545MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  33%|███▎      | 6.21G/18.6G [00:11<00:22, 545MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  34%|███▎      | 6.27G/18.6G [00:12<00:22, 548MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  34%|███▍      | 6.33G/18.6G [00:12<00:22, 551MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  34%|███▍      | 6.40G/18.6G [00:12<00:22, 553MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  35%|███▍      | 6.46G/18.6G [00:12<00:22, 551MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  35%|███▌      | 6.52G/18.6G [00:12<00:22, 548MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  35%|███▌      | 6.59G/18.6G [00:12<00:21, 548MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  36%|███▌      | 6.65G/18.6G [00:12<00:21, 545MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  36%|███▌      | 6.71G/18.6G [00:12<00:22, 541MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  36%|███▋      | 6.77G/18.6G [00:13<00:21, 538MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  37%|███▋      | 6.84G/18.6G [00:13<00:21, 540MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  37%|███▋      | 6.90G/18.6G [00:13<00:22, 524MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  37%|███▋      | 6.96G/18.6G [00:13<00:23, 502MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  38%|███▊      | 7.01G/18.6G [00:13<00:23, 499MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  38%|███▊      | 7.08G/18.6G [00:13<00:22, 507MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  38%|███▊      | 7.14G/18.6G [00:13<00:22, 520MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  39%|███▊      | 7.20G/18.6G [00:13<00:21, 524MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  39%|███▉      | 7.27G/18.6G [00:14<00:22, 511MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  39%|███▉      | 7.33G/18.6G [00:14<00:21, 517MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  40%|███▉      | 7.38G/18.6G [00:14<00:22, 505MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  40%|████      | 7.44G/18.6G [00:14<00:21, 513MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  40%|████      | 7.51G/18.6G [00:14<00:21, 523MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  41%|████      | 7.57G/18.6G [00:14<00:20, 538MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  41%|████      | 7.63G/18.6G [00:14<00:20, 545MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  41%|████▏     | 7.70G/18.6G [00:14<00:19, 551MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  42%|████▏     | 7.76G/18.6G [00:14<00:19, 555MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  42%|████▏     | 7.82G/18.6G [00:15<00:19, 559MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  42%|████▏     | 7.89G/18.6G [00:15<00:19, 558MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  43%|████▎     | 7.95G/18.6G [00:15<00:19, 557MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  43%|████▎     | 8.01G/18.6G [00:15<00:19, 549MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  43%|████▎     | 8.07G/18.6G [00:15<00:18, 557MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  44%|████▎     | 8.14G/18.6G [00:15<00:18, 555MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  44%|████▍     | 8.20G/18.6G [00:15<00:19, 522MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  44%|████▍     | 8.26G/18.6G [00:15<00:19, 531MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  45%|████▍     | 8.33G/18.6G [00:15<00:18, 542MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  45%|████▌     | 8.39G/18.6G [00:16<00:19, 528MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  45%|████▌     | 8.45G/18.6G [00:16<00:19, 523MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  46%|████▌     | 8.51G/18.6G [00:16<00:19, 521MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  46%|████▌     | 8.58G/18.6G [00:16<00:18, 534MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  46%|████▋     | 8.64G/18.6G [00:16<00:18, 542MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  47%|████▋     | 8.70G/18.6G [00:16<00:18, 549MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  47%|████▋     | 8.77G/18.6G [00:16<00:18, 528MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  47%|████▋     | 8.83G/18.6G [00:16<00:18, 520MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  48%|████▊     | 8.89G/18.6G [00:17<00:18, 529MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  48%|████▊     | 8.95G/18.6G [00:17<00:17, 543MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  48%|████▊     | 9.02G/18.6G [00:17<00:17, 549MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  49%|████▉     | 9.08G/18.6G [00:17<00:17, 557MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  49%|████▉     | 9.14G/18.6G [00:17<00:18, 520MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  49%|████▉     | 9.21G/18.6G [00:17<00:17, 524MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  50%|████▉     | 9.27G/18.6G [00:17<00:17, 534MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  50%|█████     | 9.33G/18.6G [00:17<00:17, 545MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  50%|█████     | 9.40G/18.6G [00:17<00:16, 552MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  51%|█████     | 9.46G/18.6G [00:18<00:16, 551MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  51%|█████     | 9.52G/18.6G [00:18<00:16, 545MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  52%|█████▏    | 9.58G/18.6G [00:18<00:17, 525MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  52%|█████▏    | 9.65G/18.6G [00:18<00:18, 498MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  52%|█████▏    | 9.70G/18.6G [00:18<00:18, 484MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  52%|█████▏    | 9.75G/18.6G [00:18<00:18, 479MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  53%|█████▎    | 9.80G/18.6G [00:18<00:18, 483MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  53%|█████▎    | 9.87G/18.6G [00:18<00:17, 504MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  53%|█████▎    | 9.93G/18.6G [00:19<00:16, 519MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  54%|█████▎    | 9.98G/18.6G [00:19<00:19, 439MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  54%|█████▍    | 10.0G/18.6G [00:19<00:19, 449MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  54%|█████▍    | 10.1G/18.6G [00:19<00:17, 478MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  55%|█████▍    | 10.2G/18.6G [00:19<00:16, 500MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  55%|█████▍    | 10.2G/18.6G [00:19<00:16, 514MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  55%|█████▌    | 10.3G/18.6G [00:19<00:16, 516MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  56%|█████▌    | 10.3G/18.6G [00:19<00:16, 517MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  56%|█████▌    | 10.4G/18.6G [00:19<00:15, 518MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  56%|█████▌    | 10.4G/18.6G [00:20<00:15, 519MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  56%|█████▋    | 10.5G/18.6G [00:20<00:15, 512MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  57%|█████▋    | 10.6G/18.6G [00:20<00:15, 523MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  57%|█████▋    | 10.6G/18.6G [00:20<00:15, 518MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  57%|█████▋    | 10.7G/18.6G [00:20<00:16, 496MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  58%|█████▊    | 10.7G/18.6G [00:20<00:24, 317MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  58%|█████▊    | 10.8G/18.6G [00:20<00:25, 311MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  58%|█████▊    | 10.8G/18.6G [00:21<00:22, 350MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  58%|█████▊    | 10.9G/18.6G [00:21<00:19, 399MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  59%|█████▊    | 10.9G/18.6G [00:21<00:18, 411MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  59%|█████▉    | 11.0G/18.6G [00:21<00:18, 416MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  59%|█████▉    | 11.0G/18.6G [00:21<00:17, 437MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  60%|█████▉    | 11.1G/18.6G [00:21<00:17, 432MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  60%|█████▉    | 11.1G/18.6G [00:21<00:16, 448MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  60%|██████    | 11.2G/18.6G [00:21<00:15, 474MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  60%|██████    | 11.3G/18.6G [00:21<00:15, 487MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  61%|██████    | 11.3G/18.6G [00:22<00:14, 500MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  61%|██████    | 11.4G/18.6G [00:22<00:14, 504MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  61%|██████▏   | 11.4G/18.6G [00:22<00:14, 499MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  62%|██████▏   | 11.5G/18.6G [00:22<00:14, 495MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  62%|██████▏   | 11.5G/18.6G [00:22<00:14, 495MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  62%|██████▏   | 11.6G/18.6G [00:22<00:14, 475MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  63%|██████▎   | 11.6G/18.6G [00:22<00:15, 461MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  63%|██████▎   | 11.7G/18.6G [00:22<00:14, 464MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  63%|██████▎   | 11.7G/18.6G [00:22<00:14, 465MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  63%|██████▎   | 11.8G/18.6G [00:23<00:15, 454MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  64%|██████▎   | 11.8G/18.6G [00:23<00:14, 471MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  64%|██████▍   | 11.9G/18.6G [00:23<00:13, 498MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  64%|██████▍   | 12.0G/18.6G [00:23<00:12, 519MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  65%|██████▍   | 12.0G/18.6G [00:23<00:12, 535MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  65%|██████▍   | 12.1G/18.6G [00:23<00:12, 543MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  65%|██████▌   | 12.2G/18.6G [00:23<00:12, 528MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  66%|██████▌   | 12.2G/18.6G [00:23<00:12, 526MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  66%|██████▌   | 12.3G/18.6G [00:24<00:13, 485MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  66%|██████▋   | 12.3G/18.6G [00:24<00:12, 505MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  67%|██████▋   | 12.4G/18.6G [00:24<00:11, 519MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  67%|██████▋   | 12.5G/18.6G [00:24<00:11, 517MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  67%|██████▋   | 12.5G/18.6G [00:24<00:12, 503MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  68%|██████▊   | 12.6G/18.6G [00:24<00:11, 521MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  68%|██████▊   | 12.6G/18.6G [00:24<00:11, 532MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  68%|██████▊   | 12.7G/18.6G [00:24<00:11, 522MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  69%|██████▊   | 12.8G/18.6G [00:24<00:10, 533MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  69%|██████▉   | 12.8G/18.6G [00:25<00:10, 541MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  69%|██████▉   | 12.9G/18.6G [00:25<00:10, 527MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  70%|██████▉   | 13.0G/18.6G [00:25<00:10, 529MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  70%|██████▉   | 13.0G/18.6G [00:25<00:10, 537MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  70%|███████   | 13.1G/18.6G [00:25<00:11, 492MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  71%|███████   | 13.1G/18.6G [00:25<00:11, 482MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  71%|███████   | 13.2G/18.6G [00:25<00:10, 499MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  71%|███████▏  | 13.3G/18.6G [00:25<00:10, 520MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  72%|███████▏  | 13.3G/18.6G [00:26<00:10, 496MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  72%|███████▏  | 13.4G/18.6G [00:26<00:10, 500MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  72%|███████▏  | 13.4G/18.6G [00:26<00:10, 516MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  73%|███████▎  | 13.5G/18.6G [00:26<00:09, 526MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  73%|███████▎  | 13.6G/18.6G [00:26<00:09, 537MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  73%|███████▎  | 13.6G/18.6G [00:26<00:09, 532MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  74%|███████▎  | 13.7G/18.6G [00:26<00:09, 524MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  74%|███████▍  | 13.8G/18.6G [00:26<00:09, 530MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  74%|███████▍  | 13.8G/18.6G [00:26<00:08, 541MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  75%|███████▍  | 13.9G/18.6G [00:27<00:08, 532MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  75%|███████▍  | 13.9G/18.6G [00:27<00:08, 526MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  75%|███████▌  | 14.0G/18.6G [00:27<00:09, 509MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  76%|███████▌  | 14.1G/18.6G [00:27<00:08, 524MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  76%|███████▌  | 14.1G/18.6G [00:27<00:08, 538MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  76%|███████▋  | 14.2G/18.6G [00:27<00:08, 546MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  77%|███████▋  | 14.3G/18.6G [00:27<00:07, 548MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  77%|███████▋  | 14.3G/18.6G [00:27<00:07, 548MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  77%|███████▋  | 14.4G/18.6G [00:28<00:07, 543MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  78%|███████▊  | 14.4G/18.6G [00:28<00:07, 547MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  78%|███████▊  | 14.5G/18.6G [00:28<00:07, 534MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  78%|███████▊  | 14.6G/18.6G [00:28<00:07, 536MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  79%|███████▊  | 14.6G/18.6G [00:28<00:07, 526MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  79%|███████▉  | 14.7G/18.6G [00:28<00:07, 510MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  79%|███████▉  | 14.8G/18.6G [00:28<00:07, 517MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  80%|███████▉  | 14.8G/18.6G [00:28<00:07, 523MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  80%|████████  | 14.9G/18.6G [00:29<00:07, 520MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  80%|████████  | 15.0G/18.6G [00:29<00:06, 529MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  81%|████████  | 15.0G/18.6G [00:29<00:06, 529MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  81%|████████  | 15.1G/18.6G [00:29<00:06, 526MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  81%|████████▏ | 15.1G/18.6G [00:29<00:06, 531MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  82%|████████▏ | 15.2G/18.6G [00:29<00:06, 526MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  82%|████████▏ | 15.3G/18.6G [00:29<00:06, 529MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  82%|████████▏ | 15.3G/18.6G [00:29<00:06, 531MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  83%|████████▎ | 15.4G/18.6G [00:29<00:06, 529MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  83%|████████▎ | 15.5G/18.6G [00:30<00:05, 531MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  83%|████████▎ | 15.5G/18.6G [00:30<00:05, 532MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  84%|████████▍ | 15.6G/18.6G [00:30<00:05, 530MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  84%|████████▍ | 15.6G/18.6G [00:30<00:05, 529MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  84%|████████▍ | 15.7G/18.6G [00:30<00:05, 534MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  85%|████████▍ | 15.8G/18.6G [00:30<00:05, 540MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  85%|████████▌ | 15.8G/18.6G [00:30<00:05, 544MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  85%|████████▌ | 15.9G/18.6G [00:31<00:07, 358MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  86%|████████▌ | 15.9G/18.6G [00:31<00:07, 372MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  86%|████████▌ | 16.0G/18.6G [00:31<00:06, 411MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  86%|████████▋ | 16.1G/18.6G [00:31<00:05, 432MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  87%|████████▋ | 16.1G/18.6G [00:31<00:05, 465MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  87%|████████▋ | 16.2G/18.6G [00:31<00:04, 494MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  87%|████████▋ | 16.2G/18.6G [00:31<00:04, 493MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  88%|████████▊ | 16.3G/18.6G [00:31<00:04, 514MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  88%|████████▊ | 16.4G/18.6G [00:32<00:04, 508MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  88%|████████▊ | 16.4G/18.6G [00:32<00:04, 521MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  89%|████████▊ | 16.5G/18.6G [00:32<00:03, 528MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  89%|████████▉ | 16.6G/18.6G [00:32<00:03, 538MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  89%|████████▉ | 16.6G/18.6G [00:32<00:03, 544MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  90%|████████▉ | 16.7G/18.6G [00:32<00:03, 555MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  90%|█████████ | 16.7G/18.6G [00:32<00:03, 559MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  90%|█████████ | 16.8G/18.6G [00:32<00:03, 563MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  91%|█████████ | 16.9G/18.6G [00:32<00:03, 566MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  91%|█████████ | 16.9G/18.6G [00:33<00:02, 570MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  91%|█████████▏| 17.0G/18.6G [00:33<00:02, 568MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  92%|█████████▏| 17.1G/18.6G [00:33<00:02, 562MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  92%|█████████▏| 17.1G/18.6G [00:33<00:02, 563MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  92%|█████████▏| 17.2G/18.6G [00:33<00:02, 562MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  93%|█████████▎| 17.2G/18.6G [00:33<00:02, 557MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  93%|█████████▎| 17.3G/18.6G [00:33<00:02, 560MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  93%|█████████▎| 17.4G/18.6G [00:33<00:02, 561MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  94%|█████████▎| 17.4G/18.6G [00:33<00:02, 558MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  94%|█████████▍| 17.5G/18.6G [00:34<00:01, 556MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  94%|█████████▍| 17.6G/18.6G [00:34<00:01, 557MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  95%|█████████▍| 17.6G/18.6G [00:34<00:01, 558MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  95%|█████████▌| 17.7G/18.6G [00:34<00:01, 559MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  95%|█████████▌| 17.8G/18.6G [00:34<00:01, 559MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  96%|█████████▌| 17.8G/18.6G [00:34<00:01, 560MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  96%|█████████▌| 17.9G/18.6G [00:34<00:01, 561MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  96%|█████████▋| 17.9G/18.6G [00:34<00:01, 550MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  97%|█████████▋| 18.0G/18.6G [00:34<00:01, 521MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  97%|█████████▋| 18.1G/18.6G [00:35<00:01, 528MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  97%|█████████▋| 18.1G/18.6G [00:35<00:00, 537MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  98%|█████████▊| 18.2G/18.6G [00:35<00:00, 532MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  98%|█████████▊| 18.3G/18.6G [00:35<00:00, 524MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  98%|█████████▊| 18.3G/18.6G [00:35<00:00, 529MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  99%|█████████▉| 18.4G/18.6G [00:35<00:00, 543MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  99%|█████████▉| 18.4G/18.6G [00:35<00:00, 548MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors:  99%|█████████▉| 18.5G/18.6G [00:35<00:00, 548MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors: 100%|█████████▉| 18.6G/18.6G [00:35<00:00, 554MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors: 100%|██████████| 18.6G/18.6G [00:36<00:00, 516MB/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 137/137 [00:00<00:00, 1.11MB/s]\u001b[0m\n",
      "\u001b[34mFound 0 modules to quantize: []\u001b[0m\n",
      "\u001b[34mtrainable params: 43,253,760 || all params: 961,625,088 || trainable%: 4.497985809621473\u001b[0m\n",
      "\u001b[34m0%|          | 0/63 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34m2%|▏         | 1/63 [02:47<2:53:18, 167.72s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 2/63 [05:35<2:50:15, 167.46s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 3/63 [08:22<2:47:22, 167.37s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 4/63 [11:09<2:44:32, 167.34s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 5/63 [13:56<2:41:44, 167.32s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 6/63 [16:44<2:38:56, 167.31s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 7/63 [19:31<2:36:08, 167.30s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 8/63 [22:18<2:33:21, 167.30s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 9/63 [25:05<2:30:33, 167.29s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 10/63 [27:53<2:27:46, 167.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7579, 'learning_rate': 1.916316904487005e-05, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 10/63 [27:53<2:27:46, 167.29s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 11/63 [30:40<2:24:59, 167.29s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 12/63 [33:27<2:22:11, 167.29s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 13/63 [36:15<2:19:24, 167.28s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 14/63 [39:02<2:16:36, 167.28s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 15/63 [41:49<2:13:49, 167.29s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 16/63 [44:36<2:11:02, 167.29s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 17/63 [47:24<2:08:15, 167.29s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 18/63 [50:11<2:05:27, 167.29s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 19/63 [52:58<2:02:40, 167.29s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 20/63 [55:46<1:59:53, 167.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.7223, 'learning_rate': 1.6002142805483686e-05, 'epoch': 0.31}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 20/63 [55:46<1:59:53, 167.29s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 21/63 [58:33<1:57:06, 167.29s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 22/63 [1:01:20<1:54:18, 167.28s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 23/63 [1:04:07<1:51:31, 167.28s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 24/63 [1:06:55<1:48:44, 167.29s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 25/63 [1:09:42<1:45:57, 167.29s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 26/63 [1:12:29<1:43:09, 167.29s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 27/63 [1:15:17<1:40:22, 167.29s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 28/63 [1:18:04<1:37:35, 167.29s/it]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 29/63 [1:20:51<1:34:48, 167.30s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 30/63 [1:23:39<1:32:00, 167.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6597, 'learning_rate': 1.1283983551465512e-05, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 30/63 [1:23:39<1:32:00, 167.29s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 31/63 [1:26:26<1:29:13, 167.29s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 32/63 [1:29:13<1:26:26, 167.30s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 33/63 [1:32:00<1:23:38, 167.30s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 34/63 [1:34:48<1:20:51, 167.30s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 35/63 [1:37:35<1:18:04, 167.29s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 36/63 [1:40:22<1:15:17, 167.30s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 37/63 [1:43:10<1:12:29, 167.30s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 38/63 [1:45:57<1:09:42, 167.29s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 39/63 [1:48:44<1:06:54, 167.29s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 40/63 [1:51:31<1:04:07, 167.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.6109, 'learning_rate': 6.232721063648148e-06, 'epoch': 0.63}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 40/63 [1:51:31<1:04:07, 167.29s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 41/63 [1:54:19<1:01:20, 167.29s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 42/63 [1:57:06<58:33, 167.30s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 43/63 [1:59:53<55:46, 167.30s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 44/63 [2:02:41<52:58, 167.30s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 45/63 [2:05:28<50:11, 167.30s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 46/63 [2:08:15<47:24, 167.30s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 47/63 [2:11:03<44:36, 167.30s/it]\u001b[0m\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (InvalidSignatureException) when calling the DescribeLogStreams operation: Signature expired: 20240201T094810Z is now earlier than 20240201T095859Z (20240201T100359Z - 5 min.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m: training_s3_path}\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# starting the train job with our uploaded datasets as input\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m huggingface_estimator\u001b[38;5;241m.\u001b[39mfit(data, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/estimator.py:1341\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job\u001b[38;5;241m.\u001b[39mwait(logs\u001b[38;5;241m=\u001b[39mlogs)\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/estimator.py:2677\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2677\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mlogs_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, log_type\u001b[38;5;241m=\u001b[39mlogs)\n\u001b[1;32m   2678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2679\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/session.py:5506\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   5485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   5486\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   5487\u001b[0m \n\u001b[1;32m   5488\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5504\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   5505\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5506\u001b[0m     _logs_for_job(\u001b[38;5;28mself\u001b[39m, job_name, wait, poll, log_type, timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/session.py:7567\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(sagemaker_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   7564\u001b[0m last_profiler_rule_statuses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   7566\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 7567\u001b[0m     _flush_log_streams(\n\u001b[1;32m   7568\u001b[0m         stream_names,\n\u001b[1;32m   7569\u001b[0m         instance_count,\n\u001b[1;32m   7570\u001b[0m         client,\n\u001b[1;32m   7571\u001b[0m         log_group,\n\u001b[1;32m   7572\u001b[0m         job_name,\n\u001b[1;32m   7573\u001b[0m         positions,\n\u001b[1;32m   7574\u001b[0m         dot,\n\u001b[1;32m   7575\u001b[0m         color_wrap,\n\u001b[1;32m   7576\u001b[0m     )\n\u001b[1;32m   7577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m request_end_time:\n\u001b[1;32m   7578\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimeout Exceeded. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m seconds elapsed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(timeout))\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/sagemaker/session.py:7734\u001b[0m, in \u001b[0;36m_flush_log_streams\u001b[0;34m(stream_names, instance_count, client, log_group, job_name, positions, dot, color_wrap)\u001b[0m\n\u001b[1;32m   7730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(stream_names) \u001b[38;5;241m<\u001b[39m instance_count:\n\u001b[1;32m   7731\u001b[0m     \u001b[38;5;66;03m# Log streams are created whenever a container starts writing to stdout/err, so this list\u001b[39;00m\n\u001b[1;32m   7732\u001b[0m     \u001b[38;5;66;03m# may be dynamic until we have a stream for every instance.\u001b[39;00m\n\u001b[1;32m   7733\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 7734\u001b[0m         streams \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mdescribe_log_streams(\n\u001b[1;32m   7735\u001b[0m             logGroupName\u001b[38;5;241m=\u001b[39mlog_group,\n\u001b[1;32m   7736\u001b[0m             logStreamNamePrefix\u001b[38;5;241m=\u001b[39mjob_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   7737\u001b[0m             orderBy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLogStreamName\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   7738\u001b[0m             limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(instance_count, \u001b[38;5;241m50\u001b[39m),\n\u001b[1;32m   7739\u001b[0m         )\n\u001b[1;32m   7740\u001b[0m         stream_names \u001b[38;5;241m=\u001b[39m [s[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogStreamName\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m streams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogStreams\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m   7742\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnextToken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m streams:\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/botocore/client.py:553\u001b[0m, in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m         _api_call\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m docstring\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _api_call\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClientEndpointBridge\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Bridges endpoint data and client creation\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m    This class handles taking out the relevant arguments from the endpoint\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m    explicit region setting is provided. For example, Amazon S3 client will\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m    utilize \"us-east-1\" by default if no region can be resolved.\"\"\"\u001b[39;00m\n\u001b[1;32m    564\u001b[0m     DEFAULT_ENDPOINT \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{service}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{region}\u001b[39;00m\u001b[38;5;124m.amazonaws.com\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/recoenv/lib/python3.11/site-packages/botocore/client.py:1009\u001b[0m, in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_to_request_dict\u001b[39m(\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1000\u001b[0m     api_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     set_user_agent_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1006\u001b[0m ):\n\u001b[1;32m   1007\u001b[0m     request_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serializer\u001b[38;5;241m.\u001b[39mserialize_to_request(\n\u001b[1;32m   1008\u001b[0m         api_params, operation_model\n\u001b[0;32m-> 1009\u001b[0m     )\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_config\u001b[38;5;241m.\u001b[39minject_host_prefix:\n\u001b[1;32m   1011\u001b[0m         request_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhost_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (InvalidSignatureException) when calling the DescribeLogStreams operation: Signature expired: 20240201T094810Z is now earlier than 20240201T095859Z (20240201T100359Z - 5 min.)"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_s3_path}\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a58eeff-2fb7-4735-b889-aa0e01b82b0f",
   "metadata": {},
   "source": [
    "* Adapter output for the first run is s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-TheBloke-Nous-Capybar-2024-01-31-15-32-29-439/output/model/\n",
    "    ** Issues - the tokenizer was of hermes and model was capybara\n",
    "    ** learning rate was very high at 2e-4\n",
    "    ** batch training size was at 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a70856b3-7da2-4bc0-b459-cbd5d4d264ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b704b0d-f954-48d5-a796-7926e5104b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439394fd-b69a-49e3-9d73-667e47f74ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoenv",
   "language": "python",
   "name": "recoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
