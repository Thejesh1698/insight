{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d53ae4-a749-4b15-816a-613ef9198290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1c316cc-439b-4d5b-a8b3-220610fe04fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('gpt_query_data.csv',header=None,names=['query', 'fin_news', 'duration', 'recency', 'vague', 'search_query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed55be8b-0eb2-4c7e-84d8-b8493894b622",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>fin_news</th>\n",
       "      <th>duration</th>\n",
       "      <th>recency</th>\n",
       "      <th>vague</th>\n",
       "      <th>search_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sebi bond platform</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>SEBI bond platform details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wint wealth</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Wint Wealth financial information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kkr private equity</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>KKR private equity details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ev infra</td>\n",
       "      <td>True</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>True</td>\n",
       "      <td>ev infra financial and business news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rural banking in india</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Rural banking sector in India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>yygggggggggg</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>inflation rate in india</td>\n",
       "      <td>True</td>\n",
       "      <td>30.0</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Current inflation rate in India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>budget</td>\n",
       "      <td>True</td>\n",
       "      <td>30.0</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>India's budget highlights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>tata</td>\n",
       "      <td>True</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>True</td>\n",
       "      <td>Tata financial and business news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>advantages of t 0 settlement</td>\n",
       "      <td>True</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Advantages of T+0 settlement in stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            query  fin_news  duration recency  vague  \\\n",
       "0              sebi bond platform      True      -1.0  Medium  False   \n",
       "1                     wint wealth      True      -1.0     Low  False   \n",
       "2              kkr private equity      True      -1.0  Medium  False   \n",
       "3                        ev infra      True      30.0  Medium   True   \n",
       "4          rural banking in india      True      -1.0  Medium  False   \n",
       "..                            ...       ...       ...     ...    ...   \n",
       "406                  yygggggggggg     False       NaN     NaN    NaN   \n",
       "407       inflation rate in india      True      30.0    High  False   \n",
       "408                        budget      True      30.0    High  False   \n",
       "409                          tata      True      30.0  Medium   True   \n",
       "410  advantages of t 0 settlement      True      -1.0  Medium  False   \n",
       "\n",
       "                              search_query  \n",
       "0               SEBI bond platform details  \n",
       "1        Wint Wealth financial information  \n",
       "2               KKR private equity details  \n",
       "3     ev infra financial and business news  \n",
       "4            Rural banking sector in India  \n",
       "..                                     ...  \n",
       "406                                    NaN  \n",
       "407        Current inflation rate in India  \n",
       "408              India's budget highlights  \n",
       "409       Tata financial and business news  \n",
       "410  Advantages of T+0 settlement in stock  \n",
       "\n",
       "[411 rows x 6 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eecba979-6009-4a98-8554-d1ea5c99b014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AmazonSageMaker-ExecutionRole-20231030T210397'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "iam = boto3.client('iam')\n",
    "response = iam.list_roles()\n",
    "sagemaker_roles = [role for role in response['Roles'] if 'SageMaker' in role['RoleName']]\n",
    "sagemaker_roles[0]['RoleName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e21f3405-767a-46b1-b7b1-3bb869897adb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /Library/Application Support/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /Users/ravi.tej/Library/Application Support/sagemaker/config.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name ravi_tej to get Role path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::005418323977:role/service-role/AmazonSageMaker-ExecutionRole-20231030T210397\n",
      "sagemaker bucket: sagemaker-ap-south-1-005418323977\n",
      "sagemaker session region: ap-south-1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20231030T210397')['Role']['Arn']\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a68775ec-a074-4632-ba50-3af56e51b3f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "from random import randint\n",
    "import sys\n",
    "sys.path.append(\"utils\")\n",
    "from pack_dataset import pack_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce43544-7ef7-4d0a-b348-4f618e380806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravi.tej/anaconda3/envs/recoenv/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"teknium/OpenHermes-2.5-Mistral-7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a32b3f-dedd-48b2-8421-d89e431174cf",
   "metadata": {},
   "source": [
    "### Generating training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71eafd0d-d8a2-4f45-8284-3acc0e933a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dbfc5558-6f97-47ab-b539-50c880f6a264",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'18/01/24'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%d/%m/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fec54e41-690c-45df-890a-e61e7a2ad2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c1da07f-7b8e-4ff3-9105-ad81a6553c4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt = (datetime.now() - timedelta(days = np.random.randint(730))).strftime('%d/%m/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f9eac8-8373-4e91-b14d-54248be52c46",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m Return date object with same year, month and day.\n",
       "\u001b[0;31mType:\u001b[0m      method_descriptor"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datetime.date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ce4db22f-e650-4ddc-b3fe-baf0b3c2b529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = f'''\n",
    "You are an expert in taking user queries on an indian financial and business website and extracting certain attributes like below. Generate the attributes in a csv safe format with columns separated by comma. The last attribute of web search query is extremely important, and should directly result in relevant financial results when applicable. If the query is too vague to get only financial results, then append it with ‘financial and business news’. Today is {dt} (%d/%m/%y). use MMMM d yyyy when applicable in web search query\n",
    "is_financial_query, days_to_filter(-1 for timeless), recency_importance(High for highly volatile, medium for moderate volatility like regulations or industry related, and low for educational and guides), query_too_vague_for_finance, web_search_query\n",
    "Generate the responses for the below user query. No preamble or postamble\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f3e67244-c404-4ca3-bb16-484fe2e14db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt_with_date(date):\n",
    "    return f'''\n",
    "You are an expert in taking user queries on an indian financial and business website and extracting certain attributes like below. You generate the attributes in a csv safe format with columns separated by comma. The final attribute of web search query is extremely important, and should directly result in relevant results when the query has any financial or business connection. If the entity or query is too vague to get only financial or business results, then append it with ‘financial and business news’. Today is {date}. When using in web query, then use %d/%m/%y\n",
    "- is_fin_business_query, recency_importance (High for very volatile, medium for slowly changing stuff like regulations or industry related, and low for very less changing like educational and guides), vague (too vague to generate financial or business results), web_search_query (ideal web search query which will result in most relevant financial results if applicable)\n",
    "Generate the responses for the below user query. No preamble or postamble.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3e3ced71-c3ec-474b-8906-1d36a06c689e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "message_template = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\" '|query_start|\\n'{''}'\\n|query_end|'\\n\"}]\n",
    "\n",
    "OUTPUT_TOKEN_LIMIT = 256 # set based on the distribution of completion tokens from gpt4\n",
    "INSTRUCTION_TOKENS = len(tokenizer.apply_chat_template(message_template, add_generation_prompt=True))\n",
    "BUFFER_TOKENS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "254c220b-3bd0-49cc-a228-b832b91e9a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INSTRUCTION_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "e3436a7d-61c9-4aeb-b77a-de10c88f0798",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|> system\\n\\nYou are an expert in taking user queries on an indian financial and business website and extracting certain attributes like below. Generate the attributes in a csv safe format with columns separated by comma. The last attribute of web search query is extremely important, and should directly result in relevant financial results when applicable. If the query is too vague to get only financial results, then append it with ‘financial and business news’. Today is 19/06/23 (%d/%m/%y). use %d/%m/%y when applicable in web search query\\nis_financial_query, days_to_filter(-1 for timeless), recency_importance(High for highly volatile, medium for moderate volatility like regulations or industry related, and low for educational and guides), query_too_vague_for_finance, web_search_query\\nGenerate the responses for the below user query. No preamble or postamble\\n<|im_end|> \\n<|im_start|> user\\n '|query_start|\\n''\\n|query_end|'\\n<|im_end|> \\n<|im_start|> assistant\\n\""
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.apply_chat_template(message_template, add_generation_prompt=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "11b86582-e879-42a5-a9de-8c1757fcdfd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INSTRUCTION_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c8f62769-db2d-4eef-83da-9ce65c79dba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.astype(str)\n",
    "df = df.replace('nan','')\n",
    "df['duration'] = df['duration'].apply(lambda x: str(int(float(x))) if x else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "40bac8d0-4619-4bc3-a39e-90a8adef1427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['response'] = df['fin_news'] + ',' + df['duration'] + ',' + df['recency'] + ',' + df['vague'] + ',' + df['search_query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "cc3446f6-0e1c-449e-9fad-e967282002d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['response'] = df['fin_news'] + ',' + df['recency'] + ',' + df['vague'] + ',' + df['search_query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "a01b7831-57de-461c-854c-8917e9cf5c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['random_date'] = [(datetime.now() - timedelta(days = np.random.randint(730))).strftime('%d/%m/%y') for _ in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "12b080b4-7335-4db5-a8cf-be5bd75c4f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_readable_date(date):\n",
    "#     date_obj = datetime.strptime(date, \"%d/%m/%y\")\n",
    "#     return date_obj.strftime(\"%B %d %Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "9c61f481-05dd-4b80-a523-237de2e8f5c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['readable_date'] = df['random_date'].apply(lambda x: get_readable_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "0c0ecc7b-448b-4ba6-ae8d-d50bec6ea6f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['response'] = df.apply(lambda x: x['response'].replace('January 18 2024', x['random_date']),axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "93a0dd68-e942-49fa-842b-75179c1d89aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True,High,False,Wipro share price on 15/10/23'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[281].response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1fdb9813-69f7-4c81-beb6-3c1bdb8b1b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "query                                   wipro share price live\n",
       "fin_news                                                  True\n",
       "duration                                                     1\n",
       "recency                                                   High\n",
       "vague                                                    False\n",
       "search_query              Wipro share price on January 18 2024\n",
       "response         True,High,False,Wipro share price on 15/10/23\n",
       "len                                                         22\n",
       "random_date                                           15/10/23\n",
       "readable_date                                 November 10 2022\n",
       "Name: 281, dtype: object"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[281]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "4ab5ae84-5ba8-4fe2-9ff3-00be2018ff22",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>fin_news</th>\n",
       "      <th>duration</th>\n",
       "      <th>recency</th>\n",
       "      <th>vague</th>\n",
       "      <th>search_query</th>\n",
       "      <th>response</th>\n",
       "      <th>len</th>\n",
       "      <th>random_date</th>\n",
       "      <th>readable_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>bajaj auto share price live</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Bajaj Auto share price on January 18 2024</td>\n",
       "      <td>True,High,False,Bajaj Auto share price on Janu...</td>\n",
       "      <td>27</td>\n",
       "      <td>28/05/22</td>\n",
       "      <td>May 28 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>share price today</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Share prices today in Indian market</td>\n",
       "      <td>True,High,False,Share prices today in Indian m...</td>\n",
       "      <td>17</td>\n",
       "      <td>07/01/24</td>\n",
       "      <td>January 07 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>ntpc share price live</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>NTPC share price live on January 18 2024</td>\n",
       "      <td>True,High,False,NTPC share price live on Janua...</td>\n",
       "      <td>21</td>\n",
       "      <td>21/09/23</td>\n",
       "      <td>September 21 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>supreme court</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>Medium</td>\n",
       "      <td>True</td>\n",
       "      <td>Supreme court financial and business news</td>\n",
       "      <td>True,Medium,True,Supreme court financial and b...</td>\n",
       "      <td>13</td>\n",
       "      <td>20/04/23</td>\n",
       "      <td>April 20 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>whats p2p</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>What is P2P lending</td>\n",
       "      <td>True,Low,False,What is P2P lending</td>\n",
       "      <td>9</td>\n",
       "      <td>16/01/23</td>\n",
       "      <td>January 16 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>stock market today</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Indian stock market performance today</td>\n",
       "      <td>True,High,False,Indian stock market performanc...</td>\n",
       "      <td>18</td>\n",
       "      <td>22/05/23</td>\n",
       "      <td>May 22 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>day trade</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Day trading strategies</td>\n",
       "      <td>True,High,False,Day trading strategies</td>\n",
       "      <td>9</td>\n",
       "      <td>15/07/22</td>\n",
       "      <td>July 15 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>reliance</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Reliance Industries financial and business news</td>\n",
       "      <td>True,Medium,False,Reliance Industries financia...</td>\n",
       "      <td>8</td>\n",
       "      <td>12/10/22</td>\n",
       "      <td>October 12 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>haryana</td>\n",
       "      <td>True</td>\n",
       "      <td>365</td>\n",
       "      <td>Medium</td>\n",
       "      <td>True</td>\n",
       "      <td>Haryana financial and business news</td>\n",
       "      <td>True,Medium,True,Haryana financial and busines...</td>\n",
       "      <td>7</td>\n",
       "      <td>17/09/23</td>\n",
       "      <td>September 17 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>fintech</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Fintech industry trends in India</td>\n",
       "      <td>True,Medium,False,Fintech industry trends in I...</td>\n",
       "      <td>7</td>\n",
       "      <td>18/11/23</td>\n",
       "      <td>November 18 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>daily news</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "      <td>True</td>\n",
       "      <td>daily financial and business news</td>\n",
       "      <td>True,High,True,daily financial and business news</td>\n",
       "      <td>10</td>\n",
       "      <td>29/05/22</td>\n",
       "      <td>May 29 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>online business loans in india</td>\n",
       "      <td>True</td>\n",
       "      <td>730</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>How to get business loans online in india</td>\n",
       "      <td>True,Medium,False,How to get business loans on...</td>\n",
       "      <td>30</td>\n",
       "      <td>27/07/23</td>\n",
       "      <td>July 27 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>how to save money for a trip</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>How to save money for travel</td>\n",
       "      <td>True,Low,False,How to save money for travel</td>\n",
       "      <td>28</td>\n",
       "      <td>24/09/22</td>\n",
       "      <td>September 24 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>tata consumer share price live</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Tata Consumer share price on January 18 2024</td>\n",
       "      <td>True,High,False,Tata Consumer share price on J...</td>\n",
       "      <td>30</td>\n",
       "      <td>06/11/23</td>\n",
       "      <td>November 06 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>what all to see while investing in real estate</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Key factors to consider when investing in real...</td>\n",
       "      <td>True,Low,False,Key factors to consider when in...</td>\n",
       "      <td>46</td>\n",
       "      <td>13/07/22</td>\n",
       "      <td>July 13 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>business insider</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>High</td>\n",
       "      <td>True</td>\n",
       "      <td>Recent Business Insider financial and business...</td>\n",
       "      <td>True,High,True,Recent Business Insider financi...</td>\n",
       "      <td>16</td>\n",
       "      <td>23/02/23</td>\n",
       "      <td>February 23 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>wipro share price live</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Wipro share price on January 18 2024</td>\n",
       "      <td>True,High,False,Wipro share price on January 1...</td>\n",
       "      <td>22</td>\n",
       "      <td>10/11/22</td>\n",
       "      <td>November 10 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>indian economic growth forecast</td>\n",
       "      <td>True</td>\n",
       "      <td>365</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Indian economic growth forecast 2024</td>\n",
       "      <td>True,Medium,False,Indian economic growth forec...</td>\n",
       "      <td>31</td>\n",
       "      <td>17/10/23</td>\n",
       "      <td>October 17 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>car</td>\n",
       "      <td>True</td>\n",
       "      <td>60</td>\n",
       "      <td>Medium</td>\n",
       "      <td>True</td>\n",
       "      <td>automobiles financial and business news</td>\n",
       "      <td>True,Medium,True,automobiles financial and bus...</td>\n",
       "      <td>3</td>\n",
       "      <td>01/03/23</td>\n",
       "      <td>March 01 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>stock market</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Indian stock market analysis January 2024</td>\n",
       "      <td>True,High,False,Indian stock market analysis J...</td>\n",
       "      <td>12</td>\n",
       "      <td>04/07/22</td>\n",
       "      <td>July 04 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>personal finance</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Low</td>\n",
       "      <td>False</td>\n",
       "      <td>Personal finance management in India</td>\n",
       "      <td>True,Low,False,Personal finance management in ...</td>\n",
       "      <td>16</td>\n",
       "      <td>08/09/23</td>\n",
       "      <td>September 08 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>commodity trading in india</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Commodity trading in India</td>\n",
       "      <td>True,Medium,False,Commodity trading in India</td>\n",
       "      <td>26</td>\n",
       "      <td>17/05/23</td>\n",
       "      <td>May 17 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>bajaj finance share price live</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Bajaj Finance share price on January 18 2024</td>\n",
       "      <td>True,High,False,Bajaj Finance share price on J...</td>\n",
       "      <td>30</td>\n",
       "      <td>31/12/22</td>\n",
       "      <td>December 31 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>ipo</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Upcoming IPOs in India</td>\n",
       "      <td>True,High,False,Upcoming IPOs in India</td>\n",
       "      <td>3</td>\n",
       "      <td>30/12/23</td>\n",
       "      <td>December 30 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>alexa</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False,,,</td>\n",
       "      <td>5</td>\n",
       "      <td>29/01/23</td>\n",
       "      <td>January 29 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>kotak bank share price live</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Kotak Bank share price live on January 18 2024</td>\n",
       "      <td>True,High,False,Kotak Bank share price live on...</td>\n",
       "      <td>27</td>\n",
       "      <td>21/04/22</td>\n",
       "      <td>April 21 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>balance of trade india</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>India's balance of trade latest data</td>\n",
       "      <td>True,Medium,False,India's balance of trade lat...</td>\n",
       "      <td>22</td>\n",
       "      <td>03/01/24</td>\n",
       "      <td>January 03 2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>hi</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>False,,,</td>\n",
       "      <td>2</td>\n",
       "      <td>13/02/23</td>\n",
       "      <td>February 13 2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>hindalco share price live</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>High</td>\n",
       "      <td>False</td>\n",
       "      <td>Hindalco share price on January 18 2024</td>\n",
       "      <td>True,High,False,Hindalco share price on Januar...</td>\n",
       "      <td>25</td>\n",
       "      <td>11/07/22</td>\n",
       "      <td>July 11 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>indian budget highlights</td>\n",
       "      <td>True</td>\n",
       "      <td>365</td>\n",
       "      <td>Medium</td>\n",
       "      <td>False</td>\n",
       "      <td>Indian Budget 2023 highlights</td>\n",
       "      <td>True,Medium,False,Indian Budget 2023 highlights</td>\n",
       "      <td>24</td>\n",
       "      <td>29/08/23</td>\n",
       "      <td>August 29 2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              query fin_news duration recency  \\\n",
       "51                      bajaj auto share price live     True        1    High   \n",
       "363                               share price today     True        1    High   \n",
       "389                           ntpc share price live     True        1    High   \n",
       "195                                   supreme court     True       30  Medium   \n",
       "353                                       whats p2p     True       -1     Low   \n",
       "374                              stock market today     True        1    High   \n",
       "63                                        day trade     True        1    High   \n",
       "165                                        reliance     True       30  Medium   \n",
       "234                                         haryana     True      365  Medium   \n",
       "297                                         fintech     True       -1  Medium   \n",
       "241                                      daily news     True        3    High   \n",
       "31                   online business loans in india     True      730  Medium   \n",
       "214                    how to save money for a trip     True       -1     Low   \n",
       "182                  tata consumer share price live     True        1    High   \n",
       "243  what all to see while investing in real estate     True       -1     Low   \n",
       "340                                business insider     True        3    High   \n",
       "281                          wipro share price live     True        1    High   \n",
       "185                 indian economic growth forecast     True      365  Medium   \n",
       "27                                              car     True       60  Medium   \n",
       "129                                    stock market     True       -1    High   \n",
       "173                                personal finance     True       -1     Low   \n",
       "82                       commodity trading in india     True       -1  Medium   \n",
       "276                  bajaj finance share price live     True        1    High   \n",
       "308                                             ipo     True       30    High   \n",
       "324                                           alexa    False                    \n",
       "391                     kotak bank share price live     True        1    High   \n",
       "286                          balance of trade india     True       30  Medium   \n",
       "217                                              hi    False                    \n",
       "52                        hindalco share price live     True        1    High   \n",
       "269                        indian budget highlights     True      365  Medium   \n",
       "\n",
       "     vague                                       search_query  \\\n",
       "51   False          Bajaj Auto share price on January 18 2024   \n",
       "363  False                Share prices today in Indian market   \n",
       "389  False           NTPC share price live on January 18 2024   \n",
       "195   True          Supreme court financial and business news   \n",
       "353  False                                What is P2P lending   \n",
       "374  False              Indian stock market performance today   \n",
       "63   False                             Day trading strategies   \n",
       "165  False    Reliance Industries financial and business news   \n",
       "234   True                Haryana financial and business news   \n",
       "297  False                   Fintech industry trends in India   \n",
       "241   True                  daily financial and business news   \n",
       "31   False          How to get business loans online in india   \n",
       "214  False                       How to save money for travel   \n",
       "182  False       Tata Consumer share price on January 18 2024   \n",
       "243  False  Key factors to consider when investing in real...   \n",
       "340   True  Recent Business Insider financial and business...   \n",
       "281  False               Wipro share price on January 18 2024   \n",
       "185  False               Indian economic growth forecast 2024   \n",
       "27    True            automobiles financial and business news   \n",
       "129  False          Indian stock market analysis January 2024   \n",
       "173  False               Personal finance management in India   \n",
       "82   False                         Commodity trading in India   \n",
       "276  False       Bajaj Finance share price on January 18 2024   \n",
       "308  False                             Upcoming IPOs in India   \n",
       "324                                                             \n",
       "391  False     Kotak Bank share price live on January 18 2024   \n",
       "286  False               India's balance of trade latest data   \n",
       "217                                                             \n",
       "52   False            Hindalco share price on January 18 2024   \n",
       "269  False                      Indian Budget 2023 highlights   \n",
       "\n",
       "                                              response  len random_date  \\\n",
       "51   True,High,False,Bajaj Auto share price on Janu...   27    28/05/22   \n",
       "363  True,High,False,Share prices today in Indian m...   17    07/01/24   \n",
       "389  True,High,False,NTPC share price live on Janua...   21    21/09/23   \n",
       "195  True,Medium,True,Supreme court financial and b...   13    20/04/23   \n",
       "353                 True,Low,False,What is P2P lending    9    16/01/23   \n",
       "374  True,High,False,Indian stock market performanc...   18    22/05/23   \n",
       "63              True,High,False,Day trading strategies    9    15/07/22   \n",
       "165  True,Medium,False,Reliance Industries financia...    8    12/10/22   \n",
       "234  True,Medium,True,Haryana financial and busines...    7    17/09/23   \n",
       "297  True,Medium,False,Fintech industry trends in I...    7    18/11/23   \n",
       "241   True,High,True,daily financial and business news   10    29/05/22   \n",
       "31   True,Medium,False,How to get business loans on...   30    27/07/23   \n",
       "214        True,Low,False,How to save money for travel   28    24/09/22   \n",
       "182  True,High,False,Tata Consumer share price on J...   30    06/11/23   \n",
       "243  True,Low,False,Key factors to consider when in...   46    13/07/22   \n",
       "340  True,High,True,Recent Business Insider financi...   16    23/02/23   \n",
       "281  True,High,False,Wipro share price on January 1...   22    10/11/22   \n",
       "185  True,Medium,False,Indian economic growth forec...   31    17/10/23   \n",
       "27   True,Medium,True,automobiles financial and bus...    3    01/03/23   \n",
       "129  True,High,False,Indian stock market analysis J...   12    04/07/22   \n",
       "173  True,Low,False,Personal finance management in ...   16    08/09/23   \n",
       "82        True,Medium,False,Commodity trading in India   26    17/05/23   \n",
       "276  True,High,False,Bajaj Finance share price on J...   30    31/12/22   \n",
       "308             True,High,False,Upcoming IPOs in India    3    30/12/23   \n",
       "324                                           False,,,    5    29/01/23   \n",
       "391  True,High,False,Kotak Bank share price live on...   27    21/04/22   \n",
       "286  True,Medium,False,India's balance of trade lat...   22    03/01/24   \n",
       "217                                           False,,,    2    13/02/23   \n",
       "52   True,High,False,Hindalco share price on Januar...   25    11/07/22   \n",
       "269    True,Medium,False,Indian Budget 2023 highlights   24    29/08/23   \n",
       "\n",
       "         readable_date  \n",
       "51         May 28 2022  \n",
       "363    January 07 2024  \n",
       "389  September 21 2023  \n",
       "195      April 20 2023  \n",
       "353    January 16 2023  \n",
       "374        May 22 2023  \n",
       "63        July 15 2022  \n",
       "165    October 12 2022  \n",
       "234  September 17 2023  \n",
       "297   November 18 2023  \n",
       "241        May 29 2022  \n",
       "31        July 27 2023  \n",
       "214  September 24 2022  \n",
       "182   November 06 2023  \n",
       "243       July 13 2022  \n",
       "340   February 23 2023  \n",
       "281   November 10 2022  \n",
       "185    October 17 2023  \n",
       "27       March 01 2023  \n",
       "129       July 04 2022  \n",
       "173  September 08 2023  \n",
       "82         May 17 2023  \n",
       "276   December 31 2022  \n",
       "308   December 30 2023  \n",
       "324    January 29 2023  \n",
       "391      April 21 2022  \n",
       "286    January 03 2024  \n",
       "217   February 13 2023  \n",
       "52        July 11 2022  \n",
       "269     August 29 2023  "
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "01508081-32bd-4cec-9d6c-5f637858726b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_text_response_as_prompt(train_row):\n",
    "    query=train_row['query']\n",
    "    messages = [{\"role\": \"system\", \"content\": generate_prompt_with_date(train_row['random_date'])},\n",
    "                {\"role\": \"user\", \"content\": f\" '|query_start|\\n'{query}'\\n|query_end|'\\n\"}]\n",
    "    context_prompt = tokenizer.decode(tokenizer.apply_chat_template(messages, add_generation_prompt=True))\n",
    "    prompt = context_prompt + train_row['response']\n",
    "    prompt = re.sub(r'\\n+','\\n',prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "71336b95-16f8-4170-a145-c3ed04a33c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f16e98c-9425-44cf-b2a5-da1364a02c53",
   "metadata": {},
   "source": [
    "### Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "6b4c730c-77c5-4b49-b941-47dd1ccb666b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "7cb55c26-9613-4b88-b4dd-dd7213d5134b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3754ec2e991f49238b0b68c339a8c650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/411 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# template dataset to add prompt to each sample\n",
    "def template_dataset(sample):\n",
    "    sample[\"text\"] = f\"{format_text_response_as_prompt(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(template_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3edafa91-8d45-4aa5-a6b0-3ae66e26755e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'bojack horseman',\n",
       " 'fin_news': 'False',\n",
       " 'duration': '',\n",
       " 'recency': '',\n",
       " 'vague': '',\n",
       " 'search_query': '',\n",
       " 'response': 'False,,,',\n",
       " 'len': 15,\n",
       " 'random_date': '17/06/23',\n",
       " 'readable_date': 'October 19 2022',\n",
       " 'text': \"<|im_start|> system\\nYou are an expert in taking user queries on an indian financial and business website and extracting certain attributes like below. You generate the attributes in a csv safe format with columns separated by comma. The final attribute of web search query is extremely important, and should directly result in relevant results when the query has any financial or business connection. If the entity or query is too vague to get only financial or business results, then append it with ‘financial and business news’. Today is 17/06/23. When using in web query, then use %d/%m/%y\\n- is_fin_business_query, recency_importance (High for very volatile, medium for slowly changing stuff like regulations or industry related, and low for very less changing like educational and guides), vague (too vague to generate financial or business results), web_search_query (ideal web search query which will result in most relevant financial results if applicable)\\nGenerate the responses for the below user query. No preamble or postamble.\\n<|im_end|> \\n<|im_start|> user\\n '|query_start|\\n'bojack horseman'\\n|query_end|'\\n<|im_end|> \\n<|im_start|> assistant\\nFalse,,,<|im_end|>\"}"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[132]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "2bab664d-d744-43b1-99bb-e890e2cdd796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': Value(dtype='string', id=None),\n",
       " 'fin_news': Value(dtype='string', id=None),\n",
       " 'duration': Value(dtype='string', id=None),\n",
       " 'recency': Value(dtype='string', id=None),\n",
       " 'vague': Value(dtype='string', id=None),\n",
       " 'search_query': Value(dtype='string', id=None),\n",
       " 'response': Value(dtype='string', id=None),\n",
       " 'len': Value(dtype='int64', id=None),\n",
       " 'random_date': Value(dtype='string', id=None),\n",
       " 'readable_date': Value(dtype='string', id=None),\n",
       " 'text': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select(range(2)).features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2037244c-d4a9-4505-8595-b32483aa6a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a311169f4f41e8b1b3366cffbd1ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/411 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729534640e62449d8719cb0f5b15e41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/411 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking dataset into chunks of 384 tokens.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e914eaf4524ea8b7f5c9b6a87e330e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/411 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples: 293\n",
      "Total number of samples: 293\n"
     ]
    }
   ],
   "source": [
    "# tokenize dataset\n",
    "dataset = dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]), batched=True, remove_columns=list(dataset.features)\n",
    ")\n",
    "# chunk dataset\n",
    "lm_dataset = pack_dataset(dataset, chunk_length=384) # We use 384 as the maximum length for packing\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "9427fa64-5dee-4ec8-84c1-83eeabc65e71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1\n",
       "})"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset.select(range(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29fd8e-f733-44c1-ac9b-ba1cc919e7bf",
   "metadata": {},
   "source": [
    "### Getting fine tune id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "dc553744-d076-4fba-8df3-4cfe02fe8b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('words.txt','r') as f:\n",
    "    words = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "05d0ba59-aacc-4603-92cb-9f0713bf8eb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "words = words.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ce9c4d06-61e7-4ba2-b90f-c3203c690931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_id = ''.join(np.random.choice(words, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "e0086253-09e2-4dec-9f54-9710910a04e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_id = 'search_query_' + finetune_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "27c5994c-7681-447e-b377-ede72a2c8a7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search_query_KiwiHammockEscalator'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "3414d1fb-0988-4bf6-b19f-f85ba3cd76f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_dataset_config = {'finetune_id': finetune_id,\n",
    "                          'date': datetime.strftime(datetime.today(),'%Y-%m-%d'),\n",
    "                          'num_datapoints': len(df),\n",
    "                            'data_source': 'gpt4',\n",
    "                          'prompt': system_prompt}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02814689-f444-43cb-bcc8-d04dfb83cd3d",
   "metadata": {},
   "source": [
    "### Save data to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "95e0f28d-a68c-410b-bdc0-84dc664d40ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd275b400ac444bbcc39ba4078cc551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/293 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded data to:\n",
      "training dataset to: s3://sagemaker-ap-south-1-005418323977/fine_tuning_datasets/2024-01-19-search_query_KiwiHammockEscalator\n"
     ]
    }
   ],
   "source": [
    "# save train_dataset to s3\n",
    "training_input_path = f's3://{sess.default_bucket()}/fine_tuning_datasets/{finetune_dataset_config[\"date\"]}-{finetune_dataset_config[\"finetune_id\"]}'\n",
    "lm_dataset.save_to_disk(training_input_path)\n",
    "\n",
    "print(\"uploaded data to:\")\n",
    "print(f\"training dataset to: {training_input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67114107-d24b-4109-ba3c-051cb03dee2c",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "ca3cb4c1-8181-40c8-81c9-db606cd4487d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "\n",
    "\n",
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters ={\n",
    "  'model_id': model_id,                             # pre-trained model\n",
    "  'dataset_path': '/opt/ml/input/data/training',    # path where sagemaker will save training dataset\n",
    "  'num_train_epochs': 6,                            # number of training epochs\n",
    "  'per_device_train_batch_size': 5,                 # batch size for training\n",
    "  'gradient_accumulation_steps': 5,                 # Number of updates steps to accumulate\n",
    "  'gradient_checkpointing': True,                   # save memory but slower backward pass\n",
    "  'bf16': True,                                     # use bfloat16 precision\n",
    "  'tf32': True,                                     # use tf32 precision\n",
    "  'learning_rate': 5e-5,                            # learning rate\n",
    "  'max_grad_norm': 0.3,                             # Maximum norm (for gradient clipping)\n",
    "  'warmup_ratio': 0.03,                             # warmup ratio\n",
    "  \"lr_scheduler_type\":\"cosine_with_restarts\",                   # learning rate scheduler\n",
    "  'save_strategy': \"epoch\",                         # save strategy for checkpoints\n",
    "  \"logging_steps\": 5,                              # log every x steps\n",
    "  'merge_adapters': True,                           # wether to merge LoRA into the model (needs more memory)\n",
    "  'use_flash_attn': True,                           # Whether to use Flash Attention\n",
    "  'output_dir': '/tmp/run'                         # output directory, where to save assets during training\n",
    "                                                    # could be used for checkpointing. The final trained\n",
    "                                                    # model will always be saved to s3 at the end of training\n",
    "}\n",
    "\n",
    "if HfFolder.get_token() is not None:\n",
    "    hyperparameters['hf_token'] = HfFolder.get_token() # huggingface token to access gated models, e.g. llama 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4764a931-82f6-4f9a-8c5b-acb6949cced4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# define Training Job Name\n",
    "job_name = f'huggingface-qlora-{hyperparameters[\"model_id\"].replace(\"/\",\"-\").replace(\".\",\"-\")}-{finetune_dataset_config[\"finetune_id\"]}'\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point          = 'run_qlora.py',    # train script\n",
    "    source_dir           = 'utils/',      # directory which includes all the files needed for training\n",
    "    instance_type        = 'ml.g5.4xlarge',   # instances type used for the training job\n",
    "    instance_count       = 1,                 # the number of instances used for training\n",
    "    max_run              = 1*60*60,        # maximum runtime in seconds (days * hours * minutes * seconds)\n",
    "    base_job_name        = job_name,          # the name of the training job\n",
    "    role                 = role,              # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size          = 100,               # the size of the EBS volume in GB\n",
    "    transformers_version = '4.28',            # the transformers version used in the training job\n",
    "    pytorch_version      = '2.0',             # the pytorch_version version used in the training job\n",
    "    py_version           = 'py310',           # the python version used in the training job\n",
    "    hyperparameters      =  hyperparameters,  # the hyperparameters passed to the training job\n",
    "    environment          = { \"HUGGINGFACE_HUB_CACHE\": \"/tmp/.cache\" }, # set env variable to cache models in /tmp\n",
    "    disable_output_compression = True         # not compress output to save training time and cost\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11888bc7-59a7-4a76-af69-763a78a0964a",
   "metadata": {},
   "source": [
    "### Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "7d006f2c-db53-4007-9a1d-7228dc627b8b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: huggingface-qlora-teknium-OpenHermes-2--2024-01-19-04-23-49-721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-19 04:23:51 Starting - Starting the training job...\n",
      "2024-01-19 04:24:11 Starting - Preparing the instances for training......\n",
      "2024-01-19 04:25:12 Downloading - Downloading input data...\n",
      "2024-01-19 04:25:37 Downloading - Downloading the training image.....................\n",
      "2024-01-19 04:29:03 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-01-19 04:29:58,796 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-01-19 04:29:58,815 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-19 04:29:58,823 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-01-19 04:29:58,825 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-01-19 04:30:00,145 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.35.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.9/7.9 MB 78.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting peft==0.5.0 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 18.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting optimum==1.14.0 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.14.0-py3-none-any.whl (398 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 398.9/398.9 kB 71.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting accelerate==0.23.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading accelerate-0.23.0-py3-none-any.whl (258 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 258.1/258.1 kB 44.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.0/105.0 MB 25.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.3 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 98.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.12.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 330.3/330.3 kB 54.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.19,>=0.14 (from transformers==4.35.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 126.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.5.0->-r requirements.txt (line 2)) (2.0.0)\u001b[0m\n",
      "\u001b[34mCollecting coloredlogs (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 15.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: transformers[sentencepiece]>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (4.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum==1.14.0->-r requirements.txt (line 3)) (2.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes->-r requirements.txt (line 5)) (1.10.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2->-r requirements.txt (line 1)) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting transformers[sentencepiece]>=4.26.0 (from optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.2/8.2 MB 112.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.1-py3-none-any.whl (8.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.3/8.3 MB 121.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.36.0-py3-none-any.whl (8.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.2/8.2 MB 117.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (0.1.99)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers==4.35.2->-r requirements.txt (line 1)) (3.20.2)\u001b[0m\n",
      "\u001b[34mCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.14.0->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 27.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (12.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.70.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (3.8.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.14.0->-r requirements.txt (line 3)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.35.2->-r requirements.txt (line 1)) (2023.5.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.9.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.5.0->-r requirements.txt (line 2)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum==1.14.0->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: safetensors, humanfriendly, huggingface-hub, coloredlogs, bitsandbytes, tokenizers, accelerate, transformers, peft, optimum\u001b[0m\n",
      "\u001b[34mAttempting uninstall: huggingface-hub\u001b[0m\n",
      "\u001b[34mFound existing installation: huggingface-hub 0.14.1\u001b[0m\n",
      "\u001b[34mUninstalling huggingface-hub-0.14.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled huggingface-hub-0.14.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.13.3\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.13.3:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.13.3\u001b[0m\n",
      "\u001b[34mAttempting uninstall: accelerate\u001b[0m\n",
      "\u001b[34mFound existing installation: accelerate 0.19.0\u001b[0m\n",
      "\u001b[34mUninstalling accelerate-0.19.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled accelerate-0.19.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.28.1\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.28.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.28.1\u001b[0m\n",
      "\u001b[34mSuccessfully installed accelerate-0.23.0 bitsandbytes-0.42.0 coloredlogs-15.0.1 huggingface-hub-0.20.2 humanfriendly-10.0 optimum-1.14.0 peft-0.5.0 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.35.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2024-01-19 04:30:15,376 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-01-19 04:30:15,376 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-01-19 04:30:15,416 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-19 04:30:15,444 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-19 04:30:15,472 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-19 04:30:15,483 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"bf16\": true,\n",
      "        \"dataset_path\": \"/opt/ml/input/data/training\",\n",
      "        \"gradient_accumulation_steps\": 5,\n",
      "        \"gradient_checkpointing\": true,\n",
      "        \"hf_token\": \"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\",\n",
      "        \"learning_rate\": 5e-05,\n",
      "        \"logging_steps\": 5,\n",
      "        \"lr_scheduler_type\": \"cosine_with_restarts\",\n",
      "        \"max_grad_norm\": 0.3,\n",
      "        \"merge_adapters\": true,\n",
      "        \"model_id\": \"teknium/OpenHermes-2.5-Mistral-7B\",\n",
      "        \"num_train_epochs\": 6,\n",
      "        \"output_dir\": \"/tmp/run\",\n",
      "        \"per_device_train_batch_size\": 5,\n",
      "        \"save_strategy\": \"epoch\",\n",
      "        \"tf32\": true,\n",
      "        \"use_flash_attn\": true,\n",
      "        \"warmup_ratio\": 0.03\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"huggingface-qlora-teknium-OpenHermes-2--2024-01-19-04-23-49-721\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-01-19-04-23-49-721/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_qlora\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"run_qlora.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":5,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":5e-05,\"logging_steps\":5,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":6,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":5,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_qlora.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_qlora\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-01-19-04-23-49-721/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"bf16\":true,\"dataset_path\":\"/opt/ml/input/data/training\",\"gradient_accumulation_steps\":5,\"gradient_checkpointing\":true,\"hf_token\":\"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\",\"learning_rate\":5e-05,\"logging_steps\":5,\"lr_scheduler_type\":\"cosine_with_restarts\",\"max_grad_norm\":0.3,\"merge_adapters\":true,\"model_id\":\"teknium/OpenHermes-2.5-Mistral-7B\",\"num_train_epochs\":6,\"output_dir\":\"/tmp/run\",\"per_device_train_batch_size\":5,\"save_strategy\":\"epoch\",\"tf32\":true,\"use_flash_attn\":true,\"warmup_ratio\":0.03},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"huggingface-qlora-teknium-OpenHermes-2--2024-01-19-04-23-49-721\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-01-19-04-23-49-721/source/sourcedir.tar.gz\",\"module_name\":\"run_qlora\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"run_qlora.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--bf16\",\"True\",\"--dataset_path\",\"/opt/ml/input/data/training\",\"--gradient_accumulation_steps\",\"5\",\"--gradient_checkpointing\",\"True\",\"--hf_token\",\"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\",\"--learning_rate\",\"5e-05\",\"--logging_steps\",\"5\",\"--lr_scheduler_type\",\"cosine_with_restarts\",\"--max_grad_norm\",\"0.3\",\"--merge_adapters\",\"True\",\"--model_id\",\"teknium/OpenHermes-2.5-Mistral-7B\",\"--num_train_epochs\",\"6\",\"--output_dir\",\"/tmp/run\",\"--per_device_train_batch_size\",\"5\",\"--save_strategy\",\"epoch\",\"--tf32\",\"True\",\"--use_flash_attn\",\"True\",\"--warmup_ratio\",\"0.03\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BF16=true\u001b[0m\n",
      "\u001b[34mSM_HP_DATASET_PATH=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_ACCUMULATION_STEPS=5\u001b[0m\n",
      "\u001b[34mSM_HP_GRADIENT_CHECKPOINTING=true\u001b[0m\n",
      "\u001b[34mSM_HP_HF_TOKEN=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\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=5e-05\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=5\u001b[0m\n",
      "\u001b[34mSM_HP_LR_SCHEDULER_TYPE=cosine_with_restarts\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_GRAD_NORM=0.3\u001b[0m\n",
      "\u001b[34mSM_HP_MERGE_ADAPTERS=true\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_ID=teknium/OpenHermes-2.5-Mistral-7B\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_EPOCHS=6\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT_DIR=/tmp/run\u001b[0m\n",
      "\u001b[34mSM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=5\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_STRATEGY=epoch\u001b[0m\n",
      "\u001b[34mSM_HP_TF32=true\u001b[0m\n",
      "\u001b[34mSM_HP_USE_FLASH_ATTN=true\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP_RATIO=0.03\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 run_qlora.py --bf16 True --dataset_path /opt/ml/input/data/training --gradient_accumulation_steps 5 --gradient_checkpointing True --hf_token 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 --learning_rate 5e-05 --logging_steps 5 --lr_scheduler_type cosine_with_restarts --max_grad_norm 0.3 --merge_adapters True --model_id teknium/OpenHermes-2.5-Mistral-7B --num_train_epochs 6 --output_dir /tmp/run --per_device_train_batch_size 5 --save_strategy epoch --tf32 True --use_flash_attn True --warmup_ratio 0.03\u001b[0m\n",
      "\u001b[34m2024-01-19 04:30:15,510 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: flash-attn in /opt/conda/lib/python3.10/site-packages (0.2.8)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.4.2.tar.gz (2.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 62.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn) (2.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.12.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (4.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (1.11.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->flash-attn) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn) (1.3.0)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.4.2-cp310-cp310-linux_x86_64.whl size=113930372 sha256=2c7ddc942e0715ef4a7ab62e3404b519a7ac040b3b6eae8fedcdc08a36ced786\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/9d/cf/7f/d14555553b5b30698dae0a4159fdd058157e7021cec565ecaa\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn\u001b[0m\n",
      "\u001b[34mInstalling collected packages: flash-attn\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mSuccessfully installed flash-attn-2.4.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.1.2 -> 23.3.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mLogging into the Hugging Face Hub with token hf_NjVkEqg...\u001b[0m\n",
      "\u001b[34mToken will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\u001b[0m\n",
      "\u001b[34mToken is valid (permission: write).\u001b[0m\n",
      "\u001b[34mYour token has been saved to /root/.cache/huggingface/token\u001b[0m\n",
      "\u001b[34mLogin successful\u001b[0m\n",
      "\u001b[34mUsing `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\u001b[0m\n",
      "\u001b[34mUsing `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/624 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 624/624 [00:00<00:00, 5.84MB/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmodel.safetensors.index.json: 100%|██████████| 25.1k/25.1k [00:00<00:00, 166MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 52.4M/9.94G [00:00<00:22, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   1%|          | 105M/9.94G [00:00<00:21, 456MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 157M/9.94G [00:00<00:21, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   2%|▏         | 210M/9.94G [00:00<00:21, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 262M/9.94G [00:00<00:20, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   3%|▎         | 315M/9.94G [00:00<00:20, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▎         | 367M/9.94G [00:00<00:20, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   4%|▍         | 419M/9.94G [00:00<00:20, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▍         | 472M/9.94G [00:01<00:20, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   5%|▌         | 524M/9.94G [00:01<00:20, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▌         | 577M/9.94G [00:01<00:19, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   6%|▋         | 629M/9.94G [00:01<00:19, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 682M/9.94G [00:01<00:19, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   7%|▋         | 734M/9.94G [00:01<00:19, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 786M/9.94G [00:01<00:19, 471MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   8%|▊         | 839M/9.94G [00:01<00:19, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 891M/9.94G [00:01<00:19, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:   9%|▉         | 944M/9.94G [00:02<00:19, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  10%|█         | 996M/9.94G [00:02<00:19, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█         | 1.05G/9.94G [00:02<00:19, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  11%|█         | 1.10G/9.94G [00:02<00:18, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.15G/9.94G [00:02<00:19, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  12%|█▏        | 1.21G/9.94G [00:02<00:19, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.26G/9.94G [00:02<00:18, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  13%|█▎        | 1.31G/9.94G [00:02<00:18, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▎        | 1.36G/9.94G [00:02<00:18, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  14%|█▍        | 1.42G/9.94G [00:03<00:18, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▍        | 1.47G/9.94G [00:03<00:18, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  15%|█▌        | 1.52G/9.94G [00:03<00:18, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▌        | 1.57G/9.94G [00:03<00:17, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  16%|█▋        | 1.63G/9.94G [00:03<00:17, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.68G/9.94G [00:03<00:17, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  17%|█▋        | 1.73G/9.94G [00:03<00:17, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.78G/9.94G [00:03<00:17, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  18%|█▊        | 1.84G/9.94G [00:03<00:17, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  19%|█▉        | 1.89G/9.94G [00:04<00:17, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|█▉        | 1.94G/9.94G [00:04<00:17, 471MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  20%|██        | 1.99G/9.94G [00:04<00:17, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.04G/9.94G [00:04<00:17, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  21%|██        | 2.10G/9.94G [00:04<00:16, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.15G/9.94G [00:04<00:16, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  22%|██▏       | 2.20G/9.94G [00:04<00:16, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.25G/9.94G [00:04<00:16, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  23%|██▎       | 2.31G/9.94G [00:04<00:16, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▎       | 2.36G/9.94G [00:05<00:16, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  24%|██▍       | 2.41G/9.94G [00:05<00:16, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▍       | 2.46G/9.94G [00:05<00:17, 431MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  25%|██▌       | 2.52G/9.94G [00:05<00:16, 440MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▌       | 2.57G/9.94G [00:05<00:16, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  26%|██▋       | 2.62G/9.94G [00:05<00:16, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.67G/9.94G [00:05<00:15, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  27%|██▋       | 2.73G/9.94G [00:05<00:15, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.78G/9.94G [00:06<00:15, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  28%|██▊       | 2.83G/9.94G [00:06<00:15, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  29%|██▉       | 2.88G/9.94G [00:06<00:16, 428MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|██▉       | 2.94G/9.94G [00:06<00:15, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  30%|███       | 2.99G/9.94G [00:06<00:15, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 3.04G/9.94G [00:06<00:15, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  31%|███       | 3.09G/9.94G [00:06<00:14, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.15G/9.94G [00:06<00:14, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  32%|███▏      | 3.20G/9.94G [00:06<00:14, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.25G/9.94G [00:07<00:14, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  33%|███▎      | 3.30G/9.94G [00:07<00:14, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▎      | 3.36G/9.94G [00:07<00:14, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  34%|███▍      | 3.41G/9.94G [00:07<00:14, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▍      | 3.46G/9.94G [00:07<00:14, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  35%|███▌      | 3.51G/9.94G [00:07<00:14, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▌      | 3.57G/9.94G [00:07<00:13, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  36%|███▋      | 3.62G/9.94G [00:07<00:13, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.67G/9.94G [00:07<00:13, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  37%|███▋      | 3.72G/9.94G [00:08<00:13, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.77G/9.94G [00:08<00:13, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  38%|███▊      | 3.83G/9.94G [00:08<00:13, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  39%|███▉      | 3.88G/9.94G [00:08<00:13, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|███▉      | 3.93G/9.94G [00:08<00:13, 453MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  40%|████      | 3.98G/9.94G [00:08<00:12, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.04G/9.94G [00:08<00:12, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  41%|████      | 4.09G/9.94G [00:08<00:12, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.14G/9.94G [00:08<00:12, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  42%|████▏     | 4.19G/9.94G [00:09<00:12, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.25G/9.94G [00:09<00:12, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  43%|████▎     | 4.30G/9.94G [00:09<00:12, 453MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▍     | 4.35G/9.94G [00:09<00:12, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  44%|████▍     | 4.40G/9.94G [00:09<00:12, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▍     | 4.46G/9.94G [00:09<00:12, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  45%|████▌     | 4.51G/9.94G [00:09<00:11, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▌     | 4.56G/9.94G [00:09<00:11, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  46%|████▋     | 4.61G/9.94G [00:10<00:17, 300MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.67G/9.94G [00:10<00:15, 331MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  47%|████▋     | 4.72G/9.94G [00:10<00:14, 361MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  48%|████▊     | 4.77G/9.94G [00:10<00:13, 385MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▊     | 4.82G/9.94G [00:10<00:12, 404MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  49%|████▉     | 4.88G/9.94G [00:10<00:12, 422MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|████▉     | 4.93G/9.94G [00:10<00:11, 428MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  50%|█████     | 4.98G/9.94G [00:11<00:11, 428MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.03G/9.94G [00:11<00:11, 434MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  51%|█████     | 5.09G/9.94G [00:11<00:11, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.14G/9.94G [00:11<00:10, 442MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  52%|█████▏    | 5.19G/9.94G [00:11<00:10, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.24G/9.94G [00:11<00:10, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  53%|█████▎    | 5.30G/9.94G [00:11<00:10, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▍    | 5.35G/9.94G [00:11<00:10, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  54%|█████▍    | 5.40G/9.94G [00:11<00:09, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▍    | 5.45G/9.94G [00:12<00:09, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  55%|█████▌    | 5.51G/9.94G [00:12<00:09, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▌    | 5.56G/9.94G [00:12<00:09, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  56%|█████▋    | 5.61G/9.94G [00:12<00:09, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.66G/9.94G [00:12<00:09, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  57%|█████▋    | 5.71G/9.94G [00:12<00:09, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  58%|█████▊    | 5.77G/9.94G [00:12<00:09, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▊    | 5.82G/9.94G [00:12<00:09, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  59%|█████▉    | 5.87G/9.94G [00:12<00:08, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|█████▉    | 5.92G/9.94G [00:13<00:08, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  60%|██████    | 5.98G/9.94G [00:13<00:08, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.03G/9.94G [00:13<00:08, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  61%|██████    | 6.08G/9.94G [00:13<00:08, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.13G/9.94G [00:13<00:08, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  62%|██████▏   | 6.19G/9.94G [00:13<00:08, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.24G/9.94G [00:13<00:08, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  63%|██████▎   | 6.29G/9.94G [00:13<00:07, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.34G/9.94G [00:14<00:07, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  64%|██████▍   | 6.40G/9.94G [00:14<00:07, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▍   | 6.45G/9.94G [00:14<00:07, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  65%|██████▌   | 6.50G/9.94G [00:14<00:07, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▌   | 6.55G/9.94G [00:14<00:07, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  66%|██████▋   | 6.61G/9.94G [00:14<00:07, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.66G/9.94G [00:14<00:07, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  67%|██████▋   | 6.71G/9.94G [00:14<00:06, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  68%|██████▊   | 6.76G/9.94G [00:14<00:06, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▊   | 6.82G/9.94G [00:15<00:06, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  69%|██████▉   | 6.87G/9.94G [00:15<00:06, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|██████▉   | 6.92G/9.94G [00:15<00:06, 456MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  70%|███████   | 6.97G/9.94G [00:15<00:06, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.03G/9.94G [00:15<00:06, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  71%|███████   | 7.08G/9.94G [00:15<00:06, 462MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.13G/9.94G [00:15<00:06, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  72%|███████▏  | 7.18G/9.94G [00:15<00:05, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.24G/9.94G [00:15<00:05, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  73%|███████▎  | 7.29G/9.94G [00:16<00:05, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.34G/9.94G [00:16<00:05, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  74%|███████▍  | 7.39G/9.94G [00:16<00:05, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▍  | 7.44G/9.94G [00:16<00:05, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  75%|███████▌  | 7.50G/9.94G [00:16<00:05, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▌  | 7.55G/9.94G [00:16<00:05, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  76%|███████▋  | 7.60G/9.94G [00:16<00:04, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  77%|███████▋  | 7.65G/9.94G [00:16<00:04, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.71G/9.94G [00:16<00:04, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  78%|███████▊  | 7.76G/9.94G [00:17<00:04, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▊  | 7.81G/9.94G [00:17<00:04, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  79%|███████▉  | 7.86G/9.94G [00:17<00:04, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|███████▉  | 7.92G/9.94G [00:17<00:04, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  80%|████████  | 7.97G/9.94G [00:17<00:04, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.02G/9.94G [00:17<00:04, 467MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  81%|████████  | 8.07G/9.94G [00:17<00:03, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.13G/9.94G [00:17<00:03, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  82%|████████▏ | 8.18G/9.94G [00:17<00:03, 465MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.23G/9.94G [00:18<00:03, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  83%|████████▎ | 8.28G/9.94G [00:18<00:03, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.34G/9.94G [00:18<00:03, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  84%|████████▍ | 8.39G/9.94G [00:18<00:03, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▍ | 8.44G/9.94G [00:18<00:03, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  85%|████████▌ | 8.49G/9.94G [00:18<00:03, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▌ | 8.55G/9.94G [00:18<00:03, 461MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  86%|████████▋ | 8.60G/9.94G [00:18<00:02, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  87%|████████▋ | 8.65G/9.94G [00:18<00:02, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.70G/9.94G [00:19<00:02, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  88%|████████▊ | 8.76G/9.94G [00:19<00:02, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▊ | 8.81G/9.94G [00:19<00:02, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  89%|████████▉ | 8.86G/9.94G [00:19<00:02, 472MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|████████▉ | 8.91G/9.94G [00:19<00:02, 469MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  90%|█████████ | 8.97G/9.94G [00:19<00:02, 470MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.02G/9.94G [00:19<00:01, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  91%|█████████ | 9.07G/9.94G [00:19<00:01, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.12G/9.94G [00:20<00:01, 464MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  92%|█████████▏| 9.18G/9.94G [00:20<00:01, 466MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.23G/9.94G [00:20<00:01, 468MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  93%|█████████▎| 9.28G/9.94G [00:20<00:01, 359MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.33G/9.94G [00:20<00:01, 383MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  94%|█████████▍| 9.38G/9.94G [00:20<00:01, 400MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▍| 9.44G/9.94G [00:20<00:01, 415MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  95%|█████████▌| 9.49G/9.94G [00:20<00:01, 429MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▌| 9.54G/9.94G [00:21<00:00, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  96%|█████████▋| 9.59G/9.94G [00:21<00:00, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  97%|█████████▋| 9.65G/9.94G [00:21<00:00, 453MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.70G/9.94G [00:21<00:00, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  98%|█████████▊| 9.75G/9.94G [00:21<00:00, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▊| 9.80G/9.94G [00:21<00:00, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors:  99%|█████████▉| 9.86G/9.94G [00:21<00:00, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|█████████▉| 9.91G/9.94G [00:21<00:00, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00001-of-00002.safetensors: 100%|██████████| 9.94G/9.94G [00:21<00:00, 454MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards:  50%|█████     | 1/2 [00:22<00:22, 22.32s/it]\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   1%|          | 31.5M/4.54G [00:00<00:15, 284MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   2%|▏         | 83.9M/4.54G [00:00<00:11, 390MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   3%|▎         | 136M/4.54G [00:00<00:10, 426MB/s] #033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   4%|▍         | 189M/4.54G [00:00<00:09, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   5%|▌         | 241M/4.54G [00:00<00:09, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   6%|▋         | 294M/4.54G [00:00<00:09, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   8%|▊         | 346M/4.54G [00:00<00:09, 460MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:   9%|▉         | 398M/4.54G [00:00<00:08, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  10%|▉         | 451M/4.54G [00:01<00:08, 463MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  11%|█         | 503M/4.54G [00:01<00:08, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  12%|█▏        | 556M/4.54G [00:01<00:08, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  13%|█▎        | 608M/4.54G [00:01<00:08, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  15%|█▍        | 661M/4.54G [00:01<00:08, 458MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  16%|█▌        | 713M/4.54G [00:01<00:08, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  17%|█▋        | 765M/4.54G [00:01<00:08, 459MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  18%|█▊        | 818M/4.54G [00:01<00:08, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  19%|█▉        | 870M/4.54G [00:01<00:08, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  20%|██        | 923M/4.54G [00:02<00:07, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  21%|██▏       | 975M/4.54G [00:02<00:07, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  23%|██▎       | 1.03G/4.54G [00:02<00:07, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  24%|██▍       | 1.08G/4.54G [00:02<00:07, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  25%|██▍       | 1.13G/4.54G [00:02<00:07, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  26%|██▌       | 1.18G/4.54G [00:02<00:07, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  27%|██▋       | 1.24G/4.54G [00:02<00:07, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  28%|██▊       | 1.29G/4.54G [00:02<00:07, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  30%|██▉       | 1.34G/4.54G [00:02<00:06, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  31%|███       | 1.39G/4.54G [00:03<00:06, 457MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  32%|███▏      | 1.45G/4.54G [00:03<00:06, 455MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  33%|███▎      | 1.50G/4.54G [00:03<00:06, 454MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  34%|███▍      | 1.55G/4.54G [00:03<00:06, 453MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  35%|███▌      | 1.60G/4.54G [00:03<00:06, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  36%|███▋      | 1.66G/4.54G [00:03<00:06, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  38%|███▊      | 1.71G/4.54G [00:03<00:06, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  39%|███▉      | 1.76G/4.54G [00:03<00:06, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  40%|███▉      | 1.81G/4.54G [00:04<00:06, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  41%|████      | 1.87G/4.54G [00:04<00:06, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  42%|████▏     | 1.92G/4.54G [00:04<00:05, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  43%|████▎     | 1.97G/4.54G [00:04<00:05, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  45%|████▍     | 2.02G/4.54G [00:04<00:05, 445MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  46%|████▌     | 2.08G/4.54G [00:04<00:05, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  47%|████▋     | 2.13G/4.54G [00:04<00:05, 450MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  48%|████▊     | 2.18G/4.54G [00:04<00:05, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  49%|████▉     | 2.23G/4.54G [00:04<00:05, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  50%|█████     | 2.29G/4.54G [00:05<00:05, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  51%|█████▏    | 2.34G/4.54G [00:05<00:04, 453MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  53%|█████▎    | 2.39G/4.54G [00:05<00:04, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  54%|█████▍    | 2.44G/4.54G [00:05<00:04, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  55%|█████▍    | 2.50G/4.54G [00:05<00:04, 452MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  56%|█████▌    | 2.55G/4.54G [00:05<00:04, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  57%|█████▋    | 2.60G/4.54G [00:05<00:04, 447MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  58%|█████▊    | 2.65G/4.54G [00:05<00:04, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  60%|█████▉    | 2.71G/4.54G [00:06<00:04, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  61%|██████    | 2.76G/4.54G [00:06<00:03, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  62%|██████▏   | 2.81G/4.54G [00:06<00:03, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  63%|██████▎   | 2.86G/4.54G [00:06<00:03, 448MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  64%|██████▍   | 2.92G/4.54G [00:06<00:03, 444MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  65%|██████▌   | 2.97G/4.54G [00:06<00:03, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  67%|██████▋   | 3.02G/4.54G [00:06<00:03, 449MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  68%|██████▊   | 3.07G/4.54G [00:06<00:03, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  69%|██████▉   | 3.12G/4.54G [00:06<00:03, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  70%|██████▉   | 3.18G/4.54G [00:07<00:03, 451MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  71%|███████   | 3.23G/4.54G [00:07<00:03, 428MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  72%|███████▏  | 3.28G/4.54G [00:07<00:02, 436MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  73%|███████▎  | 3.33G/4.54G [00:07<00:02, 437MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  75%|███████▍  | 3.39G/4.54G [00:07<00:02, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  76%|███████▌  | 3.44G/4.54G [00:07<00:02, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  77%|███████▋  | 3.49G/4.54G [00:07<00:02, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  78%|███████▊  | 3.54G/4.54G [00:07<00:02, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  79%|███████▉  | 3.60G/4.54G [00:08<00:02, 446MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  80%|████████  | 3.65G/4.54G [00:08<00:03, 292MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  82%|████████▏ | 3.70G/4.54G [00:08<00:02, 328MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  83%|████████▎ | 3.75G/4.54G [00:08<00:02, 356MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  84%|████████▍ | 3.81G/4.54G [00:08<00:01, 374MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  85%|████████▍ | 3.86G/4.54G [00:08<00:01, 396MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  86%|████████▌ | 3.91G/4.54G [00:08<00:01, 411MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  87%|████████▋ | 3.96G/4.54G [00:09<00:01, 424MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  88%|████████▊ | 4.02G/4.54G [00:09<00:01, 433MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  90%|████████▉ | 4.07G/4.54G [00:09<00:01, 439MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  91%|█████████ | 4.12G/4.54G [00:09<00:01, 368MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  92%|█████████▏| 4.16G/4.54G [00:09<00:01, 366MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  93%|█████████▎| 4.22G/4.54G [00:09<00:00, 385MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  94%|█████████▍| 4.27G/4.54G [00:09<00:00, 402MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  95%|█████████▌| 4.32G/4.54G [00:09<00:00, 415MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  96%|█████████▋| 4.37G/4.54G [00:10<00:00, 427MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  97%|█████████▋| 4.42G/4.54G [00:10<00:00, 434MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors:  99%|█████████▊| 4.48G/4.54G [00:10<00:00, 441MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|█████████▉| 4.53G/4.54G [00:10<00:00, 438MB/s]#033[A\u001b[0m\n",
      "\u001b[34mmodel-00002-of-00002.safetensors: 100%|██████████| 4.54G/4.54G [00:10<00:00, 435MB/s]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:33<00:00, 15.57s/it]\u001b[0m\n",
      "\u001b[34mDownloading shards: 100%|██████████| 2/2 [00:33<00:00, 16.58s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]\u001b[0m\n",
      "\u001b[34mgeneration_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mgeneration_config.json: 100%|██████████| 120/120 [00:00<00:00, 1.45MB/s]\u001b[0m\n",
      "\u001b[34mFound 7 modules to quantize: ['up_proj', 'k_proj', 'down_proj', 'q_proj', 'gate_proj', 'v_proj', 'o_proj']\u001b[0m\n",
      "\u001b[34mtrainable params: 167,772,160 || all params: 7,409,520,640 || trainable%: 2.2642781922259414\u001b[0m\n",
      "\u001b[34m0%|          | 0/66 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34mThe input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\u001b[0m\n",
      "\u001b[34m2%|▏         | 1/66 [00:15<17:16, 15.95s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 2/66 [00:31<16:54, 15.86s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 3/66 [00:47<16:37, 15.83s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 4/66 [01:03<16:20, 15.82s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 5/66 [01:19<16:04, 15.81s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 2.3272, 'learning_rate': 4.972941274911953e-05, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34m8%|▊         | 5/66 [01:19<16:04, 15.81s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 6/66 [01:34<15:48, 15.81s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 7/66 [01:50<15:32, 15.81s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 8/66 [02:06<15:16, 15.80s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 9/66 [02:22<15:00, 15.80s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 10/66 [02:38<14:45, 15.80s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5807, 'learning_rate': 4.8096988312782174e-05, 'epoch': 0.85}\u001b[0m\n",
      "\u001b[34m15%|█▌        | 10/66 [02:38<14:45, 15.80s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 11/66 [02:53<14:29, 15.80s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 12/66 [03:09<14:12, 15.80s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 13/66 [03:25<13:57, 15.80s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 14/66 [03:41<13:41, 15.80s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 15/66 [03:57<13:25, 15.80s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.2055, 'learning_rate': 4.508018828701612e-05, 'epoch': 1.27}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 15/66 [03:57<13:25, 15.80s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 16/66 [04:12<13:10, 15.80s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 17/66 [04:28<12:54, 15.80s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 18/66 [04:44<12:38, 15.80s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 19/66 [05:00<12:22, 15.80s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 20/66 [05:16<12:06, 15.80s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1589, 'learning_rate': 4.085983210409114e-05, 'epoch': 1.69}\u001b[0m\n",
      "\u001b[34m30%|███       | 20/66 [05:16<12:06, 15.80s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 21/66 [05:31<11:50, 15.80s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 22/66 [05:47<11:35, 15.80s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 23/66 [06:03<11:19, 15.80s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 24/66 [06:19<11:03, 15.80s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 25/66 [06:35<10:47, 15.80s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1248, 'learning_rate': 3.568887733575706e-05, 'epoch': 2.12}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 25/66 [06:35<10:47, 15.80s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 26/66 [06:50<10:31, 15.80s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 27/66 [07:06<10:16, 15.80s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 28/66 [07:22<10:00, 15.80s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 29/66 [07:38<09:44, 15.80s/it]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 30/66 [07:54<09:28, 15.80s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1105, 'learning_rate': 2.9877258050403212e-05, 'epoch': 2.54}\u001b[0m\n",
      "\u001b[34m45%|████▌     | 30/66 [07:54<09:28, 15.80s/it]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 31/66 [08:09<09:13, 15.80s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 32/66 [08:25<08:57, 15.80s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 33/66 [08:41<08:41, 15.80s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 34/66 [08:57<08:25, 15.80s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 35/66 [09:13<08:09, 15.80s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1016, 'learning_rate': 2.3773308141814552e-05, 'epoch': 2.97}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 35/66 [09:13<08:09, 15.80s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 36/66 [09:28<07:53, 15.79s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 37/66 [09:44<07:38, 15.79s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 38/66 [10:00<07:22, 15.79s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 39/66 [10:16<07:06, 15.80s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 40/66 [10:32<06:50, 15.80s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0871, 'learning_rate': 1.7742883068638447e-05, 'epoch': 3.39}\u001b[0m\n",
      "\u001b[34m61%|██████    | 40/66 [10:32<06:50, 15.80s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 41/66 [10:47<06:34, 15.80s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 42/66 [11:03<06:19, 15.80s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 43/66 [11:19<06:03, 15.80s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 44/66 [11:35<05:47, 15.80s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 45/66 [11:51<05:31, 15.80s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0817, 'learning_rate': 1.2147431395169459e-05, 'epoch': 3.81}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 45/66 [11:51<05:31, 15.80s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 46/66 [12:06<05:15, 15.80s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 47/66 [12:22<05:00, 15.80s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 48/66 [12:38<04:44, 15.79s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 49/66 [12:54<04:28, 15.79s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 50/66 [13:10<04:12, 15.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0732, 'learning_rate': 7.3223304703363135e-06, 'epoch': 4.24}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 50/66 [13:10<04:12, 15.79s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 51/66 [13:25<03:56, 15.80s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 52/66 [13:41<03:41, 15.80s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 53/66 [13:57<03:25, 15.80s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 54/66 [14:13<03:09, 15.79s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 55/66 [14:29<02:53, 15.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0672, 'learning_rate': 3.5567847499932e-06, 'epoch': 4.66}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 55/66 [14:29<02:53, 15.79s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 56/66 [14:44<02:37, 15.79s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 57/66 [15:00<02:22, 15.80s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 58/66 [15:16<02:06, 15.80s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 59/66 [15:31<01:48, 15.50s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 60/66 [15:47<01:35, 15.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0682, 'learning_rate': 1.0764916066947794e-06, 'epoch': 5.08}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 60/66 [15:47<01:35, 15.88s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 61/66 [16:03<01:19, 15.86s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 62/66 [16:19<01:03, 15.84s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 63/66 [16:35<00:47, 15.83s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 64/66 [16:51<00:31, 15.82s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 65/66 [17:06<00:15, 15.81s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.065, 'learning_rate': 3.011359487068987e-08, 'epoch': 5.51}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 65/66 [17:06<00:15, 15.81s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 66/66 [17:22<00:00, 15.81s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 1043.7466, 'train_samples_per_second': 1.684, 'train_steps_per_second': 0.063, 'train_loss': 0.3078810519567042, 'epoch': 5.59}\u001b[0m\n",
      "\u001b[34m100%|██████████| 66/66 [17:23<00:00, 15.81s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 66/66 [17:23<00:00, 15.81s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.39s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 1.60k/1.60k [00:00<00:00, 13.6MB/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 32.0MB/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json: 100%|██████████| 51.0/51.0 [00:00<00:00, 459kB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/101 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 101/101 [00:00<00:00, 799kB/s]\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34mSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\u001b[0m\n",
      "\u001b[34m2024-01-19 04:53:00,764 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-01-19 04:53:00,764 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-01-19 04:53:00,765 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-01-19 04:53:07 Uploading - Uploading generated training model\n",
      "2024-01-19 04:53:38 Completed - Training job completed\n",
      "Training seconds: 1706\n",
      "Billable seconds: 1706\n"
     ]
    }
   ],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {'training': training_input_path}\n",
    "# starting the train job with our uploaded datasets as input\n",
    "huggingface_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e892d3-14fd-4859-8f58-2d697c53df30",
   "metadata": {},
   "source": [
    "### Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "479ab67d-cffa-4882-80ed-53baebdca49d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py39\n",
      "INFO:sagemaker.image_uris:Defaulting to only supported image scope: gpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.ap-south-1.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi1.1.0-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"1.1.0\",\n",
    "  session=sess,\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "178c5821-f988-478c-aa91-dddb90f0cda0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize a boto3 S3 client\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0d3e1dbb-4b40-4ebe-a4e2-202b788d385a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "f3ec5398-0420-4f85-8b2e-f49862525c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-ap-south-1-005418323977/huggingface-qlora-teknium-OpenHermes-2--2024-01-19-04-23-49-721/output/model/'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "20c6e63d-f332-4e76-9671-6796e9d054fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "model_s3_path = huggingface_estimator.model_data[\"S3DataSource\"][\"S3Uri\"]\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.xlarge\"\n",
    "number_of_gpu = 1\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"/opt/ml/model\", # path to where sagemaker stores the model\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(320), # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(384), # Max length of the generation (including input text)\n",
    "}\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  model_data={'S3DataSource':{'S3Uri': model_s3_path,'S3DataType': 'S3Prefix','CompressionType': 'None'}},\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "5ea873e8-032f-45f0-91b2-84862c6759ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search_query_KiwiHammockEscalator'"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "c43fc2e3-bdc0-41f9-a839-8f8f70ff7a16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: huggingface-pytorch-tgi-inference-2024-01-19-09-26-14-961\n",
      "INFO:sagemaker:Creating endpoint-config with name OpenHermes-search-query-KiwiHammockEscalator\n",
      "INFO:sagemaker:Creating endpoint with name OpenHermes-search-query-KiwiHammockEscalator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------!"
     ]
    }
   ],
   "source": [
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "    endpoint_name = f\"OpenHermes-{finetune_id.replace('_','-')}\",\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "b52d778b-5f90-45a9-b434-e38c7c66208c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenHermes-search-query-KiwiHammockEscalator'"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e98c2-2525-45f4-a943-4e4ae77689a1",
   "metadata": {},
   "source": [
    "### Test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "286b5403-7771-4b46-955a-b4a28ec3b966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smr = sess.boto_session.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "e784b639-16fb-4294-80ca-6e33f2d943f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.9,\n",
    "    \"temperature\": 0.7,\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"repetition_penalty\": 1.02,\n",
    "    \"stop\": [\"###\", \"</s>\", tokenizer.eos_token],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "745c1480-8e2d-4fdd-a529-2193750ad1eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today = datetime.now().strftime('%d/%m/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "75a2a007-e591-488e-b79e-4ea69788870e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19/01/24'"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "bf3b0e76-8bf6-41fc-a749-61f5048da689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = f'''\n",
    "You are an expert in taking user queries on an indian financial and business website and extracting certain attributes like below. You generate the attributes in a csv safe format with columns separated by comma. The final attribute of web search query is extremely important, and should directly result in relevant results when the query has any financial or business connection. If the entity or query is too vague to get only financial or business results, then append it with ‘financial and business news’. Today is {today}. When using in web query, then use %d/%m/%y\n",
    "- is_fin_business_query, recency_importance (High for very volatile, medium for slowly changing stuff like regulations or industry related, and low for very less changing like educational and guides), vague (too vague to generate financial or business results), web_search_query (ideal web search query which will result in most relevant financial results if applicable)\n",
    "Generate the responses for the below user query. No preamble or postamble.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "f623c962-834e-44ca-9775-a98c8d0217b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are an expert in taking user queries on an indian financial and business website and extracting certain attributes like below. You generate the attributes in a csv safe format with columns separated by comma. The final attribute of web search query is extremely important, and should directly result in relevant results when the query has any financial or business connection. If the entity or query is too vague to get only financial or business results, then append it with ‘financial and business news’. Today is 19/01/24. When using in web query, then use %d/%m/%y\\n- is_fin_business_query, recency_importance (High for very volatile, medium for slowly changing stuff like regulations or industry related, and low for very less changing like educational and guides), vague (too vague to generate financial or business results), web_search_query (ideal web search query which will result in most relevant financial results if applicable)\\nGenerate the responses for the below user query. No preamble or postamble.\\n'"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "0843eef4-c34d-4539-8753-c9722b7af19b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_query_for_prompt(query):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": f\"|query_start|\\n'{query}'\\n|query_end|'\\n\"}]\n",
    "    context_prompt = tokenizer.decode(tokenizer.apply_chat_template(messages, add_generation_prompt=True))\n",
    "    prompt = re.sub(r'\\n+','\\n',context_prompt)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "ae61ea81-ba8e-400c-9f01-b40f48986ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|im_start|> system\\nYou are an expert in taking user queries on an indian financial and business website and extracting certain attributes like below. You generate the attributes in a csv safe format with columns separated by comma. The final attribute of web search query is extremely important, and should directly result in relevant results when the query has any financial or business connection. If the entity or query is too vague to get only financial or business results, then append it with ‘financial and business news’. Today is 19/01/24. When using in web query, then use %d/%m/%y\\n- is_fin_business_query, recency_importance (High for very volatile, medium for slowly changing stuff like regulations or industry related, and low for very less changing like educational and guides), vague (too vague to generate financial or business results), web_search_query (ideal web search query which will result in most relevant financial results if applicable)\\nGenerate the responses for the below user query. No preamble or postamble.\\n<|im_end|> \\n<|im_start|> user\\n|query_start|\\n'sensex today'\\n|query_end|'\\n<|im_end|> \\n<|im_start|> assistant\\n\""
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_query_for_prompt('sensex today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "c12df7da-6549-4664-b2c2-20f58a2fd016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "request = {\"inputs\": format_query_for_prompt('apple'), \"parameters\": parameters, \"stream\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "3d1afdab-df7f-45cb-9c59-d6be931cc9ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "f1c78992-889d-4912-a35d-8957e41d8ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "\n",
    "class TokenIterator:\n",
    "    def __init__(self, stream):\n",
    "        self.byte_iterator = iter(stream)\n",
    "        self.buffer = io.BytesIO()\n",
    "        self.read_pos = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        while True:\n",
    "            self.buffer.seek(self.read_pos)\n",
    "            line = self.buffer.readline()\n",
    "            if line and line[-1] == ord(\"\\n\"):\n",
    "                self.read_pos += len(line) + 1\n",
    "                full_line = line[:-1].decode(\"utf-8\")\n",
    "                line_data = json.loads(full_line.lstrip(\"data:\").rstrip(\"/n\"))\n",
    "                return line_data[\"token\"][\"text\"]\n",
    "            chunk = next(self.byte_iterator)\n",
    "            self.buffer.seek(0, io.SEEK_END)\n",
    "            self.buffer.write(chunk[\"PayloadPart\"][\"Bytes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "ab0edd53-e525-4bc4-a0b8-bdf3cce766d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.05632305145263672 seconds\n",
      "True,Medium,True,Apple financial and business news<|im_end|>"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "resp = smr.invoke_endpoint_with_response_stream(\n",
    "    EndpointName=f\"OpenHermes-{finetune_id.replace('_','-')}\",\n",
    "    Body=json.dumps(request),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "print(f'done in {time.time() - t} seconds')\n",
    "# k = resp['Body'].read()\n",
    "for token in TokenIterator(resp[\"Body\"]):\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "28fa45ea-e916-470a-b44c-0b0445300124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from flask import Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "1f549d1c-2000-429c-8006-4dda7bb90b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def completion(query):\n",
    "    request = {\"inputs\": format_query_for_prompt(query), \"parameters\": parameters, \"stream\": True}\n",
    "    def stream(request):\n",
    "        t = time.time()\n",
    "        resp = smr.invoke_endpoint_with_response_stream(\n",
    "            EndpointName=f\"OpenHermes-ApricotTangerineScallop-TGI\",\n",
    "            Body=json.dumps(request),\n",
    "            ContentType=\"application/json\",\n",
    "        )\n",
    "        print(f'done in {time.time() - t} seconds')\n",
    "        # k = resp['Body'].read()\n",
    "        for token in TokenIterator(resp[\"Body\"]):\n",
    "            yield token\n",
    "    return Response(stream(request), mimetype='text/event-stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "35245c44-f9aa-4390-9a48-073838070abf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.34.15'"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "a6d8db3d-6483-4935-93cc-952fa42fd9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response streamed [200 OK]>"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion('banana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "63a1bbf1-28a1-4aeb-8bef-63e5d1561e82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Response' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[451], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m a:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(a)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Response' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in a.:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1448fc-1e55-433e-9d58-3860fd74889e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "43d1f5fd-dbfa-4781-bae5-9ba4eb977636",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.978435754776001 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'[{\"generated_text\":\"True,Medium,True,Apple financial and business news\"}]'"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "resp = smr.invoke_endpoint(\n",
    "    EndpointName=f\"OpenHermes-{finetune_id.replace('_','-')}\",\n",
    "    Body=json.dumps(request),\n",
    "    ContentType=\"application/json\",\n",
    ")\n",
    "print(f'done in {time.time() - t} seconds')\n",
    "k = resp['Body'].read()\n",
    "\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "954ed731-cf7a-48e2-838c-272da233f084",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['True', 'Medium', 'True', 'Apple financial and business news']"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(k)[0]['generated_text'].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "ad00d866-30e9-4afc-8433-450398435764",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint configuration with name: OpenHermes-search-query-KiwiHammockEscalator\n",
      "INFO:sagemaker:Deleting endpoint with name: OpenHermes-search-query-KiwiHammockEscalator\n"
     ]
    }
   ],
   "source": [
    "llm.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "72fcacbb-f11c-4509-9ebc-564e63a24f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6104f-7a89-4838-a858-4db1fd5bf8cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recoenv",
   "language": "python",
   "name": "recoenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
